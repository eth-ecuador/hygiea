{"version":3,"sources":["../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/constant.js","../../../../../front-doctor/node_modules/sync-multihash-sha2/src/sha256/node.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/is.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/token.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/common.js","../../../../../front-doctor/node_modules/is-network-error/index.js","../../../../../front-doctor/node_modules/sync-multihash-sha2/src/sha256/digest.js","../../../../../front-doctor/node_modules/dnum/node_modules/.pnpm/from-exponential%401.1.1/node_modules/from-exponential/src/helpers.js","../../../../../front-doctor/node_modules/random-int/index.js","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/telemetry/utils.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/storage/context.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/subgraph/service.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/pdp/auth.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/errors/pdp.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/pdp/validation.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/pdp-capabilities.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/sp-registry/service.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/utils/sdk-version.ts","../../../../../front-doctor/node_modules/multiformats/src/link.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/utils/piece.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/utils/errors.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/piece.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/sp.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/storage/service.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/Hash.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/decode-pdp-errors.ts","../../../../../front-doctor/node_modules/multiformats/src/bases/interface.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/piece-url.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/telemetry/service.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/utils/index.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/telemetry/index.ts","../../../../../front-doctor/node_modules/p-retry/index.js","../../../../../front-doctor/node_modules/unlimited-timeout/index.js","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/utils/epoch.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/internal/errors.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/internal/bytes.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/retriever/index.ts","../../../../../front-doctor/node_modules/multiformats/src/vendor/varint.js","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/format.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/retriever/utils.ts","../../../../../front-doctor/node_modules/multiformats/src/bytes.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/warm-storage/service.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/synapse.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/session/key.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/calibration.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/pdp/index.ts","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/src/index.js","../../../../../front-doctor/node_modules/delay/index.js","../../../../../front-doctor/node_modules/multiformats/src/varint.ts","../../../../../front-doctor/node_modules/multiformats/src/hashes/hasher.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/Solidity.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/abis/index.ts","../../../../../front-doctor/node_modules/multiformats/src/vendor/base-x.js","../../../../../front-doctor/node_modules/iso-web/src/http.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/decode.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/4array.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/5map.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/zero-comm.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/byte-utils.js","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/retriever/filbeam.ts","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/2bytes.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/0uint.js","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/rand.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/hashes/src/_u64.ts","../../../../../front-doctor/node_modules/multiformats/src/hashes/digest.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/retriever/subgraph.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/storage/manager.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/curves/src/abstract/utils.ts","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/3string.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/ipld/cbor.js","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/errors/base.ts","../../../../../front-doctor/node_modules/multiformats/src/bases/base36.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/retriever/chain.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/telemetry/singleton.ts","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/7float.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/ipld/sha256.js","../../../../../front-doctor/node_modules/multiformats/src/bases/base32.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/Hex.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/internal/cursor.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/hashes/src/sha2.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/hashes/src/ripemd160.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/pdp/server.ts","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/node.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/uint64.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/piece/tree.js","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/hashes/src/_md.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/capabilities.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/internal/abiParameters.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/utils/metadata.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/metadata.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/utils/network.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/AbiParameters.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/hashes/src/utils.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/hashes/src/cryptoNode.ts","../../../../../front-doctor/node_modules/multiformats/src/bases/base58.ts","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/proof.js","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/abis/erc20.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/hashes/src/sha256.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/utils/eip712.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/pdp/verifier.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/constants.ts","../../../../../front-doctor/node_modules/dnum/node_modules/.pnpm/from-exponential%401.1.1/node_modules/from-exponential/src/index.js","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/hashes/src/legacy.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/%40noble/hashes/src/sha3.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/internal/hex.ts","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/jump.js","../../../../../front-doctor/node_modules/iso-web/src/signals.js","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/Errors.ts","../../../../../front-doctor/node_modules/multiformats/src/cid.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/abis/generated.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-core/src/utils/viem.ts","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/multihash.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/digest.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/6tag.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/encode.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/fr32.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/ipld.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/piece/size/unpadded.js","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/1negint.js","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/payments/service.ts","../../../../../front-doctor/node_modules/multiformats/src/bases/base.ts","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/piece/size/padded.js","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/internal/lru.ts","../../../../../front-doctor/node_modules/%40ipld/dag-cbor/node_modules/cborg/lib/bl.js","../../../../../front-doctor/node_modules/%40web3-storage/data-segment/src/piece/size/expanded.js","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/Json.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/PublicKey.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/Bytes.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/utils/constants.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/Address.ts","../../../../../front-doctor/node_modules/dnum/src/utils.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/node_modules/ox/core/TypedData.ts","../../../../../front-doctor/node_modules/dnum/src/dnum.ts","../../../../../front-doctor/node_modules/%40filoz/synapse-sdk/src/subgraph/queries.ts","../../../../../front-doctor/node_modules/dnum/src/formatting.ts","../../../../../front-doctor/node_modules/dnum/src/operations.ts","../../../../../front-doctor/node_modules/multiformats/src/index.ts"],"sourcesContent":["/**\n * Number of bits per byte\n */\nconst BITS_PER_BYTE = 8\n\n/**\n * The number of Frs per Block.\n */\nexport const FRS_PER_QUAD = 4\n\nexport const LEAFS_PER_QUAD = /** @type {4n} */ (BigInt(FRS_PER_QUAD))\n\n/**\n * The amount of bits in an Fr when not padded.\n */\nexport const IN_BITS_FR = 254\n/**\n * The amount of bits in an Fr when padded.\n */\nexport const OUT_BITS_FR = 256\n\nexport const IN_BYTES_PER_QUAD =\n  /** @type {127} */\n  ((FRS_PER_QUAD * IN_BITS_FR) / BITS_PER_BYTE)\n\nexport const OUT_BYTES_PER_QUAD =\n  /** @type {128} */\n  ((FRS_PER_QUAD * OUT_BITS_FR) / BITS_PER_BYTE)\n\nexport const PADDED_BYTES_PER_QUAD = /** @type {127n} */ (\n  BigInt(IN_BYTES_PER_QUAD)\n)\n\nexport const EXPANDED_BYTES_PER_QUAD = /** @type {128n} */ (\n  BigInt(OUT_BYTES_PER_QUAD)\n)\n\nexport const BYTES_PER_FR =\n  /** @type {32} */\n  OUT_BYTES_PER_QUAD / FRS_PER_QUAD\n\nexport const FR_RATIO = IN_BITS_FR / OUT_BITS_FR\n\n/**\n * Size of a node in the merkle tree.\n */\nexport const NODE_SIZE =\n  /** @type {32} */\n  (OUT_BYTES_PER_QUAD / FRS_PER_QUAD)\n\nexport const EXPANDED_BYTES_PER_NODE = /** @type {32n} */ (BigInt(NODE_SIZE))\n\n/**\n * The smallest amount of data for which FR32 padding has a defined result.\n * Silently upgrading 2 leaves to 4 would break the symmetry so we require\n * an extra byte and the rest can be 0 padded to expand to 4 leaves.\n */\nexport const MIN_PAYLOAD_SIZE = 2 * NODE_SIZE + 1\n","import crypto from 'node:crypto'\nimport { name, size, code, prefix, Digest } from './digest.js'\n\nexport { name, size, code }\n\n/**\n * @param {Uint8Array} payload\n * @returns {import('multiformats').MultihashDigest<typeof code>}\n */\nexport const digest = (payload) => {\n  const digest = new Uint8Array(prefix.length + size)\n  digest.set(prefix, 0)\n  digest.set(\n    crypto.createHash('sha256').update(payload).digest(),\n    prefix.length\n  )\n\n  return new Digest(digest)\n}\n","// This is an unfortunate replacement for @sindresorhus/is that we need to\n// re-implement for performance purposes. In particular the is.observable()\n// check is expensive, and unnecessary for our purposes. The values returned\n// are compatible with @sindresorhus/is, however.\n\nconst typeofs = [\n  'string',\n  'number',\n  'bigint',\n  'symbol'\n]\n\nconst objectTypeNames = [\n  'Function',\n  'Generator',\n  'AsyncGenerator',\n  'GeneratorFunction',\n  'AsyncGeneratorFunction',\n  'AsyncFunction',\n  'Observable',\n  'Array',\n  'Buffer',\n  'Object',\n  'RegExp',\n  'Date',\n  'Error',\n  'Map',\n  'Set',\n  'WeakMap',\n  'WeakSet',\n  'ArrayBuffer',\n  'SharedArrayBuffer',\n  'DataView',\n  'Promise',\n  'URL',\n  'HTMLElement',\n  'Int8Array',\n  'Uint8Array',\n  'Uint8ClampedArray',\n  'Int16Array',\n  'Uint16Array',\n  'Int32Array',\n  'Uint32Array',\n  'Float32Array',\n  'Float64Array',\n  'BigInt64Array',\n  'BigUint64Array'\n]\n\n/**\n * @param {any} value\n * @returns {string}\n */\nexport function is (value) {\n  if (value === null) {\n    return 'null'\n  }\n  if (value === undefined) {\n    return 'undefined'\n  }\n  if (value === true || value === false) {\n    return 'boolean'\n  }\n  const typeOf = typeof value\n  if (typeofs.includes(typeOf)) {\n    return typeOf\n  }\n  /* c8 ignore next 4 */\n  // not going to bother testing this, it's not going to be valid anyway\n  if (typeOf === 'function') {\n    return 'Function'\n  }\n  if (Array.isArray(value)) {\n    return 'Array'\n  }\n  if (isBuffer(value)) {\n    return 'Buffer'\n  }\n  const objectType = getObjectType(value)\n  if (objectType) {\n    return objectType\n  }\n  /* c8 ignore next */\n  return 'Object'\n}\n\n/**\n * @param {any} value\n * @returns {boolean}\n */\nfunction isBuffer (value) {\n  return value && value.constructor && value.constructor.isBuffer && value.constructor.isBuffer.call(null, value)\n}\n\n/**\n * @param {any} value\n * @returns {string|undefined}\n */\nfunction getObjectType (value) {\n  const objectTypeName = Object.prototype.toString.call(value).slice(8, -1)\n  if (objectTypeNames.includes(objectTypeName)) {\n    return objectTypeName\n  }\n  /* c8 ignore next */\n  return undefined\n}\n","class Type {\n  /**\n   * @param {number} major\n   * @param {string} name\n   * @param {boolean} terminal\n   */\n  constructor (major, name, terminal) {\n    this.major = major\n    this.majorEncoded = major << 5\n    this.name = name\n    this.terminal = terminal\n  }\n\n  /* c8 ignore next 3 */\n  toString () {\n    return `Type[${this.major}].${this.name}`\n  }\n\n  /**\n   * @param {Type} typ\n   * @returns {number}\n   */\n  compare (typ) {\n    /* c8 ignore next 1 */\n    return this.major < typ.major ? -1 : this.major > typ.major ? 1 : 0\n  }\n}\n\n// convert to static fields when better supported\nType.uint = new Type(0, 'uint', true)\nType.negint = new Type(1, 'negint', true)\nType.bytes = new Type(2, 'bytes', true)\nType.string = new Type(3, 'string', true)\nType.array = new Type(4, 'array', false)\nType.map = new Type(5, 'map', false)\nType.tag = new Type(6, 'tag', false) // terminal?\nType.float = new Type(7, 'float', true)\nType.false = new Type(7, 'false', true)\nType.true = new Type(7, 'true', true)\nType.null = new Type(7, 'null', true)\nType.undefined = new Type(7, 'undefined', true)\nType.break = new Type(7, 'break', true)\n// Type.indefiniteLength = new Type(0, 'indefiniteLength', true)\n\nclass Token {\n  /**\n   * @param {Type} type\n   * @param {any} [value]\n   * @param {number} [encodedLength]\n   */\n  constructor (type, value, encodedLength) {\n    this.type = type\n    this.value = value\n    this.encodedLength = encodedLength\n    /** @type {Uint8Array|undefined} */\n    this.encodedBytes = undefined\n    /** @type {Uint8Array|undefined} */\n    this.byteValue = undefined\n  }\n\n  /* c8 ignore next 3 */\n  toString () {\n    return `Token[${this.type}].${this.value}`\n  }\n}\n\nexport { Type, Token }\n","const decodeErrPrefix = 'CBOR decode error:'\nconst encodeErrPrefix = 'CBOR encode error:'\n\nconst uintMinorPrefixBytes = []\nuintMinorPrefixBytes[23] = 1\nuintMinorPrefixBytes[24] = 2\nuintMinorPrefixBytes[25] = 3\nuintMinorPrefixBytes[26] = 5\nuintMinorPrefixBytes[27] = 9\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} need\n */\nfunction assertEnoughData (data, pos, need) {\n  if (data.length - pos < need) {\n    throw new Error(`${decodeErrPrefix} not enough data for type`)\n  }\n}\n\nexport {\n  decodeErrPrefix,\n  encodeErrPrefix,\n  uintMinorPrefixBytes,\n  assertEnoughData\n}\n","const objectToString = Object.prototype.toString;\n\nconst isError = value => objectToString.call(value) === '[object Error]';\n\nconst errorMessages = new Set([\n\t'network error', // Chrome\n\t'Failed to fetch', // Chrome\n\t'NetworkError when attempting to fetch resource.', // Firefox\n\t'The Internet connection appears to be offline.', // Safari 16\n\t'Network request failed', // `cross-fetch`\n\t'fetch failed', // Undici (Node.js)\n\t'terminated', // Undici (Node.js)\n\t' A network error occurred.', // Bun (WebKit)\n\t'Network connection lost', // Cloudflare Workers (fetch)\n]);\n\nexport default function isNetworkError(error) {\n\tconst isValid = error\n\t\t&& isError(error)\n\t\t&& error.name === 'TypeError'\n\t\t&& typeof error.message === 'string';\n\n\tif (!isValid) {\n\t\treturn false;\n\t}\n\n\tconst {message, stack} = error;\n\n\t// Safari 17+ has generic message but no stack for network errors\n\tif (message === 'Load failed') {\n\t\treturn stack === undefined\n\t\t\t// Sentry adds its own stack trace to the fetch error, so also check for that\n\t\t\t|| '__sentry_captured__' in error;\n\t}\n\n\t// Deno network errors start with specific text\n\tif (message.startsWith('error sending request for url')) {\n\t\treturn true;\n\t}\n\n\t// Standard network error messages\n\treturn errorMessages.has(message);\n}\n","export const name = 'sha2-256'\nexport const code = 0x12\nexport const size = 32\n\nexport const prefix = new Uint8Array([18, 32])\n\nexport class Digest {\n  /**\n   * @param {Uint8Array} bytes\n   */\n  constructor(bytes) {\n    /** @type {typeof code} */\n    this.code = code\n    /** @type {typeof name} */\n    this.name = name\n    this.bytes = bytes\n    /** @type {typeof size} */\n    this.size = size\n    this.digest = bytes.subarray(2)\n  }\n}\n","/**\n * Return two parts array of exponential number\n * @param {number|string|Array} num\n * @return {string[]}\n */\nexport function getExponentialParts(num) {\n    return Array.isArray(num) ? num : String(num).split(/[eE]/);\n}\n\n/**\n *\n * @param {number|string|Array} num - number or array of its parts\n */\nexport function isExponential(num) {\n    const eParts = getExponentialParts(num);\n    return !Number.isNaN(Number(eParts[1]));\n}\n","export default function randomInteger(minimum, maximum) {\n\tif (maximum === undefined) {\n\t\tmaximum = minimum;\n\t\tminimum = 0;\n\t}\n\n\tif (typeof minimum !== 'number' || typeof maximum !== 'number') {\n\t\tthrow new TypeError('Expected all arguments to be numbers');\n\t}\n\n\tconst actualMinimum = Math.min(minimum, maximum);\n\tconst actualMaximum = Math.max(minimum, maximum);\n\n\treturn Math.floor(\n\t\t(Math.random() * (actualMaximum - actualMinimum + 1)) + actualMinimum\n\t);\n}\n","import type * as SentryBrowser from '@sentry/browser'\nimport type * as SentryNode from '@sentry/node'\n\n/**\n * The telemetry module here and elsewhere needs to know whether we're running in a browser context or not.\n * We determine this once here and export.\n * This presumably should be done somewhere more broadly scoped within Synapse,\n * but we're doing it here for now.\n */\nexport const isBrowser =\n  typeof (globalThis as any).window !== 'undefined' && typeof (globalThis as any).document !== 'undefined'\n\nexport type SentryBrowserType = typeof SentryBrowser.default\nexport type SentryNodeType = typeof SentryNode.default\nexport type SentryType = SentryNodeType | SentryBrowserType\n\n/**\n * Dynamically import the correct Sentry package for whether we're running in a browser or Node.\n * Returns null if the Sentry dependencies are not available (optional peer dependencies).\n */\nexport async function getSentry(): Promise<SentryType | null> {\n  try {\n    if (isBrowser) {\n      return (await import('@sentry/browser')) satisfies typeof SentryBrowser\n    }\n    return (await import('@sentry/node')) satisfies typeof SentryNode\n  } catch {\n    // Sentry dependencies not available (optional peer dependencies)\n    return null\n  }\n}\n\n/**\n * Map of regex patterns to their replacement strings for URL sanitization.\n * Order matters: more specific patterns should come before more general ones.\n */\nconst URL_SANITIZATION_PATTERNS: Array<[RegExp, string]> = [\n  // Remove query parameters to reduce cardinality\n  [/\\?.+/, ''],\n\n  // Replace UUIDs (format: 8-4-4-4-12 hex digits)\n  [/\\/[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}/gi, '/<UUID>'],\n\n  // Replace CIDs (Content Identifiers - bafk, bafy, etc.)\n  [/\\/baf[a-z0-9]{50,}/g, '/<CID>'],\n\n  // Replace transaction hashes (0x followed by 16+ hex chars)\n  [/\\/0x[a-f0-9]{16,}/gi, '/<txHash>'],\n\n  // Replace numeric IDs in paths (e.g., dataset IDs)\n  [/\\/[0-9]+\\b/g, '/<ID>'],\n]\n\n/**\n * Sanitizes a string representing a URL, METHOD + URL, or path for use in span names by replacing variable parts with placeholders.\n * This improves span grouping and reduces cardinality in telemetry data.\n *\n * Replacements:\n * - Query parameters → removed entirely\n * - UUIDs (8-4-4-4-12 format) → /<UUID>\n * - CIDs (bafk..., bafy...) → /<CID>\n * - Transaction hashes (0x + 16+ hex chars) → /<txHash>\n * - Numeric IDs → /<ID>\n *\n * @param url - The URL to sanitize\n * @returns Sanitized URL string suitable for span naming\n *\n * @example\n * sanitizeUrlForSpan('GET https://pdp.com/pdp/piece/bafkzcibf7pc.../status?foo=bar')\n * // Returns: 'GET https://pdp.com/pdp/piece/<CID>/status'\n *\n * @example\n * sanitizeUrlForSpan('POST https://pdp.com/pdp/data-sets/27/pieces/added/0xabc123...')\n * // Returns: 'POST https://pdp.com/pdp/data-sets/<ID>/pieces/added/<txHash>'\n */\nexport function sanitizeUrlForSpan(urlOrPath: string): string {\n  let sanitized = urlOrPath\n\n  for (const [pattern, replacement] of URL_SANITIZATION_PATTERNS) {\n    sanitized = sanitized.replace(pattern, replacement)\n  }\n\n  return sanitized\n}\n","/**\n * StorageContext - Represents a specific Service Provider + Data Set pair\n *\n * This class provides a connection to a specific service provider and data set,\n * handling uploads and downloads within that context. It manages:\n * - Provider selection and data set creation/reuse\n * - PieceCID calculation and validation\n * - Payment rail setup through Warm Storage\n * - Batched piece additions for efficiency\n *\n * @example\n * ```typescript\n * // Create storage context (auto-selects provider)\n * const context = await synapse.storage.createContext()\n *\n * // Upload data to this context's provider\n * const result = await context.upload(data)\n * console.log('Stored at:', result.pieceCid)\n *\n * // Download data from this context's provider\n * const retrieved = await context.download(result.pieceCid)\n * ```\n */\n\nimport { asPieceCID } from '@filoz/synapse-core/piece'\nimport * as SP from '@filoz/synapse-core/sp'\nimport { randIndex, randU256 } from '@filoz/synapse-core/utils'\nimport type { ethers } from 'ethers'\nimport type { Hex } from 'viem'\nimport type { PaymentsService } from '../payments/index.ts'\nimport { PDPAuthHelper, PDPServer } from '../pdp/index.ts'\nimport { PDPVerifier } from '../pdp/verifier.ts'\nimport { SPRegistryService } from '../sp-registry/index.ts'\nimport type { ProviderInfo } from '../sp-registry/types.ts'\nimport type { Synapse } from '../synapse.ts'\nimport type {\n  CreateContextsOptions,\n  DownloadOptions,\n  EnhancedDataSetInfo,\n  MetadataEntry,\n  PieceCID,\n  PieceStatus,\n  PreflightInfo,\n  ProviderSelectionResult,\n  StorageServiceOptions,\n  UploadCallbacks,\n  UploadOptions,\n  UploadResult,\n} from '../types.ts'\nimport {\n  calculateLastProofDate,\n  createError,\n  epochToDate,\n  getCurrentEpoch,\n  METADATA_KEYS,\n  SIZE_CONSTANTS,\n  timeUntilEpoch,\n} from '../utils/index.ts'\nimport { combineMetadata, metadataMatches, objectToEntries, validatePieceMetadata } from '../utils/metadata.ts'\nimport type { WarmStorageService } from '../warm-storage/index.ts'\n\nconst NO_REMAINING_PROVIDERS_ERROR_MESSAGE = 'No approved service providers available'\n\nexport class StorageContext {\n  private readonly _synapse: Synapse\n  private readonly _provider: ProviderInfo\n  private readonly _pdpServer: PDPServer\n  private readonly _warmStorageService: WarmStorageService\n  private readonly _warmStorageAddress: string\n  private readonly _withCDN: boolean\n  private readonly _signer: ethers.Signer\n  private readonly _uploadBatchSize: number\n  private _dataSetId: number | undefined\n  private readonly _dataSetMetadata: Record<string, string>\n\n  // AddPieces batching state\n  private _pendingPieces: Array<{\n    pieceCid: PieceCID\n    resolve: (pieceId: number) => void\n    reject: (error: Error) => void\n    callbacks?: UploadCallbacks\n    metadata?: MetadataEntry[]\n  }> = []\n\n  private _isProcessing: boolean = false\n\n  // Upload tracking for batching (using symbols for simple idempotency)\n  private _activeUploads: Set<symbol> = new Set()\n  // Timeout to wait before processing batch if there are other in-progress uploads, this allows\n  // more uploads to join our batch\n  private readonly _uploadBatchWaitTimeout: number = 15000 // 15 seconds, half Filecoin's blocktime\n\n  // Public properties from interface\n  public readonly serviceProvider: string\n\n  // Getter for withCDN\n  get withCDN(): boolean {\n    return this._withCDN\n  }\n\n  // Getter for provider info\n  get provider(): ProviderInfo {\n    return this._provider\n  }\n\n  // Getter for data set metadata\n  get dataSetMetadata(): Record<string, string> {\n    return this._dataSetMetadata\n  }\n\n  // Getter for data set ID\n  get dataSetId(): number | undefined {\n    return this._dataSetId\n  }\n\n  /**\n   * Validate data size against minimum and maximum limits\n   * @param sizeBytes - Size of data in bytes\n   * @param context - Context for error messages (e.g., 'upload', 'preflightUpload')\n   * @throws Error if size is outside allowed limits\n   */\n  private static validateRawSize(sizeBytes: number, context: string): void {\n    if (sizeBytes < SIZE_CONSTANTS.MIN_UPLOAD_SIZE) {\n      throw createError(\n        'StorageContext',\n        context,\n        `Data size ${sizeBytes} bytes is below minimum allowed size of ${SIZE_CONSTANTS.MIN_UPLOAD_SIZE} bytes`\n      )\n    }\n\n    if (sizeBytes > SIZE_CONSTANTS.MAX_UPLOAD_SIZE) {\n      // This restriction is ~arbitrary for now, but there is a hard limit on PDP uploads in Curio\n      // of 254 MiB, see: https://github.com/filecoin-project/curio/blob/3ddc785218f4e237f0c073bac9af0b77d0f7125c/pdp/handlers_upload.go#L38\n      // We can increase this in future, arbitrarily, but we first need to:\n      //  - Handle streaming input.\n      //  - Chunking input at size 254 MiB and make a separate piece per each chunk\n      //  - Combine the pieces using \"subPieces\" and an aggregate PieceCID in our AddRoots call\n      throw createError(\n        'StorageContext',\n        context,\n        `Data size ${sizeBytes} bytes exceeds maximum allowed size of ${\n          SIZE_CONSTANTS.MAX_UPLOAD_SIZE\n        } bytes (${Math.floor(SIZE_CONSTANTS.MAX_UPLOAD_SIZE / 1024 / 1024)} MiB)`\n      )\n    }\n  }\n\n  constructor(\n    synapse: Synapse,\n    warmStorageService: WarmStorageService,\n    provider: ProviderInfo,\n    dataSetId: number | undefined,\n    options: StorageServiceOptions,\n    dataSetMetadata: Record<string, string>\n  ) {\n    this._synapse = synapse\n    this._provider = provider\n    this._withCDN = options.withCDN ?? false\n    this._signer = synapse.getSigner()\n    this._warmStorageService = warmStorageService\n    this._uploadBatchSize = Math.max(1, options.uploadBatchSize ?? SIZE_CONSTANTS.DEFAULT_UPLOAD_BATCH_SIZE)\n    this._dataSetMetadata = dataSetMetadata\n\n    // Set public properties\n    this._dataSetId = dataSetId\n    this.serviceProvider = provider.serviceProvider\n\n    // Get WarmStorage address from Synapse (which already handles override)\n    this._warmStorageAddress = synapse.getWarmStorageAddress()\n\n    // Create PDPAuthHelper for signing operations\n    const authHelper = new PDPAuthHelper(this._warmStorageAddress, this._signer, BigInt(synapse.getChainId()))\n\n    // Create PDPServer instance with provider URL from PDP product\n    if (!provider.products.PDP?.data.serviceURL) {\n      throw new Error(`Provider ${provider.id} does not have a PDP product with serviceURL`)\n    }\n    this._pdpServer = new PDPServer(authHelper, provider.products.PDP.data.serviceURL)\n  }\n\n  /**\n   * Creates new storage contexts with specified options\n   * Each context corresponds to a different data set\n   */\n  static async createContexts(\n    synapse: Synapse,\n    warmStorageService: WarmStorageService,\n    options: CreateContextsOptions\n  ): Promise<StorageContext[]> {\n    const count = options?.count ?? 2\n    const resolutions: ProviderSelectionResult[] = []\n    const clientAddress = await synapse.getClient().getAddress()\n    const registryAddress = warmStorageService.getServiceProviderRegistryAddress()\n    const spRegistry = new SPRegistryService(synapse.getProvider(), registryAddress)\n    if (options.dataSetIds) {\n      const selections = []\n      for (const dataSetId of new Set(options.dataSetIds)) {\n        selections.push(\n          StorageContext.resolveByDataSetId(dataSetId, warmStorageService, spRegistry, clientAddress, {\n            withCDN: options.withCDN,\n            withIpni: options.withIpni,\n            dev: options.dev,\n            metadata: options.metadata,\n          })\n        )\n        if (selections.length >= count) {\n          break\n        }\n      }\n      resolutions.push(...(await Promise.all(selections)))\n    }\n    const resolvedProviderIds = resolutions.map((resolution) => resolution.provider.id)\n    if (resolutions.length < count) {\n      if (options.providerIds) {\n        const selections = []\n        // NOTE: Set.difference is unavailable in some targets\n        for (const providerId of [...new Set(options.providerIds)].filter(\n          (providerId) => !resolvedProviderIds.includes(providerId)\n        )) {\n          selections.push(\n            StorageContext.resolveByProviderId(\n              clientAddress,\n              providerId,\n              options.metadata ?? {},\n              warmStorageService,\n              spRegistry,\n              options.forceCreateDataSets\n            )\n          )\n          resolvedProviderIds.push(providerId)\n          if (selections.length + resolutions.length >= count) {\n            break\n          }\n        }\n        resolutions.push(...(await Promise.all(selections)))\n      }\n    }\n    if (resolutions.length < count) {\n      const excludeProviderIds = [...(options.excludeProviderIds ?? []), ...resolvedProviderIds]\n      for (let i = resolutions.length; i < count; i++) {\n        try {\n          const resolution = await StorageContext.smartSelectProvider(\n            clientAddress,\n            options.metadata ?? {},\n            warmStorageService,\n            spRegistry,\n            excludeProviderIds,\n            options.forceCreateDataSets ?? false,\n            options.withIpni ?? false,\n            options.dev ?? false\n          )\n          excludeProviderIds.push(resolution.provider.id)\n          resolutions.push(resolution)\n        } catch (error) {\n          if (error instanceof Error && error.message.includes(NO_REMAINING_PROVIDERS_ERROR_MESSAGE)) {\n            break\n          }\n          throw error\n        }\n      }\n    }\n    return await Promise.all(\n      resolutions.map(\n        async (resolution) =>\n          await StorageContext.createWithSelectedProvider(resolution, synapse, warmStorageService, options)\n      )\n    )\n  }\n\n  /**\n   * Static factory method to create a StorageContext\n   * Handles provider selection and data set selection/creation\n   */\n  static async create(\n    synapse: Synapse,\n    warmStorageService: WarmStorageService,\n    options: StorageServiceOptions = {}\n  ): Promise<StorageContext> {\n    // Create SPRegistryService\n    const registryAddress = warmStorageService.getServiceProviderRegistryAddress()\n    const spRegistry = new SPRegistryService(synapse.getProvider(), registryAddress)\n\n    // Resolve provider and data set based on options\n    const resolution = await StorageContext.resolveProviderAndDataSet(synapse, warmStorageService, spRegistry, options)\n\n    return await StorageContext.createWithSelectedProvider(resolution, synapse, warmStorageService, options)\n  }\n\n  private static async createWithSelectedProvider(\n    resolution: ProviderSelectionResult,\n    synapse: Synapse,\n    warmStorageService: WarmStorageService,\n    options: StorageServiceOptions = {}\n  ): Promise<StorageContext> {\n    // Notify callback about provider selection\n    try {\n      options.callbacks?.onProviderSelected?.(resolution.provider)\n    } catch (error) {\n      // Log but don't propagate callback errors\n      console.error('Error in onProviderSelected callback:', error)\n    }\n\n    if (resolution.dataSetId !== -1) {\n      options.callbacks?.onDataSetResolved?.({\n        isExisting: resolution.dataSetId !== -1,\n        dataSetId: resolution.dataSetId,\n        provider: resolution.provider,\n      })\n    }\n\n    return new StorageContext(\n      synapse,\n      warmStorageService,\n      resolution.provider,\n      resolution.dataSetId === -1 ? undefined : resolution.dataSetId,\n      options,\n      resolution.dataSetMetadata\n    )\n  }\n\n  /**\n   * Resolve provider and data set based on provided options\n   * Uses lazy loading to minimize RPC calls\n   */\n  private static async resolveProviderAndDataSet(\n    synapse: Synapse,\n    warmStorageService: WarmStorageService,\n    spRegistry: SPRegistryService,\n    options: StorageServiceOptions\n  ): Promise<ProviderSelectionResult> {\n    const clientAddress = await synapse.getClient().getAddress()\n\n    // Handle explicit data set ID selection (highest priority)\n    if (options.dataSetId != null && options.forceCreateDataSet !== true) {\n      return await StorageContext.resolveByDataSetId(\n        options.dataSetId,\n        warmStorageService,\n        spRegistry,\n        clientAddress,\n        options\n      )\n    }\n\n    // Convert options to metadata format - merge withCDN flag into metadata if needed\n    const requestedMetadata = combineMetadata(options.metadata, options.withCDN)\n\n    // Handle explicit provider ID selection\n    if (options.providerId != null) {\n      return await StorageContext.resolveByProviderId(\n        clientAddress,\n        options.providerId,\n        requestedMetadata,\n        warmStorageService,\n        spRegistry,\n        options.forceCreateDataSet\n      )\n    }\n\n    // Handle explicit provider address selection\n    if (options.providerAddress != null) {\n      return await StorageContext.resolveByProviderAddress(\n        options.providerAddress,\n        warmStorageService,\n        spRegistry,\n        clientAddress,\n        requestedMetadata,\n        options.forceCreateDataSet\n      )\n    }\n\n    // Smart selection when no specific parameters provided\n    return await StorageContext.smartSelectProvider(\n      clientAddress,\n      requestedMetadata,\n      warmStorageService,\n      spRegistry,\n      options.excludeProviderIds ?? [],\n      options.forceCreateDataSet ?? false,\n      options.withIpni ?? false,\n      options.dev ?? false\n    )\n  }\n\n  /**\n   * Resolve using a specific data set ID\n   */\n  private static async resolveByDataSetId(\n    dataSetId: number,\n    warmStorageService: WarmStorageService,\n    spRegistry: SPRegistryService,\n    signerAddress: string,\n    options: StorageServiceOptions\n  ): Promise<ProviderSelectionResult> {\n    // Fetch data sets to find the specific one\n    const dataSets = await warmStorageService.getClientDataSetsWithDetails(signerAddress)\n    const dataSet = dataSets.find((ds) => ds.pdpVerifierDataSetId === dataSetId)\n\n    if (dataSet == null || !dataSet.isLive || !dataSet.isManaged) {\n      throw createError(\n        'StorageContext',\n        'resolveByDataSetId',\n        `Data set ${dataSetId} not found, not owned by ${signerAddress}, ` +\n          'or not managed by the current WarmStorage contract'\n      )\n    }\n\n    // Validate consistency with other parameters if provided\n    if (options.providerId != null || options.providerAddress != null) {\n      await StorageContext.validateDataSetConsistency(dataSet, options, spRegistry)\n    }\n\n    // Look up provider by ID from the data set\n    const provider = await spRegistry.getProvider(dataSet.providerId)\n    if (provider == null) {\n      throw createError(\n        'StorageContext',\n        'resolveByDataSetId',\n        `Provider ID ${dataSet.providerId} for data set ${dataSetId} not found in registry`\n      )\n    }\n\n    // Validate CDN settings match if specified\n    if (options.withCDN != null && dataSet.withCDN !== options.withCDN) {\n      throw createError(\n        'StorageContext',\n        'resolveByDataSetId',\n        `Data set ${dataSetId} has CDN ${dataSet.withCDN ? 'enabled' : 'disabled'}, ` +\n          `but requested ${options.withCDN ? 'enabled' : 'disabled'}`\n      )\n    }\n\n    // Backfill data set metadata from chain\n    const dataSetMetadata = await warmStorageService.getDataSetMetadata(dataSetId)\n\n    return {\n      provider,\n      dataSetId,\n      isExisting: true,\n      dataSetMetadata,\n    }\n  }\n\n  /**\n   * Validate data set consistency with provided options\n   */\n  private static async validateDataSetConsistency(\n    dataSet: EnhancedDataSetInfo,\n    options: StorageServiceOptions,\n    spRegistry: SPRegistryService\n  ): Promise<void> {\n    // Validate provider ID if specified\n    if (options.providerId != null) {\n      if (dataSet.providerId !== options.providerId) {\n        throw createError(\n          'StorageContext',\n          'validateDataSetConsistency',\n          `Data set ${dataSet.pdpVerifierDataSetId} belongs to provider ID ${dataSet.providerId}, ` +\n            `but provider ID ${options.providerId} was requested`\n        )\n      }\n    }\n\n    // Validate provider address if specified\n    if (options.providerAddress != null) {\n      // Look up the actual provider to get its serviceProvider address\n      const actualProvider = await spRegistry.getProvider(dataSet.providerId)\n      if (\n        actualProvider == null ||\n        actualProvider.serviceProvider.toLowerCase() !== options.providerAddress.toLowerCase()\n      ) {\n        throw createError(\n          'StorageContext',\n          'validateDataSetConsistency',\n          `Data set ${dataSet.pdpVerifierDataSetId} belongs to provider ${actualProvider?.serviceProvider ?? 'unknown'}, ` +\n            `but provider ${options.providerAddress} was requested`\n        )\n      }\n    }\n  }\n\n  /**\n   * Resolve using a specific provider ID\n   */\n  private static async resolveByProviderId(\n    signerAddress: string,\n    providerId: number,\n    requestedMetadata: Record<string, string>,\n    warmStorageService: WarmStorageService,\n    spRegistry: SPRegistryService,\n    forceCreateDataSet?: boolean\n  ): Promise<ProviderSelectionResult> {\n    // Fetch provider (always) and dataSets (only if not forcing) in parallel\n    const [provider, dataSets] = await Promise.all([\n      spRegistry.getProvider(providerId),\n      forceCreateDataSet ? Promise.resolve(null) : warmStorageService.getClientDataSetsWithDetails(signerAddress),\n    ])\n\n    if (provider == null) {\n      throw createError('StorageContext', 'resolveByProviderId', `Provider ID ${providerId} not found in registry`)\n    }\n\n    // If forcing creation, skip the search for existing data sets\n    if (forceCreateDataSet === true) {\n      return {\n        provider,\n        dataSetId: -1, // Marker for new data set\n        isExisting: false,\n        dataSetMetadata: requestedMetadata,\n      }\n    }\n\n    // dataSets is guaranteed non-null here since forceCreateDataSet is false\n\n    // Filter for this provider's data sets with matching metadata\n    const providerDataSets = (\n      dataSets as Awaited<ReturnType<typeof warmStorageService.getClientDataSetsWithDetails>>\n    ).filter((ps) => {\n      if (ps.providerId !== provider.id || !ps.isLive || !ps.isManaged || ps.pdpEndEpoch !== 0) {\n        return false\n      }\n      // Check if metadata matches\n      return metadataMatches(ps.metadata, requestedMetadata)\n    })\n\n    if (providerDataSets.length > 0) {\n      // Sort by preference: data sets with pieces first, then by ID\n      const sorted = providerDataSets.sort((a, b) => {\n        if (a.currentPieceCount > 0 && b.currentPieceCount === 0) return -1\n        if (b.currentPieceCount > 0 && a.currentPieceCount === 0) return 1\n        return a.pdpVerifierDataSetId - b.pdpVerifierDataSetId\n      })\n\n      // Fetch metadata for existing data set\n      const dataSetMetadata = await warmStorageService.getDataSetMetadata(sorted[0].pdpVerifierDataSetId)\n\n      return {\n        provider,\n        dataSetId: sorted[0].pdpVerifierDataSetId,\n        isExisting: true,\n        dataSetMetadata,\n      }\n    }\n\n    // Need to create new data set\n    return {\n      provider,\n      dataSetId: -1, // Marker for new data set\n      isExisting: false,\n      dataSetMetadata: requestedMetadata,\n    }\n  }\n\n  /**\n   * Resolve using a specific provider address\n   */\n  private static async resolveByProviderAddress(\n    providerAddress: string,\n    warmStorageService: WarmStorageService,\n    spRegistry: SPRegistryService,\n    signerAddress: string,\n    requestedMetadata: Record<string, string>,\n    forceCreateDataSet?: boolean\n  ): Promise<ProviderSelectionResult> {\n    // Get provider by address\n    const provider = await spRegistry.getProviderByAddress(providerAddress)\n    if (provider == null) {\n      throw createError(\n        'StorageContext',\n        'resolveByProviderAddress',\n        `Provider ${providerAddress} not found in registry`\n      )\n    }\n\n    // Use the providerId resolution logic\n    return await StorageContext.resolveByProviderId(\n      signerAddress,\n      provider.id,\n      requestedMetadata,\n      warmStorageService,\n      spRegistry,\n      forceCreateDataSet\n    )\n  }\n\n  /**\n   * Smart provider selection algorithm\n   * Prioritizes existing data sets and provider health\n   */\n  private static async smartSelectProvider(\n    signerAddress: string,\n    requestedMetadata: Record<string, string>,\n    warmStorageService: WarmStorageService,\n    spRegistry: SPRegistryService,\n    excludeProviderIds: number[],\n    forceCreateDataSet: boolean,\n    withIpni: boolean,\n    dev: boolean\n  ): Promise<ProviderSelectionResult> {\n    // Strategy:\n    // 1. Try to find existing data sets first\n    // 2. If no existing data sets, find a healthy provider\n\n    // Get client's data sets\n    const dataSets = await warmStorageService.getClientDataSetsWithDetails(signerAddress)\n\n    const skipProviderIds = new Set<number>(excludeProviderIds)\n    // Filter for managed data sets with matching metadata\n    const managedDataSets = dataSets.filter(\n      (ps) =>\n        ps.isLive &&\n        ps.isManaged &&\n        ps.pdpEndEpoch === 0 &&\n        metadataMatches(ps.metadata, requestedMetadata) &&\n        !skipProviderIds.has(ps.providerId)\n    )\n\n    if (managedDataSets.length > 0 && !forceCreateDataSet) {\n      // Prefer data sets with pieces, sort by ID (older first)\n      const sorted = managedDataSets.sort((a, b) => {\n        if (a.currentPieceCount > 0 && b.currentPieceCount === 0) return -1\n        if (b.currentPieceCount > 0 && a.currentPieceCount === 0) return 1\n        return a.pdpVerifierDataSetId - b.pdpVerifierDataSetId\n      })\n\n      // Create async generator that yields providers lazily\n      async function* generateProviders(): AsyncGenerator<ProviderInfo> {\n        // First, yield providers from existing data sets (in sorted order)\n        for (const dataSet of sorted) {\n          if (skipProviderIds.has(dataSet.providerId)) {\n            continue\n          }\n          skipProviderIds.add(dataSet.providerId)\n          const provider = await spRegistry.getProvider(dataSet.providerId)\n\n          if (provider == null) {\n            console.warn(\n              `Provider ID ${dataSet.providerId} for data set ${dataSet.pdpVerifierDataSetId} is not currently approved`\n            )\n            continue\n          }\n\n          if (withIpni && provider.products.PDP?.data.ipniIpfs === false) {\n            continue\n          }\n\n          const serviceStatus = provider.products.PDP?.capabilities?.serviceStatus\n          if (!dev && serviceStatus === '0x646576') {\n            // \"dev\" in hex\n            continue\n          }\n\n          yield provider\n        }\n      }\n\n      try {\n        const selectedProvider = await StorageContext.selectProviderWithPing(generateProviders())\n\n        // Find the first matching data set ID for this provider\n        // Match by provider ID (stable identifier in the registry)\n        const matchingDataSet = sorted.find((ps) => ps.providerId === selectedProvider.id)\n\n        if (matchingDataSet == null) {\n          console.warn(\n            `Could not match selected provider ${selectedProvider.serviceProvider} (ID: ${selectedProvider.id}) ` +\n              `to existing data sets. Falling back to selecting from all providers.`\n          )\n          // Fall through to select from all approved providers below\n        } else {\n          // Fetch metadata for existing data set\n          const dataSetMetadata = await warmStorageService.getDataSetMetadata(matchingDataSet.pdpVerifierDataSetId)\n\n          return {\n            provider: selectedProvider,\n            dataSetId: matchingDataSet.pdpVerifierDataSetId,\n            isExisting: true,\n            dataSetMetadata,\n          }\n        }\n      } catch (_error) {\n        console.warn('All providers from existing data sets failed health check. Falling back to all providers.')\n        // Fall through to select from all approved providers below\n      }\n    }\n\n    // No existing data sets - select from all approved providers. First we get approved IDs from\n    // WarmStorage, then fetch provider details.\n    const approvedIds = await warmStorageService.getApprovedProviderIds()\n    const approvedProviders = await spRegistry.getProviders(approvedIds)\n    const allProviders = approvedProviders.filter(\n      (provider: ProviderInfo) =>\n        (!withIpni || provider.products.PDP?.data.ipniIpfs === true) &&\n        (dev || provider.products.PDP?.capabilities?.serviceStatus !== '0x646576') &&\n        !excludeProviderIds.includes(provider.id)\n    )\n\n    if (allProviders.length === 0) {\n      throw createError('StorageContext', 'smartSelectProvider', NO_REMAINING_PROVIDERS_ERROR_MESSAGE)\n    }\n\n    // Random selection from all providers\n    const provider = await StorageContext.selectRandomProvider(allProviders)\n\n    return {\n      provider,\n      dataSetId: -1, // Marker for new data set\n      isExisting: false,\n      dataSetMetadata: requestedMetadata,\n    }\n  }\n\n  /**\n   * Select a random provider from a list with ping validation\n   * @param providers - Array of providers to select from\n   * @param withIpni - Filter for IPNI support\n   * @param dev - Include dev providers\n   * @returns Selected provider\n   */\n  private static async selectRandomProvider(providers: ProviderInfo[]): Promise<ProviderInfo> {\n    if (providers.length === 0) {\n      throw createError('StorageContext', 'selectRandomProvider', 'No providers available')\n    }\n\n    // Create async generator that yields providers in random order\n    async function* generateRandomProviders(): AsyncGenerator<ProviderInfo> {\n      const remaining = [...providers]\n\n      while (remaining.length > 0) {\n        // Remove and yield the selected provider\n        const selected = remaining.splice(randIndex(remaining.length), 1)[0]\n        yield selected\n      }\n    }\n\n    return await StorageContext.selectProviderWithPing(generateRandomProviders())\n  }\n\n  /**\n   * Select a provider from an async iterator with ping validation.\n   * This is shared logic used by both smart selection and random selection.\n   * @param providers - Async iterable of providers to try\n   * @returns The first provider that responds\n   * @throws If all providers fail\n   */\n  private static async selectProviderWithPing(providers: AsyncIterable<ProviderInfo>): Promise<ProviderInfo> {\n    let providerCount = 0\n\n    // Try providers in order until we find one that responds to ping\n    for await (const provider of providers) {\n      providerCount++\n      try {\n        // Create a temporary PDPServer for this specific provider's endpoint\n        if (!provider.products.PDP?.data.serviceURL) {\n          // Skip providers without PDP products\n          continue\n        }\n        const providerPdpServer = new PDPServer(null, provider.products.PDP.data.serviceURL)\n        await providerPdpServer.ping()\n        return provider\n      } catch (error) {\n        console.warn(\n          `Provider ${provider.serviceProvider} failed ping test:`,\n          error instanceof Error ? error.message : String(error)\n        )\n        // Continue to next provider\n      }\n    }\n\n    // All providers failed ping test\n    if (providerCount === 0) {\n      throw createError('StorageContext', 'selectProviderWithPing', 'No providers available to select from')\n    }\n\n    throw createError(\n      'StorageContext',\n      'selectProviderWithPing',\n      `All ${providerCount} providers failed health check. Storage may be temporarily unavailable.`\n    )\n  }\n\n  /**\n   * Static method to perform preflight checks for an upload\n   * @param size - The size of data to upload in bytes\n   * @param withCDN - Whether CDN is enabled\n   * @param warmStorageService - WarmStorageService instance\n   * @param paymentsService - PaymentsService instance\n   * @returns Preflight check results without provider/dataSet specifics\n   */\n  static async performPreflightCheck(\n    warmStorageService: WarmStorageService,\n    paymentsService: PaymentsService,\n    size: number,\n    withCDN: boolean\n  ): Promise<PreflightInfo> {\n    // Validate size before proceeding\n    StorageContext.validateRawSize(size, 'preflightUpload')\n\n    // Check allowances and get costs in a single call\n    const allowanceCheck = await warmStorageService.checkAllowanceForStorage(size, withCDN, paymentsService)\n\n    // Return preflight info\n    return {\n      estimatedCost: {\n        perEpoch: allowanceCheck.costs.perEpoch,\n        perDay: allowanceCheck.costs.perDay,\n        perMonth: allowanceCheck.costs.perMonth,\n      },\n      allowanceCheck: {\n        sufficient: allowanceCheck.sufficient,\n        message: allowanceCheck.message,\n      },\n      selectedProvider: null,\n      selectedDataSetId: null,\n    }\n  }\n\n  /**\n   * Run preflight checks for an upload\n   * @param size - The size of data to upload in bytes\n   * @returns Preflight information including costs and allowances\n   */\n  async preflightUpload(size: number): Promise<PreflightInfo> {\n    // Use the static method for core logic\n    const preflightResult = await StorageContext.performPreflightCheck(\n      this._warmStorageService,\n      this._synapse.payments,\n      size,\n      this._withCDN\n    )\n\n    // Return preflight info with provider and dataSet specifics\n    return preflightResult\n  }\n\n  /**\n   * Upload data to the service provider\n   *\n   * Accepts Uint8Array or ReadableStream<Uint8Array>.\n   * For large files, prefer streaming to minimize memory usage.\n   *\n   * Note: When uploading to multiple contexts, pieceCid should be pre-calculated and passed in options\n   * to avoid redundant computation. For streaming uploads, pieceCid must be provided in options as it\n   * cannot be calculated without consuming the stream.\n   */\n  async upload(data: Uint8Array | ReadableStream<Uint8Array>, options?: UploadOptions): Promise<UploadResult> {\n    performance.mark('synapse:upload-start')\n\n    // Validation Phase: Check data size and calculate pieceCid\n    let size: number | undefined\n    const pieceCid = options?.pieceCid\n    if (data instanceof Uint8Array) {\n      size = data.length\n      StorageContext.validateRawSize(size, 'upload')\n    }\n    // Note: Size is unknown for streams (size will be undefined)\n\n    // Track this upload for batching purposes\n    const uploadId = Symbol('upload')\n    this._activeUploads.add(uploadId)\n\n    try {\n      let uploadResult: SP.UploadPieceResponse\n      // Upload Phase: Upload data to service provider\n      try {\n        performance.mark('synapse:pdpServer.uploadPiece-start')\n        uploadResult = await this._pdpServer.uploadPiece(data, {\n          ...options,\n          pieceCid,\n        })\n        performance.mark('synapse:pdpServer.uploadPiece-end')\n        performance.measure(\n          'synapse:pdpServer.uploadPiece',\n          'synapse:pdpServer.uploadPiece-start',\n          'synapse:pdpServer.uploadPiece-end'\n        )\n      } catch (error) {\n        performance.mark('synapse:pdpServer.uploadPiece-end')\n        performance.measure(\n          'synapse:pdpServer.uploadPiece',\n          'synapse:pdpServer.uploadPiece-start',\n          'synapse:pdpServer.uploadPiece-end'\n        )\n        throw createError('StorageContext', 'uploadPiece', 'Failed to upload piece to service provider', error)\n      }\n\n      // Poll for piece to be \"parked\" (ready)\n      performance.mark('synapse:findPiece-start')\n      await this._pdpServer.findPiece(uploadResult.pieceCid)\n      performance.mark('synapse:findPiece-end')\n      performance.measure('synapse:findPiece', 'synapse:findPiece-start', 'synapse:findPiece-end')\n\n      // Upload phase complete - remove from active tracking\n      this._activeUploads.delete(uploadId)\n\n      // Notify upload complete\n      if (options?.onUploadComplete != null) {\n        options.onUploadComplete(uploadResult.pieceCid)\n      }\n\n      // Add Piece Phase: Queue the AddPieces operation for sequential processing\n\n      // Validate metadata early (before queueing) to fail fast\n      if (options?.metadata != null) {\n        validatePieceMetadata(options.metadata)\n      }\n\n      const finalPieceId = await new Promise<number>((resolve, reject) => {\n        // Add to pending batch\n        this._pendingPieces.push({\n          pieceCid: uploadResult.pieceCid,\n          resolve,\n          reject,\n          callbacks: options,\n          metadata: options?.metadata ? objectToEntries(options.metadata) : undefined,\n        })\n\n        // Debounce: defer processing to next event loop tick\n        // This allows multiple synchronous upload() calls to queue up before processing\n        setTimeout(() => {\n          void this._processPendingPieces().catch((error) => {\n            console.error('Failed to process pending pieces batch:', error)\n          })\n        }, 0)\n      })\n\n      // Return upload result\n      performance.mark('synapse:upload-end')\n      performance.measure('synapse:upload', 'synapse:upload-start', 'synapse:upload-end')\n      return {\n        pieceCid: uploadResult.pieceCid,\n        size: uploadResult.size,\n        pieceId: finalPieceId,\n      }\n    } finally {\n      this._activeUploads.delete(uploadId)\n    }\n  }\n\n  /**\n   * Process pending pieces by batching them into a single AddPieces operation\n   * This method is called from the promise queue to ensure sequential execution\n   */\n  private async _processPendingPieces(): Promise<void> {\n    if (this._isProcessing || this._pendingPieces.length === 0) {\n      return\n    }\n    this._isProcessing = true\n\n    // Wait for any in-flight uploads to complete before processing, but only if we don't\n    // already have a full batch - no point waiting for more if we can process a full batch now.\n    // Snapshot the current uploads so we don't wait for new uploads that start during our wait.\n    const uploadsToWaitFor = new Set(this._activeUploads)\n\n    if (uploadsToWaitFor.size > 0 && this._pendingPieces.length < this._uploadBatchSize) {\n      const waitStart = Date.now()\n      const pollInterval = 200\n\n      while (uploadsToWaitFor.size > 0 && Date.now() - waitStart < this._uploadBatchWaitTimeout) {\n        // Check which of our snapshot uploads have completed\n        for (const uploadId of uploadsToWaitFor) {\n          if (!this._activeUploads.has(uploadId)) {\n            uploadsToWaitFor.delete(uploadId)\n          }\n        }\n\n        if (uploadsToWaitFor.size > 0) {\n          await new Promise((resolve) => setTimeout(resolve, pollInterval))\n        }\n      }\n\n      const waited = Date.now() - waitStart\n      if (waited > pollInterval) {\n        console.debug(`Waited ${waited}ms for ${uploadsToWaitFor.size} active upload(s) to complete`)\n      }\n    }\n\n    // Extract up to uploadBatchSize pending pieces\n    const batch = this._pendingPieces.splice(0, this._uploadBatchSize)\n    try {\n      // Create piece data array and metadata from the batch\n      const pieceCids: PieceCID[] = batch.map((item) => item.pieceCid)\n      const metadataArray: MetadataEntry[][] = batch.map((item) => item.metadata ?? [])\n      const confirmedPieceIds: number[] = []\n\n      if (this.dataSetId) {\n        const [, dataSetInfo] = await Promise.all([\n          this._warmStorageService.validateDataSet(this.dataSetId),\n          this._warmStorageService.getDataSet(this.dataSetId),\n        ])\n        // Add pieces to the data set\n        const addPiecesResult = await this._pdpServer.addPieces(\n          this.dataSetId, // PDPVerifier data set ID\n          dataSetInfo.clientDataSetId, // Client's dataset ID\n          pieceCids,\n          metadataArray\n        )\n\n        // Notify callbacks with transaction\n        batch.forEach((item) => {\n          item.callbacks?.onPieceAdded?.(addPiecesResult.txHash as Hex)\n        })\n        const addPiecesResponse = await SP.pollForAddPiecesStatus(addPiecesResult)\n\n        // Handle transaction tracking if available\n        confirmedPieceIds.push(...(addPiecesResponse.confirmedPieceIds ?? []))\n\n        batch.forEach((item) => {\n          item.callbacks?.onPieceConfirmed?.(confirmedPieceIds)\n        })\n      } else {\n        const payer = await this._synapse.getClient().getAddress()\n        // Prepare metadata - merge withCDN flag into metadata if needed\n        const baseMetadataObj = this._dataSetMetadata ?? {}\n        const metadataObj =\n          this._withCDN && !(METADATA_KEYS.WITH_CDN in baseMetadataObj)\n            ? { ...baseMetadataObj, [METADATA_KEYS.WITH_CDN]: '' }\n            : baseMetadataObj\n\n        // Convert to MetadataEntry[] for PDP operations (requires ordered array)\n        const finalMetadata = objectToEntries(metadataObj)\n        // Create a new data set and add pieces to it\n        const createAndAddPiecesResult = await this._pdpServer.createAndAddPieces(\n          randU256(),\n          this._provider.payee,\n          payer,\n          this._synapse.getWarmStorageAddress(),\n          pieceCids,\n          {\n            dataset: finalMetadata,\n            pieces: metadataArray,\n          }\n        )\n        batch.forEach((item) => {\n          item.callbacks?.onPieceAdded?.(createAndAddPiecesResult.txHash as Hex)\n        })\n        const confirmedDataset = await SP.pollForDataSetCreationStatus(createAndAddPiecesResult)\n        this._dataSetId = confirmedDataset.dataSetId\n\n        const confirmedPieces = await SP.pollForAddPiecesStatus({\n          statusUrl: new URL(\n            `/pdp/data-sets/${confirmedDataset.dataSetId}/pieces/added/${confirmedDataset.createMessageHash}`,\n            this._pdpServer.getServiceURL()\n          ).toString(),\n        })\n\n        confirmedPieceIds.push(...(confirmedPieces.confirmedPieceIds ?? []))\n\n        batch.forEach((item) => {\n          item.callbacks?.onPieceConfirmed?.(confirmedPieceIds)\n        })\n      }\n\n      // Resolve all promises in the batch with their respective piece IDs\n      batch.forEach((item, index) => {\n        const pieceId = confirmedPieceIds[index]\n        if (pieceId == null) {\n          throw createError('StorageContext', 'addPieces', `Server did not return piece ID for piece at index ${index}`)\n        }\n        item.resolve(pieceId)\n      })\n    } catch (error) {\n      // Reject all promises in the batch\n      const finalError = createError('StorageContext', 'addPieces', 'Failed to add piece to data set', error)\n      batch.forEach((item) => {\n        item.reject(finalError)\n      })\n    } finally {\n      this._isProcessing = false\n      if (this._pendingPieces.length > 0) {\n        void this._processPendingPieces().catch((error) => {\n          console.error('Failed to process pending pieces batch:', error)\n        })\n      }\n    }\n  }\n\n  /**\n   * Download data from this specific service provider\n   * @param pieceCid - The PieceCID identifier\n   * @param options - Download options\n   * @returns The downloaded data\n   */\n  async download(pieceCid: string | PieceCID, options?: DownloadOptions): Promise<Uint8Array> {\n    // Pass through to storage manager with our provider hint and withCDN setting\n    // Use storage manager if available (production), otherwise use provider download for tests\n    const downloadFn = this._synapse.storage?.download ?? this._synapse.download\n    return await downloadFn.call(this._synapse.storage ?? this._synapse, pieceCid, {\n      providerAddress: this._provider.serviceProvider,\n      withCDN: (options as any)?.withCDN ?? this._withCDN,\n    })\n  }\n\n  /**\n   * Download data from the service provider\n   * @deprecated Use download() instead. This method will be removed in a future version.\n   */\n  async providerDownload(pieceCid: string | PieceCID, options?: DownloadOptions): Promise<Uint8Array> {\n    console.warn('providerDownload() is deprecated. Use download() instead.')\n    return await this.download(pieceCid, options)\n  }\n\n  /**\n   * Get information about the service provider used by this service\n   * @returns Provider information including pricing (currently same for all providers)\n   */\n  async getProviderInfo(): Promise<ProviderInfo> {\n    return await this._synapse.getProviderInfo(this.serviceProvider)\n  }\n\n  /**\n   * Get the list of piece CIDs for this service service's data set.\n   * @returns Array of piece CIDs as PieceCID objects\n   * @deprecated Use getPieces() generator for better memory efficiency with large data sets\n   */\n  async getDataSetPieces(): Promise<PieceCID[]> {\n    if (this.dataSetId == null) {\n      return []\n    }\n\n    const pieces: PieceCID[] = []\n    for await (const { pieceCid } of this.getPieces()) {\n      pieces.push(pieceCid)\n    }\n    return pieces\n  }\n\n  /**\n   * Get all active pieces for this data set as an async generator.\n   * This provides lazy evaluation and better memory efficiency for large data sets.\n   * @param options - Optional configuration object\n   * @param options.batchSize - The batch size for each pagination call (default: 100)\n   * @param options.signal - Optional AbortSignal to cancel the operation\n   * @yields Object with pieceCid and pieceId - the piece ID is needed for certain operations like deletion\n   */\n  async *getPieces(options?: {\n    batchSize?: number\n    signal?: AbortSignal\n  }): AsyncGenerator<{ pieceCid: PieceCID; pieceId: number }> {\n    if (this._dataSetId == null) {\n      return\n    }\n    const pdpVerifierAddress = this._warmStorageService.getPDPVerifierAddress()\n    const pdpVerifier = new PDPVerifier(this._synapse.getProvider(), pdpVerifierAddress)\n\n    const batchSize = options?.batchSize ?? 100\n    const signal = options?.signal\n    let offset = 0\n    let hasMore = true\n\n    while (hasMore) {\n      if (signal?.aborted) {\n        throw createError('StorageContext', 'getPieces', 'Operation aborted')\n      }\n\n      const result = await pdpVerifier.getActivePieces(this._dataSetId, { offset, limit: batchSize, signal })\n\n      // Yield pieces one by one for lazy evaluation\n      for (let i = 0; i < result.pieces.length; i++) {\n        if (signal?.aborted) {\n          throw createError('StorageContext', 'getPieces', 'Operation aborted')\n        }\n\n        yield {\n          pieceCid: result.pieces[i].pieceCid,\n          pieceId: result.pieces[i].pieceId,\n        }\n      }\n\n      hasMore = result.hasMore\n      offset += batchSize\n    }\n  }\n  private async _getPieceIdByCID(pieceCid: string | PieceCID): Promise<number> {\n    if (this.dataSetId == null) {\n      throw createError('StorageContext', 'getPieceIdByCID', 'Data set not found')\n    }\n    const parsedPieceCID = asPieceCID(pieceCid)\n    if (parsedPieceCID == null) {\n      throw createError('StorageContext', 'deletePiece', 'Invalid PieceCID provided')\n    }\n\n    const dataSetData = await this._pdpServer.getDataSet(this.dataSetId)\n    const pieceData = dataSetData.pieces.find((piece) => piece.pieceCid.toString() === parsedPieceCID.toString())\n    if (pieceData == null) {\n      throw createError('StorageContext', 'deletePiece', 'Piece not found in data set')\n    }\n    return pieceData.pieceId\n  }\n\n  /**\n   * Delete a piece with given CID from this data set\n   * @param piece - The PieceCID identifier or a piece number to delete by pieceID\n   * @returns Transaction hash of the delete operation\n   */\n  async deletePiece(piece: string | PieceCID | number): Promise<string> {\n    if (this.dataSetId == null) {\n      throw createError('StorageContext', 'deletePiece', 'Data set not found')\n    }\n    const pieceId = typeof piece === 'number' ? piece : await this._getPieceIdByCID(piece)\n    const dataSetInfo = await this._warmStorageService.getDataSet(this.dataSetId)\n\n    return this._pdpServer.deletePiece(this.dataSetId, dataSetInfo.clientDataSetId, pieceId)\n  }\n\n  /**\n   * Check if a piece exists on this service provider.\n   * @param pieceCid - The PieceCID (piece CID) to check\n   * @returns True if the piece exists on this provider, false otherwise\n   */\n  async hasPiece(pieceCid: string | PieceCID): Promise<boolean> {\n    const parsedPieceCID = asPieceCID(pieceCid)\n    if (parsedPieceCID == null) {\n      return false\n    }\n\n    try {\n      await this._pdpServer.findPiece(parsedPieceCID)\n      return true\n    } catch {\n      return false\n    }\n  }\n\n  /**\n   * Check if a piece exists on this service provider and get its proof status.\n   * Also returns timing information about when the piece was last proven and when the next\n   * proof is due.\n   *\n   * Note: Proofs are submitted for entire data sets, not individual pieces. The timing information\n   * returned reflects when the data set (containing this piece) was last proven and when the next\n   * proof is due.\n   *\n   * @param pieceCid - The PieceCID (piece CID) to check\n   * @returns Status information including existence, data set timing, and retrieval URL\n   */\n  async pieceStatus(pieceCid: string | PieceCID): Promise<PieceStatus> {\n    if (this.dataSetId == null) {\n      throw createError('StorageContext', 'pieceStatus', 'Data set not found')\n    }\n    const parsedPieceCID = asPieceCID(pieceCid)\n    if (parsedPieceCID == null) {\n      throw createError('StorageContext', 'pieceStatus', 'Invalid PieceCID provided')\n    }\n\n    // Run multiple operations in parallel for better performance\n    const [exists, dataSetData, currentEpoch] = await Promise.all([\n      // Check if piece exists on provider\n      this.hasPiece(parsedPieceCID),\n      // Get data set data\n      this._pdpServer\n        .getDataSet(this.dataSetId)\n        .catch((error) => {\n          console.debug('Failed to get data set data:', error)\n          return null\n        }),\n      // Get current epoch\n      getCurrentEpoch(this._synapse.getProvider()),\n    ])\n    const network = this._synapse.getNetwork()\n\n    // Initialize return values\n    let retrievalUrl: string | null = null\n    let pieceId: number | undefined\n    let lastProven: Date | null = null\n    let nextProofDue: Date | null = null\n    let inChallengeWindow = false\n    let hoursUntilChallengeWindow = 0\n    let isProofOverdue = false\n\n    // If piece exists, get provider info for retrieval URL and proving params in parallel\n    if (exists) {\n      const [providerInfo, provingParams] = await Promise.all([\n        // Get provider info for retrieval URL\n        this.getProviderInfo().catch(() => null),\n        // Get proving period configuration (only if we have data set data)\n        dataSetData != null\n          ? Promise.all([this._warmStorageService.getMaxProvingPeriod(), this._warmStorageService.getChallengeWindow()])\n              .then(([maxProvingPeriod, challengeWindow]) => ({\n                maxProvingPeriod,\n                challengeWindow,\n              }))\n              .catch(() => null)\n          : Promise.resolve(null),\n      ])\n\n      // Set retrieval URL if we have provider info\n      if (providerInfo != null) {\n        // Remove trailing slash from serviceURL to avoid double slashes\n        if (!providerInfo.products.PDP?.data.serviceURL) {\n          throw new Error(`Provider ${providerInfo.id} does not have a PDP product with serviceURL`)\n        }\n        retrievalUrl = `${providerInfo.products.PDP.data.serviceURL.replace(\n          /\\/$/,\n          ''\n        )}/piece/${parsedPieceCID.toString()}`\n      }\n\n      // Process proof timing data if we have data set data and proving params\n      if (dataSetData != null && provingParams != null) {\n        // Check if this PieceCID is in the data set\n        const pieceData = dataSetData.pieces.find((piece) => piece.pieceCid.toString() === parsedPieceCID.toString())\n\n        if (pieceData != null) {\n          pieceId = pieceData.pieceId\n\n          // Calculate timing based on nextChallengeEpoch\n          if (dataSetData.nextChallengeEpoch > 0) {\n            // nextChallengeEpoch is when the challenge window STARTS, not ends!\n            // The proving deadline is nextChallengeEpoch + challengeWindow\n            const challengeWindowStart = dataSetData.nextChallengeEpoch\n            const provingDeadline = challengeWindowStart + provingParams.challengeWindow\n\n            // Calculate when the next proof is due (end of challenge window)\n            nextProofDue = epochToDate(provingDeadline, network)\n\n            // Calculate last proven date (one proving period before next challenge)\n            const lastProvenDate = calculateLastProofDate(\n              dataSetData.nextChallengeEpoch,\n              provingParams.maxProvingPeriod,\n              network\n            )\n            if (lastProvenDate != null) {\n              lastProven = lastProvenDate\n            }\n\n            // Check if we're in the challenge window\n            inChallengeWindow = Number(currentEpoch) >= challengeWindowStart && Number(currentEpoch) < provingDeadline\n\n            // Check if proof is overdue (past the proving deadline)\n            isProofOverdue = Number(currentEpoch) >= provingDeadline\n\n            // Calculate hours until challenge window starts (only if before challenge window)\n            if (Number(currentEpoch) < challengeWindowStart) {\n              const timeUntil = timeUntilEpoch(challengeWindowStart, Number(currentEpoch))\n              hoursUntilChallengeWindow = timeUntil.hours\n            }\n          } else {\n            // If nextChallengeEpoch is 0, it might mean:\n            // 1. Proof was just submitted and system is updating\n            // 2. Data set is not active\n            // In case 1, we might have just proven, so set lastProven to very recent\n            // This is a temporary state and should resolve quickly\n            console.debug('Data set has nextChallengeEpoch=0, may have just been proven')\n          }\n        }\n      }\n    }\n\n    return {\n      exists,\n      dataSetLastProven: lastProven,\n      dataSetNextProofDue: nextProofDue,\n      retrievalUrl,\n      pieceId,\n      inChallengeWindow,\n      hoursUntilChallengeWindow,\n      isProofOverdue,\n    }\n  }\n\n  /**\n   * Terminates the data set by sending on-chain message.\n   * This will also result in the removal of all pieces in the data set.\n   * @returns Transaction response\n   */\n  async terminate(): Promise<ethers.TransactionResponse> {\n    if (this.dataSetId == null) {\n      throw createError('StorageContext', 'terminate', 'Data set not found')\n    }\n    return this._synapse.storage.terminateDataSet(this.dataSetId)\n  }\n}\n","/**\n * SubgraphService - A service for querying a subgraph to find service providers for a given piece.\n *\n * This service abstracts the logic for connecting to and querying a GraphQL endpoint,\n * which can be a direct URL or a Goldsky-hosted subgraph.\n *\n * @example\n * ```typescript\n * import { SubgraphService } from '@filoz/synapse-sdk/subgraph'\n *\n * // Using a direct endpoint\n * const subgraphService = new SubgraphService({ endpoint: 'https://your-subgraph-endpoint.com/query' });\n *\n * // Using Goldsky configuration\n * const goldskyService = new SubgraphService({\n *   goldsky: {\n *     projectId: 'your-project-id',\n *     subgraphName: 'your-subgraph-name',\n *     version: 'v1.0.0'\n *   }\n * });\n *\n * const providers = await subgraphService.getApprovedProvidersForPieceCID('bafkzcib...');\n * console.log(providers);\n * ```\n */\n\nimport { asPieceCID } from '@filoz/synapse-core/piece'\nimport { fromHex, toHex } from 'multiformats/bytes'\nimport { CID } from 'multiformats/cid'\nimport { type PDPOffering, PRODUCTS, type ProductType, type ServiceProduct } from '../sp-registry/types.ts'\nimport type { PieceCID, ProviderInfo, SubgraphConfig, SubgraphRetrievalService } from '../types.ts'\nimport { createError } from '../utils/errors.ts'\nimport { QUERIES } from './queries.ts'\n\n// Simplified response types\ninterface GraphQLResponse<T = any> {\n  data?: T\n  errors?: Array<{ message: string }>\n}\n\n/**\n * Options for pagination in subgraph queries\n */\nexport interface PaginationOptions {\n  first?: number\n  skip?: number\n}\n\n/**\n * Options for flexible subgraph queries with custom where clauses\n */\nexport interface QueryOptions extends PaginationOptions {\n  where?: Record<string, any>\n  orderBy?: string\n  orderDirection?: 'asc' | 'desc'\n}\n\n/**\n * Options for nested entity queries in subgraphs\n */\nexport interface NestedQueryOptions extends QueryOptions {\n  nestedWhere?: Record<string, any>\n}\n\n/**\n * Extended provider statistics including fault information\n */\nexport interface ProviderStats extends ProviderInfo {\n  status: string\n  totalFaultedPeriods: number\n  totalFaultedPieces: number\n  totalDataSets: number\n  totalPieces: number\n  totalDataSize: number\n  createdAt: number\n  updatedAt: number\n}\n\n/**\n * Basic data set information from subgraph\n */\nexport interface SubgraphDataSetInfo {\n  id: string\n  setId: number\n  isActive: boolean\n  leafCount: number\n  totalDataSize: number\n  totalPieces: number\n  totalProofs: number\n  totalProvedPieces: number\n  totalFaultedPieces: number\n  createdAt: number\n  updatedAt: number\n}\n\n/**\n * Detailed data set information from subgraph with additional metadata\n */\nexport interface DetailedSubgraphDataSetInfo extends SubgraphDataSetInfo {\n  listener: string\n  payer: string\n  withCDN: boolean\n  challengeRange: number\n  lastProvenEpoch: number\n  nextChallengeEpoch: number\n  totalFaultedPeriods: number\n  metadataKeys: string[]\n  metadataValues: string[]\n  serviceProvider: ProviderInfo\n  rails?: {\n    id: string\n    type: string\n    railId: number\n    token: string\n    paymentRate: number\n    settledUpto: number\n    endEpoch: number\n  }[]\n}\n\n/**\n * Piece information with data set context\n */\nexport interface PieceInfo {\n  id: string\n  setId: number\n  pieceId: number\n  rawSize: number\n  leafCount: number\n  cid: PieceCID | null\n  removed: boolean\n  totalProofsSubmitted: number\n  totalPeriodsFaulted: number\n  lastProvenEpoch: number\n  lastProvenAt: number\n  lastFaultedEpoch: number\n  lastFaultedAt: number\n  createdAt: number\n  metadataKeys: string[]\n  metadataValues: string[]\n  dataSet: {\n    id: string\n    setId: number\n    isActive: boolean\n    serviceProvider: ProviderInfo\n  }\n}\n\n/**\n * Fault record information\n */\nexport interface FaultRecord {\n  id: string\n  dataSetId: number\n  pieceIds: number[]\n  currentChallengeEpoch: number\n  nextChallengeEpoch: number\n  periodsFaulted: number\n  deadline: number\n  createdAt: number\n  dataSet: {\n    id: string\n    setId: number\n    serviceProvider: ProviderInfo\n  }\n}\n\nexport class SubgraphService implements SubgraphRetrievalService {\n  private readonly endpoint: string\n  private readonly headers: Record<string, string>\n\n  constructor(subgraphConfig: SubgraphConfig) {\n    this.endpoint = this.resolveEndpoint(subgraphConfig)\n    this.headers = this.buildHeaders(subgraphConfig.apiKey)\n  }\n\n  /**\n   * Resolves the GraphQL endpoint from configuration\n   */\n  private resolveEndpoint(config: SubgraphConfig): string {\n    if (config.endpoint != null && config.endpoint.trim() !== '') {\n      return config.endpoint.trim()\n    }\n\n    if (config.goldsky != null) {\n      return this.buildGoldskyEndpoint(config.goldsky)\n    }\n\n    throw createError(\n      'SubgraphService',\n      'constructor',\n      'Invalid configuration: provide either endpoint or complete goldsky config'\n    )\n  }\n\n  /**\n   * Builds Goldsky endpoint URL\n   */\n  private buildGoldskyEndpoint(goldsky: NonNullable<SubgraphConfig['goldsky']>): string {\n    const { projectId, subgraphName, version } = goldsky\n\n    if (\n      projectId?.trim() == null ||\n      projectId?.trim() === '' ||\n      subgraphName?.trim() == null ||\n      subgraphName?.trim() === '' ||\n      version?.trim() == null ||\n      version?.trim() === ''\n    ) {\n      throw createError(\n        'SubgraphService',\n        'constructor',\n        'Incomplete Goldsky config: projectId, subgraphName, and version required'\n      )\n    }\n\n    return `https://api.goldsky.com/api/public/${projectId}/subgraphs/${subgraphName}/${version}/gn`\n  }\n\n  /**\n   * Builds HTTP headers for requests\n   */\n  private buildHeaders(apiKey?: string): Record<string, string> {\n    const headers = { 'Content-Type': 'application/json' }\n\n    if (apiKey != null && apiKey !== '') {\n      return { ...headers, Authorization: `Bearer ${apiKey}` }\n    }\n\n    return headers\n  }\n\n  /**\n   * Normalizes query options with defaults\n   */\n  private normalizeQueryOptions(options: QueryOptions = {}): QueryOptions {\n    return {\n      where: {},\n      first: 10,\n      skip: 0,\n      orderBy: 'createdAt',\n      orderDirection: 'desc',\n      ...options,\n    } as const\n  }\n\n  /**\n   * Executes a GraphQL query\n   */\n  private async executeQuery<T>(query: string, variables: Record<string, any>, operation: string): Promise<T> {\n    try {\n      const response = await fetch(this.endpoint, {\n        method: 'POST',\n        headers: this.headers,\n        body: JSON.stringify({ query, variables }),\n      })\n\n      if (!response.ok) {\n        const errorText = await response.text()\n        throw createError('SubgraphService', operation, `HTTP ${response.status}: ${errorText}`)\n      }\n\n      const result = (await response.json()) as GraphQLResponse<T>\n\n      if (result.errors != null && result.errors.length > 0) {\n        const errorMsg = result.errors.map((e) => e.message).join('; ')\n        throw createError('SubgraphService', operation, `GraphQL errors: ${errorMsg}`)\n      }\n\n      return result.data as T\n    } catch (error) {\n      if (error instanceof Error && error.name === 'SynapseError') {\n        throw error\n      }\n\n      throw createError('SubgraphService', operation, `Query execution failed: ${(error as Error).message}`, {\n        cause: error,\n      })\n    }\n  }\n\n  /**\n   * Maps a ProductType value back to its corresponding key in the PRODUCTS constant.\n   *\n   * This method performs a reverse lookup to find the key that corresponds to the given\n   * ProductType value.\n   *\n   */\n  private getProductType(productType: ProductType): keyof typeof PRODUCTS {\n    const entry = Object.entries(PRODUCTS).find(([, value]) => value === productType)\n    return entry != null ? (entry[0] as keyof typeof PRODUCTS) : 'PDP'\n  }\n\n  /**\n   * Transforms raw provider data from the subgraph into a structured ProviderInfo object.\n   *\n   * This method safely converts subgraph provider data into the SDK's ProviderInfo format,\n   * handling potential missing fields and parsing errors gracefully.\n   *\n   */\n  private transformProviderData(data: any): ProviderInfo {\n    // Provide safe defaults for required fields\n    const safeData = {\n      providerId: data?.providerId ?? 0,\n      serviceProvider: data?.serviceProvider ?? '',\n      payee: data?.payee ?? '',\n      name: data?.name ?? '',\n      description: data?.description ?? '',\n      status: data?.status ?? 'UNKNOWN',\n      products: Array.isArray(data?.products) ? data.products : [],\n    }\n\n    return {\n      id: safeData.providerId,\n      serviceProvider: safeData.serviceProvider,\n      payee: safeData.payee,\n      name: safeData.name,\n      description: safeData.description,\n      active: safeData.status === 'APPROVED',\n      products: this.transformProducts(safeData.products),\n    }\n  }\n\n  /**\n   * Transforms an array of product data into a structured products record.\n   */\n  private transformProducts(products: any[]): Partial<Record<'PDP', ServiceProduct>> {\n    return products.reduce(\n      (productAcc: Record<string, ServiceProduct>, product: any) => {\n        const productType = this.getProductType(product?.productType)\n        const serviceProduct = this.createServiceProduct(product, productType)\n\n        if (serviceProduct != null) {\n          productAcc[productType] = serviceProduct\n        }\n\n        return productAcc\n      },\n      {} as Record<string, ServiceProduct>\n    )\n  }\n\n  /**\n   * Creates a ServiceProduct from raw product data with error handling.\n   */\n  private createServiceProduct(product: any, productType: keyof typeof PRODUCTS): ServiceProduct | null {\n    try {\n      return {\n        type: productType,\n        isActive: product?.isActive ?? false,\n        capabilities: this.transformCapabilities(product?.capabilityValues),\n        data: this.parseProductData(product?.decodedProductData),\n      }\n    } catch (error) {\n      console.warn(\n        `SubgraphService: Failed to create service product for type ${productType}:`,\n        error instanceof Error ? error.message : 'Unknown error'\n      )\n      return null\n    }\n  }\n\n  /**\n   * Transforms capability values into a key-value record.\n   */\n  private transformCapabilities(capabilityValues: any[]): Record<string, string> {\n    if (!Array.isArray(capabilityValues)) {\n      return {}\n    }\n\n    return capabilityValues.reduce(\n      (capabilityAcc: Record<string, string>, capability: any) => {\n        if (capability?.key != null && capability?.value != null) {\n          capabilityAcc[capability.key] = String(capability.value)\n        }\n        return capabilityAcc\n      },\n      {} as Record<string, string>\n    )\n  }\n\n  /**\n   * Safely parses product data JSON with error handling.\n   */\n  private parseProductData(decodedProductData: string): PDPOffering {\n    try {\n      if (decodedProductData == null || decodedProductData.trim() === '') {\n        throw new Error('Empty or null product data')\n      }\n\n      const parsed = JSON.parse(decodedProductData) as PDPOffering\n\n      // Validate required fields exist\n      if (parsed?.serviceURL == null) {\n        throw new Error('Missing required serviceURL field')\n      }\n\n      return parsed\n    } catch (error) {\n      console.warn(\n        `SubgraphService: Failed to parse product data, using defaults:`,\n        error instanceof Error ? error.message : 'Unknown error'\n      )\n\n      // Return safe defaults for PDPOffering\n      return {\n        serviceURL: '',\n        minPieceSizeInBytes: 0n,\n        maxPieceSizeInBytes: 0n,\n        ipniPiece: false,\n        ipniIpfs: false,\n        storagePricePerTibPerDay: 0n,\n        minProvingPeriodInEpochs: 0n,\n        location: '',\n        paymentTokenAddress: '0x0000000000000000000000000000000000000000',\n      }\n    }\n  }\n\n  /**\n   * Safely parses timestamp values\n   */\n  private parseTimestamp(value?: number | string): number {\n    if (value == null) return 0\n    const parsed = Number(value)\n    return Number.isNaN(parsed) ? 0 : parsed\n  }\n\n  /**\n   * Safely converts a hex format CID to PieceCID format\n   * @param hexCid - The CID in hex format\n   * @returns The CID in PieceCID format or null if conversion fails\n   */\n  private safeConvertHexToCid(hexCid: string): PieceCID | null {\n    try {\n      const cleanHex = hexCid.startsWith('0x') ? hexCid.slice(2) : hexCid\n      const cidBytes = fromHex(cleanHex)\n      const cid = CID.decode(cidBytes)\n      const pieceCid = asPieceCID(cid)\n\n      if (pieceCid == null) {\n        throw new Error(`Failed to convert CID to PieceCID format: ${hexCid}`)\n      }\n\n      return pieceCid\n    } catch (error) {\n      console.warn(\n        `SubgraphService: queryProviders: Failed to convert CID to PieceCID format: ${\n          error instanceof Error ? error.message : 'Unknown error'\n        }`\n      )\n      return null\n    }\n  }\n\n  /**\n   * Validates provider data completeness\n   */\n  private isValidProviderData(data: any): boolean {\n    return data?.id != null && data.id.trim() !== '' && data?.products != null && data.products.length > 0\n  }\n\n  /**\n   * Queries the subgraph to find approved service providers that have a specific piece (PieceCID).\n   *\n   * It sends a GraphQL query to the configured endpoint and parses the response to extract\n   * a list of providers, including their addresses and retrieval URLs.\n   *\n   * @param pieceCid - The piece commitment (PieceCID) to search for.\n   * @returns A promise that resolves to an array of `ProviderInfo` objects.\n   *          Returns an empty array if no providers are found or if an error occurs during the fetch.\n   */\n  async getApprovedProvidersForPieceCID(pieceCid: PieceCID): Promise<ProviderInfo[]> {\n    const pieceCidParsed = asPieceCID(pieceCid)\n    if (pieceCidParsed == null) {\n      throw createError('SubgraphService', 'getApprovedProvidersForPieceCID', 'Invalid PieceCID')\n    }\n    const hexPieceCid = toHex(pieceCidParsed.bytes)\n\n    const data = await this.executeQuery<{ pieces: any[] }>(\n      QUERIES.GET_APPROVED_PROVIDERS_FOR_PIECE_LINK,\n      { cid: hexPieceCid },\n      'getApprovedProvidersForPieceCID'\n    )\n\n    if (data?.pieces == null || data.pieces.length === 0) {\n      console.log(`SubgraphService: No providers found for PieceCID: ${pieceCidParsed.toString()}`)\n      return []\n    }\n\n    const uniqueProviderMap = data.pieces.reduce((acc: Map<string, any>, piece: any) => {\n      const provider = piece.dataSet.serviceProvider\n      const address = provider?.serviceProvider?.toLowerCase() as string\n\n      if (address == null || address === '' || acc.has(address)) {\n        return acc\n      }\n\n      if (!this.isValidProviderData(provider)) {\n        console.warn('SubgraphService: Skipping incomplete provider data for approved provider:', provider)\n        return acc\n      }\n\n      acc.set(address, provider)\n\n      return acc\n    }, new Map<string, any>())\n\n    return Array.from(uniqueProviderMap.values()).map((provider) => this.transformProviderData(provider))\n  }\n\n  /**\n   * Queries the subgraph to find a specific approved service provider by their address.\n   *\n   * @param address - The wallet address of the provider to search for.\n   * @returns A promise that resolves to an `ProviderInfo` object if the provider is found, or `null` otherwise.\n   */\n  async getProviderByAddress(address: string): Promise<ProviderInfo | null> {\n    const data = await this.executeQuery<{ provider: any | null }>(\n      QUERIES.GET_PROVIDER_BY_ADDRESS,\n      { serviceProvider: address },\n      'getProviderByAddress'\n    )\n\n    if (data?.provider == null) {\n      console.log(`SubgraphService: No provider found for address: ${address}`)\n      return null\n    }\n\n    return this.transformProviderData(data.provider)\n  }\n\n  /**\n   * Generic method to query providers with flexible where clauses\n   *\n   * @param options - Query options including where clause, pagination, and ordering\n   * @returns A promise that resolves to an array of `ProviderInfo` objects\n   *\n   * @example\n   * ```typescript\n   * // Get providers with specific status\n   * const approvedProviders = await service.queryProviders({\n   *   where: { status: \"APPROVED\" },\n   *   first: 10,\n   *   orderBy: \"approvedAt\",\n   *   orderDirection: \"desc\"\n   * });\n   *\n   * // Get providers with minimum data sets\n   * const activeProviders = await service.queryProviders({\n   *   where: { totalDataSets_gte: \"5\" },\n   *   first: 20\n   * });\n   * ```\n   */\n  async queryProviders(options: QueryOptions = {}): Promise<ProviderInfo[]> {\n    const data = await this.executeQuery<{ providers: any[] }>(\n      QUERIES.GET_PROVIDERS_FLEXIBLE,\n      this.normalizeQueryOptions(options),\n      'queryProviders'\n    )\n\n    if (data?.providers == null || data?.providers?.length === 0) {\n      console.log('SubgraphService: No providers found for the given criteria')\n      return []\n    }\n\n    return data.providers\n      .filter((provider) => this.isValidProviderData(provider))\n      .map((provider) => this.transformProviderData(provider))\n  }\n\n  /**\n   * Generic method to query data sets with flexible where clauses\n   *\n   * @param options - Query options including where clause, pagination, and ordering\n   * @returns A promise that resolves to an array of `DetailedSubgraphDataSetInfo` objects\n   *\n   * @example\n   * ```typescript\n   * // Get active data sets\n   * const activeDataSets = await service.queryDataSets({\n   *   where: { isActive: true },\n   *   first: 50,\n   *   orderBy: \"createdAt\",\n   *   orderDirection: \"desc\"\n   * });\n   *\n   * // Get data sets by owner with minimum data size\n   * const largeDataSets = await service.queryDataSets({\n   *   where: {\n   *     owner: \"0x123...\",\n   *     totalDataSize_gte: \"1000000000\"\n   *   }\n   * });\n   * ```\n   */\n  async queryDataSets(options: QueryOptions = {}): Promise<DetailedSubgraphDataSetInfo[]> {\n    const data = await this.executeQuery<{ dataSets: any[] }>(\n      QUERIES.GET_DATA_SETS_FLEXIBLE,\n      this.normalizeQueryOptions(options),\n      'queryDataSets'\n    )\n\n    if (data?.dataSets == null || data?.dataSets?.length === 0) {\n      console.log('SubgraphService: No data sets found for the given criteria')\n      return []\n    }\n\n    return data.dataSets.map((dataSet: any) => ({\n      id: dataSet.id,\n      setId: this.parseTimestamp(dataSet.setId),\n      listener: dataSet.listener ?? '',\n      payer: dataSet.payer ?? '',\n      withCDN: dataSet.withCDN ?? false,\n      isActive: dataSet.isActive,\n      leafCount: this.parseTimestamp(dataSet.leafCount),\n      challengeRange: this.parseTimestamp(dataSet.challengeRange),\n      lastProvenEpoch: this.parseTimestamp(dataSet.lastProvenEpoch),\n      nextChallengeEpoch: this.parseTimestamp(dataSet.nextChallengeEpoch),\n      totalPieces: this.parseTimestamp(dataSet.totalPieces),\n      totalDataSize: this.parseTimestamp(dataSet.totalDataSize),\n      totalProofs: this.parseTimestamp(dataSet.totalProofs),\n      totalProvedPieces: this.parseTimestamp(dataSet.totalProvedPieces),\n      totalFaultedPeriods: this.parseTimestamp(dataSet.totalFaultedPeriods),\n      totalFaultedPieces: this.parseTimestamp(dataSet.totalFaultedPieces),\n      metadataKeys: dataSet.metadataKeys ?? [],\n      metadataValues: dataSet.metadataValues ?? [],\n      createdAt: this.parseTimestamp(dataSet.createdAt),\n      updatedAt: this.parseTimestamp(dataSet.updatedAt),\n      serviceProvider:\n        dataSet.serviceProvider != null\n          ? this.transformProviderData(dataSet.serviceProvider)\n          : this.transformProviderData({}), // Create default provider\n      rails:\n        dataSet.rails != null\n          ? dataSet.rails.map((rail: any) => ({\n              id: rail.id,\n              type: rail.type,\n              railId: this.parseTimestamp(rail.railId),\n              token: rail.token,\n              paymentRate: this.parseTimestamp(rail.paymentRate),\n              settledUpto: this.parseTimestamp(rail.settledUpto),\n              endEpoch: this.parseTimestamp(rail.endEpoch),\n            }))\n          : undefined,\n    }))\n  }\n\n  /**\n   * Generic method to query pieces with flexible where clauses\n   *\n   * @param options - Query options including where clause, pagination, and ordering\n   * @returns A promise that resolves to an array of `PieceInfo` objects\n   *\n   * @example\n   * ```typescript\n   * // Get pieces by data set\n   * const dataSetPieces = await service.queryPieces({\n   *   where: { dataSet: \"0x123...\" },\n   *   first: 100,\n   *   orderBy: \"createdAt\"\n   * });\n   *\n   * // Get non-removed pieces with minimum size\n   * const largePieces = await service.queryPieces({\n   *   where: {\n   *     removed: false,\n   *     rawSize_gte: \"1000000\"\n   *   }\n   * });\n   * ```\n   */\n  async queryPieces(options: QueryOptions = {}): Promise<PieceInfo[]> {\n    const data = await this.executeQuery<{ pieces: any[] }>(\n      QUERIES.GET_PIECES_FLEXIBLE,\n      this.normalizeQueryOptions(options),\n      'queryPieces'\n    )\n\n    if (data?.pieces == null || data?.pieces?.length === 0) {\n      console.log('SubgraphService: No pieces found for the given criteria')\n      return []\n    }\n\n    return data.pieces.map((piece) => ({\n      id: piece.id,\n      setId: this.parseTimestamp(piece.setId),\n      pieceId: this.parseTimestamp(piece.pieceId),\n      rawSize: this.parseTimestamp(piece.rawSize),\n      leafCount: this.parseTimestamp(piece.leafCount),\n      cid: this.safeConvertHexToCid(piece.cid),\n      removed: piece.removed,\n      totalProofsSubmitted: this.parseTimestamp(piece.totalProofsSubmitted),\n      totalPeriodsFaulted: this.parseTimestamp(piece.totalPeriodsFaulted),\n      lastProvenEpoch: this.parseTimestamp(piece.lastProvenEpoch),\n      lastProvenAt: this.parseTimestamp(piece.lastProvenAt),\n      lastFaultedEpoch: this.parseTimestamp(piece.lastFaultedEpoch),\n      lastFaultedAt: this.parseTimestamp(piece.lastFaultedAt),\n      createdAt: this.parseTimestamp(piece.createdAt),\n      metadataKeys: piece.metadataKeys ?? [],\n      metadataValues: piece.metadataValues ?? [],\n      dataSet: {\n        id: piece.dataSet.id,\n        setId: this.parseTimestamp(piece.dataSet.setId),\n        isActive: piece.dataSet.isActive,\n        serviceProvider: this.transformProviderData(piece.dataSet.serviceProvider),\n      },\n    }))\n  }\n\n  /**\n   * Generic method to query fault records with flexible where clauses\n   *\n   * @param options - Query options including where clause, pagination, and ordering\n   * @returns A promise that resolves to an array of `FaultRecord` objects\n   *\n   * @example\n   * ```typescript\n   * // Get recent fault records\n   * const recentFaults = await service.queryFaultRecords({\n   *   where: { createdAt_gte: \"1640995200\" },\n   *   first: 20,\n   *   orderBy: \"createdAt\",\n   *   orderDirection: \"desc\"\n   * });\n   *\n   * // Get fault records for specific data set\n   * const dataSetFaults = await service.queryFaultRecords({\n   *   where: { dataSetId: \"123\" }\n   * });\n   * ```\n   */\n  async queryFaultRecords(options: QueryOptions = {}): Promise<FaultRecord[]> {\n    const data = await this.executeQuery<{ faultRecords: any[] }>(\n      QUERIES.GET_FAULT_RECORDS_FLEXIBLE,\n      this.normalizeQueryOptions(options),\n      'queryFaultRecords'\n    )\n\n    if (data?.faultRecords == null || data?.faultRecords?.length === 0) {\n      console.log('SubgraphService: No fault records found for the given criteria')\n      return []\n    }\n\n    return data.faultRecords.map((fault) => ({\n      id: fault.id,\n      dataSetId: this.parseTimestamp(fault.dataSetId),\n      pieceIds: fault.pieceIds.map((id: any) => this.parseTimestamp(id)),\n      currentChallengeEpoch: this.parseTimestamp(fault.currentChallengeEpoch),\n      nextChallengeEpoch: this.parseTimestamp(fault.nextChallengeEpoch),\n      periodsFaulted: this.parseTimestamp(fault.periodsFaulted),\n      deadline: this.parseTimestamp(fault.deadline),\n      createdAt: this.parseTimestamp(fault.createdAt),\n      dataSet: {\n        id: fault.dataSet.id,\n        setId: this.parseTimestamp(fault.dataSet.setId),\n        serviceProvider: this.transformProviderData(fault.dataSet.serviceProvider),\n      },\n    }))\n  }\n}\n","/**\n * EIP-712 Authentication helpers for PDP operations\n */\n\nimport { asPieceCID, type PieceCID } from '@filoz/synapse-core/piece'\nimport { ethers } from 'ethers'\nimport type { AuthSignature, MetadataEntry } from '../types.ts'\nimport { METADATA_KEYS } from '../utils/constants.ts'\nimport { EIP712_TYPES } from '../utils/eip712.ts'\n\n// Declare window.ethereum for TypeScript\ndeclare global {\n  interface Window {\n    ethereum?: any\n  }\n}\n\n/**\n * Helper class for creating EIP-712 typed signatures for PDP operations\n *\n * This class provides methods to create cryptographic signatures required for\n * authenticating PDP (Proof of Data Possession) operations with service providers.\n * All signatures are EIP-712 compatible for improved security and UX.\n *\n * Can be used standalone or through the Synapse SDK.\n *\n * @example\n * ```typescript\n * // Direct instantiation with ethers signer\n * import { PDPAuthHelper } from '@filoz/synapse-sdk'\n * import { ethers } from 'ethers'\n *\n * const wallet = new ethers.Wallet(privateKey, provider)\n * const auth = new PDPAuthHelper(contractAddress, wallet, BigInt(chainId))\n *\n * // Or get from Synapse instance (convenience method)\n * const synapse = await Synapse.create({ privateKey, rpcURL })\n * const auth = synapse.getPDPAuthHelper()\n *\n * // Sign operations for PDP service authentication\n * const createSig = await auth.signCreateDataSet(0, providerAddress, false)\n * const addPiecesSig = await auth.signAddPieces(0, 1, pieceDataArray)\n * ```\n */\nexport class PDPAuthHelper {\n  private readonly signer: ethers.Signer\n  private readonly domain: ethers.TypedDataDomain\n  public readonly WITH_CDN_METADATA: MetadataEntry = { key: METADATA_KEYS.WITH_CDN, value: '' }\n\n  constructor(serviceContractAddress: string, signer: ethers.Signer, chainId: bigint) {\n    this.signer = signer\n\n    // EIP-712 domain\n    this.domain = {\n      name: 'FilecoinWarmStorageService',\n      version: '1',\n      chainId: Number(chainId),\n      verifyingContract: serviceContractAddress,\n    }\n  }\n\n  /**\n   * Get the actual signer, unwrapping NonceManager if needed\n   */\n  private getUnderlyingSigner(): ethers.Signer {\n    // Check if this is a NonceManager-wrapped signer\n    if ('signer' in this.signer && this.signer.constructor.name === 'NonceManager') {\n      // Access the underlying signer for signTypedData support\n      return (this.signer as any).signer\n    }\n    return this.signer\n  }\n\n  /**\n   * Check if the signer is a browser provider (MetaMask, etc)\n   */\n  private async isMetaMaskSigner(): Promise<boolean> {\n    try {\n      // Get the actual signer (unwrap NonceManager if needed)\n      const actualSigner = this.getUnderlyingSigner()\n\n      // If it's a Wallet, it can sign locally, so not a MetaMask signer\n      if (actualSigner.constructor.name === 'Wallet') {\n        return false\n      }\n\n      // Check if signer has a provider\n      const provider = actualSigner.provider\n      if (provider == null) {\n        return false\n      }\n\n      // Check for ethers v6 BrowserProvider\n      if ('_eip1193Provider' in provider) {\n        return true\n      }\n\n      // If it's a JsonRpcProvider or WebSocketProvider, it's not a browser provider\n      // These can sign locally with a wallet\n      if (provider instanceof ethers.JsonRpcProvider || provider instanceof ethers.WebSocketProvider) {\n        return false\n      }\n\n      // For any other provider with request method (potential EIP-1193 provider)\n      if ('request' in provider && typeof (provider as any).request === 'function') {\n        return true\n      }\n    } catch {\n      // Silently fail and return false\n    }\n    return false\n  }\n\n  /**\n   * Sign typed data with MetaMask-friendly display\n   * This bypasses ethers.js conversion to show human-readable values in MetaMask\n   */\n  private async signWithMetaMask(\n    types: Record<string, Array<{ name: string; type: string }>>,\n    value: any\n  ): Promise<string> {\n    const provider = this.signer.provider\n    if (provider == null) {\n      throw new Error('No provider available')\n    }\n\n    const signerAddress = await this.signer.getAddress()\n\n    // Determine the primary type (the first one that isn't a dependency)\n    let primaryType = ''\n    for (const typeName of Object.keys(types)) {\n      // Skip Cid and PieceData as they are dependencies\n      if (typeName !== 'Cid' && typeName !== 'PieceData') {\n        primaryType = typeName\n        break\n      }\n    }\n\n    // Construct the full typed data payload for MetaMask\n    const typedData = {\n      types: {\n        EIP712Domain: [\n          { name: 'name', type: 'string' },\n          { name: 'version', type: 'string' },\n          { name: 'chainId', type: 'uint256' },\n          { name: 'verifyingContract', type: 'address' },\n        ],\n        ...types,\n      },\n      primaryType,\n      domain: this.domain,\n      message: value,\n    }\n\n    // For ethers v6, we need to access the underlying EIP-1193 provider\n    let eip1193Provider: any\n    if ('_eip1193Provider' in provider) {\n      // BrowserProvider in ethers v6\n      eip1193Provider = (provider as any)._eip1193Provider\n    } else if ('request' in provider) {\n      // Already an EIP-1193 provider\n      eip1193Provider = provider\n    } else {\n      // Fallback to provider.send\n      eip1193Provider = provider\n    }\n\n    // Call MetaMask directly for better UX\n    let signature: string\n    if (eip1193Provider != null && 'request' in eip1193Provider) {\n      // Use EIP-1193 request method\n      signature = await eip1193Provider.request({\n        method: 'eth_signTypedData_v4',\n        params: [signerAddress, JSON.stringify(typedData)],\n      })\n    } else {\n      // Fallback to send method\n      signature = await (provider as any).send('eth_signTypedData_v4', [signerAddress, JSON.stringify(typedData)])\n    }\n\n    return signature\n  }\n\n  /**\n   * Create signature for data set creation\n   *\n   * This signature authorizes a service provider to create a new data set\n   * on behalf of the client. The signature includes the client's dataset ID,\n   * the service provider's payment address, and CDN preference.\n   *\n   * @param clientDataSetId - Unique dataset ID for the client (typically starts at 0 and increments)\n   * @param payee - Service provider's address that will receive payments\n   * @param metadata - Service parameters as key-value pairs\n   * @returns Promise resolving to authentication signature for data set creation\n   *\n   * @example\n   * ```typescript\n   * const auth = new PDPAuthHelper(contractAddress, signer, chainId)\n   * const signature = await auth.signCreateDataSet(\n   *   0,                                // First dataset for this client\n   *   '0x1234...abcd',                  // Service provider address\n   *   PDPAuthHelper.WITH_CDN_METADATA   // Enable CDN service\n   * )\n   * ```\n   */\n  async signCreateDataSet(\n    clientDataSetId: bigint,\n    payee: string,\n    metadata: MetadataEntry[] = []\n  ): Promise<AuthSignature> {\n    let signature: string\n    const types = { CreateDataSet: EIP712_TYPES.CreateDataSet, MetadataEntry: EIP712_TYPES.MetadataEntry }\n\n    // Check if we should use MetaMask-friendly signing\n    const useMetaMask = await this.isMetaMaskSigner()\n\n    if (useMetaMask) {\n      // Use MetaMask-friendly signing for better UX\n      const value = {\n        clientDataSetId: clientDataSetId.toString(), // Keep as string for MetaMask display\n        metadata,\n        payee,\n      }\n\n      signature = await this.signWithMetaMask(types, value)\n    } else {\n      // Use standard ethers.js signing (for private keys, etc)\n      const value = {\n        clientDataSetId,\n        metadata,\n        payee,\n      }\n\n      // Use underlying signer for typed data signing (handles NonceManager)\n      const actualSigner = this.getUnderlyingSigner()\n      signature = await actualSigner.signTypedData(this.domain, types, value)\n    }\n\n    // Return signature with components\n    const sig = ethers.Signature.from(signature)\n\n    // For EIP-712, signedData contains the actual message hash that was signed\n    const signedData = ethers.TypedDataEncoder.hash(this.domain, types, {\n      clientDataSetId,\n      metadata,\n      payee,\n    })\n\n    return {\n      signature,\n      v: sig.v,\n      r: sig.r,\n      s: sig.s,\n      signedData,\n    }\n  }\n\n  /**\n   * Create signature for adding pieces to a data set\n   *\n   * This signature authorizes a service provider to add new data pieces\n   * to an existing data set. Each piece represents aggregated data that\n   * will be proven using PDP challenges.\n   *\n   * @param clientDataSetId - Client's dataset ID (same as used in createDataSet)\n   * @param nonce - Random nonce for replay protection\n   * @param pieceDataArray - Array of piece data containing PieceCID CIDs and raw sizes\n   * @returns Promise resolving to authentication signature for adding pieces\n   *\n   * @example\n   * ```typescript\n   * const auth = new PDPAuthHelper(contractAddress, signer, chainId)\n   * const pieceData = [{\n   *   cid: 'bafkzcibc...', // PieceCID of aggregated data\n   *   rawSize: Number(SIZE_CONSTANTS.MiB)     // Raw size in bytes before padding\n   * }]\n   * const nonce = randU256() // Generate random nonce\n   * const signature = await auth.signAddPieces(\n   *   0,           // Same dataset ID as data set creation\n   *   nonce,       // Random nonce for replay protection\n   *   pieceData    // Array of pieces to add\n   * )\n   * ```\n   */\n  async signAddPieces(\n    clientDataSetId: bigint,\n    nonce: bigint,\n    pieceDataArray: PieceCID[] | string[],\n    metadata: MetadataEntry[][] = []\n  ): Promise<AuthSignature> {\n    if (metadata.length === 0) {\n      // make metadata array match length of pieceDataArray\n      metadata = Array(pieceDataArray.length).fill([])\n    } else if (metadata.length !== pieceDataArray.length) {\n      throw new Error('metadata length must match pieceDataArray length')\n    }\n\n    const pieceMetadata: { pieceIndex: number; metadata: MetadataEntry[] }[] = []\n\n    // Transform the piece data into the proper format for EIP-712\n    const formattedPieceData = []\n    for (let i = 0; i < pieceDataArray.length; i++) {\n      const piece = pieceDataArray[i]\n      const pieceCid = typeof piece === 'string' ? asPieceCID(piece) : piece\n      if (pieceCid == null) {\n        throw new Error(`Invalid PieceCID: ${String(pieceCid)}`)\n      }\n\n      // Format as nested structure matching Solidity's Cids.Cid struct\n      formattedPieceData.push({\n        data: pieceCid.bytes, // This will be a Uint8Array\n      })\n      pieceMetadata.push({\n        pieceIndex: i,\n        metadata: metadata[i],\n      })\n    }\n    const types = {\n      AddPieces: EIP712_TYPES.AddPieces,\n      Cid: EIP712_TYPES.Cid,\n      PieceMetadata: EIP712_TYPES.PieceMetadata,\n      MetadataEntry: EIP712_TYPES.MetadataEntry,\n    }\n\n    let signature: string\n\n    // Check if we should use MetaMask-friendly signing\n    const useMetaMask = await this.isMetaMaskSigner()\n\n    if (useMetaMask) {\n      // Use MetaMask-friendly signing with properly structured data\n      const value = {\n        clientDataSetId: clientDataSetId.toString(), // Keep as string for MetaMask display\n        nonce: nonce.toString(), // Keep as string for MetaMask display\n        pieceData: formattedPieceData.map((item) => ({\n          data: ethers.hexlify(item.data), // Convert Uint8Array to hex string for MetaMask\n        })),\n        pieceMetadata: pieceMetadata,\n      }\n\n      signature = await this.signWithMetaMask(types, value)\n    } else {\n      // Use standard ethers.js signing with bigint values\n      const value = {\n        clientDataSetId,\n        nonce,\n        pieceData: formattedPieceData,\n        pieceMetadata: pieceMetadata,\n      }\n\n      // Use underlying signer for typed data signing (handles NonceManager)\n      const actualSigner = this.getUnderlyingSigner()\n      signature = await actualSigner.signTypedData(this.domain, types, value)\n    }\n\n    // Return signature with components\n    const sig = ethers.Signature.from(signature)\n\n    // For EIP-712, signedData contains the actual message hash that was signed\n    const signedData = ethers.TypedDataEncoder.hash(this.domain, types, {\n      clientDataSetId,\n      nonce,\n      pieceData: formattedPieceData,\n      pieceMetadata: pieceMetadata,\n    })\n\n    return {\n      signature,\n      v: sig.v,\n      r: sig.r,\n      s: sig.s,\n      signedData,\n    }\n  }\n\n  /**\n   * Create signature for scheduling piece removals\n   *\n   * This signature authorizes a service provider to schedule specific pieces\n   * for removal from the data set. Pieces are typically removed after the\n   * next successful proof submission.\n   *\n   * @param clientDataSetId - Client's dataset ID\n   * @param pieceIds - Array of piece IDs to schedule for removal\n   * @returns Promise resolving to authentication signature for scheduling removals\n   *\n   * @example\n   * ```typescript\n   * const auth = new PDPAuthHelper(contractAddress, signer, chainId)\n   * const signature = await auth.signSchedulePieceRemovals(\n   *   0,           // Dataset ID\n   *   [1, 2, 3]    // Piece IDs to remove\n   * )\n   * ```\n   */\n  async signSchedulePieceRemovals(clientDataSetId: bigint, pieceIds: Array<bigint>): Promise<AuthSignature> {\n    let signature: string\n\n    // Check if we should use MetaMask-friendly signing\n    const useMetaMask = await this.isMetaMaskSigner()\n\n    if (useMetaMask) {\n      // Use MetaMask-friendly signing for better UX\n      const value = {\n        clientDataSetId: clientDataSetId.toString(), // Keep as string for MetaMask display\n        pieceIds: pieceIds.map((id) => id.toString()), // Convert to string array for display\n      }\n\n      signature = await this.signWithMetaMask({ SchedulePieceRemovals: EIP712_TYPES.SchedulePieceRemovals }, value)\n    } else {\n      // Use standard ethers.js signing with BigInt values\n      const value = { clientDataSetId, pieceIds }\n\n      // Use underlying signer for typed data signing (handles NonceManager)\n      const actualSigner = this.getUnderlyingSigner()\n      signature = await actualSigner.signTypedData(\n        this.domain,\n        { SchedulePieceRemovals: EIP712_TYPES.SchedulePieceRemovals },\n        value\n      )\n    }\n\n    const sig = ethers.Signature.from(signature)\n\n    // For EIP-712, signedData contains the actual message hash that was signed\n    const signedData = ethers.TypedDataEncoder.hash(\n      this.domain,\n      { SchedulePieceRemovals: EIP712_TYPES.SchedulePieceRemovals },\n      { clientDataSetId, pieceIds }\n    )\n\n    return {\n      signature,\n      v: sig.v,\n      r: sig.r,\n      s: sig.s,\n      signedData,\n    }\n  }\n\n  /**\n   * Create signature for data set deletion\n   *\n   * This signature authorizes complete deletion of a data set and all\n   * its associated data. This action is irreversible and will terminate\n   * the storage service for this dataset.\n   *\n   * @param clientDataSetId - Client's dataset ID to delete\n   * @returns Promise resolving to authentication signature for data set deletion\n   *\n   * @example\n   * ```typescript\n   * const auth = new PDPAuthHelper(contractAddress, signer, chainId)\n   * const signature = await auth.signDeleteDataSet(\n   *   0  // Dataset ID to delete\n   * )\n   * ```\n   */\n  async signDeleteDataSet(clientDataSetId: bigint): Promise<AuthSignature> {\n    let signature: string\n\n    // Check if we should use MetaMask-friendly signing\n    const useMetaMask = await this.isMetaMaskSigner()\n\n    if (useMetaMask) {\n      // Use MetaMask-friendly signing for better UX\n      const value = {\n        clientDataSetId: clientDataSetId.toString(), // Keep as string for MetaMask display\n      }\n\n      signature = await this.signWithMetaMask({ DeleteDataSet: EIP712_TYPES.DeleteDataSet }, value)\n    } else {\n      // Use standard ethers.js signing\n      const value = { clientDataSetId }\n\n      // Use underlying signer for typed data signing (handles NonceManager)\n      const actualSigner = this.getUnderlyingSigner()\n      signature = await actualSigner.signTypedData(this.domain, { DeleteDataSet: EIP712_TYPES.DeleteDataSet }, value)\n    }\n\n    const sig = ethers.Signature.from(signature)\n\n    // For EIP-712, signedData contains the actual message hash that was signed\n    const signedData = ethers.TypedDataEncoder.hash(\n      this.domain,\n      { DeleteDataSet: EIP712_TYPES.DeleteDataSet },\n      { clientDataSetId }\n    )\n\n    return {\n      signature,\n      v: sig.v,\n      r: sig.r,\n      s: sig.s,\n      signedData,\n    }\n  }\n\n  /**\n   * Get the address of the signer\n   * @returns Promise resolving to the signer's Ethereum address\n   */\n  async getSignerAddress(): Promise<string> {\n    return await this.signer.getAddress()\n  }\n}\n","import { SIZE_CONSTANTS } from '../utils/constants.ts'\nimport { decodePDPError } from '../utils/decode-pdp-errors.ts'\nimport { isSynapseError, SynapseError } from './base.ts'\n\nexport class LocationHeaderError extends SynapseError {\n  override name: 'LocationHeaderError' = 'LocationHeaderError'\n\n  constructor(location?: string | null) {\n    super(`Location header format is invalid: ${location ?? '<none>'}`)\n  }\n\n  static override is(value: unknown): value is LocationHeaderError {\n    return isSynapseError(value) && value.name === 'LocationHeaderError'\n  }\n}\n\nexport class CreateDataSetError extends SynapseError {\n  override name: 'CreateDataSetError' = 'CreateDataSetError'\n\n  constructor(error: string) {\n    const decodedError = decodePDPError(error)\n    super(`Failed to create data set.`, {\n      details: decodedError,\n    })\n  }\n\n  static override is(value: unknown): value is CreateDataSetError {\n    return isSynapseError(value) && value.name === 'CreateDataSetError'\n  }\n}\n\nexport class PollDataSetCreationStatusError extends SynapseError {\n  override name: 'PollDataSetCreationStatusError' = 'PollDataSetCreationStatusError'\n\n  constructor(error: string) {\n    const decodedError = decodePDPError(error)\n    super(`Failed to check data set creation status.`, {\n      details: decodedError,\n    })\n  }\n\n  static override is(value: unknown): value is PollDataSetCreationStatusError {\n    return isSynapseError(value) && value.name === 'PollDataSetCreationStatusError'\n  }\n}\n\nexport class GetDataSetError extends SynapseError {\n  override name: 'GetDataSetError' = 'GetDataSetError'\n\n  constructor(error: string) {\n    super(error ? 'Failed to get data set.' : 'Data set not found.', {\n      details: error ? decodePDPError(error) : undefined,\n    })\n  }\n\n  static override is(value: unknown): value is GetDataSetError {\n    return isSynapseError(value) && value.name === 'GetDataSetError'\n  }\n}\n\nexport class PostPieceError extends SynapseError {\n  override name: 'PostPieceError' = 'PostPieceError'\n\n  constructor(error: string) {\n    const decodedError = decodePDPError(error)\n    super(`Failed to create upload session.`, {\n      details: decodedError,\n    })\n  }\n\n  static override is(value: unknown): value is PostPieceError {\n    return isSynapseError(value) && value.name === 'PostPieceError'\n  }\n}\n\nexport class UploadPieceError extends SynapseError {\n  override name: 'UploadPieceError' = 'UploadPieceError'\n\n  constructor(error: string) {\n    const decodedError = decodePDPError(error)\n    super(`Failed to upload piece.`, {\n      details: decodedError,\n    })\n  }\n\n  static override is(value: unknown): value is UploadPieceError {\n    return isSynapseError(value) && value.name === 'UploadPieceError'\n  }\n}\n\nexport class FindPieceError extends SynapseError {\n  override name: 'FindPieceError' = 'FindPieceError'\n\n  constructor(error: string) {\n    const decodedError = decodePDPError(error)\n    super(`Failed to find piece.`, {\n      details: decodedError,\n    })\n  }\n\n  static override is(value: unknown): value is FindPieceError {\n    return isSynapseError(value) && value.name === 'FindPieceError'\n  }\n}\n\nexport class AddPiecesError extends SynapseError {\n  override name: 'AddPiecesError' = 'AddPiecesError'\n\n  constructor(error: string) {\n    const decodedError = decodePDPError(error)\n    super(`Failed to add pieces.`, {\n      details: decodedError,\n    })\n  }\n\n  static override is(value: unknown): value is AddPiecesError {\n    return isSynapseError(value) && value.name === 'AddPiecesError'\n  }\n}\n\nexport class PollForAddPiecesStatusError extends SynapseError {\n  override name: 'PollForAddPiecesStatusError' = 'PollForAddPiecesStatusError'\n\n  constructor(error: string) {\n    const decodedError = decodePDPError(error)\n    super(`Failed to poll for add pieces status.`, {\n      details: decodedError,\n    })\n  }\n\n  static override is(value: unknown): value is PollForAddPiecesStatusError {\n    return isSynapseError(value) && value.name === 'PollForAddPiecesStatusError'\n  }\n}\n\nexport class DeletePieceError extends SynapseError {\n  override name: 'DeletePieceError' = 'DeletePieceError'\n\n  constructor(error: string) {\n    const decodedError = decodePDPError(error)\n    super(`Failed to delete piece.`, {\n      details: decodedError,\n    })\n  }\n\n  static override is(value: unknown): value is DeletePieceError {\n    return isSynapseError(value) && value.name === 'DeletePieceError'\n  }\n}\n\nexport class InvalidUploadSizeError extends SynapseError {\n  override name: 'InvalidUploadSizeError' = 'InvalidUploadSizeError'\n\n  constructor(size: number) {\n    super(`Invalid upload size.`, {\n      details: `Size ${size} bytes is below minimum allowed size of ${SIZE_CONSTANTS.MIN_UPLOAD_SIZE} bytes or exceeds maximum allowed size of ${SIZE_CONSTANTS.MAX_UPLOAD_SIZE} bytes`,\n    })\n  }\n}\n","/**\n * Type guards and validation utilities for PDP server responses\n *\n * These validators ensure that responses from untrusted PDP servers\n * match the expected format before using them in the SDK.\n */\n\nimport { asPieceCID } from '@filoz/synapse-core/piece'\nimport type { DataSetData, DataSetPieceData } from '../types.ts'\nimport type {\n  DataSetCreationStatusResponse,\n  FindPieceResponse,\n  PieceAdditionStatusResponse,\n  PieceStatusResponse,\n} from './server.ts'\n\n/**\n * Type guard for DataSetCreationStatusResponse\n * Validates the response from checking data set creation status\n *\n * @param value - The value to validate\n * @returns True if the value matches DataSetCreationStatusResponse interface\n */\nexport function isDataSetCreationStatusResponse(value: unknown): value is DataSetCreationStatusResponse {\n  if (typeof value !== 'object' || value == null) {\n    return false\n  }\n\n  const obj = value as Record<string, unknown>\n\n  // Required fields\n  if (typeof obj.createMessageHash !== 'string') {\n    return false\n  }\n  if (typeof obj.dataSetCreated !== 'boolean') {\n    return false\n  }\n  if (typeof obj.service !== 'string') {\n    return false\n  }\n  if (typeof obj.txStatus !== 'string') {\n    return false\n  }\n  if (obj.ok !== null && typeof obj.ok !== 'boolean') {\n    return false\n  }\n\n  // Optional field\n  if (obj.dataSetId !== undefined && typeof obj.dataSetId !== 'number') {\n    return false\n  }\n\n  return true\n}\n\n/**\n * Type guard for PieceAdditionStatusResponse\n * Validates the response from checking piece addition status\n *\n * @param value - The value to validate\n * @returns True if the value matches PieceAdditionStatusResponse interface\n */\nexport function isPieceAdditionStatusResponse(value: unknown): value is PieceAdditionStatusResponse {\n  if (typeof value !== 'object' || value == null) {\n    return false\n  }\n\n  const obj = value as Record<string, unknown>\n\n  // Required fields\n  if (typeof obj.txHash !== 'string') {\n    return false\n  }\n  if (typeof obj.txStatus !== 'string') {\n    return false\n  }\n  if (typeof obj.dataSetId !== 'number') {\n    return false\n  }\n  if (typeof obj.pieceCount !== 'number') {\n    return false\n  }\n  if (obj.addMessageOk !== null && typeof obj.addMessageOk !== 'boolean') {\n    return false\n  }\n\n  // Optional field - confirmedPieceIds\n  if (obj.confirmedPieceIds !== undefined) {\n    if (!Array.isArray(obj.confirmedPieceIds)) {\n      return false\n    }\n    // Check all elements are numbers\n    for (const id of obj.confirmedPieceIds) {\n      if (typeof id !== 'number') {\n        return false\n      }\n    }\n  }\n\n  return true\n}\n\n/**\n * Type guard for FindPieceResponse\n * Validates the response from finding a piece\n * Supports both pieceCid (new) and piece_cid (legacy) field names for backward compatibility\n *\n * @param value - The value to validate\n * @returns True if the value matches FindPieceResponse interface\n */\nexport function isFindPieceResponse(value: unknown): value is FindPieceResponse {\n  if (typeof value !== 'object' || value == null) {\n    return false\n  }\n\n  const obj = value as Record<string, unknown>\n\n  if (typeof obj.pieceCid !== 'string') {\n    return false\n  }\n\n  // Validate that the piece CID is a valid PieceCID\n  if (asPieceCID(obj.pieceCid) == null) {\n    return false\n  }\n\n  return true\n}\n\n/**\n * Validates and returns a DataSetCreationStatusResponse\n * @param value - The value to validate\n * @throws Error if validation fails\n */\nexport function validateDataSetCreationStatusResponse(value: unknown): DataSetCreationStatusResponse {\n  if (!isDataSetCreationStatusResponse(value)) {\n    throw new Error('Invalid data set creation status response format')\n  }\n  return value\n}\n\nexport function validatePieceDeleteResponse(value: unknown): { txHash: string } {\n  if (typeof value !== 'object' || value == null) {\n    throw new Error('Invalid piece delete response format')\n  }\n\n  const obj = value as Record<string, unknown>\n\n  if (typeof obj.txHash !== 'string') {\n    throw new Error('Invalid piece delete response format')\n  }\n\n  return {\n    txHash: obj.txHash,\n  }\n}\n\n/**\n * Validates and returns a PieceAdditionStatusResponse\n * @param value - The value to validate\n * @throws Error if validation fails\n */\nexport function validatePieceAdditionStatusResponse(value: unknown): PieceAdditionStatusResponse {\n  if (!isPieceAdditionStatusResponse(value)) {\n    throw new Error('Invalid piece addition status response format')\n  }\n  return value\n}\n\n/**\n * Validates and returns a FindPieceResponse\n * Normalizes the response to always have pieceCid field as a PieceCID object\n * @param value - The value to validate\n * @throws Error if validation fails\n */\nexport function validateFindPieceResponse(value: unknown): FindPieceResponse {\n  if (!isFindPieceResponse(value)) {\n    // Check if it failed specifically due to invalid PieceCID\n    if (typeof value === 'object' && value != null) {\n      const obj = value as Record<string, unknown>\n      const cidStr = (obj.pieceCid ?? obj.piece_cid) as string | undefined\n      if (cidStr != null && asPieceCID(cidStr) == null) {\n        throw new Error('Invalid find piece response: pieceCid is not a valid PieceCID')\n      }\n    }\n    throw new Error('Invalid find piece response format')\n  }\n\n  const obj = value as any\n\n  // Get the CID string from either field\n  const cidStr = (obj.pieceCid ?? obj.piece_cid) as string\n\n  // Convert to PieceCID object (we know it's valid because isFindPieceResponse already checked)\n  const pieceCid = asPieceCID(cidStr)\n  if (pieceCid == null) {\n    // This should never happen since we validated above, but just in case\n    throw new Error('Invalid find piece response: pieceCid is not a valid PieceCID')\n  }\n\n  // Return normalized response with PieceCID object\n  return {\n    pieceCid,\n  }\n}\n\n/**\n * Type guard for PieceStatusResponse\n * Validates the response from checking piece indexing and IPNI status\n *\n * @param value - The value to validate\n * @returns True if the value matches PieceStatusResponse interface\n */\nexport function isPieceStatusResponse(value: unknown): value is PieceStatusResponse {\n  if (typeof value !== 'object' || value == null) {\n    return false\n  }\n\n  const obj = value as Record<string, unknown>\n\n  // Required fields\n  if (typeof obj.pieceCid !== 'string') {\n    return false\n  }\n  if (typeof obj.status !== 'string') {\n    return false\n  }\n  if (typeof obj.indexed !== 'boolean') {\n    return false\n  }\n  if (typeof obj.advertised !== 'boolean') {\n    return false\n  }\n  if (typeof obj.retrieved !== 'boolean') {\n    return false\n  }\n\n  // Optional field\n  if (obj.retrievedAt !== undefined && typeof obj.retrievedAt !== 'string') {\n    return false\n  }\n\n  return true\n}\n\n/**\n * Validates and returns a PieceStatusResponse\n * @param value - The value to validate\n * @throws Error if validation fails\n */\nexport function validatePieceStatusResponse(value: unknown): PieceStatusResponse {\n  if (!isPieceStatusResponse(value)) {\n    throw new Error('Invalid piece status response format')\n  }\n  return value\n}\n\n/**\n * Converts and validates individual data set piece data\n * Returns null if validation fails\n *\n * @param value - The value to validate and convert\n * @returns Converted DataSetPieceData or null if invalid\n */\nexport function asDataSetPieceData(value: unknown): DataSetPieceData | null {\n  if (typeof value !== 'object' || value == null) {\n    return null\n  }\n\n  const obj = value as Record<string, unknown>\n\n  // Required fields\n  if (typeof obj.pieceId !== 'number') {\n    return null\n  }\n  if (typeof obj.pieceCid !== 'string') {\n    return null\n  }\n  if (typeof obj.subPieceCid !== 'string') {\n    return null\n  }\n  if (typeof obj.subPieceOffset !== 'number') {\n    return null\n  }\n\n  // Convert CIDs to PieceCID objects\n  const pieceCid = asPieceCID(obj.pieceCid)\n  const subPieceCid = asPieceCID(obj.subPieceCid)\n  if (pieceCid == null || subPieceCid == null) {\n    return null\n  }\n\n  return {\n    pieceId: obj.pieceId,\n    pieceCid,\n    subPieceCid,\n    subPieceOffset: obj.subPieceOffset,\n  }\n}\n\n/**\n * Converts and validates data set data\n * Returns null if validation fails\n *\n * @param value - The value to validate and convert\n * @returns Converted DataSetData or null if invalid\n */\nexport function asDataSetData(value: unknown): DataSetData | null {\n  if (typeof value !== 'object' || value == null) {\n    return null\n  }\n\n  const obj = value as Record<string, unknown>\n\n  // Required field - id\n  if (typeof obj.id !== 'number') {\n    return null\n  }\n\n  // Required field - pieces (array of DataSetPieceData)\n  if (!Array.isArray(obj.pieces)) {\n    return null\n  }\n\n  const convertedPieces: DataSetPieceData[] = []\n  for (const piece of obj.pieces) {\n    const convertedPiece = asDataSetPieceData(piece)\n    if (convertedPiece == null) {\n      return null\n    }\n    convertedPieces.push(convertedPiece)\n  }\n\n  // Required field - nextChallengeEpoch\n  if (typeof obj.nextChallengeEpoch !== 'number') {\n    return null\n  }\n\n  return {\n    id: obj.id,\n    pieces: convertedPieces,\n    nextChallengeEpoch: obj.nextChallengeEpoch,\n  }\n}\n","import type { Hex } from 'viem'\nimport { bytesToHex, hexToString, isHex, numberToBytes, stringToHex, toBytes } from 'viem'\nimport type { PDPOffering } from '../warm-storage/providers.ts'\nimport { decodeAddressCapability } from './capabilities.ts'\n\n// Standard capability keys for PDP product type (must match ServiceProviderRegistry.sol REQUIRED_PDP_KEYS)\nexport const CAP_SERVICE_URL = 'serviceURL'\nexport const CAP_MIN_PIECE_SIZE = 'minPieceSizeInBytes'\nexport const CAP_MAX_PIECE_SIZE = 'maxPieceSizeInBytes'\nexport const CAP_IPNI_PIECE = 'ipniPiece' // Optional\nexport const CAP_IPNI_IPFS = 'ipniIpfs' // Optional\nexport const CAP_STORAGE_PRICE = 'storagePricePerTibPerDay'\nexport const CAP_MIN_PROVING_PERIOD = 'minProvingPeriodInEpochs'\nexport const CAP_LOCATION = 'location'\nexport const CAP_PAYMENT_TOKEN = 'paymentTokenAddress'\n\n/**\n * Decode PDP capabilities from keys/values arrays into a PDPOffering object.\n * Based on Curio's capabilitiesToOffering function.\n */\nexport function decodePDPCapabilities(capabilities: Record<string, Hex>): PDPOffering {\n  return {\n    serviceURL: hexToString(capabilities.serviceURL),\n    minPieceSizeInBytes: BigInt(capabilities.minPieceSizeInBytes),\n    maxPieceSizeInBytes: BigInt(capabilities.maxPieceSizeInBytes),\n    ipniPiece: 'ipniPiece' in capabilities,\n    ipniIpfs: 'ipniIpfs' in capabilities,\n    storagePricePerTibPerDay: BigInt(capabilities.storagePricePerTibPerDay),\n    minProvingPeriodInEpochs: BigInt(capabilities.minProvingPeriodInEpochs),\n    location: hexToString(capabilities.location),\n    paymentTokenAddress: decodeAddressCapability(capabilities.paymentTokenAddress),\n  }\n}\n\nexport function encodePDPCapabilities(\n  pdpOffering: PDPOffering,\n  capabilities?: Record<string, string>\n): [string[], Hex[]] {\n  const capabilityKeys = []\n  const capabilityValues: Hex[] = []\n\n  capabilityKeys.push(CAP_SERVICE_URL)\n  capabilityValues.push(stringToHex(pdpOffering.serviceURL))\n  capabilityKeys.push(CAP_MIN_PIECE_SIZE)\n  capabilityValues.push(bytesToHex(numberToBytes(pdpOffering.minPieceSizeInBytes)))\n  capabilityKeys.push(CAP_MAX_PIECE_SIZE)\n  capabilityValues.push(bytesToHex(numberToBytes(pdpOffering.maxPieceSizeInBytes)))\n  if (pdpOffering.ipniPiece) {\n    capabilityKeys.push(CAP_IPNI_PIECE)\n    capabilityValues.push('0x01')\n  }\n  if (pdpOffering.ipniIpfs) {\n    capabilityKeys.push(CAP_IPNI_IPFS)\n    capabilityValues.push('0x01')\n  }\n  capabilityKeys.push(CAP_STORAGE_PRICE)\n  capabilityValues.push(bytesToHex(numberToBytes(pdpOffering.storagePricePerTibPerDay)))\n  capabilityKeys.push(CAP_MIN_PROVING_PERIOD)\n  capabilityValues.push(bytesToHex(numberToBytes(pdpOffering.minProvingPeriodInEpochs)))\n  capabilityKeys.push(CAP_LOCATION)\n  capabilityValues.push(stringToHex(pdpOffering.location))\n  capabilityKeys.push(CAP_PAYMENT_TOKEN)\n  capabilityValues.push(pdpOffering.paymentTokenAddress)\n\n  if (capabilities != null) {\n    for (const [key, value] of Object.entries(capabilities)) {\n      capabilityKeys.push(key)\n      if (!value) {\n        capabilityValues.push('0x01')\n      } else if (isHex(value)) {\n        capabilityValues.push(value)\n      } else {\n        capabilityValues.push(bytesToHex(toBytes(value)))\n      }\n    }\n  }\n\n  return [capabilityKeys, capabilityValues]\n}\n","/**\n * SPRegistryService - Service for interacting with ServiceProviderRegistry contract\n *\n * Manages service provider registration, product offerings, and provider queries.\n * Handles encoding/decoding of product data internally.\n *\n * @example\n * ```typescript\n * import { SPRegistryService } from '@filoz/synapse-sdk/sp-registry'\n *\n * const spRegistry = await SPRegistryService.create(provider, registryAddress)\n *\n * // Register as a provider\n * const tx = await spRegistry.registerProvider(signer, {\n *   name: 'My Storage Service',\n *   description: 'Fast and reliable storage',\n *   pdpOffering: { ... }\n * })\n *\n * // Query providers\n * const providers = await spRegistry.getAllActiveProviders()\n * ```\n */\n\nimport { capabilitiesListToObject, decodePDPCapabilities, encodePDPCapabilities } from '@filoz/synapse-core/utils'\nimport { ethers } from 'ethers'\nimport { CONTRACT_ABIS, CONTRACT_ADDRESSES } from '../utils/constants.ts'\nimport { getFilecoinNetworkType } from '../utils/index.ts'\nimport type {\n  PDPOffering,\n  PDPServiceInfo,\n  ProductType,\n  ProviderInfo,\n  ProviderRegistrationInfo,\n  ServiceProduct,\n} from './types.ts'\n\nexport class SPRegistryService {\n  private readonly _provider: ethers.Provider\n  private readonly _registryAddress: string\n  private _registryContract: ethers.Contract | null = null\n\n  /**\n   * Constructor for SPRegistryService\n   */\n  constructor(provider: ethers.Provider, registryAddress: string) {\n    this._provider = provider\n    this._registryAddress = registryAddress\n  }\n\n  /**\n   * Create a new SPRegistryService instance\n   */\n  static async create(provider: ethers.Provider, registryAddress: string): Promise<SPRegistryService> {\n    return new SPRegistryService(provider, registryAddress)\n  }\n\n  /**\n   * Get cached registry contract instance or create new one\n   */\n  private _getRegistryContract(): ethers.Contract {\n    if (this._registryContract == null) {\n      this._registryContract = new ethers.Contract(\n        this._registryAddress,\n        CONTRACT_ABIS.SERVICE_PROVIDER_REGISTRY,\n        this._provider\n      )\n    }\n    return this._registryContract\n  }\n\n  // ========== Provider Management ==========\n\n  /**\n   * Register as a new service provider with optional PDP product\n   * @param signer - Signer to register as provider\n   * @param info - Provider registration information\n   * @returns Transaction response containing the provider ID\n   *\n   * @example\n   * ```typescript\n   * const tx = await spRegistry.registerProvider(signer, {\n   *   payee: '0x...', // Address that will receive payments\n   *   name: 'My Storage Provider',\n   *   description: 'High-performance storage service',\n   *   pdpOffering: {\n   *     serviceURL: 'https://provider.example.com',\n   *     minPieceSizeInBytes: SIZE_CONSTANTS.KiB,\n   *     maxPieceSizeInBytes: SIZE_CONSTANTS.GiB,\n   *     // ... other PDP fields\n   *   },\n   *   capabilities: { 'region': 'us-east', 'tier': 'premium' }\n   * })\n   *\n   * // Wait for transaction and get provider ID from event\n   * const receipt = await tx.wait()\n   * const event = receipt.logs.find(log =>\n   *   log.topics[0] === ethers.id('ProviderRegistered(uint256,address,address)')\n   * )\n   * const providerId = event ? parseInt(event.topics[1], 16) : null\n   * ```\n   */\n  async registerProvider(signer: ethers.Signer, info: ProviderRegistrationInfo): Promise<ethers.TransactionResponse> {\n    const contract = this._getRegistryContract().connect(signer) as ethers.Contract\n\n    // Get registration fee\n    const registrationFee = await contract.REGISTRATION_FEE()\n\n    // Prepare product data and capabilities\n    const productType = 0 // ProductType.PDP\n\n    const [capabilityKeys, capabilityValues] = encodePDPCapabilities(info.pdpOffering, info.capabilities)\n\n    // Register provider with all parameters in a single call\n    const tx = await contract.registerProvider(\n      info.payee,\n      info.name,\n      info.description,\n      productType,\n      capabilityKeys,\n      capabilityValues,\n      { value: registrationFee }\n    )\n\n    return tx\n  }\n\n  /**\n   * Update provider information\n   * @param signer - Provider's signer\n   * @param name - New name\n   * @param description - New description\n   * @returns Transaction response\n   */\n  async updateProviderInfo(\n    signer: ethers.Signer,\n    name: string,\n    description: string\n  ): Promise<ethers.TransactionResponse> {\n    const contract = this._getRegistryContract().connect(signer) as ethers.Contract\n    return await contract.updateProviderInfo(name, description)\n  }\n\n  /**\n   * Remove provider registration\n   * @param signer - Provider's signer\n   * @returns Transaction response\n   */\n  async removeProvider(signer: ethers.Signer): Promise<ethers.TransactionResponse> {\n    const contract = this._getRegistryContract().connect(signer) as ethers.Contract\n    return await contract.removeProvider()\n  }\n\n  // ========== Provider Queries ==========\n\n  /**\n   * Get provider information by ID\n   * @param providerId - Provider ID\n   * @returns Provider info with decoded products\n   */\n  async getProvider(providerId: number): Promise<ProviderInfo | null> {\n    try {\n      const contract = this._getRegistryContract()\n      // TODO: use getProviderWithProduct\n      const rawProvider = await contract.getProvider(providerId)\n\n      if (rawProvider.info.serviceProvider === ethers.ZeroAddress) {\n        return null\n      }\n\n      // Get products for this provider\n      const products = await this._getProviderProducts(providerId)\n\n      return this._convertToProviderInfo(providerId, rawProvider.info, products)\n    } catch (error) {\n      if (error instanceof Error && error.message.includes('Provider not found')) {\n        return null\n      }\n      throw error\n    }\n  }\n\n  /**\n   * Get provider information by address\n   * @param address - Provider address\n   * @returns Provider info with decoded products\n   */\n  async getProviderByAddress(address: string): Promise<ProviderInfo | null> {\n    try {\n      const contract = this._getRegistryContract()\n      const provider = await contract.getProviderByAddress(address)\n\n      // Check if provider exists (beneficiary address will be zero if not found)\n      if (provider.info.serviceProvider === ethers.ZeroAddress) {\n        return null\n      }\n\n      // Get products for this provider and convert to ProviderInfo\n      const products = await this._getProviderProducts(Number(provider.providerId))\n      return this._convertToProviderInfo(Number(provider.providerId), provider.info, products)\n    } catch (error) {\n      console.warn('Error fetching provider by address:', error)\n      return null\n    }\n  }\n\n  /**\n   * Get provider ID by address\n   * @param address - Provider address\n   * @returns Provider ID (0 if not found)\n   */\n  async getProviderIdByAddress(address: string): Promise<number> {\n    const contract = this._getRegistryContract()\n    const id = await contract.getProviderIdByAddress(address)\n    return Number(id)\n  }\n\n  /**\n   * Get all active providers (handles pagination internally)\n   * @returns List of all active providers\n   */\n  async getAllActiveProviders(): Promise<ProviderInfo[]> {\n    const contract = this._getRegistryContract()\n    const providerPromises: Promise<ProviderInfo[]>[] = []\n    const pageSize = 50 // Fetch 50 providers at a time (conservative for multicall limits)\n    let offset = 0\n    let hasMore = true\n\n    // Loop through all pages and start fetching provider details in parallel\n    while (hasMore) {\n      const result = await contract.getAllActiveProviders(offset, pageSize)\n      const providerIds = result[0] // First element is the array of provider IDs\n      hasMore = result[1] // Second element is the hasMore flag\n\n      // Convert BigInt IDs to numbers and start fetching provider details\n      if (providerIds.length > 0) {\n        const ids = providerIds.map((id: bigint) => Number(id))\n        providerPromises.push(this.getProviders(ids))\n      }\n\n      offset += pageSize\n    }\n\n    // Wait for all provider details to be fetched and flatten the results\n    const providerBatches = await Promise.all(providerPromises)\n    return providerBatches.flat()\n  }\n\n  /**\n   * Get active providers by product type (handles pagination internally)\n   * @param productType - Product type to filter by\n   * @returns List of providers with specified product type\n   */\n  async getActiveProvidersByProductType(productType: ProductType): Promise<ProviderInfo[]> {\n    const contract = this._getRegistryContract()\n    const providerPromises: Promise<ProviderInfo[]>[] = []\n\n    let offset = 0\n    const limit = 50 // Fetch in batches (conservative for multicall limits)\n    let hasMore = true\n\n    // Loop through all pages and start fetching provider details in parallel\n    while (hasMore) {\n      const result = await contract.getProvidersByProductType(productType, true, offset, limit)\n\n      // Convert BigInt IDs to numbers and start fetching provider details\n      if (result.providerIds.length > 0) {\n        const ids = result.providerIds.map((id: bigint) => Number(id))\n        providerPromises.push(this.getProviders(ids))\n      }\n\n      hasMore = result.hasMore\n      offset += limit\n    }\n\n    // Wait for all provider details to be fetched and flatten the results\n    const providerBatches = await Promise.all(providerPromises)\n    const allProviders = providerBatches.flat()\n\n    return allProviders\n  }\n\n  /**\n   * Check if provider is active\n   * @param providerId - Provider ID\n   * @returns Whether provider is active\n   */\n  async isProviderActive(providerId: number): Promise<boolean> {\n    const contract = this._getRegistryContract()\n    return await contract.isProviderActive(providerId)\n  }\n\n  /**\n   * Check if address is a registered provider\n   * @param address - Address to check\n   * @returns Whether address is registered\n   */\n  async isRegisteredProvider(address: string): Promise<boolean> {\n    const contract = this._getRegistryContract()\n    return await contract.isRegisteredProvider(address)\n  }\n\n  /**\n   * Get total number of providers\n   * @returns Total provider count\n   */\n  async getProviderCount(): Promise<number> {\n    const contract = this._getRegistryContract()\n    const count = await contract.getProviderCount()\n    return Number(count)\n  }\n\n  /**\n   * Get number of active providers\n   * @returns Active provider count\n   */\n  async activeProviderCount(): Promise<number> {\n    const contract = this._getRegistryContract()\n    const count = await contract.activeProviderCount()\n    return Number(count)\n  }\n\n  // ========== Product Management ==========\n\n  /**\n   * Add PDP product to provider\n   * @param signer - Provider's signer\n   * @param pdpOffering - PDP offering details\n   * @param capabilities - Optional capability keys\n   * @returns Transaction response\n   */\n  async addPDPProduct(\n    signer: ethers.Signer,\n    pdpOffering: PDPOffering,\n    capabilities: Record<string, string> = {}\n  ): Promise<ethers.TransactionResponse> {\n    const contract = this._getRegistryContract().connect(signer) as ethers.Contract\n\n    // Encode PDP offering\n    const [capabilityKeys, capabilityValues] = encodePDPCapabilities(pdpOffering, capabilities)\n\n    // Add product\n    return await contract.addProduct(\n      0, // ProductType.PDP\n      capabilityKeys,\n      capabilityValues\n    )\n  }\n\n  /**\n   * Update PDP product with capabilities\n   * @param signer - Provider's signer\n   * @param pdpOffering - Updated PDP offering\n   * @param capabilities - Updated capability key-value pairs\n   * @returns Transaction response\n   */\n  async updatePDPProduct(\n    signer: ethers.Signer,\n    pdpOffering: PDPOffering,\n    capabilities: Record<string, string> = {}\n  ): Promise<ethers.TransactionResponse> {\n    const contract = this._getRegistryContract().connect(signer) as ethers.Contract\n\n    // Encode PDP offering\n    const [capabilityKeys, capabilityValues] = encodePDPCapabilities(pdpOffering, capabilities)\n\n    // Update product\n    return await contract.updateProduct(\n      0, // ProductType.PDP\n      capabilityKeys,\n      capabilityValues\n    )\n  }\n\n  /**\n   * Remove product from provider\n   * @param signer - Provider's signer\n   * @param productType - Type of product to remove\n   * @returns Transaction response\n   */\n  async removeProduct(signer: ethers.Signer, productType: ProductType): Promise<ethers.TransactionResponse> {\n    const contract = this._getRegistryContract().connect(signer) as ethers.Contract\n    return await contract.removeProduct(productType)\n  }\n\n  /**\n   * Get PDP service info for a provider\n   * @param providerId - Provider ID\n   * @returns PDP service info or null if not found\n   */\n  async getPDPService(providerId: number): Promise<PDPServiceInfo | null> {\n    try {\n      const contract = this._getRegistryContract()\n      const result = await contract.getProviderWithProduct(providerId, 0) // 0 = ProductType.PDP\n\n      // This also handles the case where the product does not exist\n      if (!result.product.isActive) {\n        return null\n      }\n\n      const capabilities = capabilitiesListToObject(result.product.capabilityKeys, result.productCapabilityValues)\n\n      return {\n        offering: decodePDPCapabilities(capabilities),\n        capabilities,\n        isActive: result.product.isActive,\n      }\n    } catch {\n      return null\n    }\n  }\n\n  /**\n   * Check if provider has a specific product type\n   * @param providerId - Provider ID\n   * @param productType - Product type to check\n   * @returns Whether provider has the product\n   */\n  async providerHasProduct(providerId: number, productType: ProductType): Promise<boolean> {\n    const contract = this._getRegistryContract()\n    return await contract.providerHasProduct(providerId, productType)\n  }\n\n  // ========== Batch Operations ==========\n\n  /**\n   * Get multiple providers by IDs using Multicall3 for efficiency\n   * @param providerIds - Array of provider IDs\n   * @returns Array of provider info\n   */\n  async getProviders(providerIds: number[]): Promise<ProviderInfo[]> {\n    if (providerIds.length === 0) {\n      return []\n    }\n\n    try {\n      // Use Multicall3 for efficiency\n      const result = await this._getProvidersWithMulticall(providerIds)\n      return result\n    } catch (_error) {\n      // TODO: Remove this fallback block and properly mock Multicall3 in tests\n      // The fallback is only needed because SPRegistryService tests don't currently\n      // mock Multicall3 calls. Once proper test infrastructure is in place, this\n      // try/catch and the _getProvidersIndividually method can be removed.\n      // Fall back to individual calls if Multicall3 fails\n      const result = await this._getProvidersIndividually(providerIds)\n      return result\n    }\n  }\n\n  /**\n   * Get providers using Multicall3 for batch efficiency\n   */\n  private async _getProvidersWithMulticall(providerIds: number[]): Promise<ProviderInfo[]> {\n    const network = await getFilecoinNetworkType(this._provider)\n    const multicall3Address = CONTRACT_ADDRESSES.MULTICALL3[network]\n    const multicall = new ethers.Contract(multicall3Address, CONTRACT_ABIS.MULTICALL3, this._provider)\n    const iface = new ethers.Interface(CONTRACT_ABIS.SERVICE_PROVIDER_REGISTRY)\n\n    // Prepare multicall batch\n    const calls = this._prepareMulticallCalls(providerIds, iface)\n\n    // Execute multicall\n    const results = await multicall.aggregate3.staticCall(calls)\n\n    // Process results\n    return this._processMulticallResults(providerIds, results, iface)\n  }\n\n  /**\n   * Prepare calls for Multicall3 batch\n   */\n  private _prepareMulticallCalls(\n    providerIds: number[],\n    iface: ethers.Interface\n  ): Array<{ target: string; allowFailure: boolean; callData: string }> {\n    const calls: Array<{ target: string; allowFailure: boolean; callData: string }> = []\n\n    for (const id of providerIds) {\n      // Add getProviderWithProduct call\n      calls.push({\n        target: this._registryAddress,\n        allowFailure: true,\n        callData: iface.encodeFunctionData('getProviderWithProduct', [id, 0]),\n      })\n    }\n\n    return calls\n  }\n\n  /**\n   * Process Multicall3 results into ProviderInfo array\n   */\n  private _processMulticallResults(providerIds: number[], results: any[], iface: ethers.Interface): ProviderInfo[] {\n    const providers: ProviderInfo[] = []\n\n    for (let i = 0; i < providerIds.length; i++) {\n      if (!results[i].success) {\n        continue\n      }\n\n      try {\n        const [, rawProvider, product, productCapabilityValues] = iface.decodeFunctionResult(\n          'getProviderWithProduct',\n          results[i].returnData\n        )[0]\n\n        const capabilities = capabilitiesListToObject(product.capabilityKeys, productCapabilityValues)\n        // Convert to ProviderInfo\n        const providerInfo = this._convertToProviderInfo(providerIds[i], rawProvider, [\n          {\n            type: 'PDP',\n            isActive: product.isActive,\n            capabilities,\n            data: decodePDPCapabilities(capabilities),\n          },\n        ])\n        if (providerInfo.serviceProvider === ethers.ZeroAddress) {\n          continue\n        }\n        providers.push(providerInfo)\n      } catch {\n        // Skip failed decoding\n      }\n    }\n\n    return providers\n  }\n\n  /**\n   * Fallback method to get providers individually\n   */\n  private async _getProvidersIndividually(providerIds: number[]): Promise<ProviderInfo[]> {\n    const providers: ProviderInfo[] = []\n    const promises = providerIds.map((id) => this.getProvider(id))\n    const results = await Promise.all(promises)\n\n    for (const provider of results) {\n      if (provider != null) {\n        providers.push(provider)\n      }\n    }\n\n    return providers\n  }\n\n  // ========== Internal Helpers ==========\n\n  /**\n   * Get products for a provider\n   * @param providerId - Provider ID\n   * @returns Array of decoded service products\n   */\n  private async _getProviderProducts(providerId: number): Promise<ServiceProduct[]> {\n    const products: ServiceProduct[] = []\n\n    // Get PDP product directly - getPDPService returns null if product doesn't exist\n    const pdpService = await this.getPDPService(providerId)\n    if (pdpService != null) {\n      products.push({\n        type: 'PDP',\n        isActive: pdpService.isActive,\n        capabilities: pdpService.capabilities,\n        data: pdpService.offering,\n      })\n    }\n\n    // Future: Add other product types here\n\n    return products\n  }\n\n  /**\n   * Convert raw provider data to ProviderInfo\n   */\n  private _convertToProviderInfo(providerId: number, providerInfo: any, productsArray: ServiceProduct[]): ProviderInfo {\n    // Convert products array to Record for direct access by type\n    const products: Partial<Record<'PDP', ServiceProduct>> = {}\n\n    for (const product of productsArray) {\n      if (product.type === 'PDP') {\n        products.PDP = product\n      }\n    }\n\n    return {\n      id: providerId,\n      serviceProvider: providerInfo.serviceProvider,\n      payee: providerInfo.payee,\n      name: providerInfo.name,\n      description: providerInfo.description,\n      active: providerInfo.isActive,\n      products,\n    }\n  }\n}\n","import packageJson from '../../package.json' with { type: 'json' }\n\n/**\n * Export the current SDK version from package.json so runtime code can stay in sync\n * without hardcoding the value in multiple places.\n */\nexport const SDK_VERSION = packageJson.version\n","import { CID, format, toJSON, fromJSON } from './cid.js'\nimport type * as API from './link/interface.js'\n// This way TS will also expose all the types from module\nexport * from './link/interface.js'\n\nconst DAG_PB_CODE = 0x70\n// eslint-disable-next-line\nconst SHA_256_CODE = 0x12\n\n/**\n * Simplified version of `create` for CIDv0.\n */\nexport function createLegacy (digest: API.MultihashDigest<typeof SHA_256_CODE>): API.LegacyLink {\n  return CID.create(0, DAG_PB_CODE, digest)\n}\n\n/**\n * Simplified version of `create` for CIDv1.\n *\n * @param code - Content encoding format code.\n * @param digest - Miltihash of the content.\n */\nexport function create <Data, Code extends number, Alg extends number> (code: Code, digest: API.MultihashDigest<Alg>): API.Link<Data, Code, Alg> {\n  return CID.create(1, code, digest)\n}\n\n/**\n * Type predicate returns true if value is the link.\n */\nexport function isLink <L extends API.Link<unknown, number, number, 0 | 1>> (value: unknown | L): value is L & CID {\n  if (value == null) {\n    return false\n  }\n\n  const withSlash = value as { '/'?: Uint8Array, bytes: Uint8Array }\n\n  if (withSlash['/'] != null && withSlash['/'] === withSlash.bytes) {\n    return true\n  }\n\n  const withAsCID = value as { asCID?: unknown }\n\n  if (withAsCID.asCID === value) {\n    return true\n  }\n\n  return false\n}\n\n/**\n * Takes cid in a string representation and creates an instance. If `base`\n * decoder is not provided will use a default from the configuration. It will\n * throw an error if encoding of the CID is not compatible with supplied (or\n * a default decoder).\n */\nexport function parse <Prefix extends string, Data, Code extends number, Alg extends number, Ver extends API.Version> (source: API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>, base?: API.MultibaseDecoder<Prefix>): API.Link<Data, Code, Alg, Ver> {\n  return CID.parse(source, base)\n}\n\nexport { format, toJSON, fromJSON }\n\n/**\n * Decoded a CID from its binary representation. The byte array must contain\n * only the CID with no additional bytes.\n *\n * An error will be thrown if the bytes provided do not contain a valid\n * binary representation of a CID.\n */\nexport function decode <Data, Code extends number, Alg extends number, Ver extends API.Version> (bytes: API.ByteView<API.Link<Data, Code, Alg, Ver>>): API.Link<Data, Code, Alg, Ver> {\n  return CID.decode(bytes)\n}\n","/**\n * Piece URL construction utilities\n *\n * These utilities help construct URLs for interacting with PDP servers\n * for piece discovery and retrieval operations.\n */\n\nimport type { PieceCID } from '../types.ts'\n\n/**\n * Construct a piece retrieval URL\n * @param retrievalEndpoint - The base retrieval endpoint URL\n * @param pieceCid - The PieceCID identifier\n * @returns Full URL for retrieving the piece\n */\nexport function constructPieceUrl(retrievalEndpoint: string, pieceCid: PieceCID): string {\n  const endpoint = retrievalEndpoint.replace(/\\/$/, '')\n  return `${endpoint}/piece/${pieceCid.toString()}`\n}\n\n/**\n * Construct a piece discovery (findPiece) URL\n * @param apiEndpoint - The base API endpoint URL\n * @param pieceCid - The PieceCID identifier\n * @returns Full URL for finding the piece\n */\nexport function constructFindPieceUrl(apiEndpoint: string, pieceCid: PieceCID): string {\n  const endpoint = apiEndpoint.replace(/\\/$/, '')\n  const params = new URLSearchParams({ pieceCid: pieceCid.toString() })\n  return `${endpoint}/pdp/piece?${params.toString()}`\n}\n","import { getGlobalTelemetry } from '../telemetry/singleton.ts'\n\n/**\n * Utility function to create descriptive errors with context\n */\nexport function createError(prefix: string, operation: string, details: string, originalError?: unknown): Error {\n  let baseMessage = `${prefix} ${operation} failed: ${details}`\n\n  // If there's an original error, append its message to provide full context\n  if (originalError != null && originalError instanceof Error) {\n    baseMessage = `${baseMessage} - ${originalError.message}`\n  }\n  let finalError: Error\n  if (originalError != null) {\n    finalError = new Error(baseMessage, { cause: originalError })\n  } else {\n    finalError = new Error(baseMessage)\n  }\n\n  // Capture to telemetry if enabled\n  // Generic error handling of uncaught errors is [configured automatically by Sentry](https://docs.sentry.io/platforms/javascript/troubleshooting/#third-party-promise-libraries).\n  getGlobalTelemetry()?.sentry?.captureException(finalError, {\n    tags: { operation: `${prefix}.${operation}` },\n    extra: {\n      synapseErrorPrefix: prefix,\n      synapseErrorOperation: operation,\n      synapseErrorDetails: details,\n      originalError,\n    },\n  })\n\n  return finalError\n}\n","/**\n * PieceCID (Piece Commitment CID) utilities\n *\n * Helper functions for working with Filecoin Piece CIDs\n */\n\nimport type { LegacyPieceLink as LegacyPieceCIDType, PieceLink as PieceCIDType } from '@web3-storage/data-segment'\nimport * as Hasher from '@web3-storage/data-segment/multihash'\nimport { Unpadded } from '@web3-storage/data-segment/piece/size'\nimport { CID } from 'multiformats/cid'\nimport * as Raw from 'multiformats/codecs/raw'\nimport * as Digest from 'multiformats/hashes/digest'\nimport * as Link from 'multiformats/link'\nimport { type Hex, hexToBytes } from 'viem'\n\nconst FIL_COMMITMENT_UNSEALED = 0xf101\nconst SHA2_256_TRUNC254_PADDED = 0x1012\n\n/**\n * Maximum upload size currently supported by PDP servers.\n *\n * 1 GiB adjusted for fr32 expansion: 1 GiB * (127/128) = 1,065,353,216 bytes\n *\n * Fr32 encoding adds 2 bits of padding per 254 bits of data, resulting in 128 bytes\n * of padded data for every 127 bytes of raw data.\n *\n * Note: While it's technically possible to upload pieces this large as Uint8Array,\n * streaming via AsyncIterable is strongly recommended for non-trivial sizes.\n * See SIZE_CONSTANTS.MAX_UPLOAD_SIZE in synapse-sdk for detailed guidance.\n */\nexport const MAX_UPLOAD_SIZE = 1_065_353_216 // 1 GiB * 127/128\n\n/**\n * PieceCID - A constrained CID type for Piece Commitments.\n * This is implemented as a Link type which is made concrete by a CID. A\n * PieceCID uses the raw codec (0x55) and the fr32-sha256-trunc254-padbintree\n * multihash function (0x1011) which encodes the base content length (as\n * padding) of the original piece, and the height of the merkle tree used to\n * hash it.\n *\n * See https://github.com/filecoin-project/FIPs/blob/master/FRCs/frc-0069.md\n * for more information.\n */\nexport type PieceCID = PieceCIDType\n\n/**\n * LegacyPieceCID - A constrained CID type for Legacy Piece Commitments.\n * This is implemented as a Link type which is made concrete by a CID.\n *\n * A LegacyPieceCID uses the fil-commitment-unsealed codec (0xf101) and the\n * sha2-256-trunc254-padded (0x1012) multihash function.\n *\n * This 32 bytes of the hash digest in a LegacyPieceCID is the same as the\n * equivalent PieceCID, but a LegacyPieceCID does not encode the length or\n * tree height of the original raw piece. A PieceCID can be converted to a\n * LegacyPieceCID, but not vice versa.\n *\n * LegacyPieceCID is commonly known as \"CommP\" or simply \"Piece Commitment\"\n * in Filecoin.\n */\nexport type LegacyPieceCID = LegacyPieceCIDType\n\n/**\n * Parse a PieceCID string into a CID and validate it\n * @param pieceCidString - The PieceCID as a string (base32 or other multibase encoding)\n * @returns The parsed and validated PieceCID CID or null if invalid\n */\nfunction parsePieceCID(pieceCidString: string): PieceCID | null {\n  try {\n    const cid = CID.parse(pieceCidString)\n    if (isValidPieceCID(cid)) {\n      return cid as PieceCID\n    }\n  } catch {\n    // ignore error\n  }\n  return null\n}\n\n/**\n * Parse a LegacyPieceCID string into a CID and validate it\n * @param pieceCidString - The LegacyPieceCID as a string (base32 or other multibase encoding)\n * @returns The parsed and validated LegacyPieceCID CID or null if invalid\n */\nfunction parseLegacyPieceCID(pieceCidString: string): LegacyPieceCID | null {\n  try {\n    const cid = CID.parse(pieceCidString)\n    if (isValidLegacyPieceCID(cid)) {\n      return cid as LegacyPieceCID\n    }\n  } catch {\n    // ignore error\n  }\n  return null\n}\n\n/**\n * Type guard to check if a value is a CID\n * @param value - The value to check\n * @returns True if it's a CID\n */\nfunction isCID(value: unknown): value is CID {\n  return typeof value === 'object' && value !== null && CID.asCID(value as CID) !== null\n}\n\n/**\n * Check if a CID is a valid PieceCID\n * @param cid - The CID to check\n * @returns True if it's a valid PieceCID\n */\nfunction isValidPieceCID(cid: PieceCID | CID): cid is PieceCID {\n  return cid.code === Raw.code && cid.multihash.code === Hasher.code\n}\n\n/**\n * Check if a CID is a valid LegacyPieceCID\n * @param cid - The CID to check\n * @returns True if it's a valid LegacyPieceCID\n */\nfunction isValidLegacyPieceCID(cid: LegacyPieceCID | CID): cid is LegacyPieceCID {\n  return cid.code === FIL_COMMITMENT_UNSEALED && cid.multihash.code === SHA2_256_TRUNC254_PADDED\n}\n\n/**\n * Convert a PieceCID input (string or CID) to a validated CID\n * This is the main function to use when accepting PieceCID inputs\n * @param pieceCidInput - PieceCID as either a CID object or string\n * @returns The validated PieceCID CID or null if not a valid PieceCID\n */\nexport function asPieceCID(pieceCidInput: PieceCID | CID | string | null | undefined): PieceCID | null {\n  if (pieceCidInput === null || pieceCidInput === undefined) {\n    return null\n  }\n\n  if (typeof pieceCidInput === 'string') {\n    return parsePieceCID(pieceCidInput)\n  }\n\n  if (isCID(pieceCidInput)) {\n    if (isValidPieceCID(pieceCidInput)) {\n      return pieceCidInput\n    }\n  }\n\n  return null\n}\n\n/**\n * Convert a LegacyPieceCID input (string or CID) to a validated CID\n * This function can be used to parse a LegacyPieceCID (CommPv1) or to downgrade a PieceCID\n * (CommPv2) to a LegacyPieceCID.\n * @param pieceCidInput - LegacyPieceCID as either a CID object or string\n * @returns The validated LegacyPieceCID CID or null if not a valid LegacyPieceCID\n */\nexport function asLegacyPieceCID(\n  pieceCidInput: PieceCID | LegacyPieceCID | CID | string | null | undefined\n): LegacyPieceCID | null {\n  if (pieceCidInput === null || pieceCidInput === undefined) {\n    return null\n  }\n\n  // Try converting as PieceCID first (handles PieceCID and CID types)\n  const pieceCid = asPieceCID(pieceCidInput as PieceCID | CID | string | null | undefined)\n  if (pieceCid != null) {\n    // Downgrade PieceCID to LegacyPieceCID\n    const digest = Digest.create(SHA2_256_TRUNC254_PADDED, pieceCid.multihash.digest.subarray(-32))\n    return Link.create(FIL_COMMITMENT_UNSEALED, digest) as LegacyPieceCID\n  }\n\n  if (typeof pieceCidInput === 'string') {\n    return parseLegacyPieceCID(pieceCidInput)\n  }\n\n  if (isCID(pieceCidInput)) {\n    if (isValidLegacyPieceCID(pieceCidInput)) {\n      return pieceCidInput\n    }\n  }\n\n  return null\n}\n\n/**\n * Extract the raw (unpadded) size from a PieceCIDv2\n *\n * PieceCIDv2 encodes the original data size in its multihash digest through\n * the tree height and padding values. This function decodes those values to\n * calculate the original raw data size.\n *\n * @param pieceCid - PieceCID\n * @returns The raw size in bytes\n * @throws {Error} If the input is not a valid PieceCIDv2\n */\nexport function getSize(pieceCid: PieceCID): number {\n  // The multihash digest contains: [padding (varint)][height (1 byte)][root (32 bytes)]\n  const digest = Hasher.Digest.fromBytes(pieceCid.multihash.bytes)\n  const height = digest.height\n  const padding = digest.padding\n\n  // rawSize = paddedSize - padding\n  // where paddedSize = 2^(height-2) * 127 (fr32 expansion)\n  const rawSize = Unpadded.fromPiece({ height, padding })\n\n  // This should be safe for all practical file sizes\n  if (rawSize > Number.MAX_SAFE_INTEGER) {\n    throw new Error(`Raw size ${rawSize} exceeds maximum safe integer`)\n  }\n\n  return Number(rawSize)\n}\n\n/**\n * Extract the raw (unpadded) size from a PieceCIDv2\n *\n * Accepts PieceCID as string, CID object, or PieceCID type\n *\n * @param pieceCidInput - PieceCID as either a CID object or string\n * @returns The raw size in bytes\n * @throws {Error} If the input is not a valid PieceCIDv2\n */\nexport function getSizeFromPieceCID(pieceCidInput: PieceCID | CID | string): number {\n  const pieceCid = asPieceCID(pieceCidInput)\n  if (pieceCid == null) {\n    throw new Error('Invalid PieceCID: input must be a valid PieceCIDv2')\n  }\n  return getSize(pieceCid)\n}\n\nexport function parse(pieceCid: string): PieceCID {\n  try {\n    const cid = CID.parse(pieceCid).toV1()\n    if (!isPieceCID(cid)) {\n      throw new Error('Invalid PieceCID: input must be a valid PieceCIDv2')\n    }\n    return cid\n  } catch {\n    throw new Error(`Invalid CID string: ${pieceCid}`)\n  }\n}\n\n/**\n * Check if a CID is a valid PieceCID\n * @param cid - The CID to check\n * @returns True if it's a valid PieceCID\n */\nexport function isPieceCID(cid: Link.Link): cid is PieceCID {\n  return (\n    typeof cid === 'object' && CID.asCID(cid) != null && cid.code === Raw.code && cid.multihash.code === Hasher.code\n  )\n}\n\n/**\n * Calculate the PieceCID (Piece Commitment) for a given data blob\n *\n * @param data - The binary data to calculate the PieceCID for\n * @returns The calculated PieceCID CID\n */\nexport function calculate(data: Uint8Array): PieceCID {\n  // TODO: consider https://github.com/storacha/fr32-sha2-256-trunc254-padded-binary-tree-multihash\n  // for more efficient PieceCID calculation in WASM\n  const hasher = Hasher.create()\n  // We'll get slightly better performance by writing in chunks to let the\n  // hasher do its work incrementally\n  const chunkSize = 2048\n  for (let i = 0; i < data.length; i += chunkSize) {\n    hasher.write(data.subarray(i, i + chunkSize))\n  }\n  const digest = hasher.digest()\n  return Link.create(Raw.code, digest) as PieceCID\n}\n\n/**\n * Calculate PieceCID from an async iterable of Uint8Array chunks.\n *\n * @param data - AsyncIterable yielding Uint8Array chunks\n * @returns Calculated PieceCID\n *\n * @example\n * const pieceCid = await calculateFromIterable(asyncIterableData)\n */\nexport async function calculateFromIterable(data: AsyncIterable<Uint8Array>): Promise<PieceCID> {\n  const hasher = Hasher.create()\n\n  for await (const chunk of data) {\n    hasher.write(chunk)\n  }\n\n  const digest = hasher.digest()\n  return Link.create(Raw.code, digest) as PieceCID\n}\n\n/**\n * Create a TransformStream that calculates PieceCID while streaming data through it\n * This allows calculating PieceCID without buffering the entire data in memory\n *\n * @returns An object with the TransformStream and a getPieceCID function to retrieve the result\n *\n * @example\n * const { stream, getPieceCID } = createPieceCIDStream()\n * await fetch(url, {\n *   method: 'PUT',\n *   body: dataStream.pipeThrough(stream)\n * })\n * const pieceCid = getPieceCID() // Available after stream completes\n */\nexport function createPieceCIDStream(): {\n  stream: TransformStream<Uint8Array, Uint8Array>\n  getPieceCID: () => PieceCID | null\n} {\n  const hasher = Hasher.create()\n  let finished = false\n  let pieceCid: PieceCID | null = null\n\n  const stream = new TransformStream<Uint8Array, Uint8Array>({\n    transform(chunk: Uint8Array, controller: TransformStreamDefaultController<Uint8Array>) {\n      // Write chunk to hasher for CommP calculation\n      hasher.write(chunk)\n      // Pass chunk through unchanged to continue upload\n      controller.enqueue(chunk)\n    },\n\n    flush() {\n      // Calculate final PieceCID when stream ends\n      const digest = hasher.digest()\n      pieceCid = Link.create(Raw.code, digest) as PieceCID\n      finished = true\n    },\n  })\n\n  return {\n    stream,\n    getPieceCID: () => {\n      if (!finished) {\n        return null\n      }\n      return pieceCid\n    },\n  }\n}\n\n/**\n * Convert Uint8Array to async iterable with optimal chunk size.\n *\n * Uses 2048-byte chunks for better hasher performance (determined by manual\n * testing with Node.js; this will likely vary by environment). This may not be\n * optimal for the streaming upload case, so further tuning may be needed to\n * find the best balance between hasher performance and upload chunk size.\n *\n * @param data - Uint8Array to convert\n * @param chunkSize - Size of chunks (default 2048)\n * @returns AsyncIterable yielding chunks\n */\nexport async function* uint8ArrayToAsyncIterable(\n  data: Uint8Array,\n  chunkSize: number = 2048\n): AsyncIterable<Uint8Array> {\n  for (let i = 0; i < data.length; i += chunkSize) {\n    yield data.subarray(i, i + chunkSize)\n  }\n}\n\n/**\n * Convert a hex representation of a PieceCID to a PieceCID object\n *\n * The contract stores the full PieceCID multihash digest (including height and padding)\n * The data comes as a hex string, we need to decode it as bytes then as a CID to get the PieceCID object\n *\n * @param pieceCidHex - The hex representation of the PieceCID\n * @returns {PieceCID} The PieceCID object\n */\nexport function hexToPieceCID(pieceCidHex: Hex | string): PieceCID {\n  const pieceDataBytes = hexToBytes(pieceCidHex as Hex)\n  const possiblePieceCID = CID.decode(pieceDataBytes)\n  const isValid = isValidPieceCID(possiblePieceCID)\n  if (!isValid) {\n    throw new Error(`Hex string '${pieceCidHex}' is a valid CID but not a valid PieceCID`)\n  }\n  return possiblePieceCID as PieceCID\n}\n\n/**\n * Download data from a Response object, validate its PieceCID, and return as Uint8Array\n *\n * This function:\n * 1. Streams data from the Response body\n * 2. Calculates PieceCID during streaming\n * 3. Collects all chunks into a Uint8Array\n * 4. Validates the calculated PieceCID matches the expected value\n *\n * @param response - The Response object from a fetch() call\n * @param expectedPieceCid - The expected PieceCID to validate against\n * @returns The downloaded data as a Uint8Array\n * @throws Error if PieceCID validation fails or download errors occur\n *\n * @example\n * ```typescript\n * const response = await fetch(url)\n * const data = await downloadAndValidate(response, 'bafkzcib...')\n * ```\n */\nexport async function downloadAndValidate(\n  response: Response,\n  expectedPieceCid: string | PieceCID\n): Promise<Uint8Array> {\n  // Parse and validate the expected PieceCID\n  const parsedPieceCid = asPieceCID(expectedPieceCid)\n  if (parsedPieceCid == null) {\n    throw new Error(`Invalid PieceCID: ${String(expectedPieceCid)}`)\n  }\n\n  // Check response is OK\n  if (!response.ok) {\n    throw new Error(`Download failed: ${response.status} ${response.statusText}`)\n  }\n\n  if (response.body == null) {\n    throw new Error('Response body is null')\n  }\n\n  // Create PieceCID calculation stream\n  const { stream: pieceCidStream, getPieceCID } = createPieceCIDStream()\n\n  // Create a stream that collects all chunks into an array\n  const chunks: Uint8Array[] = []\n  const collectStream = new TransformStream<Uint8Array, Uint8Array>({\n    transform(chunk: Uint8Array, controller: TransformStreamDefaultController<Uint8Array>) {\n      chunks.push(chunk)\n      controller.enqueue(chunk)\n    },\n  })\n\n  // Pipe the response through both streams\n  const pipelineStream = response.body.pipeThrough(pieceCidStream).pipeThrough(collectStream)\n\n  // Consume the stream to completion\n  const reader = pipelineStream.getReader()\n  try {\n    while (true) {\n      const { done } = await reader.read()\n      if (done) break\n    }\n  } finally {\n    reader.releaseLock()\n  }\n\n  if (chunks.length === 0) {\n    throw new Error('Response body is empty')\n  }\n\n  // Get the calculated PieceCID\n  const calculatedPieceCid = getPieceCID()\n\n  if (calculatedPieceCid == null) {\n    throw new Error('Failed to calculate PieceCID from stream')\n  }\n\n  // Verify the PieceCID\n  if (calculatedPieceCid.toString() !== parsedPieceCid.toString()) {\n    throw new Error(\n      `PieceCID verification failed. Expected: ${String(parsedPieceCid)}, Got: ${String(calculatedPieceCid)}`\n    )\n  }\n\n  // Combine all chunks into a single Uint8Array\n  const totalLength = chunks.reduce((acc, chunk) => acc + chunk.length, 0)\n  const result = new Uint8Array(totalLength)\n  let offset = 0\n  for (const chunk of chunks) {\n    result.set(chunk, offset)\n    offset += chunk.length\n  }\n\n  return result\n}\n","/**\n * Synapse Core - Service Provider HTTP Operations\n *\n * @example\n * ```ts\n * import * as SP from '@filoz/synapse-core/sp'\n * ```\n *\n * @packageDocumentation\n */\n\nimport { HttpError, request, TimeoutError } from 'iso-web/http'\nimport type { Simplify } from 'type-fest'\nimport { type Address, type Hex, isHex } from 'viem'\nimport {\n  AddPiecesError,\n  CreateDataSetError,\n  DeletePieceError,\n  FindPieceError,\n  GetDataSetError,\n  InvalidUploadSizeError,\n  LocationHeaderError,\n  PollDataSetCreationStatusError,\n  PollForAddPiecesStatusError,\n  PostPieceError,\n  UploadPieceError,\n} from './errors/pdp.ts'\nimport type { PieceCID } from './piece.ts'\nimport * as Piece from './piece.ts'\nimport { SIZE_CONSTANTS } from './utils/constants.ts'\nimport { createPieceUrl } from './utils/piece-url.ts'\n\nlet TIMEOUT = 1000 * 60 * 5 // 5 minutes\nexport const RETRIES = Infinity\nexport const FACTOR = 1\nexport const MIN_TIMEOUT = 4000 // interval between retries in milliseconds\n\n// Just for testing purposes\nexport function setTimeout(timeout: number) {\n  TIMEOUT = timeout\n}\n\n/**\n * Convert AsyncIterable to ReadableStream with broad browser compatibility.\n * Provides fallback for environments where ReadableStream.from() is not available.\n *\n * Uses pull-based streaming to implement proper backpressure and ensure all\n * chunks are consumed in order.\n */\nfunction asyncIterableToReadableStream(iterable: AsyncIterable<Uint8Array>): ReadableStream<Uint8Array> {\n  if (!isAsyncIterable(iterable)) {\n    throw new Error('Input must be an AsyncIterable')\n  }\n\n  // Use native ReadableStream.from() if available\n  // See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/from_static for latest\n  // support matrix, as of late 2025 this is still \"Experimental\"\n  if (typeof ReadableStream.from === 'function') {\n    return ReadableStream.from(iterable)\n  }\n\n  // Fallback implementation using pull-based streaming\n  const iterator = iterable[Symbol.asyncIterator]()\n\n  return new ReadableStream({\n    async pull(controller) {\n      try {\n        const { value, done } = await iterator.next()\n        if (done) {\n          controller.close()\n        } else {\n          controller.enqueue(value)\n        }\n      } catch (error) {\n        // run cleanup on internal errors\n        if (iterator.return) {\n          try {\n            await iterator.return()\n          } catch {\n            // safely ignore\n          }\n        }\n        controller.error(error)\n      }\n    },\n    async cancel() {\n      // Clean up iterator if stream is cancelled\n      if (iterator.return) {\n        await iterator.return()\n      }\n    },\n  })\n}\n\n/**\n * The options for the create data set on PDP API.\n *\n * @param endpoint - The endpoint of the PDP API.\n * @param recordKeeper - The address of the record keeper.\n * @param extraData - The extra data for the create data set.\n */\nexport type PDPCreateDataSetOptions = {\n  endpoint: string\n  recordKeeper: Address\n  extraData: Hex\n}\n\n/**\n * Create a data set on PDP API\n *\n * POST /pdp/data-sets\n *\n * @param options - The options for the create data set on PDP API.\n * @param options.endpoint - The endpoint of the PDP API.\n * @param options.recordKeeper - The address of the record keeper.\n * @param options.extraData - The extra data for the create data set.\n * @returns The response from the create data set on PDP API.\n */\nexport async function createDataSet(options: PDPCreateDataSetOptions) {\n  // Send the create data set message to the PDP\n  const response = await request.post(new URL(`pdp/data-sets`, options.endpoint), {\n    body: JSON.stringify({\n      recordKeeper: options.recordKeeper,\n      extraData: options.extraData,\n    }),\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    timeout: TIMEOUT,\n  })\n\n  if (response.error) {\n    if (HttpError.is(response.error)) {\n      throw new CreateDataSetError(await response.error.response.text())\n    }\n    throw response.error\n  }\n\n  const location = response.result.headers.get('Location')\n  const hash = location?.split('/').pop()\n  if (!location || !hash || !isHex(hash)) {\n    throw new LocationHeaderError(location)\n  }\n\n  return {\n    txHash: hash,\n    statusUrl: new URL(location, options.endpoint).toString(),\n  }\n}\n\nexport type PollForDataSetCreationStatusOptions = {\n  statusUrl: string\n}\n\nexport type DataSetCreatedResponse =\n  | {\n      createMessageHash: Hex\n      dataSetCreated: false\n      service: string\n      txStatus: 'pending' | 'confirmed' | 'rejected'\n      ok: boolean\n    }\n  | DataSetCreateSuccess\n\nexport type DataSetCreateSuccess = {\n  createMessageHash: Hex\n  dataSetCreated: true\n  service: string\n  txStatus: 'confirmed'\n  ok: true\n  dataSetId: number\n}\n\n/**\n * Poll for the data set creation status.\n *\n * GET /pdp/data-sets/created({txHash})\n *\n * @param options - The options for the poll for data set creation status.\n * @param options.statusUrl - The status URL of the data set creation.\n * @returns The data set creation status.\n */\nexport async function pollForDataSetCreationStatus(options: PollForDataSetCreationStatusOptions) {\n  const response = await request.json.get<DataSetCreatedResponse>(options.statusUrl, {\n    async onResponse(response) {\n      if (response.ok) {\n        const data = (await response.clone().json()) as DataSetCreatedResponse\n\n        if (data.dataSetCreated) {\n          return response\n        }\n        throw new Error('Not created yet')\n      }\n    },\n    retry: {\n      shouldRetry: (ctx) => ctx.error.message === 'Not created yet',\n      retries: RETRIES,\n      factor: FACTOR,\n      minTimeout: MIN_TIMEOUT,\n    },\n\n    timeout: TIMEOUT,\n  })\n  if (response.error) {\n    if (HttpError.is(response.error)) {\n      throw new PollDataSetCreationStatusError(await response.error.response.text())\n    }\n    throw response.error\n  }\n\n  return response.result as DataSetCreateSuccess\n}\n\nexport type PDPCreateDataSetAndAddPiecesOptions = {\n  endpoint: string\n  recordKeeper: Address\n  extraData: Hex\n  pieces: PieceCID[]\n}\n\n/**\n * Create a data set and add pieces to it on PDP API\n *\n * POST /pdp/data-sets/create-and-add\n *\n * @param options - The options for the create data set and add pieces to it on PDP API.\n * @param options.endpoint - The endpoint of the PDP API.\n * @param options.recordKeeper - The address of the record keeper.\n * @param options.extraData - The extra data for the create data set.\n * @returns The response from the create data set and add pieces to it on PDP API.\n */\nexport async function createDataSetAndAddPieces(options: PDPCreateDataSetAndAddPiecesOptions) {\n  // Send the create data set message to the PDP\n  const response = await request.post(new URL(`pdp/data-sets/create-and-add`, options.endpoint), {\n    body: JSON.stringify({\n      recordKeeper: options.recordKeeper,\n      extraData: options.extraData,\n      pieces: options.pieces.map((piece) => ({\n        pieceCid: piece.toString(),\n        subPieces: [{ subPieceCid: piece.toString() }],\n      })),\n    }),\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    timeout: TIMEOUT,\n  })\n\n  if (response.error) {\n    if (HttpError.is(response.error)) {\n      throw new CreateDataSetError(await response.error.response.text())\n    }\n    throw response.error\n  }\n\n  const location = response.result.headers.get('Location')\n  const hash = location?.split('/').pop()\n  if (!location || !hash || !isHex(hash)) {\n    throw new LocationHeaderError(location)\n  }\n\n  return {\n    txHash: hash,\n    statusUrl: new URL(location, options.endpoint).toString(),\n  }\n}\n\nexport type GetDataSetOptions = {\n  endpoint: string\n  dataSetId: bigint\n}\n\nexport type GetDataSetResponse = {\n  id: number\n  nextChallengeEpoch: number\n  pieces: SPPiece[]\n}\n\nexport type SPPiece = {\n  pieceCid: string\n  pieceId: number\n  subPieceCid: string\n  subPieceOffset: number\n}\n\n/**\n * Get a data set from the PDP API.\n *\n * GET /pdp/data-sets/{dataSetId}\n *\n * @param options - The options for the get data set from the PDP API.\n * @param options.endpoint - The endpoint of the PDP API.\n * @param options.dataSetId - The ID of the data set.\n * @returns The data set from the PDP API.\n */\nexport async function getDataSet(options: GetDataSetOptions) {\n  const response = await request.json.get<GetDataSetResponse>(\n    new URL(`pdp/data-sets/${options.dataSetId}`, options.endpoint)\n  )\n  if (response.error) {\n    if (HttpError.is(response.error)) {\n      throw new GetDataSetError(await response.error.response.text())\n    }\n    throw response.error\n  }\n\n  return response.result\n}\n\nexport type GetPiecesForDataSetOptions = {\n  endpoint: string\n  dataSetId: bigint\n  chainId: number\n  address: Address\n  cdn: boolean\n}\n\nexport type SPPieceWithUrl = Simplify<\n  SPPiece & {\n    pieceUrl: string\n  }\n>\n\n/**\n * Get the pieces for a data set from the PDP API.\n *\n *\n * @param options - The options for the get pieces for data set.\n * @param options.endpoint - The endpoint of the PDP API.\n * @param options.dataSetId - The ID of the data set.\n * @param options.chainId - The chain ID.\n * @param options.address - The address of the user.\n * @param options.cdn - Whether the CDN is enabled.\n */\nexport async function getPiecesForDataSet(options: GetPiecesForDataSetOptions): Promise<SPPieceWithUrl[]> {\n  const dataSet = await getDataSet(options)\n  const pieces = dataSet.pieces.map((piece) => ({\n    pieceCid: piece.pieceCid,\n    pieceId: piece.pieceId,\n    pieceUrl: createPieceUrl(piece.pieceCid, options.cdn, options.address, options.chainId, options.endpoint),\n    subPieceCid: piece.subPieceCid,\n    subPieceOffset: piece.subPieceOffset,\n  }))\n\n  return pieces\n}\n\nexport type UploadPieceOptions = {\n  endpoint: string\n  data: Uint8Array\n  pieceCid: PieceCID\n}\n\nexport type UploadPieceResponse = {\n  pieceCid: PieceCID\n  size: number\n}\n\n/**\n * Upload a piece to the PDP API.\n *\n * POST /pdp/piece\n *\n * @param options - The options for the upload piece.\n * @param options.endpoint - The endpoint of the PDP API.\n * @param options.data - The data to upload.\n * @returns The response from the upload piece.\n */\nexport async function uploadPiece(options: UploadPieceOptions): Promise<void> {\n  const size = options.data.length\n  if (size < SIZE_CONSTANTS.MIN_UPLOAD_SIZE || size > SIZE_CONSTANTS.MAX_UPLOAD_SIZE) {\n    throw new InvalidUploadSizeError(size)\n  }\n\n  const pieceCid = options.pieceCid\n  if (!Piece.isPieceCID(pieceCid)) {\n    throw new Error(`Invalid PieceCID: ${String(options.pieceCid)}`)\n  }\n  const response = await request.post(new URL(`pdp/piece`, options.endpoint), {\n    body: JSON.stringify({\n      pieceCid: pieceCid.toString(),\n    }),\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    timeout: TIMEOUT,\n  })\n\n  if (response.error) {\n    if (HttpError.is(response.error)) {\n      throw new PostPieceError(await response.error.response.text())\n    }\n    throw response.error\n  }\n  if (response.result.status === 200) {\n    // Piece already exists on server\n    return\n  }\n\n  // Extract upload ID from Location header\n  const location = response.result.headers.get('Location')\n  const uploadUuid = location?.split('/').pop()\n  if (!location || !uploadUuid) {\n    throw new LocationHeaderError(location)\n  }\n\n  const uploadResponse = await request.put(new URL(`pdp/piece/upload/${uploadUuid}`, options.endpoint), {\n    body: options.data,\n    headers: {\n      'Content-Type': 'application/octet-stream',\n      'Content-Length': options.data.length.toString(),\n    },\n    timeout: false,\n  })\n\n  if (uploadResponse.error) {\n    if (HttpError.is(uploadResponse.error)) {\n      throw new UploadPieceError(await uploadResponse.error.response.text())\n    }\n    throw uploadResponse.error\n  }\n}\n\nexport type UploadPieceStreamingOptions = {\n  endpoint: string\n  data: AsyncIterable<Uint8Array> | ReadableStream<Uint8Array>\n  size?: number\n  onProgress?: (bytesUploaded: number) => void\n  pieceCid?: PieceCID\n  signal?: AbortSignal\n}\n\n/**\n * Upload piece data using the 3-step CommP-last streaming protocol.\n *\n * Protocol:\n * 1. POST /pdp/piece/uploads → get upload session UUID\n * 2. PUT /pdp/piece/uploads/{uuid} → stream data while calculating CommP\n * 3. POST /pdp/piece/uploads/{uuid} → finalize with calculated CommP\n *\n * @param options - Upload options\n * @param options.endpoint - The endpoint of the PDP API\n * @param options.data - AsyncIterable or ReadableStream yielding Uint8Array chunks\n * @param options.size - Optional known size for Content-Length header\n * @param options.onProgress - Optional progress callback\n * @param options.signal - Optional AbortSignal to cancel the upload\n * @returns PieceCID and size of uploaded data\n * @throws Error if upload fails at any step or if size exceeds MAX_UPLOAD_SIZE\n */\nexport async function uploadPieceStreaming(options: UploadPieceStreamingOptions): Promise<UploadPieceResponse> {\n  // Create upload session (POST /pdp/piece/uploads)\n  const createResponse = await request.post(new URL('pdp/piece/uploads', options.endpoint), {\n    timeout: TIMEOUT,\n    signal: options.signal,\n  })\n\n  if (createResponse.error) {\n    if (HttpError.is(createResponse.error)) {\n      throw new PostPieceError(`Failed to create upload session: ${await createResponse.error.response.text()}`)\n    }\n    throw createResponse.error\n  }\n\n  if (createResponse.result.status !== 201) {\n    throw new PostPieceError(`Expected 201 Created, got ${createResponse.result.status}`)\n  }\n\n  // Extract UUID from Location header: /pdp/piece/uploads/{uuid}\n  const location = createResponse.result.headers.get('Location')\n  if (!location) {\n    throw new LocationHeaderError('Upload session created but Location header missing')\n  }\n\n  const locationMatch = location.match(/\\/pdp\\/piece\\/uploads\\/([a-fA-F0-9-]+)/)\n  if (!locationMatch) {\n    throw new LocationHeaderError(`Invalid Location header format: ${location}`)\n  }\n\n  const uploadUuid = locationMatch[1]\n\n  // Create CommP calculator stream only if PieceCID not provided\n  let getPieceCID: () => PieceCID | null = () => options.pieceCid ?? null\n  let pieceCidStream: TransformStream<Uint8Array, Uint8Array> | null = null\n\n  if (options.pieceCid == null) {\n    const result = Piece.createPieceCIDStream()\n    pieceCidStream = result.stream\n    getPieceCID = result.getPieceCID\n  }\n\n  // Convert to ReadableStream if needed (skip if already ReadableStream)\n  const dataStream = asReadableStream(options.data)\n\n  // Add size tracking and progress reporting\n  let bytesUploaded = 0\n  const trackingStream = new TransformStream<Uint8Array, Uint8Array>({\n    transform(chunk, controller) {\n      bytesUploaded += chunk.length\n\n      // Check size limit\n      if (bytesUploaded > Piece.MAX_UPLOAD_SIZE) {\n        throw new InvalidUploadSizeError(bytesUploaded)\n      }\n\n      // Report progress if callback provided\n      if (options.onProgress) {\n        options.onProgress(bytesUploaded)\n      }\n\n      controller.enqueue(chunk)\n    },\n  })\n\n  // Chain streams: data → tracking → CommP calculation (if needed)\n  const bodyStream = pieceCidStream\n    ? dataStream.pipeThrough(trackingStream).pipeThrough(pieceCidStream)\n    : dataStream.pipeThrough(trackingStream)\n\n  // PUT /pdp/piece/uploads/{uuid} with streaming body\n  const headers: Record<string, string> = {\n    'Content-Type': 'application/octet-stream',\n  }\n\n  // Add Content-Length if size is known (recommended for server)\n  if (options.size !== undefined) {\n    headers['Content-Length'] = options.size.toString()\n  }\n\n  const uploadResponse = await request.put(new URL(`pdp/piece/uploads/${uploadUuid}`, options.endpoint), {\n    body: bodyStream,\n    headers,\n    timeout: false, // No timeout for streaming upload\n    signal: options.signal,\n    duplex: 'half', // Required for streaming request bodies\n  } as Parameters<typeof request.put>[1] & { duplex: 'half' })\n\n  if (uploadResponse.error) {\n    if (HttpError.is(uploadResponse.error)) {\n      throw new UploadPieceError(`Failed to upload piece: ${await uploadResponse.error.response.text()}`)\n    }\n    throw uploadResponse.error\n  }\n\n  if (uploadResponse.result.status !== 204) {\n    throw new UploadPieceError(`Expected 204 No Content, got ${uploadResponse.result.status}`)\n  }\n\n  // Get PieceCID (either provided or calculated) and finalize\n  const pieceCid = getPieceCID()\n  if (pieceCid === null) {\n    throw new Error('Failed to calculate PieceCID during upload')\n  }\n\n  const finalizeBody = JSON.stringify({\n    pieceCid: pieceCid.toString(),\n  })\n\n  // POST /pdp/piece/uploads/{uuid} with PieceCID\n  const finalizeResponse = await request.post(new URL(`pdp/piece/uploads/${uploadUuid}`, options.endpoint), {\n    body: finalizeBody,\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    timeout: TIMEOUT,\n    signal: options.signal,\n  })\n\n  if (finalizeResponse.error) {\n    if (HttpError.is(finalizeResponse.error)) {\n      throw new PostPieceError(`Failed to finalize upload: ${await finalizeResponse.error.response.text()}`)\n    }\n    throw finalizeResponse.error\n  }\n\n  if (finalizeResponse.result.status !== 200) {\n    throw new PostPieceError(`Expected 200 OK for finalization, got ${finalizeResponse.result.status}`)\n  }\n\n  return {\n    pieceCid,\n    size: bytesUploaded,\n  }\n}\n\nexport type FindPieceOptions = {\n  endpoint: string\n  pieceCid: PieceCID\n}\n\n/**\n * Find a piece on the PDP API.\n *\n * GET /pdp/piece?pieceCid={pieceCid}\n *\n * @param options - The options for the find piece.\n * @param options.endpoint - The endpoint of the PDP API.\n * @param options.pieceCid - The piece CID to find.\n * @returns\n */\nexport async function findPiece(options: FindPieceOptions): Promise<PieceCID> {\n  const { pieceCid, endpoint } = options\n  const params = new URLSearchParams({ pieceCid: pieceCid.toString() })\n\n  const response = await request.json.get<{ pieceCid: string }>(new URL(`pdp/piece?${params.toString()}`, endpoint), {\n    retry: {\n      statusCodes: [404],\n      retries: RETRIES,\n      factor: FACTOR,\n    },\n    timeout: TIMEOUT,\n  })\n\n  if (response.error) {\n    if (HttpError.is(response.error)) {\n      throw new FindPieceError(await response.error.response.text())\n    }\n    if (TimeoutError.is(response.error)) {\n      throw new FindPieceError('Timeout waiting for piece to be found')\n    }\n    throw response.error\n  }\n  const data = response.result\n  return Piece.parse(data.pieceCid)\n}\n\nexport type AddPiecesOptions = {\n  endpoint: string\n  dataSetId: bigint\n  pieces: PieceCID[]\n  extraData: Hex\n}\n\n/**\n * Add pieces to a data set on the PDP API.\n *\n * POST /pdp/data-sets/{dataSetId}/pieces\n *\n * @param options - The options for the add pieces.\n * @param options.endpoint - The endpoint of the PDP API.\n * @param options.dataSetId - The ID of the data set.\n * @param options.pieces - The pieces to add.\n * @param options.extraData - The extra data for the add pieces.\n * @returns The response from the add pieces.\n */\nexport async function addPieces(options: AddPiecesOptions) {\n  const { endpoint, dataSetId, pieces, extraData } = options\n  const response = await request.post(new URL(`pdp/data-sets/${dataSetId}/pieces`, endpoint), {\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      pieces: pieces.map((piece) => ({\n        pieceCid: piece.toString(),\n        subPieces: [{ subPieceCid: piece.toString() }],\n      })),\n      extraData: extraData,\n    }),\n    timeout: TIMEOUT,\n  })\n\n  if (response.error) {\n    if (HttpError.is(response.error)) {\n      throw new AddPiecesError(await response.error.response.text())\n    }\n    throw response.error\n  }\n  const location = response.result.headers.get('Location')\n  const txHash = location?.split('/').pop()\n  if (!location || !txHash || !isHex(txHash)) {\n    throw new LocationHeaderError(location)\n  }\n\n  return {\n    txHash: txHash as Hex,\n    statusUrl: new URL(location, endpoint).toString(),\n  }\n}\n\nexport type AddPiecesResponse =\n  | {\n      addMessageOk: null\n      dataSetId: number\n      pieceCount: number\n      piecesAdded: boolean\n      txHash: Hex\n      txStatus: 'pending' | 'confirmed' | 'rejected'\n    }\n  | {\n      addMessageOk: true\n      confirmedPieceIds: number[]\n      dataSetId: number\n      pieceCount: number\n      piecesAdded: boolean\n      txHash: Hex\n      txStatus: 'pending' | 'confirmed' | 'rejected'\n    }\n  | AddPiecesSuccess\n\nexport type AddPiecesSuccess = {\n  addMessageOk: true\n  confirmedPieceIds: number[]\n  dataSetId: number\n  pieceCount: number\n  piecesAdded: true\n  txHash: Hex\n  txStatus: 'confirmed'\n}\n\nexport type PollForAddPiecesStatusOptions = {\n  statusUrl: string\n}\n\n/**\n * Poll for the add pieces status.\n *\n * GET /pdp/data-sets/{dataSetId}/pieces/added/{txHash}\n *\n * @param options - The options for the poll for add pieces status.\n * @param options.statusUrl - The status URL of the add pieces.\n * @returns The add pieces status.\n */\nexport async function pollForAddPiecesStatus(options: PollForAddPiecesStatusOptions) {\n  const response = await request.json.get<AddPiecesResponse>(options.statusUrl, {\n    async onResponse(response) {\n      if (response.ok) {\n        const data = (await response.clone().json()) as AddPiecesResponse\n\n        if (data.piecesAdded) {\n          return response\n        }\n        throw new Error('Not added yet')\n      }\n    },\n    retry: {\n      shouldRetry: (ctx) => ctx.error.message === 'Not added yet',\n      retries: RETRIES,\n      factor: FACTOR,\n      minTimeout: MIN_TIMEOUT,\n    },\n    timeout: 1000 * 60 * 5,\n  })\n  if (response.error) {\n    if (HttpError.is(response.error)) {\n      throw new PollForAddPiecesStatusError(await response.error.response.text())\n    }\n    throw response.error\n  }\n  return response.result as AddPiecesSuccess\n}\n\nexport type DeletePieceOptions = {\n  endpoint: string\n  dataSetId: bigint\n  pieceId: bigint\n  extraData: Hex\n}\n\nexport type DeletePieceResponse = {\n  txHash: Hex\n}\n\n/**\n * Delete a piece from a data set on the PDP API.\n *\n * DELETE /pdp/data-sets/{dataSetId}/pieces/{pieceId}\n */\nexport async function deletePiece(options: DeletePieceOptions) {\n  const { endpoint, dataSetId, pieceId, extraData } = options\n  const response = await request.json.delete<DeletePieceResponse>(\n    new URL(`pdp/data-sets/${dataSetId}/pieces/${pieceId}`, endpoint),\n    {\n      body: { extraData },\n    }\n  )\n\n  if (response.error) {\n    if (HttpError.is(response.error)) {\n      throw new DeletePieceError(await response.error.response.text())\n    }\n    throw response.error\n  }\n\n  return response.result\n}\n\nexport async function ping(endpoint: string) {\n  const response = await request.get(new URL(`pdp/ping`, endpoint))\n  if (response.error) {\n    throw new Error('Ping failed')\n  }\n  return response.result\n}\n\n/**\n * Type guard to check if a value is a ReadableStream\n * @param value - The value to check\n * @returns True if it's a ReadableStream\n */\nfunction isReadableStream(value: unknown): value is ReadableStream<Uint8Array> {\n  return (\n    typeof value === 'object' &&\n    value !== null &&\n    'getReader' in value &&\n    typeof (value as ReadableStream<Uint8Array>).getReader === 'function'\n  )\n}\n\n/**\n * Convert AsyncIterable or ReadableStream to ReadableStream\n * @param data - AsyncIterable or ReadableStream to convert\n * @returns ReadableStream\n */\nfunction asReadableStream(data: AsyncIterable<Uint8Array> | ReadableStream<Uint8Array>): ReadableStream<Uint8Array> {\n  return isReadableStream(data) ? data : asyncIterableToReadableStream(data)\n}\n\n/**\n * Type guard to check if a value is an AsyncIterable\n * @param value - The value to check\n * @returns True if it's an AsyncIterable\n */\nfunction isAsyncIterable(value: unknown): value is AsyncIterable<Uint8Array> {\n  return (\n    typeof value === 'object' &&\n    value !== null &&\n    Symbol.asyncIterator in value &&\n    typeof (value as AsyncIterable<Uint8Array>)[Symbol.asyncIterator] === 'function'\n  )\n}\n","/**\n * Compatibility wrapper for backwards compatibility\n * @deprecated StorageService has been renamed to StorageContext.\n * Import StorageContext from './context.ts' instead.\n */\n\nexport { StorageContext as StorageService } from './context.ts'\n","import { ripemd160 as noble_ripemd160 } from '@noble/hashes/ripemd160'\nimport { keccak_256 as noble_keccak256 } from '@noble/hashes/sha3'\nimport { sha256 as noble_sha256 } from '@noble/hashes/sha256'\nimport * as Bytes from './Bytes.js'\nimport type * as Errors from './Errors.js'\nimport * as Hex from './Hex.js'\n\n/**\n * Calculates the [Keccak256](https://en.wikipedia.org/wiki/SHA-3) hash of a {@link ox#Bytes.Bytes} or {@link ox#Hex.Hex} value.\n *\n * This function is a re-export of `keccak_256` from [`@noble/hashes`](https://github.com/paulmillr/noble-hashes), an audited & minimal JS hashing library.\n *\n * @example\n * ```ts twoslash\n * import { Hash } from 'ox'\n *\n * Hash.keccak256('0xdeadbeef')\n * // @log: '0xd4fd4e189132273036449fc9e11198c739161b4c0116a9a2dccdfa1c492006f1'\n * ```\n *\n * @example\n * ### Calculate Hash of a String\n *\n * ```ts twoslash\n * import { Hash, Hex } from 'ox'\n *\n * Hash.keccak256(Hex.fromString('hello world'))\n * // @log: '0x3ea2f1d0abf3fc66cf29eebb70cbd4e7fe762ef8a09bcc06c8edf641230afec0'\n * ```\n *\n * @example\n * ### Configure Return Type\n *\n * ```ts twoslash\n * import { Hash } from 'ox'\n *\n * Hash.keccak256('0xdeadbeef', { as: 'Bytes' })\n * // @log: Uint8Array [...]\n * ```\n *\n * @param value - {@link ox#Bytes.Bytes} or {@link ox#Hex.Hex} value.\n * @param options - Options.\n * @returns Keccak256 hash.\n */\nexport function keccak256<\n  value extends Hex.Hex | Bytes.Bytes,\n  as extends 'Hex' | 'Bytes' =\n    | (value extends Hex.Hex ? 'Hex' : never)\n    | (value extends Bytes.Bytes ? 'Bytes' : never),\n>(\n  value: value | Hex.Hex | Bytes.Bytes,\n  options: keccak256.Options<as> = {},\n): keccak256.ReturnType<as> {\n  const { as = typeof value === 'string' ? 'Hex' : 'Bytes' } = options\n  const bytes = noble_keccak256(Bytes.from(value))\n  if (as === 'Bytes') return bytes as never\n  return Hex.fromBytes(bytes) as never\n}\n\nexport declare namespace keccak256 {\n  type Options<as extends 'Hex' | 'Bytes' = 'Hex' | 'Bytes'> = {\n    /** The return type. @default 'Hex' */\n    as?: as | 'Hex' | 'Bytes' | undefined\n  }\n\n  type ReturnType<as extends 'Hex' | 'Bytes' = 'Hex' | 'Bytes'> =\n    | (as extends 'Bytes' ? Bytes.Bytes : never)\n    | (as extends 'Hex' ? Hex.Hex : never)\n\n  type ErrorType =\n    | Bytes.from.ErrorType\n    | Hex.fromBytes.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Calculates the [Ripemd160](https://en.wikipedia.org/wiki/RIPEMD) hash of a {@link ox#Bytes.Bytes} or {@link ox#Hex.Hex} value.\n *\n * This function is a re-export of `ripemd160` from [`@noble/hashes`](https://github.com/paulmillr/noble-hashes), an audited & minimal JS hashing library.\n *\n * @example\n * ```ts twoslash\n * import { Hash } from 'ox'\n *\n * Hash.ripemd160('0xdeadbeef')\n * // '0x226821c2f5423e11fe9af68bd285c249db2e4b5a'\n * ```\n *\n * @param value - {@link ox#Bytes.Bytes} or {@link ox#Hex.Hex} value.\n * @param options - Options.\n * @returns Ripemd160 hash.\n */\nexport function ripemd160<\n  value extends Hex.Hex | Bytes.Bytes,\n  as extends 'Hex' | 'Bytes' =\n    | (value extends Hex.Hex ? 'Hex' : never)\n    | (value extends Bytes.Bytes ? 'Bytes' : never),\n>(\n  value: value | Hex.Hex | Bytes.Bytes,\n  options: ripemd160.Options<as> = {},\n): ripemd160.ReturnType<as> {\n  const { as = typeof value === 'string' ? 'Hex' : 'Bytes' } = options\n  const bytes = noble_ripemd160(Bytes.from(value))\n  if (as === 'Bytes') return bytes as never\n  return Hex.fromBytes(bytes) as never\n}\n\nexport declare namespace ripemd160 {\n  type Options<as extends 'Hex' | 'Bytes' = 'Hex' | 'Bytes'> = {\n    /** The return type. @default 'Hex' */\n    as?: as | 'Hex' | 'Bytes' | undefined\n  }\n\n  type ReturnType<as extends 'Hex' | 'Bytes' = 'Hex' | 'Bytes'> =\n    | (as extends 'Bytes' ? Bytes.Bytes : never)\n    | (as extends 'Hex' ? Hex.Hex : never)\n\n  type ErrorType =\n    | Bytes.from.ErrorType\n    | Hex.fromBytes.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Calculates the [Sha256](https://en.wikipedia.org/wiki/SHA-256) hash of a {@link ox#Bytes.Bytes} or {@link ox#Hex.Hex} value.\n *\n * This function is a re-export of `sha256` from [`@noble/hashes`](https://github.com/paulmillr/noble-hashes), an audited & minimal JS hashing library.\n *\n * @example\n * ```ts twoslash\n * import { Hash } from 'ox'\n *\n * Hash.sha256('0xdeadbeef')\n * // '0x5f78c33274e43fa9de5659265c1d917e25c03722dcb0b8d27db8d5feaa813953'\n * ```\n *\n * @param value - {@link ox#Bytes.Bytes} or {@link ox#Hex.Hex} value.\n * @param options - Options.\n * @returns Sha256 hash.\n */\nexport function sha256<\n  value extends Hex.Hex | Bytes.Bytes,\n  as extends 'Hex' | 'Bytes' =\n    | (value extends Hex.Hex ? 'Hex' : never)\n    | (value extends Bytes.Bytes ? 'Bytes' : never),\n>(\n  value: value | Hex.Hex | Bytes.Bytes,\n  options: sha256.Options<as> = {},\n): sha256.ReturnType<as> {\n  const { as = typeof value === 'string' ? 'Hex' : 'Bytes' } = options\n  const bytes = noble_sha256(Bytes.from(value))\n  if (as === 'Bytes') return bytes as never\n  return Hex.fromBytes(bytes) as never\n}\n\nexport declare namespace sha256 {\n  type Options<as extends 'Hex' | 'Bytes' = 'Hex'> = {\n    /** The return type. @default 'Hex' */\n    as?: as | 'Hex' | 'Bytes' | undefined\n  }\n\n  type ReturnType<as extends 'Hex' | 'Bytes' = 'Hex'> =\n    | (as extends 'Bytes' ? Bytes.Bytes : never)\n    | (as extends 'Hex' ? Hex.Hex : never)\n\n  type ErrorType =\n    | Bytes.from.ErrorType\n    | Hex.fromBytes.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Checks if a string is a valid hash value.\n *\n * @example\n * ```ts twoslash\n * import { Hash } from 'ox'\n *\n * Hash.validate('0x')\n * // @log: false\n *\n * Hash.validate('0x3ea2f1d0abf3fc66cf29eebb70cbd4e7fe762ef8a09bcc06c8edf641230afec0')\n * // @log: true\n * ```\n *\n * @param value - Value to check.\n * @returns Whether the value is a valid hash.\n */\nexport function validate(value: string): value is Hex.Hex {\n  return Hex.validate(value) && Hex.size(value) === 32\n}\n\nexport declare namespace validate {\n  type ErrorType =\n    | Hex.validate.ErrorType\n    | Hex.size.ErrorType\n    | Errors.GlobalErrorType\n}\n","import type { AbiError } from 'abitype'\nimport type { Hex } from 'viem'\nimport { AbiErrorSignatureNotFoundError, decodeErrorResult } from 'viem'\nimport { formatAbiItem, formatAbiItemWithArgs } from 'viem/utils'\nimport * as Abis from '../abis/index.ts'\n\nexport function decodePDPError(error: string) {\n  const regex = /(?:vm error|revert reason)=\\[(.*?)\\]/g\n  const matches = error.matchAll(regex)\n\n  for (const match of matches) {\n    const extractedContent = match[1]\n    if (extractedContent?.startsWith('0x')) {\n      let error: Error\n\n      // try warm storage abi\n      try {\n        const value = decodeErrorResult({\n          abi: Abis.storage,\n          data: extractedContent as Hex,\n        })\n\n        return `Warm Storage\\n${formatPDPError(value)}`\n      } catch (err) {\n        error = err as Error\n      }\n\n      // try payments abi\n      if (error instanceof AbiErrorSignatureNotFoundError) {\n        try {\n          const value = decodeErrorResult({\n            abi: Abis.payments,\n            data: extractedContent as Hex,\n          })\n\n          return `Payments\\n${formatPDPError(value)}`\n        } catch (err) {\n          error = err as Error\n        }\n      }\n\n      // try pdp verifier abi\n      if (error instanceof AbiErrorSignatureNotFoundError) {\n        try {\n          const value = decodeErrorResult({\n            abi: Abis.pdp,\n            data: extractedContent as Hex,\n          })\n\n          return `PDP Verifier\\n${formatPDPError(value)}`\n        } catch (err) {\n          error = err as Error\n        }\n      }\n\n      return `Unable to decode error\\n${error}`\n    } else if (extractedContent?.startsWith('Error(')) {\n      return `\\n${extractedContent.replace('Error(', '').replace(')', '')}`\n    }\n  }\n  return `Service Provider PDP\\n${error}`\n}\n\n/**\n * Format the PDP error for display, stringifies the error and adds the inputs and args\n *\n * @param error - The PDP error to format\n */\nfunction formatPDPError(error: { abiItem: AbiError; args: readonly unknown[] | undefined; errorName: string }) {\n  const errorWithParams = error.abiItem\n    ? formatAbiItem(error.abiItem, {\n        includeName: true,\n      })\n    : undefined\n  const formattedArgs = error.args\n    ? formatAbiItemWithArgs({\n        abiItem: error.abiItem,\n        args: error.args,\n        includeName: false,\n        includeFunctionName: false,\n      })\n    : undefined\n\n  return [\n    errorWithParams ? `${errorWithParams}` : '',\n    formattedArgs && formattedArgs !== '()'\n      ? `${[...Array(error.errorName?.length ?? 0).keys()].map(() => ' ').join('')}${formattedArgs}`\n      : '',\n  ].join('\\n')\n}\n","// Base encoders / decoders just base encode / decode between binary and\n// textual representation. They are unaware of multibase.\n\n/**\n * Base encoder just encodes bytes into base encoded string.\n */\nexport interface BaseEncoder {\n  /**\n   * Base encodes to a **plain** (and not a multibase) string. Unlike\n   * `encode` no multibase prefix is added.\n   */\n  baseEncode(bytes: Uint8Array): string\n}\n\n/**\n * Base decoder decodes encoded with matching base encoding into bytes.\n */\nexport interface BaseDecoder {\n  /**\n   * Decodes **plain** (and not a multibase) string. Unlike\n   * decode\n   */\n  baseDecode(text: string): Uint8Array\n}\n\n/**\n * Base codec is just dual of encoder and decoder.\n */\nexport interface BaseCodec {\n  encoder: BaseEncoder\n  decoder: BaseDecoder\n}\n\n/**\n * Multibase represents base encoded strings with a prefix first character\n * describing it's encoding.\n */\nexport type Multibase<Prefix extends string> =\n  | string\n  | string & { [0]: Prefix }\n\n/**\n * Multibase encoder for the specific base encoding encodes bytes into\n * multibase of that encoding.\n */\nexport interface MultibaseEncoder<Prefix extends string> {\n  /**\n   * Name of the encoding.\n   */\n  name: string\n  /**\n   * Prefix character for that base encoding.\n   */\n  prefix: Prefix\n  /**\n   * Encodes binary data into **multibase** string (which will have a\n   * prefix added).\n   */\n  encode(bytes: Uint8Array): Multibase<Prefix>\n}\n\n/**\n * Interface implemented by multibase decoder, that takes multibase strings\n * to bytes. It may support single encoding like base32 or multiple encodings\n * like base32, base58btc, base64. If passed multibase is incompatible it will\n * throw an exception.\n */\nexport interface MultibaseDecoder<Prefix extends string> {\n  /**\n   * Decodes **multibase** string (which must have a multibase prefix added).\n   * If prefix does not match\n   */\n  decode(multibase: Multibase<Prefix>): Uint8Array\n}\n\n/**\n * Dual of multibase encoder and decoder.\n */\nexport interface MultibaseCodec<Prefix extends string> {\n  name: string\n  prefix: Prefix\n  encoder: MultibaseEncoder<Prefix>\n  decoder: MultibaseDecoder<Prefix>\n}\n\nexport interface UnibaseDecoder<Prefix extends string> extends MultibaseDecoder<Prefix> {\n  // Reserve this property so it can be used to derive type.\n  readonly decoders?: null\n\n  readonly prefix: Prefix\n}\n\nexport interface CombobaseDecoder<Prefix extends string> extends MultibaseDecoder<Prefix> {\n  readonly decoders: Record<Prefix, UnibaseDecoder<Prefix>>\n}\n","import type { Address } from 'viem'\n\nexport function createPieceUrl(cid: string, cdn: boolean, address: Address, chainId: number, pdpUrl: string) {\n  if (cdn) {\n    const endpoint = chainId === 314 ? `https://${address}.filbeam.io` : `https://${address}.calibration.filbeam.io`\n\n    const url = new URL(`/${cid}`, endpoint)\n    return url.toString()\n  } else {\n    return createPieceUrlPDP(cid, pdpUrl)\n  }\n}\n\nfunction createPieceUrlPDP(cid: string, pdpUrl: string) {\n  const endpoint = pdpUrl\n  const url = `piece/${cid}`\n  return new URL(url, endpoint).toString()\n}\n","/**\n * TelemetryService - Main telemetry service for Synapse SDK.\n * Per [issue #328](https://github.com/FilOzone/synapse-sdk/issues/328) this is primarily a thin wrapper around sentry.io.\n * It allows a caller to pass through [Sentry configuration options](https://docs.sentry.io/platforms/javascript/guides/nextjs/configuration/options/), where Synapse will apply some defaults if they aren't otherwise set.\n * (See the constructor for more information.)\n * The underlying Sentry instance can be accessed via `.sentry` for invoking any other [Sentry APIs](https://docs.sentry.io/platforms/javascript/apis/).\n *\n * In addition, to help with support tickets, the TelemetryService can be queried to get recent events:\n *\n * ```typescript\n * const dump = synapse.telemetry.debugDump()\n * console.log(JSON.stringify(dump, null, 2))\n * ```\n */\n\nimport type { BrowserOptions, ErrorEvent, EventHint } from '@sentry/browser'\nimport type { NodeOptions } from '@sentry/node'\nimport type { FilecoinNetworkType } from '../types.ts'\nimport { SDK_VERSION } from '../utils/sdk-version.ts'\nimport {\n  getSentry,\n  isBrowser,\n  type SentryBrowserType,\n  type SentryNodeType,\n  type SentryType,\n  sanitizeUrlForSpan,\n} from './utils.ts'\n\ntype SentryInitOptions = BrowserOptions | NodeOptions\ntype SentrySetTags = Parameters<SentryType['setTags']>[0]\n\ntype SentryBeforeSendFunction = (event: ErrorEvent, hint: EventHint) => Promise<ErrorEvent | null>\n\n/**\n * Extract the beforeSendSpan function type from both BrowserOptions and NodeOptions.\n * This ensures we match Sentry's expected signature exactly.\n */\ntype SentryBeforeSendSpanFunction = NonNullable<SentryInitOptions['beforeSendSpan']>\n\nexport interface TelemetryConfig {\n  /**\n   * Additional options to pass to the Sentry SDK's init method.\n   * See https://docs.sentry.io/platforms/javascript/configuration/options/\n   */\n  sentryInitOptions?: SentryInitOptions\n  /**\n   * Additional tags to set on the Sentry SDK.\n   * See https://docs.sentry.io/platforms/javascript/apis/#setTags\n   */\n  sentrySetTags?: SentrySetTags\n}\n\n/**\n * Configuration about the \"runtime environment\" for Synapse that needs Synapse-specific knowledge.\n * This isn't to be confused with [Sentry's Runtime context](https://develop.sentry.dev/sdk/data-model/event-payloads/contexts/#runtime-context).\n */\nexport interface TelemetryRuntimeContext {\n  filecoinNetwork: FilecoinNetworkType\n}\n\nexport interface DebugDump {\n  events: any[]\n}\n\n/**\n * Main telemetry service that manages the adapter and provides high-level APIs\n */\nexport class TelemetryService {\n  private eventBuffer: any[] = []\n  private readonly maxBufferSize = 15\n\n  sentry: SentryType | null = null\n\n  /**\n   * This is a separate function rather than being in the constructor because it is async. This is called by initGlobalTelemetry in singleton.ts, which is called by Synapse.create in synapse.ts.\n   * Default values that make sense for synapse-sdk will be set for some [Sentry configuration options](https://docs.sentry.io/platforms/javascript/guides/nextjs/configuration/options/) if they aren't otherwise specified.\n   * See the source for the specific defaults.\n   */\n  public async initSentry(config: TelemetryConfig, context: TelemetryRuntimeContext): Promise<void> {\n    const Sentry = await getSentry()\n    if (!Sentry) {\n      // Sentry dependencies not available, telemetry will be disabled\n      return\n    }\n    this.sentry = Sentry\n\n    // sentry attempts to dedupe some duplicate errors, see https://docs.sentry.io/platforms/javascript/configuration/integrations/dedupe/\n    const integrations = [Sentry.dedupeIntegration()]\n    let runtime: 'browser' | 'node'\n    if (isBrowser) {\n      runtime = 'browser'\n      integrations.push(\n        // only error-handling integrations\n        (Sentry as SentryBrowserType).globalHandlersIntegration({ onerror: true, onunhandledrejection: true })\n      )\n    } else {\n      runtime = 'node'\n      integrations.push(\n        // only error-handling integrations\n        (Sentry as SentryNodeType).onUncaughtExceptionIntegration(),\n        (Sentry as SentryNodeType).onUnhandledRejectionIntegration()\n      )\n    }\n\n    const globalTags = {\n      ...config.sentrySetTags, // get any tags consumers want to set\n\n      // things that consumers should not need, nor be able, to override\n      filecoinNetwork: context.filecoinNetwork, // The network (mainnet/calibration) that the synapse-sdk is being used in.\n      synapseSdkVersion: `@filoz/synapse-sdk@v${SDK_VERSION}`, // The version of the synapse-sdk that is being used.\n    }\n\n    this.sentry.init({\n      // Maps to Sentry project \"synapse-sdk-2\" on the backend.\n      dsn: 'https://7a07cc9e3b5bf5a8fada2f25dc76cd49@o4510235322023936.ingest.us.sentry.io/4510308233445376',\n      // Setting this option to false will prevent the SDK from sending default PII data to Sentry.\n      // For example, automatic IP address collection on events\n      sendDefaultPii: false,\n      // Enable tracing/performance monitoring\n      tracesSampleRate: 1.0, // Capture 100% of transactions for development (adjust in production)\n      integrations,\n      defaultIntegrations: false,\n      ...config.sentryInitOptions,\n      beforeSend: this.createBeforeSend(config),\n      beforeSendSpan: this.createBeforeSendSpan(config, globalTags),\n      release: `@filoz/synapse-sdk@v${SDK_VERSION}`,\n    })\n\n    // Things that we don't need to search for in sentry UI, but may be useful for debugging should be set as context.\n    // See https://docs.sentry.io/platforms/javascript/guides/nextjs/apis/#setContext\n    // In this case, we're using the \"common context\" of \"runtime\" as its the closest match.\n    // See https://develop.sentry.dev/sdk/data-model/event-payloads/contexts/#runtime-context\n    this.sentry.setContext('runtime', {\n      type: runtime,\n      // userAgent may not be useful for searching, but will be useful for debugging\n      userAgent: isBrowser && 'navigator' in globalThis ? (globalThis as any).navigator.userAgent : undefined,\n    })\n\n    // Things that we can search in the sentry UI (i.e. not millions of unique potential values, like userAgent would have) should be set as tags\n    this.sentry.setTags(globalTags)\n  }\n\n  /**\n   * Create a function that stores any events before Sentry sends to help with local debugging via `debugDump`.\n   * This function is intended to be set to [Sentry's `beforeSend` option](https://docs.sentry.io/platforms/javascript/guides/nextjs/configuration/options/#beforeSend).\n   * If the TelemetryConfig specified a `beforeSend` function, that function will be called after storing the event locally.\n   * The created `beforeSend` function is not [currently doing any filtering](https://docs.sentry.io/platforms/javascript/configuration/filtering/#using-before-send).\n   * @param config\n   * @returns Function that can be set for `beforeSend` Sentry option.\n   */\n  protected createBeforeSend(config: TelemetryConfig): SentryBeforeSendFunction {\n    return (async (event, hint) => {\n      this.addToEventBuffer(event)\n\n      if (config.sentryInitOptions?.beforeSend != null) {\n        return await config.sentryInitOptions.beforeSend(event, hint)\n      }\n\n      return event\n    }) satisfies SentryBeforeSendFunction\n  }\n\n  /**\n   * Create a function that sanitizes span descriptions before sending to Sentry.\n   * This function is intended to be set to [Sentry's `beforeSendSpan` option](https://docs.sentry.io/platforms/javascript/configuration/options/#beforeSendSpan).\n   * If the TelemetryConfig specified a `beforeSendSpan` function, that function will be called first, then sanitization will be applied.\n   * The sanitization replaces variable parts (UUIDs, CIDs, transaction hashes, numeric IDs) with placeholders to improve span grouping and reduce cardinality.\n   * Only applies to spans with descriptions that start with HTTP verbs (GET, POST, PUT, etc.).\n   *\n   * In addition, we ensure `op=http.client` spans get the tags that were set  with `sentry.setTags`.\n   * Without this, `op=http.client` spans will miss tags like `synapseSdkVersion`.\n   * We don't know why  `op=http.client` doesn't otherwise get \"global tags\", but this is our workaround.\n   * We want this so we can group by `<server.address,url.sanitizedPath,http.response.status_code>` and still filter by `synapseSdkVersion`.\n   * @param config\n   * @returns Function that can be set for `beforeSendSpan` Sentry option.\n   */\n  protected createBeforeSendSpan(\n    config: TelemetryConfig,\n    globalTags: Record<string, string>\n  ): SentryBeforeSendSpanFunction {\n    const httpVerbPattern = /^(GET|POST|PUT|PATCH|DELETE|HEAD|OPTIONS|TRACE|CONNECT)\\s/i\n\n    return ((span) => {\n      // Call user-provided beforeSendSpan first, if it exists\n      let modifiedSpan = span\n      if (config.sentryInitOptions?.beforeSendSpan != null) {\n        const userModifiedSpan = config.sentryInitOptions.beforeSendSpan(span)\n        if (userModifiedSpan != null) {\n          modifiedSpan = userModifiedSpan\n        }\n      }\n\n      // Sanitize the span description to reduce cardinality (only for HTTP verb spans)\n      // beforeSendSpan receives a plain JSON object with a description property\n      if (modifiedSpan.description && httpVerbPattern.test(modifiedSpan.description)) {\n        modifiedSpan.description = sanitizeUrlForSpan(modifiedSpan.description)\n\n        // Ensure the url.* tags have a sanitized path as well\n        if (modifiedSpan.op === 'http.client' || modifiedSpan.data['sentry.op'] === 'http.client') {\n          modifiedSpan.data = {\n            // Apply the \"global tags\" since `op=http.client` spans don't otherwise have them.\n            ...globalTags,\n            ...modifiedSpan.data,\n            // We call sanitizeUrlForSpan again here because modifiedSpan.description has a HTTP verb and a domain name before the path.\n            // The alternative is to remove the HTTP verb and domain name entirely.\n            'url.sanitizedPath': sanitizeUrlForSpan(modifiedSpan.data?.['url.path']?.toString() ?? ''),\n          }\n        }\n      }\n\n      return modifiedSpan\n    }) satisfies SentryBeforeSendSpanFunction\n  }\n\n  /**\n   * Get debug dump for support tickets\n   *\n   * Returns enough information for devs to dive into the data on filoz.sentry.io\n   *\n   * @example\n   * ```typescript\n   * const dump = synapse.telemetry.debugDump()\n   * console.log(JSON.stringify(dump, null, 2))\n   * ```\n   */\n  debugDump(limit = 50): DebugDump {\n    return {\n      events: this.eventBuffer.slice(-limit),\n    }\n  }\n\n  /**\n   * Add event to circular buffer\n   * @internal\n   */\n  private addToEventBuffer(event: any): void {\n    this.eventBuffer.push(event)\n    if (this.eventBuffer.length > this.maxBufferSize) {\n      this.eventBuffer.shift()\n    }\n  }\n}\n","export * from './constants.ts'\nexport { EIP712_ENCODED_TYPES, EIP712_TYPE_HASHES, EIP712_TYPES } from './eip712.ts'\nexport * from './epoch.ts'\nexport { createError } from './errors.ts'\nexport { combineMetadata, metadataMatches } from './metadata.ts'\nexport { getFilecoinNetworkType } from './network.ts'\nexport { constructFindPieceUrl, constructPieceUrl } from './piece.ts'\n","/**\n * Telemetry module exports\n *\n * Provides types for configuring telemetry and working with debug dumps.\n * The TelemetryService is accessed via synapse.telemetry getter.\n */\n\nexport { type DebugDump, type TelemetryConfig, TelemetryService } from './service.ts'\nexport { getGlobalTelemetry, initGlobalTelemetry } from './singleton.ts'\n","import isNetworkError from 'is-network-error';\n\nfunction validateRetries(retries) {\n\tif (typeof retries === 'number') {\n\t\tif (retries < 0) {\n\t\t\tthrow new TypeError('Expected `retries` to be a non-negative number.');\n\t\t}\n\n\t\tif (Number.isNaN(retries)) {\n\t\t\tthrow new TypeError('Expected `retries` to be a valid number or Infinity, got NaN.');\n\t\t}\n\t} else if (retries !== undefined) {\n\t\tthrow new TypeError('Expected `retries` to be a number or Infinity.');\n\t}\n}\n\nfunction validateNumberOption(name, value, {min = 0, allowInfinity = false} = {}) {\n\tif (value === undefined) {\n\t\treturn;\n\t}\n\n\tif (typeof value !== 'number' || Number.isNaN(value)) {\n\t\tthrow new TypeError(`Expected \\`${name}\\` to be a number${allowInfinity ? ' or Infinity' : ''}.`);\n\t}\n\n\tif (!allowInfinity && !Number.isFinite(value)) {\n\t\tthrow new TypeError(`Expected \\`${name}\\` to be a finite number.`);\n\t}\n\n\tif (value < min) {\n\t\tthrow new TypeError(`Expected \\`${name}\\` to be \\u2265 ${min}.`);\n\t}\n}\n\nexport class AbortError extends Error {\n\tconstructor(message) {\n\t\tsuper();\n\n\t\tif (message instanceof Error) {\n\t\t\tthis.originalError = message;\n\t\t\t({message} = message);\n\t\t} else {\n\t\t\tthis.originalError = new Error(message);\n\t\t\tthis.originalError.stack = this.stack;\n\t\t}\n\n\t\tthis.name = 'AbortError';\n\t\tthis.message = message;\n\t}\n}\n\nfunction calculateDelay(retriesConsumed, options) {\n\tconst attempt = Math.max(1, retriesConsumed + 1);\n\tconst random = options.randomize ? (Math.random() + 1) : 1;\n\n\tlet timeout = Math.round(random * options.minTimeout * (options.factor ** (attempt - 1)));\n\ttimeout = Math.min(timeout, options.maxTimeout);\n\n\treturn timeout;\n}\n\nfunction calculateRemainingTime(start, max) {\n\tif (!Number.isFinite(max)) {\n\t\treturn max;\n\t}\n\n\treturn max - (performance.now() - start);\n}\n\nasync function onAttemptFailure({error, attemptNumber, retriesConsumed, startTime, options}) {\n\tconst normalizedError = error instanceof Error\n\t\t? error\n\t\t: new TypeError(`Non-error was thrown: \"${error}\". You should only throw errors.`);\n\n\tif (normalizedError instanceof AbortError) {\n\t\tthrow normalizedError.originalError;\n\t}\n\n\tconst retriesLeft = Number.isFinite(options.retries)\n\t\t? Math.max(0, options.retries - retriesConsumed)\n\t\t: options.retries;\n\n\tconst maxRetryTime = options.maxRetryTime ?? Number.POSITIVE_INFINITY;\n\n\tconst context = Object.freeze({\n\t\terror: normalizedError,\n\t\tattemptNumber,\n\t\tretriesLeft,\n\t\tretriesConsumed,\n\t});\n\n\tawait options.onFailedAttempt(context);\n\n\tif (calculateRemainingTime(startTime, maxRetryTime) <= 0) {\n\t\tthrow normalizedError;\n\t}\n\n\tconst consumeRetry = await options.shouldConsumeRetry(context);\n\n\tconst remainingTime = calculateRemainingTime(startTime, maxRetryTime);\n\n\tif (remainingTime <= 0 || retriesLeft <= 0) {\n\t\tthrow normalizedError;\n\t}\n\n\tif (normalizedError instanceof TypeError && !isNetworkError(normalizedError)) {\n\t\tif (consumeRetry) {\n\t\t\tthrow normalizedError;\n\t\t}\n\n\t\toptions.signal?.throwIfAborted();\n\t\treturn false;\n\t}\n\n\tif (!await options.shouldRetry(context)) {\n\t\tthrow normalizedError;\n\t}\n\n\tif (!consumeRetry) {\n\t\toptions.signal?.throwIfAborted();\n\t\treturn false;\n\t}\n\n\tconst delayTime = calculateDelay(retriesConsumed, options);\n\tconst finalDelay = Math.min(delayTime, remainingTime);\n\n\tif (finalDelay > 0) {\n\t\tawait new Promise((resolve, reject) => {\n\t\t\tconst onAbort = () => {\n\t\t\t\tclearTimeout(timeoutToken);\n\t\t\t\toptions.signal?.removeEventListener('abort', onAbort);\n\t\t\t\treject(options.signal.reason);\n\t\t\t};\n\n\t\t\tconst timeoutToken = setTimeout(() => {\n\t\t\t\toptions.signal?.removeEventListener('abort', onAbort);\n\t\t\t\tresolve();\n\t\t\t}, finalDelay);\n\n\t\t\tif (options.unref) {\n\t\t\t\ttimeoutToken.unref?.();\n\t\t\t}\n\n\t\t\toptions.signal?.addEventListener('abort', onAbort, {once: true});\n\t\t});\n\t}\n\n\toptions.signal?.throwIfAborted();\n\n\treturn true;\n}\n\nexport default async function pRetry(input, options = {}) {\n\toptions = {...options};\n\n\tvalidateRetries(options.retries);\n\n\tif (Object.hasOwn(options, 'forever')) {\n\t\tthrow new Error('The `forever` option is no longer supported. For many use-cases, you can set `retries: Infinity` instead.');\n\t}\n\n\toptions.retries ??= 10;\n\toptions.factor ??= 2;\n\toptions.minTimeout ??= 1000;\n\toptions.maxTimeout ??= Number.POSITIVE_INFINITY;\n\toptions.maxRetryTime ??= Number.POSITIVE_INFINITY;\n\toptions.randomize ??= false;\n\toptions.onFailedAttempt ??= () => {};\n\toptions.shouldRetry ??= () => true;\n\toptions.shouldConsumeRetry ??= () => true;\n\n\t// Validate numeric options and normalize edge cases\n\tvalidateNumberOption('factor', options.factor, {min: 0, allowInfinity: false});\n\tvalidateNumberOption('minTimeout', options.minTimeout, {min: 0, allowInfinity: false});\n\tvalidateNumberOption('maxTimeout', options.maxTimeout, {min: 0, allowInfinity: true});\n\tvalidateNumberOption('maxRetryTime', options.maxRetryTime, {min: 0, allowInfinity: true});\n\n\t// Treat non-positive factor as 1 to avoid zero backoff or negative behavior\n\tif (!(options.factor > 0)) {\n\t\toptions.factor = 1;\n\t}\n\n\toptions.signal?.throwIfAborted();\n\n\tlet attemptNumber = 0;\n\tlet retriesConsumed = 0;\n\tconst startTime = performance.now();\n\n\twhile (Number.isFinite(options.retries) ? retriesConsumed <= options.retries : true) {\n\t\tattemptNumber++;\n\n\t\ttry {\n\t\t\toptions.signal?.throwIfAborted();\n\n\t\t\tconst result = await input(attemptNumber);\n\n\t\t\toptions.signal?.throwIfAborted();\n\n\t\t\treturn result;\n\t\t} catch (error) {\n\t\t\tif (await onAttemptFailure({\n\t\t\t\terror,\n\t\t\t\tattemptNumber,\n\t\t\t\tretriesConsumed,\n\t\t\t\tstartTime,\n\t\t\t\toptions,\n\t\t\t})) {\n\t\t\t\tretriesConsumed++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Should not reach here, but in case it does, throw an error\n\tthrow new Error('Retry attempts exhausted without throwing an error.');\n}\n\nexport function makeRetriable(function_, options) {\n\treturn function (...arguments_) {\n\t\treturn pRetry(() => function_.apply(this, arguments_), options);\n\t};\n}\n","// Maximum safe timeout value for setTimeout in JavaScript (2^31 - 1 milliseconds)\n// This is approximately 24.8 days\nexport const MAX_TIMEOUT = 2_147_483_647;\n\n// Brand symbol to identify our timeout/interval objects\n// Use Symbol.for to ensure cross-copy compatibility (monorepos, hoisted deps, etc.)\nconst brandSymbol = Symbol.for('sindresorhus/unlimited-timeout#brand');\n\nexport function setTimeout(callback, delay, ...arguments_) {\n\tif (typeof callback !== 'function') {\n\t\tthrow new TypeError('Expected callback to be a function');\n\t}\n\n\t// Coerce delay to number, matching native setTimeout behavior\n\tdelay ??= 0;\n\tdelay = Number(delay);\n\n\tlet shouldUnref = false;\n\tconst timeout = {\n\t\t[brandSymbol]: true,\n\t\tid: undefined,\n\t\tcleared: false,\n\t\tref() {\n\t\t\tshouldUnref = false;\n\t\t\ttimeout.id?.ref?.();\n\t\t\treturn timeout;\n\t\t},\n\t\tunref() {\n\t\t\tshouldUnref = true;\n\t\t\ttimeout.id?.unref?.();\n\t\t\treturn timeout;\n\t\t},\n\t};\n\n\t// Treat delays beyond MAX_SAFE_INTEGER as Infinity (precision loss)\n\t// and positive Infinity means wait forever (never fire)\n\tif (delay === Number.POSITIVE_INFINITY || delay > Number.MAX_SAFE_INTEGER) {\n\t\treturn timeout;\n\t}\n\n\t// Clamp invalid values to 0 (NaN, negative numbers result in immediate firing)\n\tif (!Number.isFinite(delay) || delay < 0) {\n\t\tdelay = 0;\n\t}\n\n\t// Track target timestamp to avoid overshoot when chunks fire late\n\tconst targetTime = performance.now() + delay;\n\n\tconst schedule = remainingDelay => {\n\t\tif (timeout.cleared) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (remainingDelay <= MAX_TIMEOUT) {\n\t\t\t// Final timeout - execute callback\n\t\t\ttimeout.id = globalThis.setTimeout(() => {\n\t\t\t\tif (!timeout.cleared) {\n\t\t\t\t\tcallback(...arguments_);\n\t\t\t\t}\n\t\t\t}, remainingDelay);\n\n\t\t\tif (shouldUnref) {\n\t\t\t\ttimeout.id?.unref?.();\n\t\t\t}\n\t\t} else {\n\t\t\t// Schedule next chunk\n\t\t\ttimeout.id = globalThis.setTimeout(() => {\n\t\t\t\tconst now = performance.now();\n\t\t\t\tconst remaining = Math.max(0, targetTime - now);\n\t\t\t\tschedule(remaining);\n\t\t\t}, MAX_TIMEOUT);\n\n\t\t\tif (shouldUnref) {\n\t\t\t\ttimeout.id?.unref?.();\n\t\t\t}\n\t\t}\n\t};\n\n\tschedule(delay);\n\n\treturn timeout;\n}\n\nexport function clearTimeout(timeout) {\n\tif (!timeout || typeof timeout !== 'object' || !timeout[brandSymbol]) {\n\t\treturn;\n\t}\n\n\ttimeout.cleared = true;\n\n\tif (timeout.id !== undefined) {\n\t\tglobalThis.clearTimeout(timeout.id);\n\t\ttimeout.id = undefined;\n\t}\n}\n\nexport function setInterval(callback, delay, ...arguments_) {\n\tif (typeof callback !== 'function') {\n\t\tthrow new TypeError('Expected callback to be a function');\n\t}\n\n\t// Coerce delay to number, matching native setInterval behavior\n\tdelay ??= 0;\n\tdelay = Number(delay);\n\n\tlet shouldUnref = false;\n\tconst interval = {\n\t\t[brandSymbol]: true,\n\t\tid: undefined,\n\t\tcleared: false,\n\t\tref() {\n\t\t\tshouldUnref = false;\n\t\t\tinterval.id?.ref?.();\n\t\t\treturn interval;\n\t\t},\n\t\tunref() {\n\t\t\tshouldUnref = true;\n\t\t\tinterval.id?.unref?.();\n\t\t\treturn interval;\n\t\t},\n\t};\n\n\t// Treat delays beyond MAX_SAFE_INTEGER as Infinity (precision loss)\n\t// and positive Infinity means wait forever (never fire)\n\tif (delay === Number.POSITIVE_INFINITY || delay > Number.MAX_SAFE_INTEGER) {\n\t\treturn interval;\n\t}\n\n\t// Clamp invalid values to 0 (NaN, negative numbers result in immediate firing)\n\tif (!Number.isFinite(delay) || delay < 0) {\n\t\tdelay = 0;\n\t}\n\n\t// Track target timestamp to avoid drift (use monotonic clock)\n\tlet nextTargetTime = performance.now() + delay;\n\n\tconst schedule = remainingDelay => {\n\t\tif (interval.cleared) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (remainingDelay <= MAX_TIMEOUT) {\n\t\t\t// Final timeout before callback\n\t\t\tinterval.id = globalThis.setTimeout(() => {\n\t\t\t\tif (interval.cleared) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\t// Pre-schedule next tick so throws don't kill the interval\n\t\t\t\tnextTargetTime += delay;\n\t\t\t\tconst now = performance.now();\n\t\t\t\tconst nextDelay = Math.max(0, nextTargetTime - now);\n\t\t\t\tschedule(nextDelay);\n\n\t\t\t\t// Now run user code — if it throws, the next tick still happens\n\t\t\t\tcallback(...arguments_);\n\t\t\t}, remainingDelay);\n\n\t\t\tif (shouldUnref) {\n\t\t\t\tinterval.id?.unref?.();\n\t\t\t}\n\t\t} else {\n\t\t\t// Schedule next chunk\n\t\t\tinterval.id = globalThis.setTimeout(() => {\n\t\t\t\tconst now = performance.now();\n\t\t\t\tconst nextDelay = Math.max(0, nextTargetTime - now);\n\t\t\t\tschedule(nextDelay);\n\t\t\t}, MAX_TIMEOUT);\n\n\t\t\tif (shouldUnref) {\n\t\t\t\tinterval.id?.unref?.();\n\t\t\t}\n\t\t}\n\t};\n\n\tschedule(delay);\n\n\treturn interval;\n}\n\nexport function clearInterval(interval) {\n\tif (!interval || typeof interval !== 'object' || !interval[brandSymbol]) {\n\t\treturn;\n\t}\n\n\tinterval.cleared = true;\n\n\tif (interval.id !== undefined) {\n\t\tglobalThis.clearTimeout(interval.id);\n\t\tinterval.id = undefined;\n\t}\n}\n","/**\n * Epoch to date conversion utilities for Filecoin networks\n */\n\nimport type { ethers } from 'ethers'\nimport type { FilecoinNetworkType } from '../types.ts'\nimport { GENESIS_TIMESTAMPS, TIME_CONSTANTS } from './constants.ts'\nimport { createError } from './index.ts'\n\n/**\n * Convert a Filecoin epoch to a JavaScript Date\n * @param epoch - The epoch number to convert\n * @param network - The Filecoin network (mainnet or calibration)\n * @returns Date object representing the epoch time\n */\nexport function epochToDate(epoch: number, network: FilecoinNetworkType): Date {\n  const genesisTimestamp = GENESIS_TIMESTAMPS[network]\n  const epochDuration = TIME_CONSTANTS.EPOCH_DURATION\n  const timestampSeconds = genesisTimestamp + epoch * epochDuration\n  return new Date(timestampSeconds * 1000) // Convert to milliseconds\n}\n\n/**\n * Convert a JavaScript Date to a Filecoin epoch\n * @param date - The date to convert\n * @param network - The Filecoin network (mainnet or calibration)\n * @returns The epoch number (rounded down to nearest epoch)\n */\nexport function dateToEpoch(date: Date, network: FilecoinNetworkType): number {\n  const genesisTimestamp = GENESIS_TIMESTAMPS[network]\n  const epochDuration = TIME_CONSTANTS.EPOCH_DURATION\n  const timestampSeconds = Math.floor(date.getTime() / 1000)\n  const secondsSinceGenesis = timestampSeconds - genesisTimestamp\n  return Math.floor(secondsSinceGenesis / epochDuration)\n}\n\n/**\n * Get the genesis timestamp for a network\n * @param network - The Filecoin network\n * @returns Genesis timestamp in seconds (Unix timestamp)\n */\nexport function getGenesisTimestamp(network: FilecoinNetworkType): number {\n  return GENESIS_TIMESTAMPS[network]\n}\n\n/**\n * Calculate the time until a future epoch\n * @param futureEpoch - The future epoch number\n * @param currentEpoch - The current epoch number\n * @returns Object with time until the epoch in various units\n */\nexport function timeUntilEpoch(\n  futureEpoch: number,\n  currentEpoch: number\n): {\n  epochs: number\n  seconds: number\n  minutes: number\n  hours: number\n  days: number\n} {\n  const epochDifference = futureEpoch - currentEpoch\n  const seconds = epochDifference * TIME_CONSTANTS.EPOCH_DURATION\n\n  return {\n    epochs: epochDifference,\n    seconds,\n    minutes: seconds / 60,\n    hours: seconds / 3600,\n    days: seconds / 86400,\n  }\n}\n\n/**\n * Calculate when the last proof should have been submitted based on current time\n * @param nextChallengeEpoch - The next challenge epoch from the data set\n * @param maxProvingPeriod - The maximum proving period in epochs\n * @param network - The Filecoin network\n * @returns Date when the last proof should have been submitted, or null if no proof submitted yet\n */\nexport function calculateLastProofDate(\n  nextChallengeEpoch: number,\n  maxProvingPeriod: number,\n  network: FilecoinNetworkType\n): Date | null {\n  // If nextChallengeEpoch is 0, no proofs scheduled\n  if (nextChallengeEpoch === 0) {\n    return null\n  }\n\n  // The last proof should have been submitted before the current proving period started\n  // Current proving period starts at nextChallengeEpoch - maxProvingPeriod\n  const lastProofEpoch = nextChallengeEpoch - maxProvingPeriod\n\n  // If this is negative, we're in the first proving period\n  if (lastProofEpoch <= 0) {\n    return null\n  }\n\n  return epochToDate(lastProofEpoch, network)\n}\n\n/**\n * Get the current epoch from the blockchain\n * @internal This is an internal utility, not part of the public API\n * @param provider - The ethers provider to query\n * @returns The current epoch as a bigint\n */\nexport async function getCurrentEpoch(provider: ethers.Provider): Promise<bigint> {\n  const blockNumber: number = await provider.getBlockNumber()\n  if (blockNumber == null) {\n    throw createError('epoch', 'getCurrentEpoch', 'Failed to get latest block number')\n  }\n  // In Filecoin, the block number is the epoch\n  return BigInt(blockNumber)\n}\n","import { version } from '../version.js'\n\n/** @internal */\nexport function getUrl(url: string) {\n  return url\n}\n\n/** @internal */\nexport function getVersion() {\n  return version\n}\n\n/** @internal */\nexport function prettyPrint(args: unknown) {\n  if (!args) return ''\n  const entries = Object.entries(args)\n    .map(([key, value]) => {\n      if (value === undefined || value === false) return null\n      return [key, value]\n    })\n    .filter(Boolean) as [string, string][]\n  const maxLength = entries.reduce((acc, [key]) => Math.max(acc, key.length), 0)\n  return entries\n    .map(([key, value]) => `  ${`${key}:`.padEnd(maxLength + 1)}  ${value}`)\n    .join('\\n')\n}\n","import * as Bytes from '../Bytes.js'\nimport type * as Errors from '../Errors.js'\n\n/** @internal */\nexport function assertSize(bytes: Bytes.Bytes, size_: number): void {\n  if (Bytes.size(bytes) > size_)\n    throw new Bytes.SizeOverflowError({\n      givenSize: Bytes.size(bytes),\n      maxSize: size_,\n    })\n}\n\n/** @internal */\nexport declare namespace assertSize {\n  type ErrorType =\n    | Bytes.size.ErrorType\n    | Bytes.SizeOverflowError\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function assertStartOffset(\n  value: Bytes.Bytes,\n  start?: number | undefined,\n) {\n  if (typeof start === 'number' && start > 0 && start > Bytes.size(value) - 1)\n    throw new Bytes.SliceOffsetOutOfBoundsError({\n      offset: start,\n      position: 'start',\n      size: Bytes.size(value),\n    })\n}\n\nexport declare namespace assertStartOffset {\n  export type ErrorType =\n    | Bytes.SliceOffsetOutOfBoundsError\n    | Bytes.size.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function assertEndOffset(\n  value: Bytes.Bytes,\n  start?: number | undefined,\n  end?: number | undefined,\n) {\n  if (\n    typeof start === 'number' &&\n    typeof end === 'number' &&\n    Bytes.size(value) !== end - start\n  ) {\n    throw new Bytes.SliceOffsetOutOfBoundsError({\n      offset: end,\n      position: 'end',\n      size: Bytes.size(value),\n    })\n  }\n}\n\n/** @internal */\nexport declare namespace assertEndOffset {\n  type ErrorType =\n    | Bytes.SliceOffsetOutOfBoundsError\n    | Bytes.size.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport const charCodeMap = {\n  zero: 48,\n  nine: 57,\n  A: 65,\n  F: 70,\n  a: 97,\n  f: 102,\n} as const\n\n/** @internal */\nexport function charCodeToBase16(char: number) {\n  if (char >= charCodeMap.zero && char <= charCodeMap.nine)\n    return char - charCodeMap.zero\n  if (char >= charCodeMap.A && char <= charCodeMap.F)\n    return char - (charCodeMap.A - 10)\n  if (char >= charCodeMap.a && char <= charCodeMap.f)\n    return char - (charCodeMap.a - 10)\n  return undefined\n}\n\n/** @internal */\nexport function pad(bytes: Bytes.Bytes, options: pad.Options = {}) {\n  const { dir, size = 32 } = options\n  if (size === 0) return bytes\n  if (bytes.length > size)\n    throw new Bytes.SizeExceedsPaddingSizeError({\n      size: bytes.length,\n      targetSize: size,\n      type: 'Bytes',\n    })\n  const paddedBytes = new Uint8Array(size)\n  for (let i = 0; i < size; i++) {\n    const padEnd = dir === 'right'\n    paddedBytes[padEnd ? i : size - i - 1] =\n      bytes[padEnd ? i : bytes.length - i - 1]!\n  }\n  return paddedBytes\n}\n\n/** @internal */\nexport declare namespace pad {\n  type Options = {\n    dir?: 'left' | 'right' | undefined\n    size?: number | undefined\n  }\n\n  type ReturnType = Bytes.Bytes\n\n  type ErrorType = Bytes.SizeExceedsPaddingSizeError | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function trim(\n  value: Bytes.Bytes,\n  options: trim.Options = {},\n): trim.ReturnType {\n  const { dir = 'left' } = options\n\n  let data = value\n\n  let sliceLength = 0\n  for (let i = 0; i < data.length - 1; i++) {\n    if (data[dir === 'left' ? i : data.length - i - 1]!.toString() === '0')\n      sliceLength++\n    else break\n  }\n  data =\n    dir === 'left'\n      ? data.slice(sliceLength)\n      : data.slice(0, data.length - sliceLength)\n\n  return data as trim.ReturnType\n}\n\n/** @internal */\nexport declare namespace trim {\n  type Options = {\n    dir?: 'left' | 'right' | undefined\n  }\n\n  type ReturnType = Bytes.Bytes\n\n  type ErrorType = Errors.GlobalErrorType\n}\n","/**\n * PieceRetriever implementations for flexible piece fetching\n *\n * This module provides different strategies for retrieving pieces:\n * - ChainRetriever: Queries on-chain data to find providers\n * - FilBeamRetriever: CDN optimization wrapper\n * - SubgraphRetriever: Queries a GraphQL subgraph to find providers\n */\n\nexport { ChainRetriever } from './chain.ts'\nexport { FilBeamRetriever } from './filbeam.ts'\nexport { SubgraphRetriever } from './subgraph.ts'\n","/* eslint-disable */\nvar encode_1 = encode;\n\nvar MSB = 0x80\n  , REST = 0x7F\n  , MSBALL = ~REST\n  , INT = Math.pow(2, 31);\n\n/**\n * @param {number} num\n * @param {number[]} out\n * @param {number} offset\n */\nfunction encode(num, out, offset) {\n  out = out || [];\n  offset = offset || 0;\n  var oldOffset = offset;\n\n  while(num >= INT) {\n    out[offset++] = (num & 0xFF) | MSB;\n    num /= 128;\n  }\n  while(num & MSBALL) {\n    out[offset++] = (num & 0xFF) | MSB;\n    num >>>= 7;\n  }\n  out[offset] = num | 0;\n  \n  // @ts-ignore\n  encode.bytes = offset - oldOffset + 1;\n  \n  return out\n}\n\nvar decode = read;\n\nvar MSB$1 = 0x80\n  , REST$1 = 0x7F;\n\n/**\n * @param {string | any[]} buf\n * @param {number} offset\n */\nfunction read(buf, offset) {\n  var res    = 0\n    , offset = offset || 0\n    , shift  = 0\n    , counter = offset\n    , b\n    , l = buf.length;\n\n  do {\n    if (counter >= l) {\n      // @ts-ignore\n      read.bytes = 0;\n      throw new RangeError('Could not decode varint')\n    }\n    b = buf[counter++];\n    res += shift < 28\n      ? (b & REST$1) << shift\n      : (b & REST$1) * Math.pow(2, shift);\n    shift += 7;\n  } while (b >= MSB$1)\n\n  // @ts-ignore\n  read.bytes = counter - offset;\n\n  return res\n}\n\nvar N1 = Math.pow(2,  7);\nvar N2 = Math.pow(2, 14);\nvar N3 = Math.pow(2, 21);\nvar N4 = Math.pow(2, 28);\nvar N5 = Math.pow(2, 35);\nvar N6 = Math.pow(2, 42);\nvar N7 = Math.pow(2, 49);\nvar N8 = Math.pow(2, 56);\nvar N9 = Math.pow(2, 63);\n\nvar length = function (/** @type {number} */ value) {\n  return (\n    value < N1 ? 1\n  : value < N2 ? 2\n  : value < N3 ? 3\n  : value < N4 ? 4\n  : value < N5 ? 5\n  : value < N6 ? 6\n  : value < N7 ? 7\n  : value < N8 ? 8\n  : value < N9 ? 9\n  :              10\n  )\n};\n\nvar varint = {\n    encode: encode_1\n  , decode: decode\n  , encodingLength: length\n};\n\nvar _brrp_varint = varint;\n\nexport default _brrp_varint;\n","import * as dn from 'dnum'\n\nexport function formatBalance(\n  data: { value?: bigint; decimals?: number; compact?: boolean; digits?: number } | undefined\n) {\n  return dn.format([data?.value ?? 0n, data?.decimals ?? 18], {\n    compact: data?.compact ?? true,\n    digits: data?.digits ?? 4,\n  })\n}\n\nexport function formatFraction(\n  data: { value?: bigint; decimals?: number; compact?: boolean; digits?: number } | undefined\n) {\n  return dn.format([data?.value ?? 0n, data?.decimals ?? 18], {\n    compact: data?.compact ?? false,\n    digits: data?.digits ?? 8,\n  })\n}\n","/**\n * Utility to attempt fetching a piece from multiple providers in parallel.\n */\n\nimport type { PieceCID, ProviderInfo } from '../types.ts'\nimport { createError } from '../utils/errors.ts'\nimport { constructFindPieceUrl, constructPieceUrl } from '../utils/piece.ts'\n\n// Define the type for provider attempt results (internal to this function)\ninterface ProviderAttemptResult {\n  response: Response\n  index: number\n}\n\n/**\n * Attempt to fetch a piece from multiple providers in parallel\n * @param providers - List of providers to try\n * @param pieceCid - The piece to fetch\n * @param retrieverName - Name of the calling retriever for error reporting\n * @param signal - Optional abort signal\n * @returns The first successful response\n */\nexport async function fetchPiecesFromProviders(\n  providers: ProviderInfo[],\n  pieceCid: PieceCID,\n  retrieverName: string,\n  signal?: AbortSignal\n): Promise<Response> {\n  // Track failures for error reporting\n  const failures: Array<{ provider: string; error: string }> = []\n\n  // Create individual abort controllers for each provider\n  const abortControllers: AbortController[] = []\n\n  const providerAttempts: Array<Promise<ProviderAttemptResult>> = providers.map(async (provider, index) => {\n    // Create a dedicated controller for this provider\n    const controller = new AbortController()\n    abortControllers[index] = controller\n\n    // If parent signal is provided, propagate abort to this controller\n    if (signal != null) {\n      signal.addEventListener(\n        'abort',\n        () => {\n          controller.abort(signal.reason)\n        },\n        { once: true }\n      )\n\n      // If parent is already aborted, abort immediately\n      if (signal.aborted) {\n        controller.abort(signal.reason)\n      }\n    }\n\n    try {\n      // Phase 1: Check if provider has the piece\n      if (!provider.products.PDP?.data.serviceURL) {\n        throw new Error(`Provider ${provider.id} does not have PDP product with serviceURL`)\n      }\n      const findUrl = constructFindPieceUrl(provider.products.PDP.data.serviceURL, pieceCid)\n      const findResponse = await fetch(findUrl, {\n        signal: controller.signal,\n      })\n\n      if (!findResponse.ok) {\n        // Provider doesn't have the piece\n        failures.push({\n          provider: provider.serviceProvider,\n          error: `findPiece returned ${findResponse.status}`,\n        })\n        throw new Error('Provider does not have piece')\n      }\n\n      // Phase 2: Provider has piece, download it\n      const downloadUrl = constructPieceUrl(provider.products.PDP.data.serviceURL, pieceCid)\n      const response = await fetch(downloadUrl, {\n        signal: controller.signal,\n      })\n\n      if (response.ok) {\n        // Don't cancel here! Let Promise.race decide the winner\n        return { response, index }\n      }\n\n      // Download failed\n      failures.push({\n        provider: provider.serviceProvider,\n        error: `download returned ${response.status}`,\n      })\n      throw new Error(`Download failed with status ${response.status}`)\n    } catch (error: any) {\n      // Log actual failures\n      const errorMsg = error.message ?? 'Unknown error'\n      if (!failures.some((f) => f.provider === provider.serviceProvider)) {\n        failures.push({ provider: provider.serviceProvider, error: errorMsg })\n      }\n      if (errorMsg !== 'This operation was aborted') {\n        // TODO: remove this at some point, it might get noisy\n        console.warn(`Failed to fetch from provider ${provider.serviceProvider}:`, errorMsg)\n      }\n      throw error\n    }\n  })\n\n  try {\n    // Use Promise.any to get the first successful response\n    const { response, index: winnerIndex } = await Promise.any(providerAttempts)\n\n    // Now that we have a winner, cancel all other requests\n    abortControllers.forEach((ctrl, i) => {\n      if (i !== winnerIndex) {\n        ctrl.abort()\n      }\n    })\n\n    return response\n  } catch (error) {\n    // Promise.any throws AggregateError when all promises reject\n    if (error instanceof AggregateError) {\n      // All providers failed\n      const failureDetails = failures.map((f) => `${f.provider}: ${f.error}`).join('; ')\n      throw createError(\n        retrieverName,\n        'fetchPiecesFromProviders',\n        `All providers failed to serve piece ${pieceCid.toString()}. Details: ${failureDetails}`\n      )\n    }\n    // Re-throw unexpected errors\n    throw error\n  }\n}\n","export const empty = new Uint8Array(0)\n\nexport function toHex (d: Uint8Array): string {\n  return d.reduce((hex, byte) => hex + byte.toString(16).padStart(2, '0'), '')\n}\n\nexport function fromHex (hex: string): Uint8Array {\n  const hexes = hex.match(/../g)\n  return hexes != null ? new Uint8Array(hexes.map(b => parseInt(b, 16))) : empty\n}\n\nexport function equals (aa: Uint8Array, bb: Uint8Array): boolean {\n  if (aa === bb) { return true }\n  if (aa.byteLength !== bb.byteLength) {\n    return false\n  }\n\n  for (let ii = 0; ii < aa.byteLength; ii++) {\n    if (aa[ii] !== bb[ii]) {\n      return false\n    }\n  }\n\n  return true\n}\n\nexport function coerce (o: ArrayBufferView | ArrayBuffer | Uint8Array): Uint8Array {\n  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') { return o }\n  if (o instanceof ArrayBuffer) { return new Uint8Array(o) }\n  if (ArrayBuffer.isView(o)) {\n    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)\n  }\n  throw new Error('Unknown type, must be binary type')\n}\n\nexport function isBinary (o: unknown): o is ArrayBuffer | ArrayBufferView {\n  return o instanceof ArrayBuffer || ArrayBuffer.isView(o)\n}\n\nexport function fromString (str: string): Uint8Array {\n  return new TextEncoder().encode(str)\n}\n\nexport function toString (b: Uint8Array): string {\n  return new TextDecoder().decode(b)\n}\n","/**\n * WarmStorageService - Consolidated interface for all Warm Storage contract operations\n *\n * This combines functionality for:\n * - Data set management and queries\n * - Service provider registration and management\n * - Client dataset ID tracking\n * - Data set creation verification\n * - CDN service management\n *\n * @example\n * ```typescript\n * import { WarmStorageService } from '@filoz/synapse-sdk/warm-storage'\n * import { ethers } from 'ethers'\n *\n * const provider = new ethers.JsonRpcProvider(rpcUrl)\n * const warmStorageService = new WarmStorageService(provider, warmStorageAddress, pdpVerifierAddress)\n *\n * // Get data sets for a client\n * const dataSets = await warmStorageService.getClientDataSets(clientAddress)\n * console.log(`Client has ${dataSets.length} data sets`)\n *\n * // Register as a service provider\n * const signer = await provider.getSigner()\n * await warmStorageService.registerServiceProvider(signer, pdpUrl, retrievalUrl)\n * ```\n */\n\nimport { ethers } from 'ethers'\nimport type { PaymentsService } from '../payments/service.ts'\nimport type { DataSetCreationStatusResponse, PDPServer } from '../pdp/server.ts'\nimport { PDPVerifier } from '../pdp/verifier.ts'\nimport type { DataSetInfo, EnhancedDataSetInfo } from '../types.ts'\nimport { CONTRACT_ADDRESSES, SIZE_CONSTANTS, TIME_CONSTANTS, TIMING_CONSTANTS } from '../utils/constants.ts'\nimport { CONTRACT_ABIS, createError, getFilecoinNetworkType, TOKENS } from '../utils/index.ts'\n\n/**\n * Service price information\n */\nexport interface ServicePriceInfo {\n  /** Price per TiB per month without CDN (in base units) */\n  pricePerTiBPerMonthNoCDN: bigint\n  /** CDN egress price per TiB (usage-based, in base units) */\n  pricePerTiBCdnEgress: bigint\n  /** Cache miss egress price per TiB (usage-based, in base units) */\n  pricePerTiBCacheMissEgress: bigint\n  /** Token address for payments */\n  tokenAddress: string\n  /** Number of epochs per month */\n  epochsPerMonth: bigint\n  /** Minimum monthly charge for any dataset size (in base units) */\n  minimumPricePerMonth: bigint\n}\n\n/**\n * Result of verifying data set creation on-chain\n */\nexport interface DataSetCreationVerification {\n  /** Whether the transaction has been mined */\n  transactionMined: boolean\n  /** Whether the transaction was successful */\n  transactionSuccess: boolean\n  /** The data set ID that was created (if successful) */\n  dataSetId?: number\n  /** Whether the data set exists and is live on-chain */\n  dataSetLive: boolean\n  /** Block number where the transaction was mined (if mined) */\n  blockNumber?: number\n  /** Gas used by the transaction (if mined) */\n  gasUsed?: bigint\n  /** Error message if something went wrong */\n  error?: string\n}\n\n/**\n * Combined status information from both PDP server and chain\n */\nexport interface ComprehensiveDataSetStatus {\n  /** Transaction hash */\n  txHash: string\n  /** Server-side status */\n  serverStatus: DataSetCreationStatusResponse | null\n  /** Chain verification status */\n  chainStatus: DataSetCreationVerification\n  /** Combined status summary */\n  summary: {\n    /** Whether creation is complete and successful, both on chain and on the server */\n    isComplete: boolean\n    /** Whether data set is live on chain */\n    isLive: boolean\n    /** Final data set ID if available */\n    dataSetId: number | null\n    /** Any error messages */\n    error: string | null\n  }\n}\n\nexport class WarmStorageService {\n  private readonly _provider: ethers.Provider\n  private readonly _warmStorageAddress: string\n  private _warmStorageContract: ethers.Contract | null = null\n  private _warmStorageViewContract: ethers.Contract | null = null\n  private _pdpVerifier: PDPVerifier | null = null\n\n  // All discovered addresses\n  private readonly _addresses: {\n    pdpVerifier: string\n    payments: string\n    usdfcToken: string\n    filBeamBeneficiary: string\n    viewContract: string\n    serviceProviderRegistry: string\n    sessionKeyRegistry: string\n  }\n\n  /**\n   * Private constructor - use WarmStorageService.create() instead\n   */\n  private constructor(\n    provider: ethers.Provider,\n    warmStorageAddress: string,\n    addresses: {\n      pdpVerifier: string\n      payments: string\n      usdfcToken: string\n      filBeamBeneficiary: string\n      viewContract: string\n      serviceProviderRegistry: string\n      sessionKeyRegistry: string\n    }\n  ) {\n    this._provider = provider\n    this._warmStorageAddress = warmStorageAddress\n    this._addresses = addresses\n  }\n\n  /**\n   * Create a new WarmStorageService instance with initialized addresses\n   */\n  static async create(provider: ethers.Provider, warmStorageAddress: string): Promise<WarmStorageService> {\n    // Get network from provider and validate it's a supported Filecoin network\n    const networkName = await getFilecoinNetworkType(provider)\n\n    // Initialize all contract addresses using Multicall3\n    const multicall = new ethers.Contract(\n      CONTRACT_ADDRESSES.MULTICALL3[networkName],\n      CONTRACT_ABIS.MULTICALL3,\n      provider\n    )\n\n    const iface = new ethers.Interface(CONTRACT_ABIS.WARM_STORAGE)\n\n    const calls = [\n      {\n        target: warmStorageAddress,\n        allowFailure: false,\n        callData: iface.encodeFunctionData('pdpVerifierAddress'),\n      },\n      {\n        target: warmStorageAddress,\n        allowFailure: false,\n        callData: iface.encodeFunctionData('paymentsContractAddress'),\n      },\n      {\n        target: warmStorageAddress,\n        allowFailure: false,\n        callData: iface.encodeFunctionData('usdfcTokenAddress'),\n      },\n      {\n        target: warmStorageAddress,\n        allowFailure: false,\n        callData: iface.encodeFunctionData('filBeamBeneficiaryAddress'),\n      },\n      {\n        target: warmStorageAddress,\n        allowFailure: false,\n        callData: iface.encodeFunctionData('viewContractAddress'),\n      },\n      {\n        target: warmStorageAddress,\n        allowFailure: false,\n        callData: iface.encodeFunctionData('serviceProviderRegistry'),\n      },\n      {\n        target: warmStorageAddress,\n        allowFailure: false,\n        callData: iface.encodeFunctionData('sessionKeyRegistry'),\n      },\n    ]\n\n    const results = await multicall.aggregate3.staticCall(calls)\n\n    const addresses = {\n      pdpVerifier: iface.decodeFunctionResult('pdpVerifierAddress', results[0].returnData)[0],\n      payments: iface.decodeFunctionResult('paymentsContractAddress', results[1].returnData)[0],\n      usdfcToken: iface.decodeFunctionResult('usdfcTokenAddress', results[2].returnData)[0],\n      filBeamBeneficiary: iface.decodeFunctionResult('filBeamBeneficiaryAddress', results[3].returnData)[0],\n      viewContract: iface.decodeFunctionResult('viewContractAddress', results[4].returnData)[0],\n      serviceProviderRegistry: iface.decodeFunctionResult('serviceProviderRegistry', results[5].returnData)[0],\n      sessionKeyRegistry: iface.decodeFunctionResult('sessionKeyRegistry', results[6].returnData)[0],\n    }\n\n    return new WarmStorageService(provider, warmStorageAddress, addresses)\n  }\n\n  getPDPVerifierAddress(): string {\n    return this._addresses.pdpVerifier\n  }\n\n  getPaymentsAddress(): string {\n    return this._addresses.payments\n  }\n\n  getUSDFCTokenAddress(): string {\n    return this._addresses.usdfcToken\n  }\n\n  getViewContractAddress(): string {\n    return this._addresses.viewContract\n  }\n\n  getServiceProviderRegistryAddress(): string {\n    return this._addresses.serviceProviderRegistry\n  }\n\n  getSessionKeyRegistryAddress(): string {\n    return this._addresses.sessionKeyRegistry\n  }\n\n  /**\n   * Get the provider instance\n   * @returns The ethers provider\n   */\n  getProvider(): ethers.Provider {\n    return this._provider\n  }\n\n  /**\n   * Get cached Warm Storage contract instance or create new one\n   */\n  private _getWarmStorageContract(): ethers.Contract {\n    if (this._warmStorageContract == null) {\n      this._warmStorageContract = new ethers.Contract(\n        this._warmStorageAddress,\n        CONTRACT_ABIS.WARM_STORAGE,\n        this._provider\n      )\n    }\n    return this._warmStorageContract\n  }\n\n  /**\n   * Get cached Warm Storage View contract instance or create new one\n   */\n  private _getWarmStorageViewContract(): ethers.Contract {\n    if (this._warmStorageViewContract == null) {\n      const viewAddress = this.getViewContractAddress()\n      this._warmStorageViewContract = new ethers.Contract(viewAddress, CONTRACT_ABIS.WARM_STORAGE_VIEW, this._provider)\n    }\n    return this._warmStorageViewContract\n  }\n\n  /**\n   * Get cached PDPVerifier instance or create new one\n   */\n  private _getPDPVerifier(): PDPVerifier {\n    if (this._pdpVerifier == null) {\n      const address = this.getPDPVerifierAddress()\n      this._pdpVerifier = new PDPVerifier(this._provider, address)\n    }\n    return this._pdpVerifier\n  }\n\n  // ========== Client Data Set Operations ==========\n\n  /**\n   * Get a single data set by ID\n   * @param dataSetId - The data set ID to retrieve\n   * @returns Data set information\n   * @throws Error if data set doesn't exist\n   */\n  async getDataSet(dataSetId: number): Promise<DataSetInfo> {\n    const viewContract = this._getWarmStorageViewContract()\n    const ds = await viewContract.getDataSet(dataSetId)\n\n    if (Number(ds.pdpRailId) === 0) {\n      throw createError('WarmStorageService', 'getDataSet', `Data set ${dataSetId} does not exist`)\n    }\n\n    // Convert from on-chain format to our interface\n    return {\n      pdpRailId: Number(ds.pdpRailId),\n      cacheMissRailId: Number(ds.cacheMissRailId),\n      cdnRailId: Number(ds.cdnRailId),\n      payer: ds.payer,\n      payee: ds.payee,\n      serviceProvider: ds.serviceProvider,\n      commissionBps: Number(ds.commissionBps),\n      clientDataSetId: ds.clientDataSetId,\n      pdpEndEpoch: Number(ds.pdpEndEpoch),\n      providerId: Number(ds.providerId),\n      dataSetId,\n    }\n  }\n\n  /**\n   * Get all data sets for a specific client\n   * @param clientAddress - The client address\n   * @returns Array of data set information\n   */\n  async getClientDataSets(clientAddress: string): Promise<DataSetInfo[]> {\n    try {\n      const viewContract = this._getWarmStorageViewContract()\n      const dataSetData = await viewContract.getClientDataSets(clientAddress)\n\n      // Convert from on-chain format to our interface\n      return dataSetData.map((ds: any) => ({\n        pdpRailId: Number(ds.pdpRailId),\n        cacheMissRailId: Number(ds.cacheMissRailId),\n        cdnRailId: Number(ds.cdnRailId),\n        payer: ds.payer,\n        payee: ds.payee,\n        serviceProvider: ds.serviceProvider,\n        commissionBps: Number(ds.commissionBps),\n        clientDataSetId: ds.clientDataSetId,\n        pdpEndEpoch: Number(ds.pdpEndEpoch),\n        providerId: Number(ds.providerId),\n      }))\n    } catch (error) {\n      throw new Error(`Failed to get client data sets: ${error instanceof Error ? error.message : String(error)}`)\n    }\n  }\n\n  /**\n   * Get all data sets for a client with enhanced details\n   * This includes live status and management information\n   * @param client - The client address\n   * @param onlyManaged - If true, only return data sets managed by this Warm Storage contract\n   * @returns Array of enhanced data set information\n   */\n  async getClientDataSetsWithDetails(client: string, onlyManaged: boolean = false): Promise<EnhancedDataSetInfo[]> {\n    const pdpVerifier = this._getPDPVerifier()\n    const viewContract = this._getWarmStorageViewContract()\n\n    // Query dataset IDs directly from the view contract\n    const ids: bigint[] = await viewContract.clientDataSets(client)\n    if (ids.length === 0) return []\n\n    // Enhance all in parallel using dataset IDs\n    const enhancedDataSetsPromises = ids.map(async (idBigInt) => {\n      const pdpVerifierDataSetId = Number(idBigInt)\n      try {\n        const base = await this.getDataSet(pdpVerifierDataSetId)\n\n        // Parallelize independent calls\n        const [isLive, listenerResult, metadata] = await Promise.all([\n          pdpVerifier.dataSetLive(pdpVerifierDataSetId),\n          pdpVerifier.getDataSetListener(pdpVerifierDataSetId).catch(() => null),\n          this.getDataSetMetadata(pdpVerifierDataSetId).catch(() => Object.create(null) as Record<string, string>),\n        ])\n\n        // Check if this data set is managed by our Warm Storage contract\n        const isManaged =\n          listenerResult != null && listenerResult.toLowerCase() === this._warmStorageAddress.toLowerCase()\n\n        // Skip unmanaged data sets if onlyManaged is true\n        if (onlyManaged && !isManaged) {\n          return null // Will be filtered out\n        }\n\n        // Get next piece ID only if the data set is live\n        const nextPieceId = isLive ? await pdpVerifier.getNextPieceId(pdpVerifierDataSetId) : 0n\n\n        return {\n          ...base,\n          pdpVerifierDataSetId,\n          nextPieceId: Number(nextPieceId),\n          currentPieceCount: Number(nextPieceId),\n          isLive,\n          isManaged,\n          withCDN: base.cdnRailId > 0,\n          metadata,\n        }\n      } catch (error) {\n        throw new Error(\n          `Failed to get details for data set ${pdpVerifierDataSetId}: ${error instanceof Error ? error.message : String(error)}`\n        )\n      }\n    })\n\n    // Wait for all promises to resolve\n    const results = await Promise.all(enhancedDataSetsPromises)\n\n    // Filter out null values (from skipped data sets when onlyManaged is true)\n    return results.filter((result): result is EnhancedDataSetInfo => result !== null)\n  }\n\n  /**\n   * Validate that a dataset is live and managed by this WarmStorage contract\n   *\n   * Performs validation checks in parallel:\n   * - Dataset exists and is live\n   * - Dataset is managed by this WarmStorage contract\n   *\n   * @param dataSetId - The PDPVerifier data set ID\n   * @throws if dataset is not valid for operations\n   */\n  async validateDataSet(dataSetId: number): Promise<void> {\n    const pdpVerifier = this._getPDPVerifier()\n\n    // Parallelize validation checks\n    const [isLive, listener] = await Promise.all([\n      pdpVerifier.dataSetLive(Number(dataSetId)),\n      pdpVerifier.getDataSetListener(Number(dataSetId)),\n    ])\n\n    // Check if data set exists and is live\n    if (!isLive) {\n      throw new Error(`Data set ${dataSetId} does not exist or is not live`)\n    }\n\n    // Verify this data set is managed by our Warm Storage contract\n    if (listener.toLowerCase() !== this._warmStorageAddress.toLowerCase()) {\n      throw new Error(\n        `Data set ${dataSetId} is not managed by this WarmStorage contract (${\n          this._warmStorageAddress\n        }), managed by ${String(listener)}`\n      )\n    }\n  }\n\n  /**\n   * Verify that a data set creation transaction was successful\n   * This checks both the transaction status and on-chain data set state\n   * @param txHashOrTransaction - Transaction hash or transaction object\n   * @returns Verification result with data set ID if found\n   */\n  async verifyDataSetCreation(\n    txHashOrTransaction: string | ethers.TransactionResponse\n  ): Promise<DataSetCreationVerification> {\n    try {\n      // Get transaction hash\n      const txHash = typeof txHashOrTransaction === 'string' ? txHashOrTransaction : txHashOrTransaction.hash\n\n      // Get transaction receipt\n      let receipt: ethers.TransactionReceipt | null\n      if (typeof txHashOrTransaction === 'string') {\n        receipt = await this._provider.getTransactionReceipt(txHash)\n      } else {\n        // If we have a transaction object, use its wait method which is more efficient\n        receipt = await txHashOrTransaction.wait(TIMING_CONSTANTS.TRANSACTION_CONFIRMATIONS)\n      }\n\n      if (receipt == null) {\n        // Transaction not yet mined\n        return {\n          transactionMined: false,\n          transactionSuccess: false,\n          dataSetLive: false,\n        }\n      }\n\n      // Transaction is mined, check if it was successful\n      const transactionSuccess = receipt.status === 1\n\n      if (!transactionSuccess) {\n        return {\n          transactionMined: true,\n          transactionSuccess: false,\n          dataSetLive: false,\n          blockNumber: receipt.blockNumber,\n          gasUsed: receipt.gasUsed,\n          error: 'Transaction failed',\n        }\n      }\n\n      // Extract data set ID from transaction logs\n      const pdpVerifier = this._getPDPVerifier()\n      const dataSetId = await pdpVerifier.extractDataSetIdFromReceipt(receipt)\n\n      if (dataSetId == null) {\n        return {\n          transactionMined: true,\n          transactionSuccess: true,\n          dataSetLive: false,\n          blockNumber: receipt.blockNumber,\n          gasUsed: receipt.gasUsed,\n          error: 'Could not find DataSetCreated event in transaction',\n        }\n      }\n\n      // Verify the data set exists and is live on-chain\n      const isLive = await pdpVerifier.dataSetLive(dataSetId)\n\n      return {\n        transactionMined: true,\n        transactionSuccess: true,\n        dataSetId,\n        dataSetLive: isLive,\n        blockNumber: receipt.blockNumber,\n        gasUsed: receipt.gasUsed,\n      }\n    } catch (error) {\n      // Error during verification (e.g., network issues)\n      return {\n        transactionMined: false,\n        transactionSuccess: false,\n        dataSetLive: false,\n        error: error instanceof Error ? error.message : 'Unknown error',\n      }\n    }\n  }\n\n  /**\n   * Get comprehensive data set creation status combining server and chain info\n   * @param txHashOrTransaction - Transaction hash or transaction object\n   * @param pdpServer - PDP server instance for status checks\n   * @returns Combined status information\n   */\n  async getComprehensiveDataSetStatus(\n    txHashOrTransaction: string | ethers.TransactionResponse,\n    pdpServer?: PDPServer\n  ): Promise<ComprehensiveDataSetStatus> {\n    const txHash = typeof txHashOrTransaction === 'string' ? txHashOrTransaction : txHashOrTransaction.hash\n\n    // Get server status if pdpServer provided\n    let serverStatus: DataSetCreationStatusResponse | null = null\n    if (pdpServer != null) {\n      try {\n        performance.mark('synapse:pdpServer.getDataSetCreationStatus-start')\n        serverStatus = await pdpServer.getDataSetCreationStatus(txHash)\n        performance.mark('synapse:pdpServer.getDataSetCreationStatus-end')\n        performance.measure(\n          'synapse:pdpServer.getDataSetCreationStatus',\n          'synapse:pdpServer.getDataSetCreationStatus-start',\n          'synapse:pdpServer.getDataSetCreationStatus-end'\n        )\n      } catch {\n        performance.mark('synapse:pdpServer.getDataSetCreationStatus-end')\n        performance.measure(\n          'synapse:pdpServer.getDataSetCreationStatus',\n          'synapse:pdpServer.getDataSetCreationStatus-start',\n          'synapse:pdpServer.getDataSetCreationStatus-end'\n        )\n        // Server doesn't have status yet or error occurred\n      }\n    }\n\n    // Get chain status (pass through the transaction object if we have it)\n    performance.mark('synapse:verifyDataSetCreation-start')\n    const chainStatus = await this.verifyDataSetCreation(txHashOrTransaction)\n    performance.mark('synapse:verifyDataSetCreation-end')\n    performance.measure(\n      'synapse:verifyDataSetCreation',\n      'synapse:verifyDataSetCreation-start',\n      'synapse:verifyDataSetCreation-end'\n    )\n\n    // Combine into summary\n    // isComplete should be true only when BOTH chain and server have confirmed the data set creation\n    const isComplete =\n      chainStatus.transactionMined &&\n      chainStatus.transactionSuccess &&\n      chainStatus.dataSetId != null &&\n      chainStatus.dataSetLive &&\n      serverStatus != null &&\n      serverStatus.ok === true &&\n      serverStatus.dataSetCreated\n    const dataSetId = serverStatus?.dataSetId ?? chainStatus.dataSetId ?? null\n\n    // Determine error from server status or chain status\n    let error: string | null = chainStatus.error ?? null\n    if (serverStatus != null && serverStatus.ok === false) {\n      error = `Server reported transaction failed (status: ${serverStatus.txStatus})`\n    }\n\n    return {\n      txHash,\n      serverStatus,\n      chainStatus,\n      summary: {\n        isComplete,\n        isLive: chainStatus.dataSetLive,\n        dataSetId,\n        error,\n      },\n    }\n  }\n\n  /**\n   * Wait for data set creation with status updates\n   * @param txHashOrTransaction - Transaction hash or transaction object to wait for\n   * @param pdpServer - PDP server for status checks\n   * @param maxWaitTime - Maximum time to wait in milliseconds\n   * @param pollInterval - Polling interval in milliseconds\n   * @param onProgress - Optional progress callback\n   * @returns Final comprehensive status\n   */\n  async waitForDataSetCreationWithStatus(\n    txHashOrTransaction: string | ethers.TransactionResponse,\n    pdpServer: PDPServer,\n    maxWaitTime: number = TIMING_CONSTANTS.DATA_SET_CREATION_TIMEOUT_MS,\n    pollInterval: number = TIMING_CONSTANTS.DATA_SET_CREATION_POLL_INTERVAL_MS,\n    onProgress?: (status: ComprehensiveDataSetStatus, elapsedMs: number) => Promise<void>\n  ): Promise<ComprehensiveDataSetStatus> {\n    const startTime = Date.now()\n\n    while (Date.now() - startTime < maxWaitTime) {\n      const status = await this.getComprehensiveDataSetStatus(txHashOrTransaction, pdpServer)\n      const elapsedMs = Date.now() - startTime\n\n      // Fire progress callback if provided\n      if (onProgress != null) {\n        try {\n          await onProgress(status, elapsedMs)\n        } catch (error) {\n          // Don't let callback errors break the polling loop\n          console.error('Error in progress callback:', error)\n        }\n      }\n\n      // Check if complete\n      if (status.summary.isComplete) {\n        return status\n      }\n\n      // Check for errors\n      if (status.summary.error != null && status.chainStatus.transactionMined) {\n        // Transaction confirmed but failed\n        throw new Error(status.summary.error)\n      }\n\n      // Wait before next poll\n      await new Promise((resolve) => setTimeout(resolve, pollInterval))\n    }\n\n    // Timeout\n    throw new Error(`Data set creation timed out after ${maxWaitTime / 1000} seconds`)\n  }\n\n  // ========== Metadata Operations ==========\n\n  /**\n   * Get all metadata for a data set\n   * @param dataSetId - The data set ID\n   * @returns Object with metadata key-value pairs\n   */\n  async getDataSetMetadata(dataSetId: number): Promise<Record<string, string>> {\n    const viewContract = this._getWarmStorageViewContract()\n    const [keys, values] = await viewContract.getAllDataSetMetadata(dataSetId)\n\n    // Create a prototype-safe object to avoid pollution risks from arbitrary keys\n    const metadata: Record<string, string> = Object.create(null)\n    for (let i = 0; i < keys.length; i++) {\n      metadata[keys[i]] = values[i]\n    }\n    return metadata\n  }\n\n  /**\n   * Get specific metadata key for a data set\n   * @param dataSetId - The data set ID\n   * @param key - The metadata key to retrieve\n   * @returns The metadata value if it exists, null otherwise\n   */\n  async getDataSetMetadataByKey(dataSetId: number, key: string): Promise<string | null> {\n    const viewContract = this._getWarmStorageViewContract()\n    const [exists, value] = await viewContract.getDataSetMetadata(dataSetId, key)\n    return exists ? value : null\n  }\n\n  /**\n   * Get all metadata for a piece in a data set\n   * @param dataSetId - The data set ID\n   * @param pieceId - The piece ID\n   * @returns Object with metadata key-value pairs\n   */\n  async getPieceMetadata(dataSetId: number, pieceId: number): Promise<Record<string, string>> {\n    const viewContract = this._getWarmStorageViewContract()\n    const [keys, values] = await viewContract.getAllPieceMetadata(dataSetId, pieceId)\n\n    // Create a prototype-safe object to avoid pollution risks from arbitrary keys\n    const metadata: Record<string, string> = Object.create(null)\n    for (let i = 0; i < keys.length; i++) {\n      metadata[keys[i]] = values[i]\n    }\n    return metadata\n  }\n\n  /**\n   * Get specific metadata key for a piece in a data set\n   * @param dataSetId - The data set ID\n   * @param pieceId - The piece ID\n   * @param key - The metadata key to retrieve\n   * @returns The metadata value if it exists, null otherwise\n   */\n  async getPieceMetadataByKey(dataSetId: number, pieceId: number, key: string): Promise<string | null> {\n    const viewContract = this._getWarmStorageViewContract()\n    const [exists, value] = await viewContract.getPieceMetadata(dataSetId, pieceId, key)\n    return exists ? value : null\n  }\n\n  // ========== Storage Cost Operations ==========\n\n  /**\n   * Get the current service price per TiB per month\n   * @returns Service price information for both CDN and non-CDN options\n   */\n  async getServicePrice(): Promise<ServicePriceInfo> {\n    const contract = this._getWarmStorageContract()\n    const pricing = await contract.getServicePrice()\n    return {\n      pricePerTiBPerMonthNoCDN: pricing.pricePerTiBPerMonthNoCDN,\n      pricePerTiBCdnEgress: pricing.pricePerTiBCdnEgress,\n      pricePerTiBCacheMissEgress: pricing.pricePerTiBCacheMissEgress,\n      tokenAddress: pricing.tokenAddress,\n      epochsPerMonth: pricing.epochsPerMonth,\n      minimumPricePerMonth: pricing.minimumPricePerMonth,\n    }\n  }\n\n  /**\n   * Calculate storage costs for a given size\n   * @param sizeInBytes - Size of data to store in bytes\n   * @returns Cost estimates per epoch, day, and month\n   * @remarks CDN costs are usage-based (egress pricing), so withCDN field reflects base storage cost only\n   */\n  async calculateStorageCost(sizeInBytes: number): Promise<{\n    perEpoch: bigint\n    perDay: bigint\n    perMonth: bigint\n    withCDN: {\n      perEpoch: bigint\n      perDay: bigint\n      perMonth: bigint\n    }\n  }> {\n    const servicePriceInfo = await this.getServicePrice()\n\n    // Calculate price per byte per epoch (base storage cost)\n    const sizeInBytesBigint = BigInt(sizeInBytes)\n    const pricePerEpoch =\n      (servicePriceInfo.pricePerTiBPerMonthNoCDN * sizeInBytesBigint) /\n      (SIZE_CONSTANTS.TiB * servicePriceInfo.epochsPerMonth)\n\n    const costs = {\n      perEpoch: pricePerEpoch,\n      perDay: pricePerEpoch * BigInt(TIME_CONSTANTS.EPOCHS_PER_DAY),\n      perMonth: pricePerEpoch * servicePriceInfo.epochsPerMonth,\n    }\n\n    // CDN costs are usage-based (egress pricing), so withCDN returns base storage cost\n    // Actual CDN costs will be charged based on egress usage\n    return {\n      ...costs,\n      withCDN: costs,\n    }\n  }\n\n  /**\n   * Check if user has sufficient allowances for a storage operation and calculate costs\n   * @param sizeInBytes - Size of data to store\n   * @param withCDN - Whether CDN is enabled\n   * @param paymentsService - PaymentsService instance to check allowances\n   * @param lockupDays - Number of days for lockup period (defaults to 10)\n   * @returns Allowance requirement details and storage costs\n   */\n  async checkAllowanceForStorage(\n    sizeInBytes: number,\n    withCDN: boolean,\n    paymentsService: PaymentsService,\n    lockupDays?: number\n  ): Promise<{\n    rateAllowanceNeeded: bigint\n    lockupAllowanceNeeded: bigint\n    currentRateAllowance: bigint\n    currentLockupAllowance: bigint\n    currentRateUsed: bigint\n    currentLockupUsed: bigint\n    sufficient: boolean\n    message?: string\n    costs: {\n      perEpoch: bigint\n      perDay: bigint\n      perMonth: bigint\n    }\n    depositAmountNeeded: bigint\n  }> {\n    // Get current allowances and calculate costs in parallel\n    const [approval, costs] = await Promise.all([\n      paymentsService.serviceApproval(this._warmStorageAddress, TOKENS.USDFC),\n      this.calculateStorageCost(sizeInBytes),\n    ])\n\n    const selectedCosts = withCDN ? costs.withCDN : costs\n    const rateNeeded = selectedCosts.perEpoch\n\n    // Calculate lockup period based on provided days (default: 10)\n    const lockupPeriod =\n      BigInt(lockupDays ?? Number(TIME_CONSTANTS.DEFAULT_LOCKUP_DAYS)) * BigInt(TIME_CONSTANTS.EPOCHS_PER_DAY)\n    const lockupNeeded = rateNeeded * lockupPeriod\n\n    // Calculate required allowances (current usage + new requirement)\n    const totalRateNeeded = BigInt(approval.rateUsed) + rateNeeded\n    const totalLockupNeeded = BigInt(approval.lockupUsed) + lockupNeeded\n\n    // Check if allowances are sufficient\n    const sufficient = approval.rateAllowance >= totalRateNeeded && approval.lockupAllowance >= totalLockupNeeded\n\n    // Calculate how much more is needed\n    const rateAllowanceNeeded = totalRateNeeded > approval.rateAllowance ? totalRateNeeded - approval.rateAllowance : 0n\n\n    const lockupAllowanceNeeded =\n      totalLockupNeeded > approval.lockupAllowance ? totalLockupNeeded - approval.lockupAllowance : 0n\n\n    // Build optional message\n    let message: string | undefined\n    if (!sufficient) {\n      const needsRate = rateAllowanceNeeded > 0n\n      const needsLockup = lockupAllowanceNeeded > 0n\n      if (needsRate && needsLockup) {\n        message = 'Insufficient rate and lockup allowances'\n      } else if (needsRate) {\n        message = 'Insufficient rate allowance'\n      } else if (needsLockup) {\n        message = 'Insufficient lockup allowance'\n      }\n    }\n\n    return {\n      rateAllowanceNeeded,\n      lockupAllowanceNeeded,\n      currentRateAllowance: approval.rateAllowance,\n      currentLockupAllowance: approval.lockupAllowance,\n      currentRateUsed: approval.rateUsed,\n      currentLockupUsed: approval.lockupUsed,\n      sufficient,\n      message,\n      costs: selectedCosts,\n      depositAmountNeeded: lockupNeeded,\n    }\n  }\n\n  /**\n   * Prepare for storage upload by checking balances and allowances\n   *\n   * This method performs a comprehensive check of the prerequisites for storage upload,\n   * including verifying sufficient funds and service allowances. It returns a list of\n   * actions that need to be executed before the upload can proceed.\n   *\n   * @param options - Configuration options for the storage upload\n   * @param options.dataSize - Size of data to store in bytes\n   * @param options.withCDN - Whether to enable CDN for faster retrieval (optional, defaults to false)\n   * @param paymentsService - Instance of PaymentsService for handling payment operations\n   *\n   * @returns Object containing:\n   *   - estimatedCost: Breakdown of storage costs (per epoch, day, and month)\n   *   - allowanceCheck: Status of service allowances with optional message\n   *   - actions: Array of required actions (deposit, approveService) that need to be executed\n   *\n   * @example\n   * ```typescript\n   * const prep = await warmStorageService.prepareStorageUpload(\n   *   { dataSize: Number(SIZE_CONSTANTS.GiB), withCDN: true },\n   *   paymentsService\n   * )\n   *\n   * if (prep.actions.length > 0) {\n   *   for (const action of prep.actions) {\n   *     console.log(`Executing: ${action.description}`)\n   *     await action.execute()\n   *   }\n   * }\n   * ```\n   */\n  async prepareStorageUpload(\n    options: {\n      dataSize: number\n      withCDN?: boolean\n    },\n    paymentsService: PaymentsService\n  ): Promise<{\n    estimatedCost: {\n      perEpoch: bigint\n      perDay: bigint\n      perMonth: bigint\n    }\n    allowanceCheck: {\n      sufficient: boolean\n      message?: string\n    }\n    actions: Array<{\n      type: 'deposit' | 'approve' | 'approveService'\n      description: string\n      execute: () => Promise<ethers.TransactionResponse>\n    }>\n  }> {\n    // Parallelize cost calculation and allowance check\n    const [costs, allowanceCheck] = await Promise.all([\n      this.calculateStorageCost(options.dataSize),\n      this.checkAllowanceForStorage(options.dataSize, options.withCDN ?? false, paymentsService),\n    ])\n\n    // Select the appropriate costs based on CDN option\n    const selectedCosts = (options.withCDN ?? false) ? costs.withCDN : costs\n\n    const actions: Array<{\n      type: 'deposit' | 'approve' | 'approveService'\n      description: string\n      execute: () => Promise<ethers.TransactionResponse>\n    }> = []\n\n    // Check if deposit is needed\n    const accountInfo = await paymentsService.accountInfo(TOKENS.USDFC)\n    const requiredBalance = selectedCosts.perMonth // Require at least 1 month of funds\n\n    if (accountInfo.availableFunds < requiredBalance) {\n      const depositAmount = requiredBalance - accountInfo.availableFunds\n      actions.push({\n        type: 'deposit',\n        description: `Deposit ${depositAmount} USDFC to payments contract`,\n        execute: async () => await paymentsService.deposit(depositAmount, TOKENS.USDFC),\n      })\n    }\n\n    // Check if service approval is needed\n    if (!allowanceCheck.sufficient) {\n      actions.push({\n        type: 'approveService',\n        description: `Approve service with rate allowance ${allowanceCheck.rateAllowanceNeeded} and lockup allowance ${allowanceCheck.lockupAllowanceNeeded}`,\n        execute: async () =>\n          await paymentsService.approveService(\n            this._warmStorageAddress,\n            allowanceCheck.rateAllowanceNeeded,\n            allowanceCheck.lockupAllowanceNeeded,\n            TIME_CONSTANTS.EPOCHS_PER_MONTH, // 30 days max lockup period\n            TOKENS.USDFC\n          ),\n      })\n    }\n\n    return {\n      estimatedCost: {\n        perEpoch: selectedCosts.perEpoch,\n        perDay: selectedCosts.perDay,\n        perMonth: selectedCosts.perMonth,\n      },\n      allowanceCheck: {\n        sufficient: allowanceCheck.sufficient,\n        message: allowanceCheck.sufficient\n          ? undefined\n          : `Insufficient allowances: rate needed ${allowanceCheck.rateAllowanceNeeded}, lockup needed ${allowanceCheck.lockupAllowanceNeeded}`,\n      },\n      actions,\n    }\n  }\n\n  // ========== Data Set Operations ==========\n\n  /**\n   * Terminate a data set with given ID\n   * @param signer - Signer which created this dataset\n   * @param dataSetId  - ID of the data set to terminate\n   * @returns Transaction receipt\n   */\n  async terminateDataSet(signer: ethers.Signer, dataSetId: number): Promise<ethers.TransactionResponse> {\n    const contract = this._getWarmStorageContract()\n    const contractWithSigner = contract.connect(signer) as ethers.Contract\n    return await contractWithSigner.terminateService(dataSetId)\n  }\n\n  // ========== Service Provider Approval Operations ==========\n\n  /**\n   * Add an approved provider by ID (owner only)\n   * @param signer - Signer with owner permissions\n   * @param providerId - Provider ID from registry\n   * @returns Transaction response\n   */\n  async addApprovedProvider(signer: ethers.Signer, providerId: number): Promise<ethers.TransactionResponse> {\n    const contract = this._getWarmStorageContract()\n    const contractWithSigner = contract.connect(signer) as ethers.Contract\n    return await contractWithSigner.addApprovedProvider(providerId)\n  }\n\n  /**\n   * Remove an approved provider by ID (owner only)\n   * @param signer - Signer with owner permissions\n   * @param providerId - Provider ID from registry\n   * @returns Transaction response\n   */\n  async removeApprovedProvider(signer: ethers.Signer, providerId: number): Promise<ethers.TransactionResponse> {\n    const contract = this._getWarmStorageContract()\n    const contractWithSigner = contract.connect(signer) as ethers.Contract\n\n    // First, we need to find the index of this provider in the array\n    const viewContract = this._getWarmStorageViewContract()\n    const approvedIds = await viewContract.getApprovedProviders(0n, 0n)\n    const index = approvedIds.findIndex((id: bigint) => Number(id) === providerId)\n\n    if (index === -1) {\n      throw new Error(`Provider ${providerId} is not in the approved list`)\n    }\n\n    return await contractWithSigner.removeApprovedProvider(providerId, index)\n  }\n\n  /**\n   * Get list of approved provider IDs\n   * @returns Array of approved provider IDs\n   */\n  async getApprovedProviderIds(): Promise<number[]> {\n    const viewContract = this._getWarmStorageViewContract()\n    const providerIds = await viewContract.getApprovedProviders(0n, 0n)\n    return providerIds.map((id: bigint) => Number(id))\n  }\n\n  /**\n   * Check if a provider ID is approved\n   * @param providerId - Provider ID to check\n   * @returns Whether the provider is approved\n   */\n  async isProviderIdApproved(providerId: number): Promise<boolean> {\n    const viewContract = this._getWarmStorageViewContract()\n    return await viewContract.isProviderApproved(providerId)\n  }\n\n  /**\n   * Get the contract owner address\n   * @returns Owner address\n   */\n  async getOwner(): Promise<string> {\n    const contract = this._getWarmStorageContract()\n    return await contract.owner()\n  }\n\n  /**\n   * Check if a signer is the contract owner\n   * @param signer - Signer to check\n   * @returns Whether the signer is the owner\n   */\n  async isOwner(signer: ethers.Signer): Promise<boolean> {\n    const signerAddress = await signer.getAddress()\n    const ownerAddress = await this.getOwner()\n    return signerAddress.toLowerCase() === ownerAddress.toLowerCase()\n  }\n\n  // ========== Proving Period Operations ==========\n\n  /**\n   * Get the maximum proving period from the WarmStorage contract\n   * @returns Maximum proving period in epochs\n   */\n  async getMaxProvingPeriod(): Promise<number> {\n    const viewContract = this._getWarmStorageViewContract()\n    const maxPeriod = await viewContract.getMaxProvingPeriod()\n    return Number(maxPeriod)\n  }\n\n  /**\n   * Get the challenge window size from the WarmStorage contract\n   * @returns Challenge window size in epochs\n   */\n  async getChallengeWindow(): Promise<number> {\n    const viewContract = this._getWarmStorageViewContract()\n    const window = await viewContract.challengeWindow()\n    return Number(window)\n  }\n  /**\n   * Increments the fixed locked-up amounts for CDN payment rails.\n   *\n   * This method tops up the prepaid balance for CDN services by adding to the existing\n   * lockup amounts. Both CDN and cache miss rails can be incremented independently.\n   *\n   * @param dataSetId - The ID of the data set\n   * @param cdnAmountToAdd - Amount to add to the CDN rail lockup\n   * @param cacheMissAmountToAdd - Amount to add to the cache miss rail lockup\n   * @returns Transaction response\n   */\n  async topUpCDNPaymentRails(\n    signer: ethers.Signer,\n    dataSetId: number,\n    cdnAmountToAdd: bigint,\n    cacheMissAmountToAdd: bigint\n  ): Promise<ethers.TransactionResponse> {\n    if (cdnAmountToAdd < 0n || cacheMissAmountToAdd < 0n) {\n      throw new Error('Top up amounts must be positive')\n    }\n    if (cdnAmountToAdd === 0n && cacheMissAmountToAdd === 0n) {\n      throw new Error('At least one top up amount must be >0')\n    }\n\n    const contract = this._getWarmStorageContract()\n    const contractWithSigner = contract.connect(signer) as ethers.Contract\n    return await contractWithSigner.topUpCDNPaymentRails(dataSetId, cdnAmountToAdd, cacheMissAmountToAdd)\n  }\n}\n","/**\n * Main Synapse class for interacting with Filecoin storage and other on-chain services\n */\n\nimport { ethers } from 'ethers'\nimport { PaymentsService } from './payments/index.ts'\nimport { ChainRetriever, FilBeamRetriever, SubgraphRetriever } from './retriever/index.ts'\nimport { SessionKey } from './session/key.ts'\nimport { SPRegistryService } from './sp-registry/index.ts'\nimport type { StorageService } from './storage/index.ts'\nimport { StorageManager } from './storage/manager.ts'\nimport { SubgraphService } from './subgraph/service.ts'\nimport type { TelemetryService } from './telemetry/service.ts'\nimport { getGlobalTelemetry, initGlobalTelemetry } from './telemetry/singleton.ts'\nimport type {\n  FilecoinNetworkType,\n  PieceCID,\n  PieceRetriever,\n  ProviderInfo,\n  StorageInfo,\n  StorageServiceOptions,\n  SubgraphConfig,\n  SynapseOptions,\n} from './types.ts'\nimport { CHAIN_IDS, CONTRACT_ADDRESSES, getFilecoinNetworkType } from './utils/index.ts'\nimport { WarmStorageService } from './warm-storage/index.ts'\n\nexport class Synapse {\n  private readonly _signer: ethers.Signer\n  private readonly _network: FilecoinNetworkType\n  private readonly _withCDN: boolean\n  private readonly _payments: PaymentsService\n  private readonly _provider: ethers.Provider\n  private readonly _warmStorageAddress: string\n  private readonly _warmStorageService: WarmStorageService\n  private readonly _pieceRetriever: PieceRetriever\n  private readonly _storageManager: StorageManager\n  private _session: SessionKey | null = null\n\n  /**\n   * Create a new Synapse instance with async initialization.\n   * @param options - Configuration options for Synapse\n   * @returns A fully initialized Synapse instance\n   */\n  static async create(options: SynapseOptions): Promise<Synapse> {\n    // Validate options\n    const providedOptions = [options.privateKey, options.provider, options.signer].filter(Boolean).length\n    if (providedOptions !== 1) {\n      throw new Error('Must provide exactly one of: privateKey, provider, or signer')\n    }\n\n    // Detect network from chain\n    let network: FilecoinNetworkType | undefined\n\n    // Create or derive signer and provider\n    let signer: ethers.Signer\n    let provider: ethers.Provider\n\n    if (options.privateKey != null) {\n      // Handle private key input\n      const rpcURL = options.rpcURL ?? options.rpcURL\n      if (rpcURL == null) {\n        throw new Error('rpcURL is required when using privateKey')\n      }\n\n      // Sanitize private key\n      let privateKey = options.privateKey\n      if (!privateKey.startsWith('0x')) {\n        privateKey = `0x${privateKey}`\n      }\n\n      // Create provider and wallet\n      // if websockets, use correct provider\n      if (/^ws(s)?:\\/\\//i.test(rpcURL)) {\n        provider = new ethers.WebSocketProvider(rpcURL)\n      } else {\n        provider = new ethers.JsonRpcProvider(rpcURL)\n      }\n\n      network = await getFilecoinNetworkType(provider)\n\n      // Create wallet with provider - always use NonceManager unless disabled\n      const wallet = new ethers.Wallet(privateKey, provider)\n      signer = options.disableNonceManager === true ? wallet : new ethers.NonceManager(wallet)\n    } else if (options.provider != null) {\n      // Handle provider input\n      provider = options.provider\n\n      network = await getFilecoinNetworkType(provider)\n\n      // Get signer - apply NonceManager unless disabled\n      // For ethers v6, we need to check if provider has getSigner method\n      if ('getSigner' in provider && typeof provider.getSigner === 'function') {\n        const baseSigner = await (provider as any).getSigner(0)\n        signer = options.disableNonceManager === true ? baseSigner : new ethers.NonceManager(baseSigner)\n      } else {\n        throw new Error('Provider does not support signing operations')\n      }\n    } else if (options.signer != null) {\n      // Handle signer input\n      signer = options.signer\n\n      // Apply NonceManager wrapper unless disabled\n      if (options.disableNonceManager !== true && !(signer instanceof ethers.NonceManager)) {\n        signer = new ethers.NonceManager(signer)\n      }\n\n      // Get provider from signer\n      if (signer.provider == null) {\n        throw new Error('Signer must have a provider')\n      }\n      provider = signer.provider\n\n      network = await getFilecoinNetworkType(provider)\n    } else {\n      // This should never happen due to validation above\n      throw new Error('No valid authentication method provided')\n    }\n\n    // Final network validation\n    if (network !== 'mainnet' && network !== 'calibration') {\n      throw new Error(`Invalid network: ${String(network)}. Only 'mainnet' and 'calibration' are supported.`)\n    }\n\n    // Create Warm Storage service with initialized addresses\n    const warmStorageAddress = options.warmStorageAddress ?? CONTRACT_ADDRESSES.WARM_STORAGE[network]\n    if (!warmStorageAddress) {\n      throw new Error(`No Warm Storage address configured for network: ${network}`)\n    }\n    const warmStorageService = await WarmStorageService.create(provider, warmStorageAddress)\n\n    // Create payments service with discovered addresses\n    const paymentsAddress = warmStorageService.getPaymentsAddress()\n    const usdfcAddress = warmStorageService.getUSDFCTokenAddress()\n    const payments = new PaymentsService(\n      provider,\n      signer,\n      paymentsAddress,\n      usdfcAddress,\n      options.disableNonceManager === true\n    )\n\n    // Create SPRegistryService for use in retrievers\n    const registryAddress = warmStorageService.getServiceProviderRegistryAddress()\n    const spRegistry = new SPRegistryService(provider, registryAddress)\n\n    // Initialize piece retriever (use provided or create default)\n    let pieceRetriever: PieceRetriever\n    if (options.pieceRetriever != null) {\n      pieceRetriever = options.pieceRetriever\n    } else {\n      // Create default retriever chain: FilBeam wraps the base retriever\n      const chainRetriever = new ChainRetriever(warmStorageService, spRegistry)\n\n      // Check for subgraph option\n      let baseRetriever: PieceRetriever = chainRetriever\n      if (options.subgraphConfig != null || options.subgraphService != null) {\n        const subgraphService =\n          options.subgraphService != null\n            ? options.subgraphService\n            : new SubgraphService(options.subgraphConfig as SubgraphConfig)\n        baseRetriever = new SubgraphRetriever(subgraphService)\n      }\n\n      // Wrap with FilBeam retriever\n      pieceRetriever = new FilBeamRetriever(baseRetriever, network)\n    }\n\n    // Create and initialize the global TelemetryService.\n    // If telemetry is disabled, this will do nothing.\n    await initGlobalTelemetry(options.telemetry || {}, { filecoinNetwork: network })\n\n    return new Synapse(\n      signer,\n      provider,\n      network,\n      payments,\n      options.withCDN === true,\n      warmStorageAddress,\n      warmStorageService,\n      pieceRetriever,\n      options.dev === false,\n      options.withIpni\n    )\n  }\n\n  private constructor(\n    signer: ethers.Signer,\n    provider: ethers.Provider,\n    network: FilecoinNetworkType,\n    payments: PaymentsService,\n    withCDN: boolean,\n\n    warmStorageAddress: string,\n    warmStorageService: WarmStorageService,\n    pieceRetriever: PieceRetriever,\n    dev: boolean,\n    withIpni?: boolean\n  ) {\n    this._signer = signer\n    this._provider = provider\n    this._network = network\n    this._payments = payments\n    this._withCDN = withCDN\n    this._warmStorageService = warmStorageService\n    this._pieceRetriever = pieceRetriever\n    this._warmStorageAddress = warmStorageAddress\n    this._session = null\n\n    // Initialize StorageManager\n    this._storageManager = new StorageManager(\n      this,\n      this._warmStorageService,\n      this._pieceRetriever,\n      this._withCDN,\n      dev,\n      withIpni\n    )\n  }\n\n  /**\n   * Gets the current network type\n   * @returns The network type ('mainnet' or 'calibration')\n   */\n  getNetwork(): FilecoinNetworkType {\n    return this._network\n  }\n\n  /**\n   * Gets the TelemetryService for error tracking and debugging.\n   * @returns The global TelemetryService instance\n   * @example\n   * ```typescript\n   * // Get debug dump for support tickets\n   * const dump = synapse.telemetry.debugDump()\n   * console.log(JSON.stringify(dump, null, 2))\n   *\n   * // Track custom events\n   * synapse.telemetry.sentry.captureCustomEvent('user-action', { action: 'upload' })\n   * ```\n   */\n  get telemetry(): TelemetryService | null {\n    return getGlobalTelemetry()\n  }\n\n  /**\n   * Gets the signer instance, possibly a session key\n   * @returns The ethers signer\n   */\n  getSigner(): ethers.Signer {\n    if (this._session == null) {\n      return this._signer\n    } else {\n      return this._session.getSigner()\n    }\n  }\n\n  /**\n   * Gets the client signer instance\n   * @returns the ethers signer\n   */\n  getClient(): ethers.Signer {\n    return this._signer\n  }\n\n  /**\n   * Wraps the signer as a session key\n   * @param sessionKeySigner The signer for the session key\n   * @returns The SessionKey object for this signer\n   */\n  createSessionKey(sessionKeySigner: ethers.Signer): SessionKey {\n    return new SessionKey(\n      this._provider,\n      this._warmStorageService.getSessionKeyRegistryAddress(),\n      sessionKeySigner,\n      this._signer\n    )\n  }\n\n  /**\n   * Sets the signer as the session key for storage actions\n   * @param sessionKey The session key used by storage contexts\n   * @example\n   * ```typescript\n   * const sessionKey = synapse.createSessionKey(privateKey)\n   *\n   * // check for previous login\n   * const expiries = await sessionKey.fetchExpiries(PDP_PERMISSIONS)\n   * const HOUR_MILLIS = BigInt(1000 * 60 * 60)\n   * if (expiries[ADD_PIECES_TYPEHASH] * BigInt(1000) < BigInt(Date.now()) + HOUR_MILLIS) {\n   *   const DAY_MILLIS = BigInt(24) * HOUR_MILLIS\n   *   const loginTx = await sessionKey.login(BigInt(Date.now()) / BigInt(1000 + 30 * DAY_MILLIS), PDP_PERMISSIONS, \"example.com\")\n   *   const loginReceipt = await loginTx.wait()\n   * }\n   *\n   * synapse.setSession(sessionKey)\n   * const context = await synapse.storage.createContext()\n   * ```\n   */\n  setSession(sessionKey: SessionKey | null) {\n    this._session = sessionKey\n  }\n\n  /**\n   * Gets the provider instance\n   * @returns The ethers provider\n   */\n  getProvider(): ethers.Provider {\n    return this._provider\n  }\n\n  /**\n   * Gets the current chain ID\n   * @returns The numeric chain ID\n   */\n  getChainId(): number {\n    return this._network === 'mainnet' ? CHAIN_IDS.mainnet : CHAIN_IDS.calibration\n  }\n\n  /**\n   * Gets the Warm Storage service address for the current network\n   * @returns The Warm Storage service address\n   */\n  getWarmStorageAddress(): string {\n    return this._warmStorageAddress\n  }\n\n  /**\n   * Gets the Payments contract address for the current network\n   * @returns The Payments contract address\n   */\n  getPaymentsAddress(): string {\n    return this._warmStorageService.getPaymentsAddress()\n  }\n\n  /**\n   * Gets the PDPVerifier contract address for the current network\n   * @returns The PDPVerifier contract address\n   */\n  getPDPVerifierAddress(): string {\n    return this._warmStorageService.getPDPVerifierAddress()\n  }\n\n  /**\n   * Gets the payment service instance\n   * @returns The payment service\n   */\n  get payments(): PaymentsService {\n    return this._payments\n  }\n\n  /**\n   * Gets the storage manager instance\n   *\n   * @returns The storage manager for all storage operations\n   */\n  get storage(): StorageManager {\n    return this._storageManager\n  }\n\n  /**\n   * Create a storage service instance.\n   *\n   * Automatically selects the best available service provider and creates or reuses a data set.\n   *\n   * @deprecated Use synapse.storage.createContext() instead. This method will be removed in a future version.\n   * @param options - Optional storage configuration\n   * @returns A configured StorageService instance ready for uploads/downloads\n   *\n   * @example\n   * ```typescript\n   * // Basic usage - auto-selects provider\n   * const storage = await synapse.createStorage()\n   * const result = await storage.upload(data)\n   *\n   * // With specific provider\n   * const storage = await synapse.createStorage({\n   *   providerId: 123\n   * })\n   *\n   * // With CDN enabled\n   * const storage = await synapse.createStorage({\n   *   withCDN: true\n   * })\n   * ```\n   */\n  async createStorage(options: StorageServiceOptions = {}): Promise<StorageService> {\n    // Use StorageManager to create context\n    return await this._storageManager.createContext(options)\n  }\n\n  /**\n   * Download data from service providers\n   * @deprecated Use synapse.storage.download() instead. This method will be removed in a future version.\n   * @param pieceCid - The PieceCID identifier (string or PieceCID object)\n   * @param options - Download options\n   * @returns The downloaded data as Uint8Array\n   *\n   * @example\n   * ```typescript\n   * // Download by PieceCID string\n   * const data = await synapse.download('bafkzcib...')\n   *\n   * // Download from specific provider\n   * const data = await synapse.download(pieceCid, {\n   *   providerAddress: '0x123...'\n   * })\n   * ```\n   */\n  async download(\n    pieceCid: string | PieceCID,\n    options?: {\n      providerAddress?: string\n      withCDN?: boolean\n    }\n  ): Promise<Uint8Array> {\n    console.warn('synapse.download() is deprecated. Use synapse.storage.download() instead.')\n    return await this._storageManager.download(pieceCid, options)\n  }\n\n  /**\n   * Get detailed information about a specific service provider\n   * @param providerAddress - The provider's address or provider ID\n   * @returns Provider information including URLs and pricing\n   */\n  async getProviderInfo(providerAddress: string | number): Promise<ProviderInfo> {\n    try {\n      // Validate address format if string provided\n      if (typeof providerAddress === 'string') {\n        try {\n          ethers.getAddress(providerAddress) // Will throw if invalid\n        } catch {\n          throw new Error(`Invalid provider address: ${providerAddress}`)\n        }\n      }\n\n      // Create SPRegistryService\n      const registryAddress = this._warmStorageService.getServiceProviderRegistryAddress()\n      const spRegistry = new SPRegistryService(this._provider, registryAddress)\n\n      let providerInfo: ProviderInfo | null\n      if (typeof providerAddress === 'string') {\n        providerInfo = await spRegistry.getProviderByAddress(providerAddress)\n      } else {\n        providerInfo = await spRegistry.getProvider(providerAddress)\n      }\n\n      // Check if provider was found in registry\n      if (providerInfo == null) {\n        throw new Error(`Provider ${providerAddress} not found in registry`)\n      }\n\n      return providerInfo\n    } catch (error) {\n      if (error instanceof Error && error.message.includes('Invalid provider address')) {\n        throw error\n      }\n      if (error instanceof Error && error.message.includes('not found')) {\n        throw error\n      }\n      throw new Error(`Failed to get provider info: ${error instanceof Error ? error.message : String(error)}`)\n    }\n  }\n\n  /**\n   * Get comprehensive information about the storage service including\n   * approved providers, pricing, contract addresses, and current allowances\n   * @deprecated Use synapse.storage.getStorageInfo() instead. This method will be removed in a future version.\n   * @returns Complete storage service information\n   */\n  async getStorageInfo(): Promise<StorageInfo> {\n    console.warn('synapse.getStorageInfo() is deprecated. Use synapse.storage.getStorageInfo() instead.')\n    return await this._storageManager.getStorageInfo()\n  }\n}\n","/**\n * SessionKey - Tracks the user's approval of a session key\n *\n * Session keys allow the user to authorize an app to take actions on\n * their behalf without prompting their wallet for signatures.\n * Session keys have a scope and an expiration.\n * Session keys should be generated on the user's computer and persisted\n * in a safe place or discarded.\n *\n * @example\n * ```typescript\n * const sessionKey = synapse.createSessionkey(privateKey)\n * const expiries = await sessionKey.fetchExpiries([ADD_PIECES_TYPEHASH])\n * if (expiries[ADD_PIECES_TYPEHASH] * BigInt(1000) < BigInt(Date.now()) + HOUR_MILLIS) {\n *   const DAY_MILLIS = BigInt(24) * HOUR_MILLIS\n *   const loginTx = await sessionKey.login(BigInt(Date.now()) / BigInt(1000 + 30 * DAY_MILLIS), PDP_PERMISSIONS, \"example.com\")\n *   const loginReceipt = await loginTx.wait()\n * }\n * synapse.setSession(sessionKey)\n * const context = await synapse.storage.createContext()\n * ```\n */\n\nimport { ethers } from 'ethers'\nimport { EIP712_TYPE_HASHES } from '../utils/eip712.ts'\nimport { CONTRACT_ABIS, CONTRACT_ADDRESSES, getFilecoinNetworkType } from '../utils/index.ts'\n\nexport const CREATE_DATA_SET_TYPEHASH = EIP712_TYPE_HASHES.CreateDataSet\nexport const ADD_PIECES_TYPEHASH = EIP712_TYPE_HASHES.AddPieces\nexport const SCHEDULE_PIECE_REMOVALS_TYPEHASH = EIP712_TYPE_HASHES.SchedulePieceRemovals\nexport const DELETE_DATA_SET_TYPEHASH = EIP712_TYPE_HASHES.DeleteDataSet\n\n// These are the PDP-related permissions that can be granted to a session key.\n// They are bytes32 hex strings that can be supplied to fetchExpiries, login, and revoke.\nexport const PDP_PERMISSIONS = [\n  CREATE_DATA_SET_TYPEHASH,\n  ADD_PIECES_TYPEHASH,\n  SCHEDULE_PIECE_REMOVALS_TYPEHASH,\n  DELETE_DATA_SET_TYPEHASH,\n]\n\nexport const PDP_PERMISSION_NAMES: Record<string, string> = {\n  [CREATE_DATA_SET_TYPEHASH]: 'CreateDataSet',\n  [ADD_PIECES_TYPEHASH]: 'AddPieces',\n  [SCHEDULE_PIECE_REMOVALS_TYPEHASH]: 'SchedulePieceRemovals',\n  [DELETE_DATA_SET_TYPEHASH]: 'DeleteDataSet',\n}\n\nconst DEFAULT_ORIGIN: string = (globalThis as any).location?.hostname || 'unknown'\n\nexport class SessionKey {\n  private readonly _provider: ethers.Provider\n  private readonly _registry: ethers.Contract\n  private readonly _signer: ethers.Signer\n  private readonly _owner: ethers.Signer\n\n  public constructor(\n    provider: ethers.Provider,\n    sessionKeyRegistryAddress: string,\n    signer: ethers.Signer,\n    owner: ethers.Signer\n  ) {\n    this._provider = provider\n    this._registry = new ethers.Contract(sessionKeyRegistryAddress, CONTRACT_ABIS.SESSION_KEY_REGISTRY, owner)\n    this._signer = signer\n    this._owner = owner\n  }\n\n  getSigner(): ethers.Signer {\n    return this._signer\n  }\n\n  /**\n   * Queries current permission expiries from the registry\n   * @param permissions Expiries to fetch, as a list of bytes32 hex strings\n   * @return map of each permission to its expiry for this session key\n   */\n  async fetchExpiries(permissions: string[] = PDP_PERMISSIONS): Promise<Record<string, bigint>> {\n    const network = await getFilecoinNetworkType(this._provider)\n\n    const multicall = new ethers.Contract(\n      CONTRACT_ADDRESSES.MULTICALL3[network],\n      CONTRACT_ABIS.MULTICALL3,\n      this._provider\n    )\n    const registryInterface = new ethers.Interface(CONTRACT_ABIS.SESSION_KEY_REGISTRY)\n\n    const [ownerAddress, signerAddress, registryAddress] = await Promise.all([\n      this._owner.getAddress(),\n      this._signer.getAddress(),\n      this._registry.getAddress(),\n    ])\n\n    // Prepare multicall batch\n    const calls: Array<{ target: string; allowFailure: boolean; callData: string }> = []\n    for (const permission of permissions) {\n      calls.push({\n        target: registryAddress,\n        allowFailure: true,\n        callData: registryInterface.encodeFunctionData('authorizationExpiry', [\n          ownerAddress,\n          signerAddress,\n          permission,\n        ]),\n      })\n    }\n\n    // Execute multicall\n    const results = await multicall.aggregate3.staticCall(calls)\n\n    const expiries: Record<string, bigint> = {}\n    for (let i = 0; i < permissions.length; i++) {\n      expiries[PDP_PERMISSIONS[i]] = registryInterface.decodeFunctionResult(\n        'authorizationExpiry',\n        results[i].returnData\n      )[0]\n    }\n    return expiries\n  }\n\n  /**\n   * Authorize signer with permissions until expiry. This can also be used to\n   * renew existing authorization by updating the expiry.\n   *\n   * @param expiry unix time (block.timestamp) that the permissions expire\n   * @param permissions list of permissions granted to the signer, as a list of bytes32 hex strings\n   * @param origin the name of the application prompting this login\n   * @return signed and broadcasted login transaction details\n   */\n  async login(\n    expiry: bigint,\n    permissions: string[] = PDP_PERMISSIONS,\n    origin = DEFAULT_ORIGIN\n  ): Promise<ethers.TransactionResponse> {\n    return await this._registry.login(await this._signer.getAddress(), expiry, permissions, origin)\n  }\n\n  /**\n   * Invalidate signer permissions, setting their expiry to zero.\n   *\n   * @param permissions list of permissions removed from the signer, as a list of bytes32 hex strings\n   * @return signed and broadcasted revoke transaction details\n   */\n  async revoke(permissions: string[] = PDP_PERMISSIONS): Promise<ethers.TransactionResponse> {\n    return await this._registry.revoke(await this._signer.getAddress(), permissions)\n  }\n}\n","import { request } from 'iso-web/http'\nimport type { Address, Hex } from 'viem'\n\nexport type ClaimTokensOptions = {\n  address: Address\n}\n\nexport type ClaimTokenResponse = [\n  {\n    faucetInfo: 'CalibnetUSDFC'\n    tx_hash: Hex\n  },\n  {\n    faucetInfo: 'CalibnetFIL'\n    tx_hash: Hex\n  },\n]\n\nexport type ClaimTokenResponseError = [\n  {\n    faucetInfo: 'CalibnetUSDFC'\n    error: { ServerError: string }\n  },\n  {\n    faucetInfo: 'CalibnetFIL'\n    error: { ServerError: string }\n  },\n]\nexport async function claimTokens(options: ClaimTokensOptions) {\n  const response = await request.json.get<ClaimTokenResponse>(\n    `https://forest-explorer.chainsafe.dev/api/claim_token_all?address=${options.address}`,\n    {\n      timeout: 20000,\n    }\n  )\n\n  if (response.error) {\n    throw new Error((response.error.cause as ClaimTokenResponseError)[0].error.ServerError)\n  }\n\n  return response.result\n}\n","/**\n * Exports the PDP components\n *\n * @packageDocumentation\n * @module PDP\n * @example\n * ```ts\n * import { PDPAuthHelper, PDPServer, PDPVerifier } from '@filoz/synapse-sdk/pdp'\n * ```\n */\n\nexport { PDPAuthHelper } from './auth.ts'\nexport type {\n  AddPiecesResponse,\n  CreateDataSetResponse,\n  DataSetCreationStatusResponse,\n  FindPieceResponse,\n  PieceAdditionStatusResponse,\n} from './server.ts'\nexport { PDPServer } from './server.ts'\n// Export validation utilities for advanced use\nexport {\n  asDataSetData,\n  asDataSetPieceData,\n  isDataSetCreationStatusResponse,\n  isFindPieceResponse,\n  isPieceAdditionStatusResponse,\n  validateDataSetCreationStatusResponse,\n  validateFindPieceResponse,\n  validatePieceAdditionStatusResponse,\n} from './validation.ts'\nexport { PDPVerifier } from './verifier.ts'\n","import * as cborg from 'cborg'\nimport { CID } from 'multiformats/cid'\n\n// https://github.com/ipfs/go-ipfs/issues/3570#issuecomment-273931692\nconst CID_CBOR_TAG = 42\n\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ByteView<T>} ByteView\n */\n\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ArrayBufferView<T>} ArrayBufferView\n */\n\n/**\n * @template T\n * @param {ByteView<T> | ArrayBufferView<T>} buf\n * @returns {ByteView<T>}\n */\nexport function toByteView (buf) {\n  if (buf instanceof ArrayBuffer) {\n    return new Uint8Array(buf, 0, buf.byteLength)\n  }\n\n  return buf\n}\n\n/**\n * cidEncoder will receive all Objects during encode, it needs to filter out\n * anything that's not a CID and return `null` for that so it's encoded as\n * normal.\n *\n * @param {any} obj\n * @returns {cborg.Token[]|null}\n */\nfunction cidEncoder (obj) {\n  if (obj.asCID !== obj && obj['/'] !== obj.bytes) {\n    return null // any other kind of object\n  }\n  const cid = CID.asCID(obj)\n  /* c8 ignore next 4 */\n  // very unlikely case, and it'll probably throw a recursion error in cborg\n  if (!cid) {\n    return null\n  }\n  const bytes = new Uint8Array(cid.bytes.byteLength + 1)\n  bytes.set(cid.bytes, 1) // prefix is 0x00, for historical reasons\n  return [\n    new cborg.Token(cborg.Type.tag, CID_CBOR_TAG),\n    new cborg.Token(cborg.Type.bytes, bytes)\n  ]\n}\n\n// eslint-disable-next-line jsdoc/require-returns-check\n/**\n * Intercept all `undefined` values from an object walk and reject the entire\n * object if we find one.\n *\n * @returns {null}\n */\nfunction undefinedEncoder () {\n  throw new Error('`undefined` is not supported by the IPLD Data Model and cannot be encoded')\n}\n\n/**\n * Intercept all `number` values from an object walk and reject the entire\n * object if we find something that doesn't fit the IPLD data model (NaN &\n * Infinity).\n *\n * @param {number} num\n * @returns {null}\n */\nfunction numberEncoder (num) {\n  if (Number.isNaN(num)) {\n    throw new Error('`NaN` is not supported by the IPLD Data Model and cannot be encoded')\n  }\n  if (num === Infinity || num === -Infinity) {\n    throw new Error('`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded')\n  }\n  return null\n}\n\n/**\n * @param {Map<any, any>} map\n * @returns {null}\n */\nfunction mapEncoder (map) {\n  for (const key of map.keys()) {\n    if (typeof key !== 'string' || key.length === 0) {\n      throw new Error('Non-string Map keys are not supported by the IPLD Data Model and cannot be encoded')\n    }\n  }\n  return null\n}\n\nconst _encodeOptions = {\n  float64: true,\n  typeEncoders: {\n    Map: mapEncoder,\n    Object: cidEncoder,\n    undefined: undefinedEncoder,\n    number: numberEncoder\n  }\n}\n\nexport const encodeOptions = {\n  ..._encodeOptions,\n  typeEncoders: {\n    ..._encodeOptions.typeEncoders\n  }\n}\n\n/**\n * @param {Uint8Array} bytes\n * @returns {CID}\n */\nfunction cidDecoder (bytes) {\n  if (bytes[0] !== 0) {\n    throw new Error('Invalid CID for CBOR tag 42; expected leading 0x00')\n  }\n  return CID.decode(bytes.subarray(1)) // ignore leading 0x00\n}\n\nconst _decodeOptions = {\n  allowIndefinite: false,\n  coerceUndefinedToNull: true,\n  allowNaN: false,\n  allowInfinity: false,\n  allowBigInt: true, // this will lead to BigInt for ints outside of\n  // safe-integer range, which may surprise users\n  strict: true,\n  useMaps: false,\n  rejectDuplicateMapKeys: true,\n  /** @type {import('cborg').TagDecoder[]} */\n  tags: []\n}\n_decodeOptions.tags[CID_CBOR_TAG] = cidDecoder\n\nexport const decodeOptions = {\n  ..._decodeOptions,\n  tags: _decodeOptions.tags.slice()\n}\n\nexport const name = 'dag-cbor'\nexport const code = 0x71\n\n/**\n * @template T\n * @param {T} node\n * @returns {ByteView<T>}\n */\nexport const encode = (node) => cborg.encode(node, _encodeOptions)\n\n/**\n * @template T\n * @param {ByteView<T> | ArrayBufferView<T>} data\n * @returns {T}\n */\nexport const decode = (data) => cborg.decode(toByteView(data), _decodeOptions)\n","import {setTimeout as safeSetTimeout, clearTimeout as safeClearTimeout} from 'unlimited-timeout';\nimport randomInteger from 'random-int';\n\nconst clearMethods = new WeakMap();\n\nexport function createDelay({clearTimeout: defaultClear, setTimeout: defaultSet} = {}) {\n\t// We cannot use `async` here as we need the promise identity.\n\treturn (milliseconds, {value, signal} = {}) => {\n\t\tif (signal?.aborted) {\n\t\t\treturn Promise.reject(signal.reason);\n\t\t}\n\n\t\tlet timeoutId;\n\t\tlet settle;\n\t\tlet rejectFunction;\n\t\tconst clear = defaultClear ?? clearTimeout;\n\n\t\tconst signalListener = () => {\n\t\t\tclear(timeoutId);\n\t\t\trejectFunction(signal.reason);\n\t\t};\n\n\t\tconst cleanup = () => {\n\t\t\tif (signal) {\n\t\t\t\tsignal.removeEventListener('abort', signalListener);\n\t\t\t}\n\t\t};\n\n\t\tconst delayPromise = new Promise((resolve, reject) => {\n\t\t\tsettle = () => {\n\t\t\t\tcleanup();\n\t\t\t\tresolve(value);\n\t\t\t};\n\n\t\t\trejectFunction = reject;\n\t\t\ttimeoutId = (defaultSet ?? setTimeout)(settle, milliseconds);\n\t\t});\n\n\t\tif (signal) {\n\t\t\tsignal.addEventListener('abort', signalListener, {once: true});\n\t\t}\n\n\t\tclearMethods.set(delayPromise, () => {\n\t\t\tclear(timeoutId);\n\t\t\ttimeoutId = null;\n\t\t\tsettle();\n\t\t});\n\n\t\treturn delayPromise;\n\t};\n}\n\nconst delay = createDelay({setTimeout: safeSetTimeout, clearTimeout: safeClearTimeout});\n\nexport default delay;\n\nexport async function rangeDelay(minimum, maximum, options) {\n\treturn delay(randomInteger(minimum, maximum), options);\n}\n\nexport function clearDelay(promise) {\n\tclearMethods.get(promise)?.();\n}\n","import varint from './vendor/varint.js'\n\nexport function decode (data: Uint8Array, offset = 0): [number, number] {\n  const code = varint.decode(data, offset)\n  return [code, varint.decode.bytes]\n}\n\nexport function encodeTo (int: number, target: Uint8Array, offset = 0): Uint8Array {\n  varint.encode(int, target, offset)\n  return target\n}\n\nexport function encodingLength (int: number): number {\n  return varint.encodingLength(int)\n}\n","import * as Digest from './digest.js'\nimport type { MultihashHasher } from './interface.js'\n\ntype Await<T> = Promise<T> | T\n\nconst DEFAULT_MIN_DIGEST_LENGTH = 20\n\nexport interface HasherInit <Name extends string, Code extends number> {\n  name: Name\n  code: Code\n  encode(input: Uint8Array): Await<Uint8Array>\n\n  /**\n   * The minimum length a hash is allowed to be truncated to in bytes\n   *\n   * @default 20\n   */\n  minDigestLength?: number\n\n  /**\n   * The maximum length a hash is allowed to be truncated to in bytes. If not\n   * specified it will be inferred from the length of the digest.\n   */\n  maxDigestLength?: number\n}\n\nexport function from <Name extends string, Code extends number> ({ name, code, encode, minDigestLength, maxDigestLength }: HasherInit<Name, Code>): Hasher<Name, Code> {\n  return new Hasher(name, code, encode, minDigestLength, maxDigestLength)\n}\n\nexport interface DigestOptions {\n  /**\n   * Truncate the returned digest to this number of bytes.\n   *\n   * This may cause the digest method to throw/reject if the passed value is\n   * greater than the digest length or below a threshold under which the risk of\n   * hash collisions is significant.\n   *\n   * The actual value of this threshold can depend on the hashing algorithm in\n   * use.\n   */\n  truncate?: number\n}\n\n/**\n * Hasher represents a hashing algorithm implementation that produces as\n * `MultihashDigest`.\n */\nexport class Hasher<Name extends string, Code extends number> implements MultihashHasher<Code> {\n  readonly name: Name\n  readonly code: Code\n  readonly encode: (input: Uint8Array) => Await<Uint8Array>\n  readonly minDigestLength: number\n  readonly maxDigestLength?: number\n\n  constructor (name: Name, code: Code, encode: (input: Uint8Array) => Await<Uint8Array>, minDigestLength?: number, maxDigestLength?: number) {\n    this.name = name\n    this.code = code\n    this.encode = encode\n    this.minDigestLength = minDigestLength ?? DEFAULT_MIN_DIGEST_LENGTH\n    this.maxDigestLength = maxDigestLength\n  }\n\n  digest (input: Uint8Array, options?: DigestOptions): Await<Digest.Digest<Code, number>> {\n    if (options?.truncate != null) {\n      if (options.truncate < this.minDigestLength) {\n        throw new Error(`Invalid truncate option, must be greater than or equal to ${this.minDigestLength}`)\n      }\n\n      if (this.maxDigestLength != null && options.truncate > this.maxDigestLength) {\n        throw new Error(`Invalid truncate option, must be less than or equal to ${this.maxDigestLength}`)\n      }\n    }\n\n    if (input instanceof Uint8Array) {\n      const result = this.encode(input)\n\n      if (result instanceof Uint8Array) {\n        return createDigest(result, this.code, options?.truncate)\n      }\n\n      return result.then(digest => createDigest(digest, this.code, options?.truncate))\n    } else {\n      throw Error('Unknown type, must be binary type')\n      /* c8 ignore next 1 */\n    }\n  }\n}\n\n/**\n * Create a Digest from the passed uint8array and code, optionally truncating it\n * first.\n */\nfunction createDigest <Code extends number> (digest: Uint8Array, code: Code, truncate?: number): Digest.Digest<Code, number> {\n  if (truncate != null && truncate !== digest.byteLength) {\n    if (truncate > digest.byteLength) {\n      throw new Error(`Invalid truncate option, must be less than or equal to ${digest.byteLength}`)\n    }\n\n    digest = digest.subarray(0, truncate)\n  }\n\n  return Digest.create(code, digest)\n}\n","export const arrayRegex = /^(.*)\\[([0-9]*)\\]$/\n\n// `bytes<M>`: binary type of `M` bytes, `0 < M <= 32`\n// https://regexr.com/6va55\nexport const bytesRegex = /^bytes([1-9]|1[0-9]|2[0-9]|3[0-2])?$/\n\n// `(u)int<M>`: (un)signed integer type of `M` bits, `0 < M <= 256`, `M % 8 == 0`\n// https://regexr.com/6v8hp\nexport const integerRegex =\n  /^(u?int)(8|16|24|32|40|48|56|64|72|80|88|96|104|112|120|128|136|144|152|160|168|176|184|192|200|208|216|224|232|240|248|256)?$/\n\nexport const maxInt8 = 2n ** (8n - 1n) - 1n\nexport const maxInt16 = 2n ** (16n - 1n) - 1n\nexport const maxInt24 = 2n ** (24n - 1n) - 1n\nexport const maxInt32 = 2n ** (32n - 1n) - 1n\nexport const maxInt40 = 2n ** (40n - 1n) - 1n\nexport const maxInt48 = 2n ** (48n - 1n) - 1n\nexport const maxInt56 = 2n ** (56n - 1n) - 1n\nexport const maxInt64 = 2n ** (64n - 1n) - 1n\nexport const maxInt72 = 2n ** (72n - 1n) - 1n\nexport const maxInt80 = 2n ** (80n - 1n) - 1n\nexport const maxInt88 = 2n ** (88n - 1n) - 1n\nexport const maxInt96 = 2n ** (96n - 1n) - 1n\nexport const maxInt104 = 2n ** (104n - 1n) - 1n\nexport const maxInt112 = 2n ** (112n - 1n) - 1n\nexport const maxInt120 = 2n ** (120n - 1n) - 1n\nexport const maxInt128 = 2n ** (128n - 1n) - 1n\nexport const maxInt136 = 2n ** (136n - 1n) - 1n\nexport const maxInt144 = 2n ** (144n - 1n) - 1n\nexport const maxInt152 = 2n ** (152n - 1n) - 1n\nexport const maxInt160 = 2n ** (160n - 1n) - 1n\nexport const maxInt168 = 2n ** (168n - 1n) - 1n\nexport const maxInt176 = 2n ** (176n - 1n) - 1n\nexport const maxInt184 = 2n ** (184n - 1n) - 1n\nexport const maxInt192 = 2n ** (192n - 1n) - 1n\nexport const maxInt200 = 2n ** (200n - 1n) - 1n\nexport const maxInt208 = 2n ** (208n - 1n) - 1n\nexport const maxInt216 = 2n ** (216n - 1n) - 1n\nexport const maxInt224 = 2n ** (224n - 1n) - 1n\nexport const maxInt232 = 2n ** (232n - 1n) - 1n\nexport const maxInt240 = 2n ** (240n - 1n) - 1n\nexport const maxInt248 = 2n ** (248n - 1n) - 1n\nexport const maxInt256 = 2n ** (256n - 1n) - 1n\n\nexport const minInt8 = -(2n ** (8n - 1n))\nexport const minInt16 = -(2n ** (16n - 1n))\nexport const minInt24 = -(2n ** (24n - 1n))\nexport const minInt32 = -(2n ** (32n - 1n))\nexport const minInt40 = -(2n ** (40n - 1n))\nexport const minInt48 = -(2n ** (48n - 1n))\nexport const minInt56 = -(2n ** (56n - 1n))\nexport const minInt64 = -(2n ** (64n - 1n))\nexport const minInt72 = -(2n ** (72n - 1n))\nexport const minInt80 = -(2n ** (80n - 1n))\nexport const minInt88 = -(2n ** (88n - 1n))\nexport const minInt96 = -(2n ** (96n - 1n))\nexport const minInt104 = -(2n ** (104n - 1n))\nexport const minInt112 = -(2n ** (112n - 1n))\nexport const minInt120 = -(2n ** (120n - 1n))\nexport const minInt128 = -(2n ** (128n - 1n))\nexport const minInt136 = -(2n ** (136n - 1n))\nexport const minInt144 = -(2n ** (144n - 1n))\nexport const minInt152 = -(2n ** (152n - 1n))\nexport const minInt160 = -(2n ** (160n - 1n))\nexport const minInt168 = -(2n ** (168n - 1n))\nexport const minInt176 = -(2n ** (176n - 1n))\nexport const minInt184 = -(2n ** (184n - 1n))\nexport const minInt192 = -(2n ** (192n - 1n))\nexport const minInt200 = -(2n ** (200n - 1n))\nexport const minInt208 = -(2n ** (208n - 1n))\nexport const minInt216 = -(2n ** (216n - 1n))\nexport const minInt224 = -(2n ** (224n - 1n))\nexport const minInt232 = -(2n ** (232n - 1n))\nexport const minInt240 = -(2n ** (240n - 1n))\nexport const minInt248 = -(2n ** (248n - 1n))\nexport const minInt256 = -(2n ** (256n - 1n))\n\nexport const maxUint8 = 2n ** 8n - 1n\nexport const maxUint16 = 2n ** 16n - 1n\nexport const maxUint24 = 2n ** 24n - 1n\nexport const maxUint32 = 2n ** 32n - 1n\nexport const maxUint40 = 2n ** 40n - 1n\nexport const maxUint48 = 2n ** 48n - 1n\nexport const maxUint56 = 2n ** 56n - 1n\nexport const maxUint64 = 2n ** 64n - 1n\nexport const maxUint72 = 2n ** 72n - 1n\nexport const maxUint80 = 2n ** 80n - 1n\nexport const maxUint88 = 2n ** 88n - 1n\nexport const maxUint96 = 2n ** 96n - 1n\nexport const maxUint104 = 2n ** 104n - 1n\nexport const maxUint112 = 2n ** 112n - 1n\nexport const maxUint120 = 2n ** 120n - 1n\nexport const maxUint128 = 2n ** 128n - 1n\nexport const maxUint136 = 2n ** 136n - 1n\nexport const maxUint144 = 2n ** 144n - 1n\nexport const maxUint152 = 2n ** 152n - 1n\nexport const maxUint160 = 2n ** 160n - 1n\nexport const maxUint168 = 2n ** 168n - 1n\nexport const maxUint176 = 2n ** 176n - 1n\nexport const maxUint184 = 2n ** 184n - 1n\nexport const maxUint192 = 2n ** 192n - 1n\nexport const maxUint200 = 2n ** 200n - 1n\nexport const maxUint208 = 2n ** 208n - 1n\nexport const maxUint216 = 2n ** 216n - 1n\nexport const maxUint224 = 2n ** 224n - 1n\nexport const maxUint232 = 2n ** 232n - 1n\nexport const maxUint240 = 2n ** 240n - 1n\nexport const maxUint248 = 2n ** 248n - 1n\nexport const maxUint256 = 2n ** 256n - 1n\n","/**\n * Synapse Core - ABIs\n *\n * @example\n * ```ts\n * import * as Abis from '@filoz/synapse-core/abis'\n * ```\n *\n * @packageDocumentation\n */\n\nexport * from './erc20.ts'\nexport * as generated from './generated.ts'\n\nimport * as generated from './generated.ts'\n\n// Merge the storage and errors ABIs\nexport const storage = [...generated.filecoinWarmStorageServiceAbi, ...generated.errorsAbi] as const\n\nexport {\n  filecoinPayV1Abi as payments,\n  filecoinWarmStorageServiceStateViewAbi as storageView,\n  pdpVerifierAbi as pdp,\n  serviceProviderRegistryAbi as serviceProviderRegistry,\n  sessionKeyRegistryAbi as sessionKeyRegistry,\n} from './generated.ts'\n","/* eslint-disable */\n// base-x encoding / decoding\n// Copyright (c) 2018 base-x contributors\n// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)\n// Distributed under the MIT software license, see the accompanying\n// file LICENSE or http://www.opensource.org/licenses/mit-license.php.\n/**\n * @param {string} ALPHABET\n * @param {any} name\n */\nfunction base (ALPHABET, name) {\n  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }\n  var BASE_MAP = new Uint8Array(256);\n  for (var j = 0; j < BASE_MAP.length; j++) {\n    BASE_MAP[j] = 255;\n  }\n  for (var i = 0; i < ALPHABET.length; i++) {\n    var x = ALPHABET.charAt(i);\n    var xc = x.charCodeAt(0);\n    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }\n    BASE_MAP[xc] = i;\n  }\n  var BASE = ALPHABET.length;\n  var LEADER = ALPHABET.charAt(0);\n  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up\n  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up\n  /**\n   * @param {any[] | Iterable<number>} source\n   */\n  function encode (source) {\n    // @ts-ignore\n    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {\n      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);\n    } else if (Array.isArray(source)) {\n      source = Uint8Array.from(source);\n    }\n    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }\n    if (source.length === 0) { return '' }\n        // Skip & count leading zeroes.\n    var zeroes = 0;\n    var length = 0;\n    var pbegin = 0;\n    var pend = source.length;\n    while (pbegin !== pend && source[pbegin] === 0) {\n      pbegin++;\n      zeroes++;\n    }\n        // Allocate enough space in big-endian base58 representation.\n    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;\n    var b58 = new Uint8Array(size);\n        // Process the bytes.\n    while (pbegin !== pend) {\n      var carry = source[pbegin];\n            // Apply \"b58 = b58 * 256 + ch\".\n      var i = 0;\n      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {\n        carry += (256 * b58[it1]) >>> 0;\n        b58[it1] = (carry % BASE) >>> 0;\n        carry = (carry / BASE) >>> 0;\n      }\n      if (carry !== 0) { throw new Error('Non-zero carry') }\n      length = i;\n      pbegin++;\n    }\n        // Skip leading zeroes in base58 result.\n    var it2 = size - length;\n    while (it2 !== size && b58[it2] === 0) {\n      it2++;\n    }\n        // Translate the result into a string.\n    var str = LEADER.repeat(zeroes);\n    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }\n    return str\n  }\n  /**\n   * @param {string | string[]} source\n   */\n  function decodeUnsafe (source) {\n    if (typeof source !== 'string') { throw new TypeError('Expected String') }\n    if (source.length === 0) { return new Uint8Array() }\n    var psz = 0;\n        // Skip leading spaces.\n    if (source[psz] === ' ') { return }\n        // Skip and count leading '1's.\n    var zeroes = 0;\n    var length = 0;\n    while (source[psz] === LEADER) {\n      zeroes++;\n      psz++;\n    }\n        // Allocate enough space in big-endian base256 representation.\n    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.\n    var b256 = new Uint8Array(size);\n        // Process the characters.\n    while (source[psz]) {\n            // Decode character\n      var carry = BASE_MAP[source.charCodeAt(psz)];\n            // Invalid character\n      if (carry === 255) { return }\n      var i = 0;\n      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {\n        carry += (BASE * b256[it3]) >>> 0;\n        b256[it3] = (carry % 256) >>> 0;\n        carry = (carry / 256) >>> 0;\n      }\n      if (carry !== 0) { throw new Error('Non-zero carry') }\n      length = i;\n      psz++;\n    }\n        // Skip trailing spaces.\n    if (source[psz] === ' ') { return }\n        // Skip leading zeroes in b256.\n    var it4 = size - length;\n    while (it4 !== size && b256[it4] === 0) {\n      it4++;\n    }\n    var vch = new Uint8Array(zeroes + (size - it4));\n    var j = zeroes;\n    while (it4 !== size) {\n      vch[j++] = b256[it4++];\n    }\n    return vch\n  }\n  /**\n   * @param {string | string[]} string\n   */\n  function decode (string) {\n    var buffer = decodeUnsafe(string);\n    if (buffer) { return buffer }\n    throw new Error(`Non-${name} character`)\n  }\n  return {\n    encode: encode,\n    decodeUnsafe: decodeUnsafe,\n    decode: decode\n  }\n}\nvar src = base;\n\nvar _brrp__multiformats_scope_baseX = src;\n\nexport default _brrp__multiformats_scope_baseX;\n","import delay from 'delay'\nimport pRetry from 'p-retry'\nimport { anySignal } from './signals.js'\n\nconst symbol = Symbol.for('request-error')\n\n/**\n * @typedef {NetworkError | TimeoutError | AbortError | HttpError} Errors\n */\n\n/**\n * Check if a value is a RequestError\n *\n * @param {unknown} value\n * @returns {value is RequestError}\n */\nexport function isRequestError(value) {\n  return value instanceof Error && symbol in value\n}\n\nexport class RequestError extends Error {\n  /** @type {boolean} */\n  [symbol] = true\n\n  name = 'RequestError'\n\n  /** @type {unknown} */\n  cause\n\n  /**\n   *\n   * @param {string} message\n   * @param {ErrorOptions} [options]\n   */\n  constructor(message, options = {}) {\n    super(message, options)\n\n    this.cause = options.cause\n  }\n\n  /**\n   * Check if a value is a RequestError\n   *\n   * @param {unknown} value\n   * @returns {value is RequestError}\n   */\n  static is(value) {\n    return isRequestError(value) && value.name === 'RequestError'\n  }\n}\n\nexport class JsonError extends RequestError {\n  name = 'JsonError'\n\n  /** @type {import('type-fest').JsonValue} */\n  cause\n\n  /**\n   *\n   * @param {{ cause: import('type-fest').JsonValue }} options\n   */\n  constructor(options) {\n    super('Failed with a JSON error, see cause.', options)\n\n    this.cause = options.cause\n  }\n\n  /**\n   * Check if a value is a JsonError\n   *\n   * @param {unknown} value\n   * @returns {value is JsonError}\n   */\n  static is(value) {\n    return isRequestError(value) && value.name === 'JsonError'\n  }\n}\n\nexport class NetworkError extends RequestError {\n  name = 'NetworkError'\n\n  /**\n   * Check if a value is a NetworkError\n   *\n   * @param {unknown} value\n   * @returns {value is NetworkError}\n   */\n  static is(value) {\n    return isRequestError(value) && value.name === 'NetworkError'\n  }\n}\n\nexport class TimeoutError extends RequestError {\n  name = 'TimeoutError'\n  /**\n   *\n   * @param {number} timeout\n   * @param {ErrorOptions} [options]\n   */\n  constructor(timeout, options = {}) {\n    super(`Request timed out after ${timeout}ms`, options)\n  }\n\n  /**\n   * Check if a value is a TimeoutError\n   *\n   * @param {unknown} value\n   * @returns {value is TimeoutError}\n   */\n  static is(value) {\n    return isRequestError(value) && value.name === 'TimeoutError'\n  }\n}\n\nexport class AbortError extends RequestError {\n  name = 'AbortError'\n\n  /** @type {AbortSignal} */\n  signal\n  /**\n   *\n   * @param {AbortSignal} signal\n   * @param {ErrorOptions} [options]\n   */\n  constructor(signal, options = {}) {\n    super(`Request aborted: ${signal.reason ?? 'unknown'}`, options)\n    this.signal = signal\n  }\n\n  /**\n   * Check if a value is a AbortError\n   *\n   * @param {unknown} value\n   * @returns {value is AbortError}\n   */\n  static is(value) {\n    return isRequestError(value) && value.name === 'AbortError'\n  }\n}\n\nexport class HttpError extends RequestError {\n  name = 'HttpError'\n\n  /** @type {number} */\n  code = 0\n\n  /** @type {Response} */\n  response\n\n  /** @type {Request} */\n  request\n\n  /** @type {import('./types.js').RequestOptions} */\n  options\n\n  /**\n   *\n   * @param {ErrorOptions & {response: Response, request: Request, options: import('./types.js').RequestOptions}} options\n   */\n  constructor(options) {\n    const msg = `${options.response.status} - ${options.response.statusText}`\n\n    super(msg)\n\n    this.code = options.response?.status ?? 0\n    this.response = options.response\n    this.request = options.request\n    this.options = options.options\n  }\n\n  /**\n   * Check if a value is a HttpError\n   *\n   * @param {unknown} value\n   * @returns {value is HttpError}\n   */\n  static is(value) {\n    return isRequestError(value) && value.name === 'HttpError'\n  }\n}\n\n/**\n * Request timeout\n *\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").RequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<Response, Errors>>}\n */\nexport async function request(resource, options = {}) {\n  const {\n    signal,\n    timeout = 5000,\n    retry,\n    fetch = globalThis.fetch.bind(globalThis),\n    json,\n    headers,\n    onResponse = () => {\n      // noop\n    },\n  } = options\n\n  // validate resource type\n  if (typeof resource !== 'string' && !(resource instanceof URL)) {\n    return {\n      error: new RequestError('`resource` must be a string or URL object'),\n    }\n  }\n\n  const timeoutSignal =\n    timeout !== false ? AbortSignal.timeout(timeout) : undefined\n  const combinedSignals = anySignal([signal, timeoutSignal])\n\n  const _headers = new Headers(headers)\n  if (json !== undefined) {\n    _headers.set(\n      'content-type',\n      _headers.get('content-type') ?? 'application/json'\n    )\n    options.body = JSON.stringify(json)\n  }\n  const request = new Request(resource, {\n    ...options,\n    headers: _headers,\n    signal: combinedSignals,\n  })\n\n  async function fn() {\n    let rsp = await fetch(request)\n\n    const result = await onResponse(rsp.clone(), request)\n\n    if (result instanceof Response) {\n      rsp = result\n    }\n\n    if (!rsp.ok) {\n      throw new HttpError({\n        response: rsp,\n        request,\n        options,\n      })\n    }\n    return rsp\n  }\n\n  try {\n    const response = await (retry\n      ? pRetry(() => fn(), {\n          retries: retry.retries,\n          factor: retry.factor ?? 2,\n          minTimeout: retry.minTimeout ?? 1000,\n          maxTimeout: retry.maxTimeout ?? Number.POSITIVE_INFINITY,\n          randomize: retry.randomize ?? false,\n          unref: retry.unref ?? false,\n          maxRetryTime: retry.maxRetryTime ?? Number.POSITIVE_INFINITY,\n          signal: combinedSignals,\n          onFailedAttempt: async (ctx) => {\n            const codes = retry.afterStatusCodes ?? [413, 429, 503]\n            if (HttpError.is(ctx.error) && codes.includes(ctx.error.code)) {\n              // Delay if needed using Retry-After header\n              const delayValue = calculateRetryAfter(ctx.error.response)\n              if (delayValue > 0) {\n                await delay(delayValue, { signal: combinedSignals })\n              }\n            }\n          },\n          shouldRetry: async (ctx) => {\n            if (retry.shouldRetry) {\n              const shouldRetry = await retry.shouldRetry(ctx)\n              return Boolean(shouldRetry)\n            }\n\n            const methods = retry.methods ?? [\n              'get',\n              'put',\n              'head',\n              'delete',\n              'options',\n              'trace',\n            ]\n\n            const statusCodes = retry.statusCodes ?? [\n              408, 413, 429, 500, 502, 503, 504,\n            ]\n            if (\n              methods.includes(request.method.toLowerCase()) &&\n              HttpError.is(ctx.error) &&\n              statusCodes.includes(ctx.error.code)\n            ) {\n              return true\n            }\n\n            return false\n          },\n        })\n      : fn())\n\n    return response.ok\n      ? { result: response }\n      : {\n          error: new HttpError({\n            response,\n            request,\n            options,\n          }),\n        }\n  } catch (error) {\n    const err = /** @type {Error} */ (error)\n\n    if (timeout !== false && timeoutSignal?.aborted) {\n      return { error: new TimeoutError(timeout, { cause: err }) }\n    }\n\n    if (signal?.aborted) {\n      return { error: new AbortError(signal, { cause: err }) }\n    }\n\n    if (HttpError.is(err)) {\n      return {\n        error: err,\n      }\n    }\n\n    return {\n      error: new NetworkError(err.message, { cause: err.cause }),\n    }\n  }\n}\n\n/**\n *\n * @param {Response} response\n */\nfunction calculateRetryAfter(response) {\n  const retryAfter =\n    response.headers.get('Retry-After') ??\n    response.headers.get('RateLimit-Reset') ??\n    response.headers.get('X-RateLimit-Reset') ?? // github\n    response.headers.get('X-Rate-Limit-Reset') // twitter\n\n  if (retryAfter === null) {\n    return 0\n  }\n\n  let after = Number(retryAfter)\n  if (Number.isNaN(after)) {\n    // is a date string\n    after = Date.parse(retryAfter) - Date.now()\n  } else {\n    // is a number of seconds\n    after *= 1000\n  }\n\n  return after\n}\n\n/**\n * Request GET\n *\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").RequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<Response, Errors>>}\n */\nrequest.get = function get(resource, options = {}) {\n  return request(resource, { ...options, method: 'GET' })\n}\n\n/**\n * Request POST\n *\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").RequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<Response, Errors>>}\n */\nrequest.post = function post(resource, options = {}) {\n  return request(resource, { ...options, method: 'POST' })\n}\n\n/**\n * Request PUT\n *\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").RequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<Response, Errors>>}\n */\nrequest.put = function put(resource, options = {}) {\n  return request(resource, { ...options, method: 'PUT' })\n}\n\n/**\n * Request DELETE\n *\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").RequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<Response, Errors>>}\n */\nrequest.delete = function del(resource, options = {}) {\n  return request(resource, { ...options, method: 'DELETE' })\n}\n\n/**\n * Request PATCH\n *\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").RequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<Response, Errors>>}\n */\nrequest.patch = function patch(resource, options = {}) {\n  return request(resource, { ...options, method: 'PATCH' })\n}\n\n/**\n * Request HEAD\n *\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").RequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<Response, Errors>>}\n */\nrequest.head = function head(resource, options = {}) {\n  return request(resource, { ...options, method: 'HEAD' })\n}\n\n/**\n * Request OPTIONS\n *\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").RequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<Response, Errors>>}\n */\nrequest.options = function optionsFn(resource, options = {}) {\n  return request(resource, { ...options, method: 'OPTIONS' })\n}\n\n/**\n * Request TRACE\n *\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").RequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<Response, Errors>>}\n */\nrequest.trace = function trace(resource, options = {}) {\n  return request(resource, { ...options, method: 'TRACE' })\n}\n\n/**\n * Request Json GET\n *\n * @template T\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").JSONRequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<T, Errors | JsonError>>}\n */\nrequest.json = async function json(resource, options = {}) {\n  const { error, result } = await request(resource, {\n    ...options,\n    body: null,\n    json: options.body,\n  })\n\n  if (error) {\n    if (\n      HttpError.is(error) &&\n      error.response.headers.get('content-type')?.includes('json')\n    ) {\n      return {\n        error: new JsonError({ cause: await error.response.json() }),\n      }\n    }\n    return { error }\n  }\n\n  if (result.ok && result.headers.get('content-type')?.includes('json')) {\n    return { result: /** @type {T} */ (await result.json()) }\n  }\n\n  return {\n    error: new RequestError('Response is not JSON', { cause: result }),\n  }\n}\n\n/**\n * Request Json GET\n *\n * @template T\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").JSONRequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<T, Errors | JsonError>>}\n */\nrequest.json.get = function get(resource, options = {}) {\n  return request.json(resource, { ...options, method: 'GET' })\n}\n\n/**\n * Request Json POST\n *\n * @template T\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").JSONRequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<T, Errors | JsonError>>}\n */\nrequest.json.post = function post(resource, options = {}) {\n  return request.json(resource, { ...options, method: 'POST' })\n}\n\n/**\n * Request Json PUT\n *\n * @template T\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").JSONRequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<T, Errors | JsonError>>}\n */\nrequest.json.put = function put(resource, options = {}) {\n  return request.json(resource, { ...options, method: 'PUT' })\n}\n\n/**\n * Request Json DELETE\n *\n * @template T\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").JSONRequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<T, Errors | JsonError>>}\n */\nrequest.json.delete = function del(resource, options = {}) {\n  return request.json(resource, { ...options, method: 'DELETE' })\n}\n\n/**\n * Request Json PATCH\n *\n * @template T\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").JSONRequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<T, Errors | JsonError>>}\n */\nrequest.json.patch = function patch(resource, options = {}) {\n  return request.json(resource, { ...options, method: 'PATCH' })\n}\n\n/**\n * Request Json HEAD\n *\n * @template T\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").JSONRequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<T, Errors | JsonError>>}\n */\nrequest.json.head = function head(resource, options = {}) {\n  return request.json(resource, { ...options, method: 'HEAD' })\n}\n\n/**\n * Request Json OPTIONS\n *\n * @template T\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").JSONRequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<T, Errors | JsonError>>}\n */\nrequest.json.options = function optionsFn(resource, options = {}) {\n  return request.json(resource, { ...options, method: 'OPTIONS' })\n}\n\n/**\n * Request Json TRACE\n *\n * @template T\n * @param {import('./types.js').RequestInput} resource\n * @param {import(\"./types.js\").JSONRequestOptions} options\n * @returns {Promise<import(\"./types.js\").MaybeResult<T, Errors | JsonError>>}\n */\nrequest.json.trace = function trace(resource, options = {}) {\n  return request.json(resource, { ...options, method: 'TRACE' })\n}\n","import { decodeErrPrefix } from './common.js'\nimport { Type } from './token.js'\nimport { jump, quick } from './jump.js'\n\n/**\n * @typedef {import('./token.js').Token} Token\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n * @typedef {import('../interface').DecodeTokenizer} DecodeTokenizer\n */\n\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n}\n\n/**\n * @implements {DecodeTokenizer}\n */\nclass Tokeniser {\n  /**\n   * @param {Uint8Array} data\n   * @param {DecodeOptions} options\n   */\n  constructor (data, options = {}) {\n    this._pos = 0\n    this.data = data\n    this.options = options\n  }\n\n  pos () {\n    return this._pos\n  }\n\n  done () {\n    return this._pos >= this.data.length\n  }\n\n  next () {\n    const byt = this.data[this._pos]\n    let token = quick[byt]\n    if (token === undefined) {\n      const decoder = jump[byt]\n      /* c8 ignore next 4 */\n      // if we're here then there's something wrong with our jump or quick lists!\n      if (!decoder) {\n        throw new Error(`${decodeErrPrefix} no decoder for major type ${byt >>> 5} (byte 0x${byt.toString(16).padStart(2, '0')})`)\n      }\n      const minor = byt & 31\n      token = decoder(this.data, this._pos, minor, this.options)\n    }\n    // @ts-ignore we get to assume encodedLength is set (crossing fingers slightly)\n    this._pos += token.encodedLength\n    return token\n  }\n}\n\nconst DONE = Symbol.for('DONE')\nconst BREAK = Symbol.for('BREAK')\n\n/**\n * @param {Token} token\n * @param {DecodeTokenizer} tokeniser\n * @param {DecodeOptions} options\n * @returns {any|BREAK|DONE}\n */\nfunction tokenToArray (token, tokeniser, options) {\n  const arr = []\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options)\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        // normal end to indefinite length array\n        break\n      }\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed array`)\n    }\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found array but not enough entries (got ${i}, expected ${token.value})`)\n    }\n    arr[i] = value\n  }\n  return arr\n}\n\n/**\n * @param {Token} token\n * @param {DecodeTokenizer} tokeniser\n * @param {DecodeOptions} options\n * @returns {any|BREAK|DONE}\n */\nfunction tokenToMap (token, tokeniser, options) {\n  const useMaps = options.useMaps === true\n  const obj = useMaps ? undefined : {}\n  const m = useMaps ? new Map() : undefined\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options)\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        // normal end to indefinite length map\n        break\n      }\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed map`)\n    }\n    if (key === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no key], expected ${token.value})`)\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${decodeErrPrefix} non-string keys not supported (got ${typeof key})`)\n    }\n    if (options.rejectDuplicateMapKeys === true) {\n      // @ts-ignore\n      if ((useMaps && m.has(key)) || (!useMaps && (key in obj))) {\n        throw new Error(`${decodeErrPrefix} found repeat map key \"${key}\"`)\n      }\n    }\n    const value = tokensToObject(tokeniser, options)\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no value], expected ${token.value})`)\n    }\n    if (useMaps) {\n      // @ts-ignore TODO reconsider this .. maybe needs to be strict about key types\n      m.set(key, value)\n    } else {\n      // @ts-ignore TODO reconsider this .. maybe needs to be strict about key types\n      obj[key] = value\n    }\n  }\n  // @ts-ignore c'mon man\n  return useMaps ? m : obj\n}\n\n/**\n * @param {DecodeTokenizer} tokeniser\n * @param {DecodeOptions} options\n * @returns {any|BREAK|DONE}\n */\nfunction tokensToObject (tokeniser, options) {\n  // should we support array as an argument?\n  // check for tokenIter[Symbol.iterator] and replace tokenIter with what that returns?\n  if (tokeniser.done()) {\n    return DONE\n  }\n\n  const token = tokeniser.next()\n\n  if (token.type === Type.break) {\n    return BREAK\n  }\n\n  if (token.type.terminal) {\n    return token.value\n  }\n\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options)\n  }\n\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options)\n  }\n\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options)\n      return options.tags[token.value](tagged)\n    }\n    throw new Error(`${decodeErrPrefix} tag not supported (${token.value})`)\n  }\n  /* c8 ignore next */\n  throw new Error('unsupported')\n}\n\n/**\n * @param {Uint8Array} data\n * @param {DecodeOptions} [options]\n * @returns {[any, Uint8Array]}\n */\nfunction decodeFirst (data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${decodeErrPrefix} data to decode must be a Uint8Array`)\n  }\n  options = Object.assign({}, defaultDecodeOptions, options)\n  const tokeniser = options.tokenizer || new Tokeniser(data, options)\n  const decoded = tokensToObject(tokeniser, options)\n  if (decoded === DONE) {\n    throw new Error(`${decodeErrPrefix} did not find any content to decode`)\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${decodeErrPrefix} got unexpected break`)\n  }\n  return [decoded, data.subarray(tokeniser.pos())]\n}\n\n/**\n * @param {Uint8Array} data\n * @param {DecodeOptions} [options]\n * @returns {any}\n */\nfunction decode (data, options) {\n  const [decoded, remainder] = decodeFirst(data, options)\n  if (remainder.length > 0) {\n    throw new Error(`${decodeErrPrefix} too many terminals, data makes no sense`)\n  }\n  return decoded\n}\n\nexport { Tokeniser, tokensToObject, decode, decodeFirst }\n","import { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\nimport { decodeErrPrefix } from './common.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} prefix\n * @param {number} length\n * @returns {Token}\n */\nfunction toToken (_data, _pos, prefix, length) {\n  return new Token(Type.array, length, prefix)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nexport function decodeArrayCompact (data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArray8 (data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArray16 (data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArray32 (data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options))\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArray64 (data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options)\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer array lengths not supported`)\n  }\n  return toToken(data, pos, 9, l)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArrayIndefinite (data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`)\n  }\n  return toToken(data, pos, 1, Infinity)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeArray (buf, token) {\n  uint.encodeUintValue(buf, Type.array.majorEncoded, token.value)\n}\n\n// using an array as a map key, are you sure about this? we can only sort\n// by map length here, it's up to the encoder to decide to look deeper\nencodeArray.compareTokens = uint.encodeUint.compareTokens\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeArray.encodedSize = function encodedSize (token) {\n  return uint.encodeUintValue.encodedSize(token.value)\n}\n","import { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\nimport { decodeErrPrefix } from './common.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} prefix\n * @param {number} length\n * @returns {Token}\n */\nfunction toToken (_data, _pos, prefix, length) {\n  return new Token(Type.map, length, prefix)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nexport function decodeMapCompact (data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMap8 (data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMap16 (data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMap32 (data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options))\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMap64 (data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options)\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer map lengths not supported`)\n  }\n  return toToken(data, pos, 9, l)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMapIndefinite (data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`)\n  }\n  return toToken(data, pos, 1, Infinity)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeMap (buf, token) {\n  uint.encodeUintValue(buf, Type.map.majorEncoded, token.value)\n}\n\n// using a map as a map key, are you sure about this? we can only sort\n// by map length here, it's up to the encoder to decide to look deeper\nencodeMap.compareTokens = uint.encodeUint.compareTokens\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeMap.encodedSize = function encodedSize (token) {\n  return uint.encodeUintValue.encodedSize(token.value)\n}\n","import * as API from './api.js'\nimport * as Node from './node.js'\nimport * as Proof from './proof.js'\n\nconst MAX_LEVEL = 64\n\n/**\n * This is a lazy zero-comm buffer which we fill up on demand.\n */\nclass ZeroComm {\n  constructor() {\n    this.bytes = new Uint8Array(MAX_LEVEL * Node.Size)\n    this.bytes.set(Node.empty(), 0)\n    /** @private */\n    this.node = Node.empty()\n    /** @private */\n    this.length = Node.Size\n  }\n  /**\n   * @param {number} start\n   * @param {number} end\n   */\n  slice(start, end) {\n    while (this.length < end) {\n      this.node = Proof.computeNode(this.node, this.node)\n      this.bytes.set(this.node, this.length)\n      this.length += Node.Size\n    }\n\n    return this.bytes.subarray(start, end)\n  }\n}\nconst ZERO_COMM = new ZeroComm()\n\n/**\n * simple access by level, only levels between `0` and `64` inclusive are\n * available otherwise throws an error.\n *\n * @param {number} level\n * @returns {API.MerkleTreeNode}\n */\nexport const fromLevel = (level) => {\n  if (level < 0 || level >= MAX_LEVEL) {\n    throw new Error(\n      `Only levels between 0 and ${MAX_LEVEL - 1} inclusive are available`\n    )\n  }\n\n  return ZERO_COMM.slice(Node.Size * level, Node.Size * (level + 1))\n}\n","// Use Uint8Array directly in the browser, use Buffer in Node.js but don't\n// speak its name directly to avoid bundlers pulling in the `Buffer` polyfill\n\n// @ts-ignore\nexport const useBuffer = globalThis.process &&\n  // @ts-ignore\n  !globalThis.process.browser &&\n  // @ts-ignore\n  globalThis.Buffer &&\n  // @ts-ignore\n  typeof globalThis.Buffer.isBuffer === 'function'\n\nconst textDecoder = new TextDecoder()\nconst textEncoder = new TextEncoder()\n\n/**\n * @param {Uint8Array} buf\n * @returns {boolean}\n */\nfunction isBuffer (buf) {\n  // @ts-ignore\n  return useBuffer && globalThis.Buffer.isBuffer(buf)\n}\n\n/**\n * @param {Uint8Array|number[]} buf\n * @returns {Uint8Array}\n */\nexport function asU8A (buf) {\n  /* c8 ignore next */\n  if (!(buf instanceof Uint8Array)) {\n    return Uint8Array.from(buf)\n  }\n  return isBuffer(buf) ? new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength) : buf\n}\n\nexport const toString = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      return end - start > 64\n        ? // eslint-disable-line operator-linebreak\n      // @ts-ignore\n        globalThis.Buffer.from(bytes.subarray(start, end)).toString('utf8')\n        : utf8Slice(bytes, start, end)\n    }\n  /* c8 ignore next 11 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      return end - start > 64\n        ? textDecoder.decode(bytes.subarray(start, end))\n        : utf8Slice(bytes, start, end)\n    }\n\nexport const fromString = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {string} string\n     */\n    (string) => {\n      return string.length > 64\n        ? // eslint-disable-line operator-linebreak\n      // @ts-ignore\n        globalThis.Buffer.from(string)\n        : utf8ToBytes(string)\n    }\n  /* c8 ignore next 7 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {string} string\n     */\n    (string) => {\n      return string.length > 64 ? textEncoder.encode(string) : utf8ToBytes(string)\n    }\n\n/**\n * Buffer variant not fast enough for what we need\n * @param {number[]} arr\n * @returns {Uint8Array}\n */\nexport const fromArray = (arr) => {\n  return Uint8Array.from(arr)\n}\n\nexport const slice = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      if (isBuffer(bytes)) {\n        return new Uint8Array(bytes.subarray(start, end))\n      }\n      return bytes.slice(start, end)\n    }\n  /* c8 ignore next 9 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      return bytes.slice(start, end)\n    }\n\nexport const concat = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array[]} chunks\n     * @param {number} length\n     * @returns {Uint8Array}\n     */\n    (chunks, length) => {\n      // might get a stray plain Array here\n      /* c8 ignore next 1 */\n      chunks = chunks.map((c) => c instanceof Uint8Array\n        ? c\n        // this case is occasionally missed during test runs so becomes coverage-flaky\n        /* c8 ignore next 4 */\n        : // eslint-disable-line operator-linebreak\n        // @ts-ignore\n        globalThis.Buffer.from(c))\n      // @ts-ignore\n      return asU8A(globalThis.Buffer.concat(chunks, length))\n    }\n  /* c8 ignore next 19 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array[]} chunks\n     * @param {number} length\n     * @returns {Uint8Array}\n     */\n    (chunks, length) => {\n      const out = new Uint8Array(length)\n      let off = 0\n      for (let b of chunks) {\n        if (off + b.length > out.length) {\n          // final chunk that's bigger than we need\n          b = b.subarray(0, out.length - off)\n        }\n        out.set(b, off)\n        off += b.length\n      }\n      return out\n    }\n\nexport const alloc = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {number} size\n     * @returns {Uint8Array}\n     */\n    (size) => {\n      // we always write over the contents we expose so this should be safe\n      // @ts-ignore\n      return globalThis.Buffer.allocUnsafe(size)\n    }\n  /* c8 ignore next 8 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {number} size\n     * @returns {Uint8Array}\n     */\n    (size) => {\n      return new Uint8Array(size)\n    }\n\nexport const toHex = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} d\n     * @returns {string}\n     */\n    (d) => {\n      if (typeof d === 'string') {\n        return d\n      }\n      // @ts-ignore\n      return globalThis.Buffer.from(toBytes(d)).toString('hex')\n    }\n  /* c8 ignore next 12 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} d\n     * @returns {string}\n     */\n    (d) => {\n      if (typeof d === 'string') {\n        return d\n      }\n      // @ts-ignore not smart enough to figure this out\n      return Array.prototype.reduce.call(toBytes(d), (p, c) => `${p}${c.toString(16).padStart(2, '0')}`, '')\n    }\n\nexport const fromHex = useBuffer\n  ? // eslint-disable-line operator-linebreak\n  /**\n   * @param {string|Uint8Array} hex\n   * @returns {Uint8Array}\n   */\n    (hex) => {\n      if (hex instanceof Uint8Array) {\n        return hex\n      }\n      // @ts-ignore\n      return globalThis.Buffer.from(hex, 'hex')\n    }\n  /* c8 ignore next 17 */\n  : // eslint-disable-line operator-linebreak\n  /**\n   * @param {string|Uint8Array} hex\n   * @returns {Uint8Array}\n   */\n    (hex) => {\n      if (hex instanceof Uint8Array) {\n        return hex\n      }\n      if (!hex.length) {\n        return new Uint8Array(0)\n      }\n      return new Uint8Array(hex.split('')\n        .map((/** @type {string} */ c, /** @type {number} */ i, /** @type {string[]} */ d) => i % 2 === 0 ? `0x${c}${d[i + 1]}` : '')\n        .filter(Boolean)\n        .map((/** @type {string} */ e) => parseInt(e, 16)))\n    }\n\n/**\n * @param {Uint8Array|ArrayBuffer|ArrayBufferView} obj\n * @returns {Uint8Array}\n */\nfunction toBytes (obj) {\n  if (obj instanceof Uint8Array && obj.constructor.name === 'Uint8Array') {\n    return obj\n  }\n  if (obj instanceof ArrayBuffer) {\n    return new Uint8Array(obj)\n  }\n  if (ArrayBuffer.isView(obj)) {\n    return new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength)\n  }\n  /* c8 ignore next */\n  throw new Error('Unknown type, must be binary type')\n}\n\n/**\n * @param {Uint8Array} b1\n * @param {Uint8Array} b2\n * @returns {number}\n */\nexport function compare (b1, b2) {\n  /* c8 ignore next 5 */\n  if (isBuffer(b1) && isBuffer(b2)) {\n    // probably not possible to get here in the current API\n    // @ts-ignore Buffer\n    return b1.compare(b2)\n  }\n  for (let i = 0; i < b1.length; i++) {\n    if (b1[i] === b2[i]) {\n      continue\n    }\n    return b1[i] < b2[i] ? -1 : 1\n  } /* c8 ignore next 3 */\n  return 0\n}\n\n// The below code is taken from https://github.com/google/closure-library/blob/8598d87242af59aac233270742c8984e2b2bdbe0/closure/goog/crypt/crypt.js#L117-L143\n// Licensed Apache-2.0.\n\n/**\n * @param {string} str\n * @returns {number[]}\n */\nfunction utf8ToBytes (str) {\n  const out = []\n  let p = 0\n  for (let i = 0; i < str.length; i++) {\n    let c = str.charCodeAt(i)\n    if (c < 128) {\n      out[p++] = c\n    } else if (c < 2048) {\n      out[p++] = (c >> 6) | 192\n      out[p++] = (c & 63) | 128\n    } else if (\n      ((c & 0xFC00) === 0xD800) && (i + 1) < str.length &&\n      ((str.charCodeAt(i + 1) & 0xFC00) === 0xDC00)) {\n      // Surrogate Pair\n      c = 0x10000 + ((c & 0x03FF) << 10) + (str.charCodeAt(++i) & 0x03FF)\n      out[p++] = (c >> 18) | 240\n      out[p++] = ((c >> 12) & 63) | 128\n      out[p++] = ((c >> 6) & 63) | 128\n      out[p++] = (c & 63) | 128\n    } else {\n      out[p++] = (c >> 12) | 224\n      out[p++] = ((c >> 6) & 63) | 128\n      out[p++] = (c & 63) | 128\n    }\n  }\n  return out\n}\n\n// The below code is mostly taken from https://github.com/feross/buffer\n// Licensed MIT. Copyright (c) Feross Aboukhadijeh\n\n/**\n * @param {Uint8Array} buf\n * @param {number} offset\n * @param {number} end\n * @returns {string}\n */\nfunction utf8Slice (buf, offset, end) {\n  const res = []\n\n  while (offset < end) {\n    const firstByte = buf[offset]\n    let codePoint = null\n    let bytesPerSequence = (firstByte > 0xef) ? 4 : (firstByte > 0xdf) ? 3 : (firstByte > 0xbf) ? 2 : 1\n\n    if (offset + bytesPerSequence <= end) {\n      let secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[offset + 1]\n          if ((secondByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1f) << 0x6 | (secondByte & 0x3f)\n            if (tempCodePoint > 0x7f) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[offset + 1]\n          thirdByte = buf[offset + 2]\n          if ((secondByte & 0xc0) === 0x80 && (thirdByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0xf) << 0xc | (secondByte & 0x3f) << 0x6 | (thirdByte & 0x3f)\n            /* c8 ignore next 3 */\n            if (tempCodePoint > 0x7ff && (tempCodePoint < 0xd800 || tempCodePoint > 0xdfff)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[offset + 1]\n          thirdByte = buf[offset + 2]\n          fourthByte = buf[offset + 3]\n          if ((secondByte & 0xc0) === 0x80 && (thirdByte & 0xc0) === 0x80 && (fourthByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0xf) << 0x12 | (secondByte & 0x3f) << 0xc | (thirdByte & 0x3f) << 0x6 | (fourthByte & 0x3f)\n            if (tempCodePoint > 0xffff && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    /* c8 ignore next 5 */\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xfffd\n      bytesPerSequence = 1\n    } else if (codePoint > 0xffff) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3ff | 0xd800)\n      codePoint = 0xdc00 | codePoint & 0x3ff\n    }\n\n    res.push(codePoint)\n    offset += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nconst MAX_ARGUMENTS_LENGTH = 0x1000\n\n/**\n * @param {number[]} codePoints\n * @returns {string}\n */\nexport function decodeCodePointsArray (codePoints) {\n  const len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n  /* c8 ignore next 10 */\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  let res = ''\n  let i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n","/**\n * FilBeamRetriever - CDN optimization wrapper for piece retrieval\n *\n * This intercepts piece requests and attempts CDN retrieval before falling back\n * to the base retriever.\n */\n\nimport type { FilecoinNetworkType, PieceCID, PieceRetriever } from '../types.ts'\n\nexport class FilBeamRetriever implements PieceRetriever {\n  private readonly baseRetriever: PieceRetriever\n  private readonly network: FilecoinNetworkType\n\n  constructor(baseRetriever: PieceRetriever, network: FilecoinNetworkType) {\n    this.baseRetriever = baseRetriever\n    this.network = network\n  }\n\n  hostname(): string {\n    return this.network === 'mainnet' ? 'filbeam.io' : 'calibration.filbeam.io'\n  }\n\n  async fetchPiece(\n    pieceCid: PieceCID,\n    client: string,\n    options?: {\n      providerAddress?: string\n      withCDN?: boolean\n      signal?: AbortSignal\n    }\n  ): Promise<Response> {\n    if (options?.withCDN === true) {\n      const cdnUrl = `https://${client}.${this.hostname()}/${pieceCid.toString()}`\n      try {\n        const cdnResponse = await fetch(cdnUrl, { signal: options?.signal })\n        if (cdnResponse.ok) {\n          return cdnResponse\n        } else if (cdnResponse.status === 402) {\n          console.warn(\n            'CDN requires payment. Please initialise Synapse SDK with the option `withCDN: true` and re-upload your files.'\n          )\n        } else {\n          console.warn('CDN fetch failed with status:', cdnResponse.status)\n        }\n      } catch (error) {\n        console.warn('CDN fetch failed:', error)\n      }\n      console.log('Falling back to direct retrieval')\n    }\n\n    return await this.baseRetriever.fetchPiece(pieceCid, client, options)\n  }\n}\n","import { Token, Type } from './token.js'\nimport { assertEnoughData, decodeErrPrefix } from './common.js'\nimport * as uint from './0uint.js'\nimport { compare, fromString, slice } from './byte-utils.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} prefix\n * @param {number} length\n * @returns {Token}\n */\nfunction toToken (data, pos, prefix, length) {\n  assertEnoughData(data, pos, prefix + length)\n  const buf = slice(data, pos + prefix, pos + prefix + length)\n  return new Token(Type.bytes, buf, prefix + length)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nexport function decodeBytesCompact (data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBytes8 (data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBytes16 (data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBytes32 (data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options))\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBytes64 (data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options)\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer bytes lengths not supported`)\n  }\n  return toToken(data, pos, 9, l)\n}\n\n/**\n * `encodedBytes` allows for caching when we do a byte version of a string\n * for key sorting purposes\n * @param {Token} token\n * @returns {Uint8Array}\n */\nfunction tokenBytes (token) {\n  if (token.encodedBytes === undefined) {\n    token.encodedBytes = token.type === Type.string ? fromString(token.value) : token.value\n  }\n  // @ts-ignore c'mon\n  return token.encodedBytes\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeBytes (buf, token) {\n  const bytes = tokenBytes(token)\n  uint.encodeUintValue(buf, token.type.majorEncoded, bytes.length)\n  buf.push(bytes)\n}\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeBytes.encodedSize = function encodedSize (token) {\n  const bytes = tokenBytes(token)\n  return uint.encodeUintValue.encodedSize(bytes.length) + bytes.length\n}\n\n/**\n * @param {Token} tok1\n * @param {Token} tok2\n * @returns {number}\n */\nencodeBytes.compareTokens = function compareTokens (tok1, tok2) {\n  return compareBytes(tokenBytes(tok1), tokenBytes(tok2))\n}\n\n/**\n * @param {Uint8Array} b1\n * @param {Uint8Array} b2\n * @returns {number}\n */\nexport function compareBytes (b1, b2) {\n  return b1.length < b2.length ? -1 : b1.length > b2.length ? 1 : compare(b1, b2)\n}\n","/* globals BigInt */\n\nimport { Token, Type } from './token.js'\nimport { decodeErrPrefix, assertEnoughData } from './common.js'\n\nexport const uintBoundaries = [24, 256, 65536, 4294967296, BigInt('18446744073709551616')]\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number}\n */\nexport function readUint8 (data, offset, options) {\n  assertEnoughData(data, offset, 1)\n  const value = data[offset]\n  if (options.strict === true && value < uintBoundaries[0]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  return value\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number}\n */\nexport function readUint16 (data, offset, options) {\n  assertEnoughData(data, offset, 2)\n  const value = (data[offset] << 8) | data[offset + 1]\n  if (options.strict === true && value < uintBoundaries[1]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  return value\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number}\n */\nexport function readUint32 (data, offset, options) {\n  assertEnoughData(data, offset, 4)\n  const value = (data[offset] * 16777216 /* 2 ** 24 */) + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3]\n  if (options.strict === true && value < uintBoundaries[2]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  return value\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number|bigint}\n */\nexport function readUint64 (data, offset, options) {\n  // assume BigInt, convert back to Number if within safe range\n  assertEnoughData(data, offset, 8)\n  const hi = (data[offset] * 16777216 /* 2 ** 24 */) + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3]\n  const lo = (data[offset + 4] * 16777216 /* 2 ** 24 */) + (data[offset + 5] << 16) + (data[offset + 6] << 8) + data[offset + 7]\n  const value = (BigInt(hi) << BigInt(32)) + BigInt(lo)\n  if (options.strict === true && value < uintBoundaries[3]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  if (value <= Number.MAX_SAFE_INTEGER) {\n    return Number(value)\n  }\n  if (options.allowBigInt === true) {\n    return value\n  }\n  throw new Error(`${decodeErrPrefix} integers outside of the safe integer range are not supported`)\n}\n\n/* not required thanks to quick[] list\nconst oneByteTokens = new Array(24).fill(0).map((v, i) => new Token(Type.uint, i, 1))\nexport function decodeUintCompact (data, pos, minor, options) {\n  return oneByteTokens[minor]\n}\n*/\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUint8 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint8(data, pos + 1, options), 2)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUint16 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint16(data, pos + 1, options), 3)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUint32 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint32(data, pos + 1, options), 5)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUint64 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint64(data, pos + 1, options), 9)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeUint (buf, token) {\n  return encodeUintValue(buf, 0, token.value)\n}\n\n/**\n * @param {Bl} buf\n * @param {number} major\n * @param {number|bigint} uint\n */\nexport function encodeUintValue (buf, major, uint) {\n  if (uint < uintBoundaries[0]) {\n    const nuint = Number(uint)\n    // pack into one byte, minor=0, additional=value\n    buf.push([major | nuint])\n  } else if (uint < uintBoundaries[1]) {\n    const nuint = Number(uint)\n    // pack into two byte, minor=0, additional=24\n    buf.push([major | 24, nuint])\n  } else if (uint < uintBoundaries[2]) {\n    const nuint = Number(uint)\n    // pack into three byte, minor=0, additional=25\n    buf.push([major | 25, nuint >>> 8, nuint & 0xff])\n  } else if (uint < uintBoundaries[3]) {\n    const nuint = Number(uint)\n    // pack into five byte, minor=0, additional=26\n    buf.push([major | 26, (nuint >>> 24) & 0xff, (nuint >>> 16) & 0xff, (nuint >>> 8) & 0xff, nuint & 0xff])\n  } else {\n    const buint = BigInt(uint)\n    if (buint < uintBoundaries[4]) {\n      // pack into nine byte, minor=0, additional=27\n      const set = [major | 27, 0, 0, 0, 0, 0, 0, 0]\n      // simulate bitwise above 32 bits\n      let lo = Number(buint & BigInt(0xffffffff))\n      let hi = Number(buint >> BigInt(32) & BigInt(0xffffffff))\n      set[8] = lo & 0xff\n      lo = lo >> 8\n      set[7] = lo & 0xff\n      lo = lo >> 8\n      set[6] = lo & 0xff\n      lo = lo >> 8\n      set[5] = lo & 0xff\n      set[4] = hi & 0xff\n      hi = hi >> 8\n      set[3] = hi & 0xff\n      hi = hi >> 8\n      set[2] = hi & 0xff\n      hi = hi >> 8\n      set[1] = hi & 0xff\n      buf.push(set)\n    } else {\n      throw new Error(`${decodeErrPrefix} encountered BigInt larger than allowable range`)\n    }\n  }\n}\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeUint.encodedSize = function encodedSize (token) {\n  return encodeUintValue.encodedSize(token.value)\n}\n\n/**\n * @param {number} uint\n * @returns {number}\n */\nencodeUintValue.encodedSize = function encodedSize (uint) {\n  if (uint < uintBoundaries[0]) {\n    return 1\n  }\n  if (uint < uintBoundaries[1]) {\n    return 2\n  }\n  if (uint < uintBoundaries[2]) {\n    return 3\n  }\n  if (uint < uintBoundaries[3]) {\n    return 5\n  }\n  return 9\n}\n\n/**\n * @param {Token} tok1\n * @param {Token} tok2\n * @returns {number}\n */\nencodeUint.compareTokens = function compareTokens (tok1, tok2) {\n  return tok1.value < tok2.value ? -1 : tok1.value > tok2.value ? 1 : /* c8 ignore next */ 0\n}\n","const crypto = globalThis.crypto\n\nexport function fallbackRandU256(): bigint {\n  let result = 0n\n  for (let i = 0; i < 32; i++) {\n    result <<= 8n\n    result |= BigInt(fallbackRandIndex(256))\n  }\n  return result\n}\n\n/**\n * @returns a random unsigned big integer between `0` and `2**256-1` inclusive\n */\nexport function randU256(): bigint {\n  if (crypto?.getRandomValues != null) {\n    const randU64s = new BigUint64Array(4)\n    crypto.getRandomValues(randU64s)\n    let result = 0n\n    randU64s.forEach((randU64) => {\n      result <<= 64n\n      result |= randU64\n    })\n    return result\n  } else {\n    return fallbackRandU256()\n  }\n}\n\nexport function fallbackRandIndex(length: number): number {\n  return Math.floor(Math.random() * length)\n}\n\n/**\n * Provides a random index into an array of supplied length (0 <= index < length)\n * @param length - exclusive upper boundary\n * @returns a valid index\n */\nexport function randIndex(length: number): number {\n  if (crypto?.getRandomValues != null) {\n    const randomBytes = new Uint32Array(1)\n    crypto.getRandomValues(randomBytes)\n    return randomBytes[0] % length\n  } else {\n    return fallbackRandIndex(length)\n  }\n}\n","/**\n * Internal helpers for u64. BigUint64Array is too slow as per 2025, so we implement it using Uint32Array.\n * @todo re-check https://issues.chromium.org/issues/42212588\n * @module\n */\nconst U32_MASK64 = /* @__PURE__ */ BigInt(2 ** 32 - 1);\nconst _32n = /* @__PURE__ */ BigInt(32);\n\nfunction fromBig(\n  n: bigint,\n  le = false\n): {\n  h: number;\n  l: number;\n} {\n  if (le) return { h: Number(n & U32_MASK64), l: Number((n >> _32n) & U32_MASK64) };\n  return { h: Number((n >> _32n) & U32_MASK64) | 0, l: Number(n & U32_MASK64) | 0 };\n}\n\nfunction split(lst: bigint[], le = false): Uint32Array[] {\n  const len = lst.length;\n  let Ah = new Uint32Array(len);\n  let Al = new Uint32Array(len);\n  for (let i = 0; i < len; i++) {\n    const { h, l } = fromBig(lst[i], le);\n    [Ah[i], Al[i]] = [h, l];\n  }\n  return [Ah, Al];\n}\n\nconst toBig = (h: number, l: number): bigint => (BigInt(h >>> 0) << _32n) | BigInt(l >>> 0);\n// for Shift in [0, 32)\nconst shrSH = (h: number, _l: number, s: number): number => h >>> s;\nconst shrSL = (h: number, l: number, s: number): number => (h << (32 - s)) | (l >>> s);\n// Right rotate for Shift in [1, 32)\nconst rotrSH = (h: number, l: number, s: number): number => (h >>> s) | (l << (32 - s));\nconst rotrSL = (h: number, l: number, s: number): number => (h << (32 - s)) | (l >>> s);\n// Right rotate for Shift in (32, 64), NOTE: 32 is special case.\nconst rotrBH = (h: number, l: number, s: number): number => (h << (64 - s)) | (l >>> (s - 32));\nconst rotrBL = (h: number, l: number, s: number): number => (h >>> (s - 32)) | (l << (64 - s));\n// Right rotate for shift===32 (just swaps l&h)\nconst rotr32H = (_h: number, l: number): number => l;\nconst rotr32L = (h: number, _l: number): number => h;\n// Left rotate for Shift in [1, 32)\nconst rotlSH = (h: number, l: number, s: number): number => (h << s) | (l >>> (32 - s));\nconst rotlSL = (h: number, l: number, s: number): number => (l << s) | (h >>> (32 - s));\n// Left rotate for Shift in (32, 64), NOTE: 32 is special case.\nconst rotlBH = (h: number, l: number, s: number): number => (l << (s - 32)) | (h >>> (64 - s));\nconst rotlBL = (h: number, l: number, s: number): number => (h << (s - 32)) | (l >>> (64 - s));\n\n// JS uses 32-bit signed integers for bitwise operations which means we cannot\n// simple take carry out of low bit sum by shift, we need to use division.\nfunction add(\n  Ah: number,\n  Al: number,\n  Bh: number,\n  Bl: number\n): {\n  h: number;\n  l: number;\n} {\n  const l = (Al >>> 0) + (Bl >>> 0);\n  return { h: (Ah + Bh + ((l / 2 ** 32) | 0)) | 0, l: l | 0 };\n}\n// Addition with more than 2 elements\nconst add3L = (Al: number, Bl: number, Cl: number): number => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0);\nconst add3H = (low: number, Ah: number, Bh: number, Ch: number): number =>\n  (Ah + Bh + Ch + ((low / 2 ** 32) | 0)) | 0;\nconst add4L = (Al: number, Bl: number, Cl: number, Dl: number): number =>\n  (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0);\nconst add4H = (low: number, Ah: number, Bh: number, Ch: number, Dh: number): number =>\n  (Ah + Bh + Ch + Dh + ((low / 2 ** 32) | 0)) | 0;\nconst add5L = (Al: number, Bl: number, Cl: number, Dl: number, El: number): number =>\n  (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0) + (El >>> 0);\nconst add5H = (low: number, Ah: number, Bh: number, Ch: number, Dh: number, Eh: number): number =>\n  (Ah + Bh + Ch + Dh + Eh + ((low / 2 ** 32) | 0)) | 0;\n\n// prettier-ignore\nexport {\n  add, add3H, add3L, add4H, add4L, add5H, add5L, fromBig, rotlBH, rotlBL, rotlSH, rotlSL, rotr32H, rotr32L, rotrBH, rotrBL, rotrSH, rotrSL, shrSH, shrSL, split, toBig\n};\n// prettier-ignore\nconst u64: { fromBig: typeof fromBig; split: typeof split; toBig: (h: number, l: number) => bigint; shrSH: (h: number, _l: number, s: number) => number; shrSL: (h: number, l: number, s: number) => number; rotrSH: (h: number, l: number, s: number) => number; rotrSL: (h: number, l: number, s: number) => number; rotrBH: (h: number, l: number, s: number) => number; rotrBL: (h: number, l: number, s: number) => number; rotr32H: (_h: number, l: number) => number; rotr32L: (h: number, _l: number) => number; rotlSH: (h: number, l: number, s: number) => number; rotlSL: (h: number, l: number, s: number) => number; rotlBH: (h: number, l: number, s: number) => number; rotlBL: (h: number, l: number, s: number) => number; add: typeof add; add3L: (Al: number, Bl: number, Cl: number) => number; add3H: (low: number, Ah: number, Bh: number, Ch: number) => number; add4L: (Al: number, Bl: number, Cl: number, Dl: number) => number; add4H: (low: number, Ah: number, Bh: number, Ch: number, Dh: number) => number; add5H: (low: number, Ah: number, Bh: number, Ch: number, Dh: number, Eh: number) => number; add5L: (Al: number, Bl: number, Cl: number, Dl: number, El: number) => number; } = {\n  fromBig, split, toBig,\n  shrSH, shrSL,\n  rotrSH, rotrSL, rotrBH, rotrBL,\n  rotr32H, rotr32L,\n  rotlSH, rotlSL, rotlBH, rotlBL,\n  add, add3L, add3H, add4L, add4H, add5H, add5L,\n};\nexport default u64;\n","import { coerce, equals as equalBytes } from '../bytes.js'\nimport * as varint from '../varint.js'\nimport type { MultihashDigest } from './interface.js'\n\n/**\n * Creates a multihash digest.\n */\nexport function create <Code extends number> (code: Code, digest: Uint8Array): Digest<Code, number> {\n  const size = digest.byteLength\n  const sizeOffset = varint.encodingLength(code)\n  const digestOffset = sizeOffset + varint.encodingLength(size)\n\n  const bytes = new Uint8Array(digestOffset + size)\n  varint.encodeTo(code, bytes, 0)\n  varint.encodeTo(size, bytes, sizeOffset)\n  bytes.set(digest, digestOffset)\n\n  return new Digest(code, size, digest, bytes)\n}\n\n/**\n * Turns bytes representation of multihash digest into an instance.\n */\nexport function decode (multihash: Uint8Array): MultihashDigest {\n  const bytes = coerce(multihash)\n  const [code, sizeOffset] = varint.decode(bytes)\n  const [size, digestOffset] = varint.decode(bytes.subarray(sizeOffset))\n  const digest = bytes.subarray(sizeOffset + digestOffset)\n\n  if (digest.byteLength !== size) {\n    throw new Error('Incorrect length')\n  }\n\n  return new Digest(code, size, digest, bytes)\n}\n\nexport function equals (a: MultihashDigest, b: unknown): b is MultihashDigest {\n  if (a === b) {\n    return true\n  } else {\n    const data = b as { code?: unknown, size?: unknown, bytes?: unknown }\n\n    return (\n      a.code === data.code &&\n      a.size === data.size &&\n      data.bytes instanceof Uint8Array &&\n      equalBytes(a.bytes, data.bytes)\n    )\n  }\n}\n\n/**\n * Represents a multihash digest which carries information about the\n * hashing algorithm and an actual hash digest.\n */\nexport class Digest<Code extends number, Size extends number> implements MultihashDigest {\n  readonly code: Code\n  readonly size: Size\n  readonly digest: Uint8Array\n  readonly bytes: Uint8Array\n\n  /**\n   * Creates a multihash digest.\n   */\n  constructor (code: Code, size: Size, digest: Uint8Array, bytes: Uint8Array) {\n    this.code = code\n    this.size = size\n    this.digest = digest\n    this.bytes = bytes\n  }\n}\n\n/**\n * Used to check that the passed multihash has the passed code\n */\nexport function hasCode <T extends number> (digest: MultihashDigest, code: T): digest is MultihashDigest<T> {\n  return digest.code === code\n}\n","/**\n * SubgraphRetriever - Uses a SubgraphService to find and retrieve pieces.\n */\n\nimport type { PieceCID, PieceRetriever, ProviderInfo, SubgraphRetrievalService } from '../types.ts'\nimport { createError } from '../utils/errors.ts'\nimport { fetchPiecesFromProviders } from './utils.ts'\n\nexport class SubgraphRetriever implements PieceRetriever {\n  private readonly subgraphService: SubgraphRetrievalService\n  private readonly childRetriever?: PieceRetriever\n\n  constructor(subgraphService: SubgraphRetrievalService, childRetriever?: PieceRetriever) {\n    this.subgraphService = subgraphService\n    this.childRetriever = childRetriever\n  }\n\n  /**\n   * Find providers that can serve pieces for a client\n   * @param pieceCid - The piece commitment (PieceCID) to search for.\n   * @param providerAddress - Optional specific provider to use\n   * @returns List of approved provider info\n   */\n  async findProviders(pieceCid: PieceCID, providerAddress?: string): Promise<ProviderInfo[]> {\n    if (providerAddress != null) {\n      const provider = await this.subgraphService.getProviderByAddress(providerAddress)\n      return provider !== null ? [provider] : []\n    }\n    return await this.subgraphService.getApprovedProvidersForPieceCID(pieceCid)\n  }\n\n  async fetchPiece(\n    pieceCid: PieceCID,\n    client: string,\n    options?: { providerAddress?: string; signal?: AbortSignal }\n  ): Promise<Response> {\n    // Helper function to try child retriever or throw error\n    const tryChildOrThrow = async (reason: string): Promise<Response> => {\n      if (this.childRetriever !== undefined) {\n        return await this.childRetriever.fetchPiece(pieceCid, client, options)\n      }\n      throw createError('SubgraphRetriever', 'fetchPiece', `Failed to retrieve piece ${pieceCid.toString()}: ${reason}`)\n    }\n\n    // Step 1: Find providers\n    let providersToTry: ProviderInfo[] = []\n    try {\n      providersToTry = await this.findProviders(pieceCid, options?.providerAddress)\n    } catch {\n      // Provider discovery failed - this is a critical error\n      return await tryChildOrThrow('Provider discovery failed and no additional retriever method was configured')\n    }\n\n    // Step 2: If no providers found, try child retriever\n    if (providersToTry.length === 0) {\n      return await tryChildOrThrow('No providers found and no additional retriever method was configured')\n    }\n\n    // Step 3: Try to fetch from providers\n    try {\n      return await fetchPiecesFromProviders(providersToTry, pieceCid, 'SubgraphRetriever', options?.signal)\n    } catch {\n      // All provider attempts failed\n      return await tryChildOrThrow(\n        'All provider retrieval attempts failed and no additional retriever method was configured'\n      )\n    }\n  }\n}\n","/**\n * StorageManager - Central facade for all storage operations\n *\n * Manages storage contexts (SP + DataSet pairs) with intelligent caching and reuse.\n * Provides both SP-agnostic operations (download from anywhere) and context-based\n * operations (upload/download to/from specific providers).\n *\n * @example\n * ```typescript\n * // Simple usage - auto-manages context\n * await synapse.storage.upload(data)\n * await synapse.storage.download(pieceCid)\n *\n * // Explicit context\n * const context = await synapse.storage.createContext({ providerId: 1 })\n * await context.upload(data)\n *\n * // Context routing\n * await synapse.storage.upload(data, { context })\n * ```\n */\n\nimport * as Piece from '@filoz/synapse-core/piece'\nimport { asPieceCID, downloadAndValidate } from '@filoz/synapse-core/piece'\nimport { randIndex } from '@filoz/synapse-core/utils'\nimport { ethers } from 'ethers'\nimport { SPRegistryService } from '../sp-registry/index.ts'\nimport type { Synapse } from '../synapse.ts'\nimport type {\n  CreateContextsOptions,\n  DownloadOptions,\n  EnhancedDataSetInfo,\n  PieceCID,\n  PieceRetriever,\n  PreflightInfo,\n  ProviderInfo,\n  StorageContextCallbacks,\n  StorageInfo,\n  StorageServiceOptions,\n  UploadCallbacks,\n  UploadResult,\n} from '../types.ts'\nimport {\n  combineMetadata,\n  createError,\n  METADATA_KEYS,\n  metadataMatches,\n  SIZE_CONSTANTS,\n  TIME_CONSTANTS,\n  TOKENS,\n} from '../utils/index.ts'\nimport type { WarmStorageService } from '../warm-storage/index.ts'\nimport { StorageContext } from './context.ts'\n\n// Combined callbacks type that can include both creation and upload callbacks\ntype CombinedCallbacks = StorageContextCallbacks & UploadCallbacks\n\n/**\n * Upload options for StorageManager.upload() - the all-in-one upload method\n *\n * This is the \"uber-shortcut\" method that can handle everything from context\n * creation to piece upload in a single call. It combines:\n * - Storage context creation options (provider selection, data set creation)\n * - Upload callbacks (both creation and upload progress)\n * - Piece-specific metadata\n *\n * Usage patterns:\n * 1. With explicit context: `{ context, callbacks?, metadata? }` - routes to context.upload()\n * 2. Auto-create context: `{ providerId?, dataSetId?, withCDN?, callbacks?, metadata? }` - creates/reuses context\n * 3. Use default context: `{ callbacks?, metadata? }` - uses cached default context\n *\n * @internal This type is intentionally not exported as it's specific to StorageManager\n */\ninterface StorageManagerUploadOptions extends StorageServiceOptions {\n  // Multiple storage providers: if provided, all other context options are invalid\n  contexts?: StorageContext[]\n\n  // Context routing - if provided, all other context options are invalid\n  context?: StorageContext\n\n  // Callbacks that can include both creation and upload callbacks\n  callbacks?: Partial<CombinedCallbacks>\n\n  /** Optional pre-calculated PieceCID to skip CommP calculation (BYO PieceCID, it will be checked by the server) */\n  pieceCid?: PieceCID\n\n  /** Optional AbortSignal to cancel the upload */\n  signal?: AbortSignal\n}\n\ninterface StorageManagerDownloadOptions extends DownloadOptions {\n  context?: StorageContext\n  providerAddress?: string\n  withCDN?: boolean\n}\n\nexport class StorageManager {\n  private readonly _synapse: Synapse\n  private readonly _warmStorageService: WarmStorageService\n  private readonly _pieceRetriever: PieceRetriever\n  private readonly _withCDN: boolean\n  private readonly _dev: boolean\n  private readonly _withIpni: boolean | undefined\n  private _defaultContexts?: StorageContext[]\n\n  constructor(\n    synapse: Synapse,\n    warmStorageService: WarmStorageService,\n    pieceRetriever: PieceRetriever,\n    withCDN: boolean,\n    dev: boolean,\n    withIpni?: boolean\n  ) {\n    this._synapse = synapse\n    this._warmStorageService = warmStorageService\n    this._pieceRetriever = pieceRetriever\n    this._withCDN = withCDN\n    this._dev = dev\n    this._withIpni = withIpni\n  }\n\n  /**\n   * Upload data to storage\n   * Uses the storage contexts or context provided in the options\n   * Otherwise creates/reuses default context\n   *\n   * Accepts Uint8Array or ReadableStream<Uint8Array>.\n   * For large files, prefer streaming to minimize memory usage.\n   *\n   * Note: Multi-context uploads (uploading to multiple providers simultaneously) currently\n   * only support Uint8Array. For streaming uploads with multiple contexts, convert your\n   * stream to Uint8Array first or use stream forking (future feature).\n   */\n  async upload(\n    data: Uint8Array | ReadableStream<Uint8Array>,\n    options?: StorageManagerUploadOptions\n  ): Promise<UploadResult> {\n    // Validate options - if context is provided, no other options should be set\n    if (options?.context != null || options?.contexts != null) {\n      const invalidOptions = []\n      if (options.providerId !== undefined) invalidOptions.push('providerId')\n      if (options.providerAddress !== undefined) invalidOptions.push('providerAddress')\n      if (options.dataSetId !== undefined) invalidOptions.push('dataSetId')\n      if (options.withCDN !== undefined) invalidOptions.push('withCDN')\n      if (options.forceCreateDataSet !== undefined) invalidOptions.push('forceCreateDataSet')\n      if (options.uploadBatchSize !== undefined) invalidOptions.push('uploadBatchSize')\n\n      if (invalidOptions.length > 0) {\n        throw createError(\n          'StorageManager',\n          'upload',\n          `Cannot specify both 'context' and other options: ${invalidOptions.join(', ')}`\n        )\n      }\n    }\n\n    if (options?.contexts != null && options.contexts.length > 0) {\n      if (options?.context != null) {\n        throw createError('StorageManager', 'upload', \"Cannot specify both 'context' and 'contexts'\")\n      }\n    }\n\n    // Get the context to use\n    const contexts =\n      options?.contexts ??\n      (options?.context\n        ? [options.context]\n        : await this.createContexts({\n            withCDN: options?.withCDN,\n            withIpni: options?.withIpni,\n            count: 1, // single context by default for now - this will be changed in a future version\n            dev: options?.dev,\n            uploadBatchSize: options?.uploadBatchSize,\n            forceCreateDataSets: options?.forceCreateDataSet,\n            metadata: options?.metadata,\n            excludeProviderIds: options?.excludeProviderIds,\n            providerIds: options?.providerId ? [options.providerId] : undefined,\n            dataSetIds: options?.dataSetId ? [options.dataSetId] : undefined,\n            callbacks: options?.callbacks,\n          }))\n\n    // Multi-context upload handling\n    if (contexts.length > 1) {\n      // Multi-context uploads require Uint8Array to calculate pieceCid once\n      if (!(data instanceof Uint8Array)) {\n        throw createError(\n          'StorageManager',\n          'upload',\n          'Multi-context uploads currently only support Uint8Array. ' +\n            'For streaming uploads to multiple providers, convert your stream to Uint8Array first.'\n        )\n      }\n\n      // Calculate pieceCid once for all contexts\n      const pieceCid = Piece.calculate(data)\n\n      // Upload to all contexts with the same pieceCid\n      return Promise.all(\n        contexts.map((context) =>\n          context.upload(data, {\n            ...options?.callbacks, // TODO: callbacks should be able to differentiate by provider\n            metadata: options?.metadata,\n            pieceCid,\n            signal: options?.signal,\n          })\n        )\n      ).then((results) => results[0]) // all results should be the same\n    } else {\n      // Single context upload - supports all data types\n      const context = contexts[0]\n\n      // Upload to single context\n      return context.upload(data, {\n        ...options?.callbacks,\n        metadata: options?.metadata,\n        signal: options?.signal,\n      })\n    }\n  }\n\n  /**\n   * Download data from storage\n   * If context is provided, routes to context.download()\n   * Otherwise performs SP-agnostic download\n   */\n  async download(pieceCid: string | PieceCID, options?: StorageManagerDownloadOptions): Promise<Uint8Array> {\n    // Validate options - if context is provided, no other options should be set\n    if (options?.context != null) {\n      const invalidOptions = []\n      if (options.providerAddress !== undefined) invalidOptions.push('providerAddress')\n      if (options.withCDN !== undefined) invalidOptions.push('withCDN')\n\n      if (invalidOptions.length > 0) {\n        throw createError(\n          'StorageManager',\n          'download',\n          `Cannot specify both 'context' and other options: ${invalidOptions.join(', ')}`\n        )\n      }\n\n      // Route to specific context\n      return await options.context.download(pieceCid, options)\n    }\n\n    // SP-agnostic download with fast path optimization\n    const parsedPieceCID = asPieceCID(pieceCid)\n    if (parsedPieceCID == null) {\n      throw createError('StorageManager', 'download', `Invalid PieceCID: ${String(pieceCid)}`)\n    }\n\n    // Use withCDN setting: option > manager default > synapse default\n    const withCDN = options?.withCDN ?? this._withCDN\n\n    // Fast path: If we have a default context with CDN disabled and no specific provider requested,\n    // check if the piece exists on the default context's provider first\n    if (this._defaultContexts != null && !withCDN && options?.providerAddress == null) {\n      // from the default contexts, select a random storage provider that has the piece\n      const contextsWithoutCDN = this._defaultContexts.filter((context) => context.withCDN === false)\n      const contextsHavePiece = await Promise.all(contextsWithoutCDN.map((context) => context.hasPiece(parsedPieceCID)))\n      const defaultContextsWithPiece = contextsWithoutCDN.filter((_context, i) => contextsHavePiece[i])\n      if (defaultContextsWithPiece.length > 0) {\n        options = {\n          ...options,\n          providerAddress:\n            defaultContextsWithPiece[randIndex(defaultContextsWithPiece.length)].provider.serviceProvider,\n        }\n      }\n    }\n\n    const clientAddress = await this._synapse.getClient().getAddress()\n\n    // Use piece retriever to fetch\n    const response = await this._pieceRetriever.fetchPiece(parsedPieceCID, clientAddress, {\n      providerAddress: options?.providerAddress,\n      withCDN,\n    })\n\n    return await downloadAndValidate(response, parsedPieceCID)\n  }\n\n  /**\n   * Run preflight checks for an upload without creating a context\n   * @param size - The size of data to upload in bytes\n   * @param options - Optional settings including withCDN flag and/or metadata\n   * @returns Preflight information including costs and allowances\n   */\n  async preflightUpload(\n    size: number,\n    options?: { withCDN?: boolean; metadata?: Record<string, string> }\n  ): Promise<PreflightInfo> {\n    // Determine withCDN from metadata if provided, otherwise use option > manager default\n    let withCDN = options?.withCDN ?? this._withCDN\n\n    // Check metadata for withCDN key - this takes precedence\n    if (options?.metadata != null && METADATA_KEYS.WITH_CDN in options.metadata) {\n      // The withCDN metadata entry should always have an empty string value by convention,\n      // but the contract only checks for key presence, not value\n      const value = options.metadata[METADATA_KEYS.WITH_CDN]\n      if (value !== '') {\n        console.warn(`Warning: withCDN metadata entry has unexpected value \"${value}\". Expected empty string.`)\n      }\n      withCDN = true // Enable CDN when key exists (matches contract behavior)\n    }\n\n    // Use the static method from StorageContext for core logic\n    return await StorageContext.performPreflightCheck(this._warmStorageService, this._synapse.payments, size, withCDN)\n  }\n\n  /**\n   * Creates storage contexts for multi-provider storage deals and other operations.\n   *\n   * By storing data with multiple independent providers, you reduce dependency on any\n   * single provider and improve overall data availability. Use contexts together as a group.\n   *\n   * Contexts are selected by priority:\n   * 1. Specified datasets (`dataSetIds`) - uses their existing providers\n   * 2. Specified providers (`providerIds` or `providerAddresses`) - finds or creates matching datasets\n   * 3. Automatically selected from remaining approved providers\n   *\n   * For automatic selection, existing datasets matching the `metadata` are reused unless\n   * `forceCreateDataSets` is true. Providers are randomly chosen to distribute across the network.\n   *\n   * @param synapse - Synapse instance\n   * @param warmStorageService - Warm storage service instance\n   * @param options - Configuration options\n   * @param options.count - Maximum number of contexts to create (default: 2)\n   * @param options.dataSetIds - Specific dataset IDs to include\n   * @param options.providerIds - Specific provider IDs to use\n   * @param options.metadata - Metadata to match when finding/creating datasets\n   * @param options.forceCreateDataSets - Always create new datasets instead of reusing existing ones\n   * @param options.excludeProviderIds - Provider IDs to skip during selection\n   * @returns Promise resolving to array of storage contexts\n   */\n  async createContexts(options?: CreateContextsOptions): Promise<StorageContext[]> {\n    const withCDN = options?.withCDN ?? this._withCDN\n    const canUseDefault =\n      options == null ||\n      (options.providerIds == null &&\n        options.dataSetIds == null &&\n        options.forceCreateDataSets !== true &&\n        options.uploadBatchSize == null)\n    if (this._defaultContexts != null) {\n      const expectedSize = options?.count ?? 2\n      if (\n        this._defaultContexts.length === expectedSize &&\n        this._defaultContexts.every((context) => options?.excludeProviderIds?.includes(context.provider.id) !== true)\n      ) {\n        const requestedMetadata = combineMetadata(options?.metadata, withCDN)\n        if (\n          this._defaultContexts.every((defaultContext) =>\n            metadataMatches(defaultContext.dataSetMetadata, requestedMetadata)\n          )\n        ) {\n          if (options?.callbacks != null) {\n            for (const defaultContext of this._defaultContexts) {\n              try {\n                options.callbacks.onProviderSelected?.(defaultContext.provider)\n              } catch (error) {\n                console.error('Error in onProviderSelected callback:', error)\n              }\n\n              if (defaultContext.dataSetId != null) {\n                try {\n                  options.callbacks.onDataSetResolved?.({\n                    isExisting: true, // Always true for cached context\n                    dataSetId: defaultContext.dataSetId,\n                    provider: defaultContext.provider,\n                  })\n                } catch (error) {\n                  console.error('Error in onDataSetResolved callback:', error)\n                }\n              }\n            }\n          }\n          return this._defaultContexts\n        }\n      }\n    }\n\n    const contexts = await StorageContext.createContexts(this._synapse, this._warmStorageService, {\n      ...options,\n      withCDN,\n      withIpni: options?.withIpni ?? this._withIpni,\n      dev: options?.dev ?? this._dev,\n    })\n\n    if (canUseDefault) {\n      this._defaultContexts = contexts\n    }\n\n    return contexts\n  }\n\n  /**\n   * Create a new storage context with specified options\n   */\n  async createContext(options?: StorageServiceOptions): Promise<StorageContext> {\n    // Determine the effective withCDN setting\n    const effectiveWithCDN = options?.withCDN ?? this._withCDN\n\n    // Check if we can return the default context\n    // We can use the default if:\n    // 1. No options provided, OR\n    // 2. Only withCDN, metadata and/or callbacks are provided (callbacks can fire for cached context)\n    const canUseDefault =\n      options == null ||\n      (options.providerId == null &&\n        options.providerAddress == null &&\n        options.dataSetId == null &&\n        options.forceCreateDataSet !== true &&\n        options.uploadBatchSize == null)\n\n    if (canUseDefault && this._defaultContexts != null) {\n      // Check if we have a default context with compatible metadata\n\n      const requestedMetadata = combineMetadata(options?.metadata, effectiveWithCDN)\n      for (const defaultContext of this._defaultContexts) {\n        if (options?.excludeProviderIds?.includes(defaultContext.provider.id)) {\n          continue\n        }\n        // Check if the requested metadata matches what the default context was created with\n        if (!metadataMatches(defaultContext.dataSetMetadata, requestedMetadata)) {\n          continue\n        }\n        // Fire callbacks for cached context to ensure consistent behavior\n        if (options?.callbacks != null) {\n          try {\n            options.callbacks.onProviderSelected?.(defaultContext.provider)\n          } catch (error) {\n            console.error('Error in onProviderSelected callback:', error)\n          }\n\n          if (defaultContext.dataSetId != null) {\n            try {\n              options.callbacks.onDataSetResolved?.({\n                isExisting: true, // Always true for cached context\n                dataSetId: defaultContext.dataSetId,\n                provider: defaultContext.provider,\n              })\n            } catch (error) {\n              console.error('Error in onDataSetResolved callback:', error)\n            }\n          }\n        }\n        return defaultContext\n      }\n    }\n\n    // Create a new context with specific options\n    const context = await StorageContext.create(this._synapse, this._warmStorageService, {\n      ...options,\n      withCDN: effectiveWithCDN,\n      withIpni: options?.withIpni ?? this._withIpni,\n      dev: options?.dev ?? this._dev,\n    })\n\n    if (canUseDefault) {\n      this._defaultContexts = [context]\n    }\n    return context\n  }\n\n  /**\n   * Get or create the default context\n   */\n  async getDefaultContext(): Promise<StorageContext> {\n    return await this.createContext()\n  }\n\n  /**\n   * Query data sets for this client\n   * @param clientAddress - Optional client address, defaults to current signer\n   * @returns Array of enhanced data set information including management status\n   */\n  async findDataSets(clientAddress?: string): Promise<EnhancedDataSetInfo[]> {\n    const address = clientAddress ?? (await this._synapse.getClient().getAddress())\n    return await this._warmStorageService.getClientDataSetsWithDetails(address)\n  }\n\n  /**\n   * Terminate a data set with given ID that belongs to the synapse signer.\n   * This will also result in the removal of all pieces in the data set.\n   * @param dataSetId - The ID of the data set to terminate\n   * @returns Transaction response\n   */\n  async terminateDataSet(dataSetId: number): Promise<ethers.TransactionResponse> {\n    return this._warmStorageService.terminateDataSet(this._synapse.getSigner(), dataSetId)\n  }\n\n  /**\n   * Get comprehensive information about the storage service including\n   * approved providers, pricing, contract addresses, and current allowances\n   * @returns Complete storage service information\n   */\n  async getStorageInfo(): Promise<StorageInfo> {\n    try {\n      // Helper function to get allowances with error handling\n      const getOptionalAllowances = async (): Promise<StorageInfo['allowances']> => {\n        try {\n          const warmStorageAddress = this._synapse.getWarmStorageAddress()\n          const approval = await this._synapse.payments.serviceApproval(warmStorageAddress, TOKENS.USDFC)\n          return {\n            service: warmStorageAddress,\n            // Forward whether operator is approved so callers can react accordingly\n            isApproved: approval.isApproved,\n            rateAllowance: approval.rateAllowance,\n            lockupAllowance: approval.lockupAllowance,\n            rateUsed: approval.rateUsed,\n            lockupUsed: approval.lockupUsed,\n          }\n        } catch {\n          // Return null if wallet not connected or any error occurs\n          return null\n        }\n      }\n\n      // Create SPRegistryService to get providers\n      const registryAddress = this._warmStorageService.getServiceProviderRegistryAddress()\n      const spRegistry = new SPRegistryService(this._synapse.getProvider(), registryAddress)\n\n      // Fetch all data in parallel for performance\n      const [pricingData, approvedIds, allowances] = await Promise.all([\n        this._warmStorageService.getServicePrice(),\n        this._warmStorageService.getApprovedProviderIds(),\n        getOptionalAllowances(),\n      ])\n\n      // Get provider details for approved IDs\n      const providers = await spRegistry.getProviders(approvedIds)\n\n      // Calculate pricing per different time units\n      const epochsPerMonth = BigInt(pricingData.epochsPerMonth)\n\n      // TODO: StorageInfo needs updating to reflect that CDN costs are usage-based\n\n      // Calculate per-epoch pricing (base storage cost)\n      const noCDNPerEpoch = BigInt(pricingData.pricePerTiBPerMonthNoCDN) / epochsPerMonth\n      // CDN costs are usage-based (egress charges), so base storage cost is the same\n      const withCDNPerEpoch = BigInt(pricingData.pricePerTiBPerMonthNoCDN) / epochsPerMonth\n\n      // Calculate per-day pricing (base storage cost)\n      const noCDNPerDay = BigInt(pricingData.pricePerTiBPerMonthNoCDN) / TIME_CONSTANTS.DAYS_PER_MONTH\n      // CDN costs are usage-based (egress charges), so base storage cost is the same\n      const withCDNPerDay = BigInt(pricingData.pricePerTiBPerMonthNoCDN) / TIME_CONSTANTS.DAYS_PER_MONTH\n\n      // Filter out providers with zero addresses\n      const validProviders = providers.filter((p: ProviderInfo) => p.serviceProvider !== ethers.ZeroAddress)\n\n      const network = this._synapse.getNetwork()\n\n      return {\n        pricing: {\n          noCDN: {\n            perTiBPerMonth: BigInt(pricingData.pricePerTiBPerMonthNoCDN),\n            perTiBPerDay: noCDNPerDay,\n            perTiBPerEpoch: noCDNPerEpoch,\n          },\n          // CDN costs are usage-based (egress charges), base storage cost is the same\n          withCDN: {\n            perTiBPerMonth: BigInt(pricingData.pricePerTiBPerMonthNoCDN),\n            perTiBPerDay: withCDNPerDay,\n            perTiBPerEpoch: withCDNPerEpoch,\n          },\n          tokenAddress: pricingData.tokenAddress,\n          tokenSymbol: 'USDFC', // Hardcoded as we know it's always USDFC\n        },\n        providers: validProviders,\n        serviceParameters: {\n          network,\n          epochsPerMonth,\n          epochsPerDay: TIME_CONSTANTS.EPOCHS_PER_DAY,\n          epochDuration: TIME_CONSTANTS.EPOCH_DURATION,\n          minUploadSize: SIZE_CONSTANTS.MIN_UPLOAD_SIZE,\n          maxUploadSize: SIZE_CONSTANTS.MAX_UPLOAD_SIZE,\n          warmStorageAddress: this._synapse.getWarmStorageAddress(),\n          paymentsAddress: this._warmStorageService.getPaymentsAddress(),\n          pdpVerifierAddress: this._warmStorageService.getPDPVerifierAddress(),\n        },\n        allowances,\n      }\n    } catch (error) {\n      throw new Error(\n        `Failed to get storage service information: ${error instanceof Error ? error.message : String(error)}`\n      )\n    }\n  }\n}\n","/**\n * Hex, bytes and number utilities.\n * @module\n */\n/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n\n// 100 lines of code in the file are duplicated from noble-hashes (utils).\n// This is OK: `abstract` directory does not use noble-hashes.\n// User may opt-in into using different hashing library. This way, noble-hashes\n// won't be included into their bundle.\nconst _0n = /* @__PURE__ */ BigInt(0);\nconst _1n = /* @__PURE__ */ BigInt(1);\nexport type Hex = Uint8Array | string; // hex strings are accepted for simplicity\nexport type PrivKey = Hex | bigint; // bigints are accepted to ease learning curve\nexport type CHash = {\n  (message: Uint8Array | string): Uint8Array;\n  blockLen: number;\n  outputLen: number;\n  create(opts?: { dkLen?: number }): any; // For shake\n};\nexport type FHash = (message: Uint8Array | string) => Uint8Array;\n\nexport function isBytes(a: unknown): a is Uint8Array {\n  return a instanceof Uint8Array || (ArrayBuffer.isView(a) && a.constructor.name === 'Uint8Array');\n}\n\nexport function abytes(item: unknown): void {\n  if (!isBytes(item)) throw new Error('Uint8Array expected');\n}\n\nexport function abool(title: string, value: boolean): void {\n  if (typeof value !== 'boolean') throw new Error(title + ' boolean expected, got ' + value);\n}\n\n// Used in weierstrass, der\nexport function numberToHexUnpadded(num: number | bigint): string {\n  const hex = num.toString(16);\n  return hex.length & 1 ? '0' + hex : hex;\n}\n\nexport function hexToNumber(hex: string): bigint {\n  if (typeof hex !== 'string') throw new Error('hex string expected, got ' + typeof hex);\n  return hex === '' ? _0n : BigInt('0x' + hex); // Big Endian\n}\n\n// Built-in hex conversion https://caniuse.com/mdn-javascript_builtins_uint8array_fromhex\nconst hasHexBuiltin: boolean =\n  // @ts-ignore\n  typeof Uint8Array.from([]).toHex === 'function' && typeof Uint8Array.fromHex === 'function';\n\n// Array where index 0xf0 (240) is mapped to string 'f0'\nconst hexes = /* @__PURE__ */ Array.from({ length: 256 }, (_, i) =>\n  i.toString(16).padStart(2, '0')\n);\n\n/**\n * Convert byte array to hex string. Uses built-in function, when available.\n * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'\n */\nexport function bytesToHex(bytes: Uint8Array): string {\n  abytes(bytes);\n  // @ts-ignore\n  if (hasHexBuiltin) return bytes.toHex();\n  // pre-caching improves the speed 6x\n  let hex = '';\n  for (let i = 0; i < bytes.length; i++) {\n    hex += hexes[bytes[i]];\n  }\n  return hex;\n}\n\n// We use optimized technique to convert hex string to byte array\nconst asciis = { _0: 48, _9: 57, A: 65, F: 70, a: 97, f: 102 } as const;\nfunction asciiToBase16(ch: number): number | undefined {\n  if (ch >= asciis._0 && ch <= asciis._9) return ch - asciis._0; // '2' => 50-48\n  if (ch >= asciis.A && ch <= asciis.F) return ch - (asciis.A - 10); // 'B' => 66-(65-10)\n  if (ch >= asciis.a && ch <= asciis.f) return ch - (asciis.a - 10); // 'b' => 98-(97-10)\n  return;\n}\n\n/**\n * Convert hex string to byte array. Uses built-in function, when available.\n * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])\n */\nexport function hexToBytes(hex: string): Uint8Array {\n  if (typeof hex !== 'string') throw new Error('hex string expected, got ' + typeof hex);\n  // @ts-ignore\n  if (hasHexBuiltin) return Uint8Array.fromHex(hex);\n  const hl = hex.length;\n  const al = hl / 2;\n  if (hl % 2) throw new Error('hex string expected, got unpadded hex of length ' + hl);\n  const array = new Uint8Array(al);\n  for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {\n    const n1 = asciiToBase16(hex.charCodeAt(hi));\n    const n2 = asciiToBase16(hex.charCodeAt(hi + 1));\n    if (n1 === undefined || n2 === undefined) {\n      const char = hex[hi] + hex[hi + 1];\n      throw new Error('hex string expected, got non-hex character \"' + char + '\" at index ' + hi);\n    }\n    array[ai] = n1 * 16 + n2; // multiply first octet, e.g. 'a3' => 10*16+3 => 160 + 3 => 163\n  }\n  return array;\n}\n\n// BE: Big Endian, LE: Little Endian\nexport function bytesToNumberBE(bytes: Uint8Array): bigint {\n  return hexToNumber(bytesToHex(bytes));\n}\nexport function bytesToNumberLE(bytes: Uint8Array): bigint {\n  abytes(bytes);\n  return hexToNumber(bytesToHex(Uint8Array.from(bytes).reverse()));\n}\n\nexport function numberToBytesBE(n: number | bigint, len: number): Uint8Array {\n  return hexToBytes(n.toString(16).padStart(len * 2, '0'));\n}\nexport function numberToBytesLE(n: number | bigint, len: number): Uint8Array {\n  return numberToBytesBE(n, len).reverse();\n}\n// Unpadded, rarely used\nexport function numberToVarBytesBE(n: number | bigint): Uint8Array {\n  return hexToBytes(numberToHexUnpadded(n));\n}\n\n/**\n * Takes hex string or Uint8Array, converts to Uint8Array.\n * Validates output length.\n * Will throw error for other types.\n * @param title descriptive title for an error e.g. 'private key'\n * @param hex hex string or Uint8Array\n * @param expectedLength optional, will compare to result array's length\n * @returns\n */\nexport function ensureBytes(title: string, hex: Hex, expectedLength?: number): Uint8Array {\n  let res: Uint8Array;\n  if (typeof hex === 'string') {\n    try {\n      res = hexToBytes(hex);\n    } catch (e) {\n      throw new Error(title + ' must be hex string or Uint8Array, cause: ' + e);\n    }\n  } else if (isBytes(hex)) {\n    // Uint8Array.from() instead of hash.slice() because node.js Buffer\n    // is instance of Uint8Array, and its slice() creates **mutable** copy\n    res = Uint8Array.from(hex);\n  } else {\n    throw new Error(title + ' must be hex string or Uint8Array');\n  }\n  const len = res.length;\n  if (typeof expectedLength === 'number' && len !== expectedLength)\n    throw new Error(title + ' of length ' + expectedLength + ' expected, got ' + len);\n  return res;\n}\n\n/**\n * Copies several Uint8Arrays into one.\n */\nexport function concatBytes(...arrays: Uint8Array[]): Uint8Array {\n  let sum = 0;\n  for (let i = 0; i < arrays.length; i++) {\n    const a = arrays[i];\n    abytes(a);\n    sum += a.length;\n  }\n  const res = new Uint8Array(sum);\n  for (let i = 0, pad = 0; i < arrays.length; i++) {\n    const a = arrays[i];\n    res.set(a, pad);\n    pad += a.length;\n  }\n  return res;\n}\n\n// Compares 2 u8a-s in kinda constant time\nexport function equalBytes(a: Uint8Array, b: Uint8Array): boolean {\n  if (a.length !== b.length) return false;\n  let diff = 0;\n  for (let i = 0; i < a.length; i++) diff |= a[i] ^ b[i];\n  return diff === 0;\n}\n\n// Global symbols in both browsers and Node.js since v11\n// See https://github.com/microsoft/TypeScript/issues/31535\ndeclare const TextEncoder: any;\n\n/**\n * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])\n */\nexport function utf8ToBytes(str: string): Uint8Array {\n  if (typeof str !== 'string') throw new Error('string expected');\n  return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809\n}\n\n// Is positive bigint\nconst isPosBig = (n: bigint) => typeof n === 'bigint' && _0n <= n;\n\nexport function inRange(n: bigint, min: bigint, max: bigint): boolean {\n  return isPosBig(n) && isPosBig(min) && isPosBig(max) && min <= n && n < max;\n}\n\n/**\n * Asserts min <= n < max. NOTE: It's < max and not <= max.\n * @example\n * aInRange('x', x, 1n, 256n); // would assume x is in (1n..255n)\n */\nexport function aInRange(title: string, n: bigint, min: bigint, max: bigint): void {\n  // Why min <= n < max and not a (min < n < max) OR b (min <= n <= max)?\n  // consider P=256n, min=0n, max=P\n  // - a for min=0 would require -1:          `inRange('x', x, -1n, P)`\n  // - b would commonly require subtraction:  `inRange('x', x, 0n, P - 1n)`\n  // - our way is the cleanest:               `inRange('x', x, 0n, P)\n  if (!inRange(n, min, max))\n    throw new Error('expected valid ' + title + ': ' + min + ' <= n < ' + max + ', got ' + n);\n}\n\n// Bit operations\n\n/**\n * Calculates amount of bits in a bigint.\n * Same as `n.toString(2).length`\n * TODO: merge with nLength in modular\n */\nexport function bitLen(n: bigint): number {\n  let len;\n  for (len = 0; n > _0n; n >>= _1n, len += 1);\n  return len;\n}\n\n/**\n * Gets single bit at position.\n * NOTE: first bit position is 0 (same as arrays)\n * Same as `!!+Array.from(n.toString(2)).reverse()[pos]`\n */\nexport function bitGet(n: bigint, pos: number): bigint {\n  return (n >> BigInt(pos)) & _1n;\n}\n\n/**\n * Sets single bit at position.\n */\nexport function bitSet(n: bigint, pos: number, value: boolean): bigint {\n  return n | ((value ? _1n : _0n) << BigInt(pos));\n}\n\n/**\n * Calculate mask for N bits. Not using ** operator with bigints because of old engines.\n * Same as BigInt(`0b${Array(i).fill('1').join('')}`)\n */\nexport const bitMask = (n: number): bigint => (_1n << BigInt(n)) - _1n;\n\n// DRBG\n\nconst u8n = (len: number) => new Uint8Array(len); // creates Uint8Array\nconst u8fr = (arr: ArrayLike<number>) => Uint8Array.from(arr); // another shortcut\ntype Pred<T> = (v: Uint8Array) => T | undefined;\n/**\n * Minimal HMAC-DRBG from NIST 800-90 for RFC6979 sigs.\n * @returns function that will call DRBG until 2nd arg returns something meaningful\n * @example\n *   const drbg = createHmacDRBG<Key>(32, 32, hmac);\n *   drbg(seed, bytesToKey); // bytesToKey must return Key or undefined\n */\nexport function createHmacDrbg<T>(\n  hashLen: number,\n  qByteLen: number,\n  hmacFn: (key: Uint8Array, ...messages: Uint8Array[]) => Uint8Array\n): (seed: Uint8Array, predicate: Pred<T>) => T {\n  if (typeof hashLen !== 'number' || hashLen < 2) throw new Error('hashLen must be a number');\n  if (typeof qByteLen !== 'number' || qByteLen < 2) throw new Error('qByteLen must be a number');\n  if (typeof hmacFn !== 'function') throw new Error('hmacFn must be a function');\n  // Step B, Step C: set hashLen to 8*ceil(hlen/8)\n  let v = u8n(hashLen); // Minimal non-full-spec HMAC-DRBG from NIST 800-90 for RFC6979 sigs.\n  let k = u8n(hashLen); // Steps B and C of RFC6979 3.2: set hashLen, in our case always same\n  let i = 0; // Iterations counter, will throw when over 1000\n  const reset = () => {\n    v.fill(1);\n    k.fill(0);\n    i = 0;\n  };\n  const h = (...b: Uint8Array[]) => hmacFn(k, v, ...b); // hmac(k)(v, ...values)\n  const reseed = (seed = u8n(0)) => {\n    // HMAC-DRBG reseed() function. Steps D-G\n    k = h(u8fr([0x00]), seed); // k = hmac(k || v || 0x00 || seed)\n    v = h(); // v = hmac(k || v)\n    if (seed.length === 0) return;\n    k = h(u8fr([0x01]), seed); // k = hmac(k || v || 0x01 || seed)\n    v = h(); // v = hmac(k || v)\n  };\n  const gen = () => {\n    // HMAC-DRBG generate() function\n    if (i++ >= 1000) throw new Error('drbg: tried 1000 values');\n    let len = 0;\n    const out: Uint8Array[] = [];\n    while (len < qByteLen) {\n      v = h();\n      const sl = v.slice();\n      out.push(sl);\n      len += v.length;\n    }\n    return concatBytes(...out);\n  };\n  const genUntil = (seed: Uint8Array, pred: Pred<T>): T => {\n    reset();\n    reseed(seed); // Steps D-G\n    let res: T | undefined = undefined; // Step H: grind until k is in [1..n-1]\n    while (!(res = pred(gen()))) reseed();\n    reset();\n    return res;\n  };\n  return genUntil;\n}\n\n// Validating curves and fields\n\nconst validatorFns = {\n  bigint: (val: any): boolean => typeof val === 'bigint',\n  function: (val: any): boolean => typeof val === 'function',\n  boolean: (val: any): boolean => typeof val === 'boolean',\n  string: (val: any): boolean => typeof val === 'string',\n  stringOrUint8Array: (val: any): boolean => typeof val === 'string' || isBytes(val),\n  isSafeInteger: (val: any): boolean => Number.isSafeInteger(val),\n  array: (val: any): boolean => Array.isArray(val),\n  field: (val: any, object: any): any => (object as any).Fp.isValid(val),\n  hash: (val: any): boolean => typeof val === 'function' && Number.isSafeInteger(val.outputLen),\n} as const;\ntype Validator = keyof typeof validatorFns;\ntype ValMap<T extends Record<string, any>> = { [K in keyof T]?: Validator };\n// type Record<K extends string | number | symbol, T> = { [P in K]: T; }\n\nexport function validateObject<T extends Record<string, any>>(\n  object: T,\n  validators: ValMap<T>,\n  optValidators: ValMap<T> = {}\n): T {\n  const checkField = (fieldName: keyof T, type: Validator, isOptional: boolean) => {\n    const checkVal = validatorFns[type];\n    if (typeof checkVal !== 'function') throw new Error('invalid validator function');\n\n    const val = object[fieldName as keyof typeof object];\n    if (isOptional && val === undefined) return;\n    if (!checkVal(val, object)) {\n      throw new Error(\n        'param ' + String(fieldName) + ' is invalid. Expected ' + type + ', got ' + val\n      );\n    }\n  };\n  for (const [fieldName, type] of Object.entries(validators)) checkField(fieldName, type!, false);\n  for (const [fieldName, type] of Object.entries(optValidators)) checkField(fieldName, type!, true);\n  return object;\n}\n// validate type tests\n// const o: { a: number; b: number; c: number } = { a: 1, b: 5, c: 6 };\n// const z0 = validateObject(o, { a: 'isSafeInteger' }, { c: 'bigint' }); // Ok!\n// // Should fail type-check\n// const z1 = validateObject(o, { a: 'tmp' }, { c: 'zz' });\n// const z2 = validateObject(o, { a: 'isSafeInteger' }, { c: 'zz' });\n// const z3 = validateObject(o, { test: 'boolean', z: 'bug' });\n// const z4 = validateObject(o, { a: 'boolean', z: 'bug' });\n\n/**\n * throws not implemented error\n */\nexport const notImplemented = (): never => {\n  throw new Error('not implemented');\n};\n\n/**\n * Memoizes (caches) computation result.\n * Uses WeakMap: the value is going auto-cleaned by GC after last reference is removed.\n */\nexport function memoized<T extends object, R, O extends any[]>(\n  fn: (arg: T, ...args: O) => R\n): (arg: T, ...args: O) => R {\n  const map = new WeakMap<T, R>();\n  return (arg: T, ...args: O): R => {\n    const val = map.get(arg);\n    if (val !== undefined) return val;\n    const computed = fn(arg, ...args);\n    map.set(arg, computed);\n    return computed;\n  };\n}\n","import { Token, Type } from './token.js'\nimport { assertEnoughData, decodeErrPrefix } from './common.js'\nimport * as uint from './0uint.js'\nimport { encodeBytes } from './2bytes.js'\nimport { toString, slice } from './byte-utils.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} prefix\n * @param {number} length\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction toToken (data, pos, prefix, length, options) {\n  const totLength = prefix + length\n  assertEnoughData(data, pos, totLength)\n  const tok = new Token(Type.string, toString(data, pos + prefix, pos + totLength), totLength)\n  if (options.retainStringBytes === true) {\n    tok.byteValue = slice(data, pos + prefix, pos + totLength)\n  }\n  return tok\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeStringCompact (data, pos, minor, options) {\n  return toToken(data, pos, 1, minor, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeString8 (data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options), options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeString16 (data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options), options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeString32 (data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options), options)\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeString64 (data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options)\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer string lengths not supported`)\n  }\n  return toToken(data, pos, 9, l, options)\n}\n\nexport const encodeString = encodeBytes\n","import * as API from '../api.js'\nimport * as CBOR from '@ipld/dag-cbor'\n\n/**\n * @type {API.MulticodecCode<typeof CBOR.code, typeof CBOR.name>}\n */\nexport const code = CBOR.code\n\nexport const name = CBOR.name\n\nexport const encode =\n  /** @type {<T>(model:T) => API.ByteView<T, typeof code>} */\n  (CBOR.encode)\n\nexport const decode =\n  /** @type {<T>(bytes:API.ByteView<T, typeof code>) => T} */\n  (CBOR.decode)\n","const symbol = Symbol.for('synapse-error')\n\nexport interface SynapseErrorOptions extends ErrorOptions {\n  cause?: Error\n  details?: string\n}\n\n/**\n * Check if a value is a SynapseError\n *\n */\nexport function isSynapseError(value: unknown): value is SynapseError {\n  return value instanceof Error && symbol in value\n}\n\nexport class SynapseError extends Error {\n  [symbol]: boolean = true\n\n  override name = 'SynapseError'\n  override cause?: Error\n  details?: string\n  shortMessage: string\n\n  constructor(message: string, options?: SynapseErrorOptions) {\n    const details =\n      options?.cause instanceof Error ? options.cause.message : options?.details ? options.details : undefined\n\n    const msg = [\n      message || 'An error occurred.',\n      ...(details ? [''] : []),\n      ...(details ? [`Details: ${details}`] : []),\n    ].join('\\n')\n    super(msg, options)\n\n    this.cause = options?.cause ?? undefined\n    this.details = details ?? undefined\n    this.shortMessage = message\n  }\n\n  static is(value: unknown): value is SynapseError {\n    return isSynapseError(value) && value.name === 'SynapseError'\n  }\n}\n","import { baseX } from './base.js'\n\nexport const base36 = baseX({\n  prefix: 'k',\n  name: 'base36',\n  alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'\n})\n\nexport const base36upper = baseX({\n  prefix: 'K',\n  name: 'base36upper',\n  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n})\n","/**\n * ChainRetriever - Queries on-chain data to find and retrieve pieces\n *\n * This retriever uses the Warm Storage service to find service providers\n * that have the requested piece, then attempts to download from them.\n */\n\nimport type { SPRegistryService } from '../sp-registry/index.ts'\nimport type { PieceCID, PieceRetriever, ProviderInfo } from '../types.ts'\nimport { createError } from '../utils/index.ts'\nimport type { WarmStorageService } from '../warm-storage/index.ts'\nimport { fetchPiecesFromProviders } from './utils.ts'\n\nexport class ChainRetriever implements PieceRetriever {\n  private readonly warmStorageService: WarmStorageService\n  private readonly childRetriever?: PieceRetriever\n  private readonly spRegistry: SPRegistryService\n\n  constructor(warmStorageService: WarmStorageService, spRegistry: SPRegistryService, childRetriever?: PieceRetriever) {\n    this.warmStorageService = warmStorageService\n    this.spRegistry = spRegistry\n    this.childRetriever = childRetriever\n  }\n\n  /**\n   * Find providers that can serve pieces for a client\n   * @param client - The client address\n   * @param providerAddress - Optional specific provider to use\n   * @returns List of provider info\n   */\n  private async findProviders(client: string, providerAddress?: string): Promise<ProviderInfo[]> {\n    if (providerAddress != null) {\n      // Direct provider case - skip data set lookup entirely\n      const provider = await this.spRegistry.getProviderByAddress(providerAddress)\n      if (provider == null) {\n        throw createError('ChainRetriever', 'findProviders', `Provider ${providerAddress} not found in registry`)\n      }\n      return [provider]\n    }\n\n    // Multiple provider case - need data sets to find providers\n\n    // Get client's data sets with details\n    const dataSets = await this.warmStorageService.getClientDataSetsWithDetails(client)\n\n    // Filter for live data sets with pieces\n    const validDataSets = dataSets.filter((ds) => ds.isLive && ds.currentPieceCount > 0)\n\n    if (validDataSets.length === 0) {\n      throw createError('ChainRetriever', 'findProviders', `No active data sets with data found for client ${client}`)\n    }\n\n    // Get unique provider IDs from data sets (much more reliable than using payee addresses)\n    const uniqueProviderIds = [...new Set(validDataSets.map((ds) => ds.providerId))]\n\n    // Batch fetch provider info for all unique provider IDs\n    const providerInfos = await this.spRegistry.getProviders(uniqueProviderIds)\n\n    // Filter out null values (providers not found in registry)\n    const validProviderInfos = providerInfos.filter((info): info is ProviderInfo => info != null)\n\n    if (validProviderInfos.length === 0) {\n      throw createError(\n        'ChainRetriever',\n        'findProviders',\n        'No valid providers found (all providers may have been removed from registry or are inactive)'\n      )\n    }\n\n    return validProviderInfos\n  }\n\n  async fetchPiece(\n    pieceCid: PieceCID,\n    client: string,\n    options?: {\n      providerAddress?: string\n      withCDN?: boolean\n      signal?: AbortSignal\n    }\n  ): Promise<Response> {\n    // Helper function to try child retriever or throw error\n    const tryChildOrThrow = async (reason: string): Promise<Response> => {\n      if (this.childRetriever !== undefined) {\n        return await this.childRetriever.fetchPiece(pieceCid, client, options)\n      }\n      throw createError('ChainRetriever', 'fetchPiece', `Failed to retrieve piece ${pieceCid.toString()}: ${reason}`)\n    }\n\n    // Find providers\n    let providersToTry: ProviderInfo[] = []\n    try {\n      providersToTry = await this.findProviders(client, options?.providerAddress)\n    } catch (error) {\n      // Provider discovery failed - this is a critical error\n      const message = error instanceof Error ? error.message : 'Provider discovery failed'\n      return await tryChildOrThrow(message)\n    }\n\n    // If no providers found, try child retriever\n    if (providersToTry.length === 0) {\n      return await tryChildOrThrow('No providers found and no additional retriever method was configured')\n    }\n\n    // Try to fetch from providers\n    try {\n      return await fetchPiecesFromProviders(providersToTry, pieceCid, 'ChainRetriever', options?.signal)\n    } catch {\n      // All provider attempts failed\n      return await tryChildOrThrow(\n        'All provider retrieval attempts failed and no additional retriever method was configured'\n      )\n    }\n  }\n}\n","/**\n * TelemetryService singleton manager used within Synapse SDK.\n * Sets up and provides a single global TelemetryService instance.\n * #initGlobalTelemetry is the entry point.\n * #getGlobalTelemetry is the expected access point within Synapse.\n * (Consumers outside of Synapse should use `synapse.telemetry`.)\n *\n * This class handles:\n * - Instantiating the TelemetryService instance.\n * - Hooking telemetry into `fetch` by wrapping it.\n * - Flushing/closing telemetry at shutdown or loss of browser focus.\n *\n * Notes:\n * - The underlying Sentry instance handles uncaught exceptions and unhandled promise rejections.\n *   No special setup is done here.\n *   See https://docs.sentry.io/platforms/javascript/troubleshooting/#third-party-promise-libraries\n * - Synapse-special error handling done in `src/utils/index.ts` is made \"telemetry aware\" by exporting `src/telemetry/utils.ts#createError()`,\n *   which wraps `src/utils/errors.ts`.\n *   `src/telemetry/utils.ts` accesses the global TelemetryService instance.\n * - A TelemetryService instance is managed as a singleton with static accessors\n *   rather than as an instance of the Synapse class,\n *   because there are cases where telemetry is needed but there is no Synapse instance available.\n *   `src/utils/errors.ts` is one such case.\n */\n\nimport { type TelemetryConfig, type TelemetryRuntimeContext, TelemetryService } from './service.ts'\nimport { isBrowser } from './utils.ts'\n\n// Global telemetry instance\nlet telemetryInstance: TelemetryService | null = null\n\n/**\n * @returns The global TelemetryService instance or null if not initialized\n */\nexport function getGlobalTelemetry(): TelemetryService | null {\n  return telemetryInstance\n}\n\n/**\n * Initialize the global TelemetryService instance if telemetry isn't disabled.\n * @param telemetryContext\n * @param telemetryConfig\n */\nexport async function initGlobalTelemetry(\n  telemetryConfig: TelemetryConfig,\n  telemetryContext: TelemetryRuntimeContext\n): Promise<void> {\n  if (!shouldEnableTelemetry(telemetryConfig, telemetryContext)) {\n    return\n  }\n\n  telemetryInstance = new TelemetryService()\n  await telemetryInstance.initSentry(telemetryConfig, telemetryContext)\n  wrapFetch()\n  setupShutdownHooks()\n}\n\n/**\n * Remove the global telemetry instance\n * This should handle all cleanup of telemetry resources.\n */\nexport function removeGlobalTelemetry(flush: boolean = true): void {\n  if (telemetryInstance == null) {\n    return\n  }\n  if (flush) {\n    void telemetryInstance?.sentry?.flush().catch(() => {\n      // Silently ignore telemetry flush errors\n    })\n  }\n  unwrapFetch()\n  telemetryInstance = null\n}\n\n/**\n * Determine if telemetry should be enabled based on configuration and environment settings.\n * Disablement takes precedence over enablement.\n * The ways to disable include setting any of the following:\n * - synapseConfig.telemetry.sentryInitOptions.enabled = false\n * - global.SYNAPSE_TELEMETRY_DISABLED = true\n * - process.env.SYNAPSE_TELEMETRY_DISABLED = true\n * We also disable if process.env.NODE_ENV == 'test', unless enablement was explicitly requested in config.\n * We only enable by default if not otherwise disabled above AND we're on the calibration network.\n * @param telemetryConfig - User-provided telemetry configuration\n * @param telemetryContext - Runtime context for telemetry, including network info.\n * @returns True if telemetry should be enabled\n */\nfunction shouldEnableTelemetry(telemetryConfig: TelemetryConfig, telemetryContext: TelemetryRuntimeContext): boolean {\n  // If explicitly disabled by user config, respect that\n  if (telemetryConfig?.sentryInitOptions?.enabled === false) {\n    return false\n  }\n\n  // If disabled by `SYNAPSE_TELEMETRY_DISABLED` environment/global variable, respect that\n  if (isTelemetryDisabledByEnv()) {\n    return false\n  }\n\n  // If in test environment, disable telemetry unless explicitly enabled by user config\n  if (telemetryConfig?.sentryInitOptions?.enabled === undefined) {\n    // we use playwright-test, which sets globalThis.PW_TEST in browser, and NODE_ENV in node\n    if (globalThis.process?.env?.NODE_ENV === 'test' || (globalThis as any).PW_TEST != null) {\n      return false\n    }\n  }\n\n  // If explicitly enabled by user config, respect that\n  if (telemetryConfig?.sentryInitOptions?.enabled === true) {\n    return true\n  }\n\n  // At this point we haven't been given a clear signal to enable or disable.\n  // In this case, we enable telemetry if we're on the calibration network.\n  return telemetryContext.filecoinNetwork === 'calibration'\n}\n\n/**\n * Check if telemetry is explicitly disabled via global variable or environment\n * Uses globalThis for consistent cross-platform access\n */\nfunction isTelemetryDisabledByEnv(): boolean {\n  // Check for global disable flag (universal)\n  if (typeof globalThis !== 'undefined') {\n    // Check for explicit disable flag\n    if ((globalThis as any).SYNAPSE_TELEMETRY_DISABLED === true) {\n      return true\n    }\n\n    // Check environment variable in Node.js\n    if ('process' in globalThis) {\n      const process = (globalThis as any).process\n      if (process?.env) {\n        const disabled = process.env.SYNAPSE_TELEMETRY_DISABLED\n        if (typeof disabled === 'string' && disabled.trim().toLowerCase() === 'true') {\n          return true\n        }\n      }\n    }\n  }\n\n  return false\n}\n\nfunction setupShutdownHooks(opts: { timeoutMs?: number } = {}) {\n  const g = globalThis as any\n  const timeout = opts.timeoutMs ?? 2000\n  let shuttingDown = false\n\n  if (isBrowser) {\n    /**\n     * We `flush` in the browser instead of `close` because users might come back to this page later, and we don't want to add\n     * \"pageShow\" event handlers and re-instantiation logic.\n     */\n    const flush = () => {\n      // Don't block; Sentry will use sendBeacon/fetch keepalive under the hood.\n      void telemetryInstance?.sentry?.flush(timeout).catch(() => {\n        // Silently ignore telemetry flush errors\n      })\n    }\n\n    // Most reliable on modern browsers & iOS Safari:\n    g.window.addEventListener('pagehide', flush, { capture: true })\n    g.document.addEventListener(\n      'visibilitychange',\n      () => {\n        if (g.document.visibilityState === 'hidden') flush()\n      },\n      { capture: true }\n    )\n\n    // Fallbacks for older browsers:\n    g.window.addEventListener('beforeunload', flush, { capture: true })\n    g.window.addEventListener('unload', flush, { capture: true })\n  } else {\n    // Node runtime\n    /**\n     * For Node.js, we only handle explicit termination signals.\n     * We `close` in Node.js instead of `flush` because the process is actually exiting and we don't need to worry about handling the \"users coming back\" situation like we do in the browser.\n     */\n    const handleSignal = () => {\n      if (shuttingDown) return\n      shuttingDown = true\n\n      // Close the sentry to release resources\n      void telemetryInstance?.sentry\n        ?.close(timeout)\n        .finally(() => {\n          shuttingDown = false\n          removeGlobalTelemetry(false) // Remove the global telemetry instance to prevent further telemetry\n        })\n        .catch(() => {\n          // silently ignore error\n        })\n    }\n\n    process.on('exit', handleSignal)\n    process.on('beforeExit', handleSignal)\n    process.on('SIGINT', handleSignal)\n    process.on('SIGTERM', handleSignal)\n    process.on('SIGQUIT', handleSignal)\n  }\n}\n\nconst originalFetch = (globalThis as any).fetch as typeof fetch\nlet isFetchWrapped = false\n/**\n * Patches `globalThis.fetch` to add manual telemetry tracking for all HTTP requests.\n * This wrapper is safe to call multiple times as it will only wrap once.\n *\n * Implementation: This function explicitly creates a [Sentry span](https://docs.sentry.io/platforms/javascript/tracing/span-metrics/)\n * for every `fetch` call by wrapping each request in `sentry.startSpan()`. The span captures HTTP metadata\n * including method, URL, status code, and content length.\n *\n * Behavior:\n * - If telemetry is disabled or not initialized, the wrapper immediately delegates to the original `fetch`\n * - If telemetry is enabled, creates a new span with op=\"http.client\" and name=\"${METHOD} ${URL}\"\n * - Captures request attributes (URL, method, hostname, port) before the fetch\n * - Captures response attributes (status code, content length) after the fetch\n * - Returns the original fetch response unchanged\n *\n * Why this is needed: We have explicitly disabled Sentry's automatic fetch instrumentation\n * (by limiting enabled integrations in service.ts). This manual wrapper gives us full control\n * over which HTTP requests are tracked and what attributes are captured for each span.\n *\n * See: https://docs.sentry.io/platforms/javascript/tracing/instrumentation/requests-module/#wrap-http-requests-in-a-span\n * See: https://docs.sentry.io/platforms/javascript/guides/node/tracing/instrumentation/requests-module/#wrap-http-requests-in-a-span\n */\nfunction wrapFetch(): void {\n  if (isFetchWrapped) {\n    return // Already wrapped\n  }\n\n  isFetchWrapped = true\n\n  ;(globalThis as any).fetch = async function wrappedFetch(\n    input: string | URL | Request,\n    init?: RequestInit\n  ): Promise<Response> {\n    // Short circuit to the original fetch if telemetry is disabled\n    const sentry = getGlobalTelemetry()?.sentry\n    if (!sentry) {\n      return originalFetch(input, init)\n    }\n    const url = input instanceof Request ? new URL(input.url) : new URL(input.toString())\n    const method = input instanceof Request ? input.method : init?.method || 'GET'\n    return await sentry.startSpan({ op: 'http.client', name: `${method} ${url}` }, async (span) => {\n      span.setAttributes({\n        'url.path': url.pathname,\n        'url.full': url.toString(),\n        'server.address': url.hostname,\n        'http.request.method': method,\n        'server.port': url.port || undefined,\n        'location.origin': isBrowser ? (globalThis as any).location?.origin : undefined,\n      })\n      const response = await originalFetch(input, init)\n      span.setAttributes({\n        'http.response.status_code': response.status,\n        'http.response_content_length': response.headers.get('content-length')\n          ? Number(response.headers.get('content-length'))\n          : undefined,\n      })\n      return response\n    })\n  }\n}\n\n/**\n * Unwrap what was done in `wrapFetch()`.\n * Useful for testing or when telemetry should be disabled.\n */\nfunction unwrapFetch(): void {\n  if (!isFetchWrapped) {\n    return\n  }\n\n  ;(globalThis as any).fetch = originalFetch\n  isFetchWrapped = false\n}\n","// TODO: shift some of the bytes logic to bytes-utils so we can use Buffer\n// where possible\n\nimport { Token, Type } from './token.js'\nimport { decodeErrPrefix } from './common.js'\nimport { encodeUint } from './0uint.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n * @typedef {import('../interface').EncodeOptions} EncodeOptions\n */\n\nconst MINOR_FALSE = 20\nconst MINOR_TRUE = 21\nconst MINOR_NULL = 22\nconst MINOR_UNDEFINED = 23\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUndefined (_data, _pos, _minor, options) {\n  if (options.allowUndefined === false) {\n    throw new Error(`${decodeErrPrefix} undefined values are not supported`)\n  } else if (options.coerceUndefinedToNull === true) {\n    return new Token(Type.null, null, 1)\n  }\n  return new Token(Type.undefined, undefined, 1)\n}\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBreak (_data, _pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`)\n  }\n  return new Token(Type.break, undefined, 1)\n}\n\n/**\n * @param {number} value\n * @param {number} bytes\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction createToken (value, bytes, options) {\n  if (options) {\n    if (options.allowNaN === false && Number.isNaN(value)) {\n      throw new Error(`${decodeErrPrefix} NaN values are not supported`)\n    }\n    if (options.allowInfinity === false && (value === Infinity || value === -Infinity)) {\n      throw new Error(`${decodeErrPrefix} Infinity values are not supported`)\n    }\n  }\n  return new Token(Type.float, value, bytes)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeFloat16 (data, pos, _minor, options) {\n  return createToken(readFloat16(data, pos + 1), 3, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeFloat32 (data, pos, _minor, options) {\n  return createToken(readFloat32(data, pos + 1), 5, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeFloat64 (data, pos, _minor, options) {\n  return createToken(readFloat64(data, pos + 1), 9, options)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n * @param {EncodeOptions} options\n */\nexport function encodeFloat (buf, token, options) {\n  const float = token.value\n\n  if (float === false) {\n    buf.push([Type.float.majorEncoded | MINOR_FALSE])\n  } else if (float === true) {\n    buf.push([Type.float.majorEncoded | MINOR_TRUE])\n  } else if (float === null) {\n    buf.push([Type.float.majorEncoded | MINOR_NULL])\n  } else if (float === undefined) {\n    buf.push([Type.float.majorEncoded | MINOR_UNDEFINED])\n  } else {\n    let decoded\n    let success = false\n    if (!options || options.float64 !== true) {\n      encodeFloat16(float)\n      decoded = readFloat16(ui8a, 1)\n      if (float === decoded || Number.isNaN(float)) {\n        ui8a[0] = 0xf9\n        buf.push(ui8a.slice(0, 3))\n        success = true\n      } else {\n        encodeFloat32(float)\n        decoded = readFloat32(ui8a, 1)\n        if (float === decoded) {\n          ui8a[0] = 0xfa\n          buf.push(ui8a.slice(0, 5))\n          success = true\n        }\n      }\n    }\n    if (!success) {\n      encodeFloat64(float)\n      decoded = readFloat64(ui8a, 1)\n      ui8a[0] = 0xfb\n      buf.push(ui8a.slice(0, 9))\n    }\n  }\n}\n\n/**\n * @param {Token} token\n * @param {EncodeOptions} options\n * @returns {number}\n */\nencodeFloat.encodedSize = function encodedSize (token, options) {\n  const float = token.value\n\n  if (float === false || float === true || float === null || float === undefined) {\n    return 1\n  }\n\n  if (!options || options.float64 !== true) {\n    encodeFloat16(float)\n    let decoded = readFloat16(ui8a, 1)\n    if (float === decoded || Number.isNaN(float)) {\n      return 3\n    }\n    encodeFloat32(float)\n    decoded = readFloat32(ui8a, 1)\n    if (float === decoded) {\n      return 5\n    }\n  }\n  return 9\n}\n\nconst buffer = new ArrayBuffer(9)\nconst dataView = new DataView(buffer, 1)\nconst ui8a = new Uint8Array(buffer, 0)\n\n/**\n * @param {number} inp\n */\nfunction encodeFloat16 (inp) {\n  if (inp === Infinity) {\n    dataView.setUint16(0, 0x7c00, false)\n  } else if (inp === -Infinity) {\n    dataView.setUint16(0, 0xfc00, false)\n  } else if (Number.isNaN(inp)) {\n    dataView.setUint16(0, 0x7e00, false)\n  } else {\n    dataView.setFloat32(0, inp)\n    const valu32 = dataView.getUint32(0)\n    const exponent = (valu32 & 0x7f800000) >> 23\n    const mantissa = valu32 & 0x7fffff\n\n    /* c8 ignore next 6 */\n    if (exponent === 0xff) {\n      // too big, Infinity, but this should be hard (impossible?) to trigger\n      dataView.setUint16(0, 0x7c00, false)\n    } else if (exponent === 0x00) {\n      // 0.0, -0.0 and subnormals, shouldn't be possible to get here because 0.0 should be counted as an int\n      dataView.setUint16(0, ((inp & 0x80000000) >> 16) | (mantissa >> 13), false)\n    } else { // standard numbers\n      // chunks of logic here borrowed from https://github.com/PJK/libcbor/blob/c78f437182533e3efa8d963ff4b945bb635c2284/src/cbor/encoding.c#L127\n      const logicalExponent = exponent - 127\n      // Now we know that 2^exponent <= 0 logically\n      /* c8 ignore next 6 */\n      if (logicalExponent < -24) {\n        /* No unambiguous representation exists, this float is not a half float\n          and is too small to be represented using a half, round off to zero.\n          Consistent with the reference implementation. */\n        // should be difficult (impossible?) to get here in JS\n        dataView.setUint16(0, 0)\n      } else if (logicalExponent < -14) {\n        /* Offset the remaining decimal places by shifting the significand, the\n          value is lost. This is an implementation decision that works around the\n          absence of standard half-float in the language. */\n        dataView.setUint16(0, ((valu32 & 0x80000000) >> 16) | /* sign bit */ (1 << (24 + logicalExponent)), false)\n      } else {\n        dataView.setUint16(0, ((valu32 & 0x80000000) >> 16) | ((logicalExponent + 15) << 10) | (mantissa >> 13), false)\n      }\n    }\n  }\n}\n\n/**\n * @param {Uint8Array} ui8a\n * @param {number} pos\n * @returns {number}\n */\nfunction readFloat16 (ui8a, pos) {\n  if (ui8a.length - pos < 2) {\n    throw new Error(`${decodeErrPrefix} not enough data for float16`)\n  }\n\n  const half = (ui8a[pos] << 8) + ui8a[pos + 1]\n  if (half === 0x7c00) {\n    return Infinity\n  }\n  if (half === 0xfc00) {\n    return -Infinity\n  }\n  if (half === 0x7e00) {\n    return NaN\n  }\n  const exp = (half >> 10) & 0x1f\n  const mant = half & 0x3ff\n  let val\n  if (exp === 0) {\n    val = mant * (2 ** -24)\n  } else if (exp !== 31) {\n    val = (mant + 1024) * (2 ** (exp - 25))\n  /* c8 ignore next 4 */\n  } else {\n    // may not be possible to get here\n    val = mant === 0 ? Infinity : NaN\n  }\n  return (half & 0x8000) ? -val : val\n}\n\n/**\n * @param {number} inp\n */\nfunction encodeFloat32 (inp) {\n  dataView.setFloat32(0, inp, false)\n}\n\n/**\n * @param {Uint8Array} ui8a\n * @param {number} pos\n * @returns {number}\n */\nfunction readFloat32 (ui8a, pos) {\n  if (ui8a.length - pos < 4) {\n    throw new Error(`${decodeErrPrefix} not enough data for float32`)\n  }\n  const offset = (ui8a.byteOffset || 0) + pos\n  return new DataView(ui8a.buffer, offset, 4).getFloat32(0, false)\n}\n\n/**\n * @param {number} inp\n */\nfunction encodeFloat64 (inp) {\n  dataView.setFloat64(0, inp, false)\n}\n\n/**\n * @param {Uint8Array} ui8a\n * @param {number} pos\n * @returns {number}\n */\nfunction readFloat64 (ui8a, pos) {\n  if (ui8a.length - pos < 8) {\n    throw new Error(`${decodeErrPrefix} not enough data for float64`)\n  }\n  const offset = (ui8a.byteOffset || 0) + pos\n  return new DataView(ui8a.buffer, offset, 8).getFloat64(0, false)\n}\n\n/**\n * @param {Token} _tok1\n * @param {Token} _tok2\n * @returns {number}\n */\nencodeFloat.compareTokens = encodeUint.compareTokens\n/*\nencodeFloat.compareTokens = function compareTokens (_tok1, _tok2) {\n  return _tok1\n  throw new Error(`${encodeErrPrefix} cannot use floats as map keys`)\n}\n*/\n","import * as API from '../api.js'\nimport * as SHA256 from 'sync-multihash-sha2/sha256'\nexport * from 'sync-multihash-sha2/sha256'\n\n/**\n * @type {API.MulticodecCode<typeof SHA256.code, typeof SHA256.name>}\n */\nexport const code = SHA256.code\n","import { rfc4648 } from './base.js'\n\nexport const base32 = rfc4648({\n  prefix: 'b',\n  name: 'base32',\n  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',\n  bitsPerChar: 5\n})\n\nexport const base32upper = rfc4648({\n  prefix: 'B',\n  name: 'base32upper',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',\n  bitsPerChar: 5\n})\n\nexport const base32pad = rfc4648({\n  prefix: 'c',\n  name: 'base32pad',\n  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',\n  bitsPerChar: 5\n})\n\nexport const base32padupper = rfc4648({\n  prefix: 'C',\n  name: 'base32padupper',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',\n  bitsPerChar: 5\n})\n\nexport const base32hex = rfc4648({\n  prefix: 'v',\n  name: 'base32hex',\n  alphabet: '0123456789abcdefghijklmnopqrstuv',\n  bitsPerChar: 5\n})\n\nexport const base32hexupper = rfc4648({\n  prefix: 'V',\n  name: 'base32hexupper',\n  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',\n  bitsPerChar: 5\n})\n\nexport const base32hexpad = rfc4648({\n  prefix: 't',\n  name: 'base32hexpad',\n  alphabet: '0123456789abcdefghijklmnopqrstuv=',\n  bitsPerChar: 5\n})\n\nexport const base32hexpadupper = rfc4648({\n  prefix: 'T',\n  name: 'base32hexpadupper',\n  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',\n  bitsPerChar: 5\n})\n\nexport const base32z = rfc4648({\n  prefix: 'h',\n  name: 'base32z',\n  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',\n  bitsPerChar: 5\n})\n","import { equalBytes } from '@noble/curves/abstract/utils'\nimport * as Bytes from './Bytes.js'\nimport * as Errors from './Errors.js'\nimport * as internal_bytes from './internal/bytes.js'\nimport * as internal from './internal/hex.js'\nimport * as Json from './Json.js'\n\nconst encoder = /*#__PURE__*/ new TextEncoder()\n\nconst hexes = /*#__PURE__*/ Array.from({ length: 256 }, (_v, i) =>\n  i.toString(16).padStart(2, '0'),\n)\n\n/** Root type for a Hex string. */\nexport type Hex = `0x${string}`\n\n/**\n * Asserts if the given value is {@link ox#Hex.Hex}.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.assert('abc')\n * // @error: InvalidHexValueTypeError:\n * // @error: Value `\"abc\"` of type `string` is an invalid hex type.\n * // @error: Hex types must be represented as `\"0x\\${string}\"`.\n * ```\n *\n * @param value - The value to assert.\n * @param options - Options.\n */\nexport function assert(\n  value: unknown,\n  options: assert.Options = {},\n): asserts value is Hex {\n  const { strict = false } = options\n  if (!value) throw new InvalidHexTypeError(value)\n  if (typeof value !== 'string') throw new InvalidHexTypeError(value)\n  if (strict) {\n    if (!/^0x[0-9a-fA-F]*$/.test(value)) throw new InvalidHexValueError(value)\n  }\n  if (!value.startsWith('0x')) throw new InvalidHexValueError(value)\n}\n\nexport declare namespace assert {\n  type Options = {\n    /** Checks if the {@link ox#Hex.Hex} value contains invalid hexadecimal characters. @default false */\n    strict?: boolean | undefined\n  }\n\n  type ErrorType =\n    | InvalidHexTypeError\n    | InvalidHexValueError\n    | Errors.GlobalErrorType\n}\n\n/**\n * Concatenates two or more {@link ox#Hex.Hex}.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.concat('0x123', '0x456')\n * // @log: '0x123456'\n * ```\n *\n * @param values - The {@link ox#Hex.Hex} values to concatenate.\n * @returns The concatenated {@link ox#Hex.Hex} value.\n */\nexport function concat(...values: readonly Hex[]): Hex {\n  return `0x${(values as Hex[]).reduce((acc, x) => acc + x.replace('0x', ''), '')}`\n}\n\nexport declare namespace concat {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Instantiates a {@link ox#Hex.Hex} value from a hex string or {@link ox#Bytes.Bytes} value.\n *\n * :::tip\n *\n * To instantiate from a **Boolean**, **String**, or **Number**, use one of the following:\n *\n * - `Hex.fromBoolean`\n *\n * - `Hex.fromString`\n *\n * - `Hex.fromNumber`\n *\n * :::\n *\n * @example\n * ```ts twoslash\n * import { Bytes, Hex } from 'ox'\n *\n * Hex.from('0x48656c6c6f20576f726c6421')\n * // @log: '0x48656c6c6f20576f726c6421'\n *\n * Hex.from(Bytes.from([72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33]))\n * // @log: '0x48656c6c6f20576f726c6421'\n * ```\n *\n * @param value - The {@link ox#Bytes.Bytes} value to encode.\n * @returns The encoded {@link ox#Hex.Hex} value.\n */\nexport function from(value: Hex | Bytes.Bytes | readonly number[]): Hex {\n  if (value instanceof Uint8Array) return fromBytes(value)\n  if (Array.isArray(value)) return fromBytes(new Uint8Array(value))\n  return value as never\n}\n\nexport declare namespace from {\n  type Options = {\n    /** The size (in bytes) of the output hex value. */\n    size?: number | undefined\n  }\n\n  type ErrorType = fromBytes.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Encodes a boolean into a {@link ox#Hex.Hex} value.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.fromBoolean(true)\n * // @log: '0x1'\n *\n * Hex.fromBoolean(false)\n * // @log: '0x0'\n *\n * Hex.fromBoolean(true, { size: 32 })\n * // @log: '0x0000000000000000000000000000000000000000000000000000000000000001'\n * ```\n *\n * @param value - The boolean value to encode.\n * @param options - Options.\n * @returns The encoded {@link ox#Hex.Hex} value.\n */\nexport function fromBoolean(\n  value: boolean,\n  options: fromBoolean.Options = {},\n): Hex {\n  const hex: Hex = `0x${Number(value)}`\n  if (typeof options.size === 'number') {\n    internal.assertSize(hex, options.size)\n    return padLeft(hex, options.size)\n  }\n  return hex\n}\n\nexport declare namespace fromBoolean {\n  type Options = {\n    /** The size (in bytes) of the output hex value. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | internal.assertSize.ErrorType\n    | padLeft.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Encodes a {@link ox#Bytes.Bytes} value into a {@link ox#Hex.Hex} value.\n *\n * @example\n * ```ts twoslash\n * import { Bytes, Hex } from 'ox'\n *\n * Hex.fromBytes(Bytes.from([72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33]))\n * // @log: '0x48656c6c6f20576f726c6421'\n * ```\n *\n * @param value - The {@link ox#Bytes.Bytes} value to encode.\n * @param options - Options.\n * @returns The encoded {@link ox#Hex.Hex} value.\n */\nexport function fromBytes(\n  value: Bytes.Bytes,\n  options: fromBytes.Options = {},\n): Hex {\n  let string = ''\n  for (let i = 0; i < value.length; i++) string += hexes[value[i]!]\n  const hex = `0x${string}` as const\n\n  if (typeof options.size === 'number') {\n    internal.assertSize(hex, options.size)\n    return padRight(hex, options.size)\n  }\n  return hex\n}\n\nexport declare namespace fromBytes {\n  type Options = {\n    /** The size (in bytes) of the output hex value. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | internal.assertSize.ErrorType\n    | padRight.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Encodes a number or bigint into a {@link ox#Hex.Hex} value.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.fromNumber(420)\n * // @log: '0x1a4'\n *\n * Hex.fromNumber(420, { size: 32 })\n * // @log: '0x00000000000000000000000000000000000000000000000000000000000001a4'\n * ```\n *\n * @param value - The number or bigint value to encode.\n * @param options - Options.\n * @returns The encoded {@link ox#Hex.Hex} value.\n */\nexport function fromNumber(\n  value: number | bigint,\n  options: fromNumber.Options = {},\n): Hex {\n  const { signed, size } = options\n\n  const value_ = BigInt(value)\n\n  let maxValue: bigint | number | undefined\n  if (size) {\n    if (signed) maxValue = (1n << (BigInt(size) * 8n - 1n)) - 1n\n    else maxValue = 2n ** (BigInt(size) * 8n) - 1n\n  } else if (typeof value === 'number') {\n    maxValue = BigInt(Number.MAX_SAFE_INTEGER)\n  }\n\n  const minValue = typeof maxValue === 'bigint' && signed ? -maxValue - 1n : 0\n\n  if ((maxValue && value_ > maxValue) || value_ < minValue) {\n    const suffix = typeof value === 'bigint' ? 'n' : ''\n    throw new IntegerOutOfRangeError({\n      max: maxValue ? `${maxValue}${suffix}` : undefined,\n      min: `${minValue}${suffix}`,\n      signed,\n      size,\n      value: `${value}${suffix}`,\n    })\n  }\n\n  const stringValue = (\n    signed && value_ < 0 ? BigInt.asUintN(size * 8, BigInt(value_)) : value_\n  ).toString(16)\n\n  const hex = `0x${stringValue}` as Hex\n  if (size) return padLeft(hex, size) as Hex\n  return hex\n}\n\nexport declare namespace fromNumber {\n  type Options =\n    | {\n        /** Whether or not the number of a signed representation. */\n        signed?: boolean | undefined\n        /** The size (in bytes) of the output hex value. */\n        size: number\n      }\n    | {\n        signed?: undefined\n        /** The size (in bytes) of the output hex value. */\n        size?: number | undefined\n      }\n\n  type ErrorType =\n    | IntegerOutOfRangeError\n    | padLeft.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Encodes a string into a {@link ox#Hex.Hex} value.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n * Hex.fromString('Hello World!')\n * // '0x48656c6c6f20576f726c6421'\n *\n * Hex.fromString('Hello World!', { size: 32 })\n * // '0x48656c6c6f20576f726c64210000000000000000000000000000000000000000'\n * ```\n *\n * @param value - The string value to encode.\n * @param options - Options.\n * @returns The encoded {@link ox#Hex.Hex} value.\n */\nexport function fromString(\n  value: string,\n  options: fromString.Options = {},\n): Hex {\n  return fromBytes(encoder.encode(value), options)\n}\n\nexport declare namespace fromString {\n  type Options = {\n    /** The size (in bytes) of the output hex value. */\n    size?: number | undefined\n  }\n\n  type ErrorType = fromBytes.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Checks if two {@link ox#Hex.Hex} values are equal.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.isEqual('0xdeadbeef', '0xdeadbeef')\n * // @log: true\n *\n * Hex.isEqual('0xda', '0xba')\n * // @log: false\n * ```\n *\n * @param hexA - The first {@link ox#Hex.Hex} value.\n * @param hexB - The second {@link ox#Hex.Hex} value.\n * @returns `true` if the two {@link ox#Hex.Hex} values are equal, `false` otherwise.\n */\nexport function isEqual(hexA: Hex, hexB: Hex) {\n  return equalBytes(Bytes.fromHex(hexA), Bytes.fromHex(hexB))\n}\n\nexport declare namespace isEqual {\n  type ErrorType = Bytes.fromHex.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Pads a {@link ox#Hex.Hex} value to the left with zero bytes until it reaches the given `size` (default: 32 bytes).\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.padLeft('0x1234', 4)\n * // @log: '0x00001234'\n * ```\n *\n * @param value - The {@link ox#Hex.Hex} value to pad.\n * @param size - The size (in bytes) of the output hex value.\n * @returns The padded {@link ox#Hex.Hex} value.\n */\nexport function padLeft(\n  value: Hex,\n  size?: number | undefined,\n): padLeft.ReturnType {\n  return internal.pad(value, { dir: 'left', size })\n}\n\nexport declare namespace padLeft {\n  type ReturnType = Hex\n  type ErrorType = internal.pad.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Pads a {@link ox#Hex.Hex} value to the right with zero bytes until it reaches the given `size` (default: 32 bytes).\n *\n * @example\n * ```ts\n * import { Hex } from 'ox'\n *\n * Hex.padRight('0x1234', 4)\n * // @log: '0x12340000'\n * ```\n *\n * @param value - The {@link ox#Hex.Hex} value to pad.\n * @param size - The size (in bytes) of the output hex value.\n * @returns The padded {@link ox#Hex.Hex} value.\n */\nexport function padRight(\n  value: Hex,\n  size?: number | undefined,\n): padRight.ReturnType {\n  return internal.pad(value, { dir: 'right', size })\n}\n\nexport declare namespace padRight {\n  type ReturnType = Hex\n  type ErrorType = internal.pad.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Generates a random {@link ox#Hex.Hex} value of the specified length.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * const hex = Hex.random(32)\n * // @log: '0x...'\n * ```\n *\n * @returns Random {@link ox#Hex.Hex} value.\n */\nexport function random(length: number): Hex {\n  return fromBytes(Bytes.random(length))\n}\n\nexport declare namespace random {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Returns a section of a {@link ox#Bytes.Bytes} value given a start/end bytes offset.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.slice('0x0123456789', 1, 4)\n * // @log: '0x234567'\n * ```\n *\n * @param value - The {@link ox#Hex.Hex} value to slice.\n * @param start - The start offset (in bytes).\n * @param end - The end offset (in bytes).\n * @param options - Options.\n * @returns The sliced {@link ox#Hex.Hex} value.\n */\nexport function slice(\n  value: Hex,\n  start?: number | undefined,\n  end?: number | undefined,\n  options: slice.Options = {},\n): Hex {\n  const { strict } = options\n  internal.assertStartOffset(value, start)\n  const value_ = `0x${value\n    .replace('0x', '')\n    .slice((start ?? 0) * 2, (end ?? value.length) * 2)}` as const\n  if (strict) internal.assertEndOffset(value_, start, end)\n  return value_\n}\n\nexport declare namespace slice {\n  type Options = {\n    /** Asserts that the sliced value is the same size as the given start/end offsets. */\n    strict?: boolean | undefined\n  }\n\n  type ErrorType =\n    | internal.assertStartOffset.ErrorType\n    | internal.assertEndOffset.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Retrieves the size of a {@link ox#Hex.Hex} value (in bytes).\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.size('0xdeadbeef')\n * // @log: 4\n * ```\n *\n * @param value - The {@link ox#Hex.Hex} value to get the size of.\n * @returns The size of the {@link ox#Hex.Hex} value (in bytes).\n */\nexport function size(value: Hex): number {\n  return Math.ceil((value.length - 2) / 2)\n}\n\nexport declare namespace size {\n  export type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Trims leading zeros from a {@link ox#Hex.Hex} value.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.trimLeft('0x00000000deadbeef')\n * // @log: '0xdeadbeef'\n * ```\n *\n * @param value - The {@link ox#Hex.Hex} value to trim.\n * @returns The trimmed {@link ox#Hex.Hex} value.\n */\nexport function trimLeft(value: Hex): trimLeft.ReturnType {\n  return internal.trim(value, { dir: 'left' })\n}\n\nexport declare namespace trimLeft {\n  type ReturnType = Hex\n\n  type ErrorType = internal.trim.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Trims trailing zeros from a {@link ox#Hex.Hex} value.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.trimRight('0xdeadbeef00000000')\n * // @log: '0xdeadbeef'\n * ```\n *\n * @param value - The {@link ox#Hex.Hex} value to trim.\n * @returns The trimmed {@link ox#Hex.Hex} value.\n */\nexport function trimRight(value: Hex): trimRight.ReturnType {\n  return internal.trim(value, { dir: 'right' })\n}\n\nexport declare namespace trimRight {\n  type ReturnType = Hex\n\n  type ErrorType = internal.trim.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Decodes a {@link ox#Hex.Hex} value into a BigInt.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.toBigInt('0x1a4')\n * // @log: 420n\n *\n * Hex.toBigInt('0x00000000000000000000000000000000000000000000000000000000000001a4', { size: 32 })\n * // @log: 420n\n * ```\n *\n * @param hex - The {@link ox#Hex.Hex} value to decode.\n * @param options - Options.\n * @returns The decoded BigInt.\n */\nexport function toBigInt(hex: Hex, options: toBigInt.Options = {}): bigint {\n  const { signed } = options\n\n  if (options.size) internal.assertSize(hex, options.size)\n\n  const value = BigInt(hex)\n  if (!signed) return value\n\n  const size = (hex.length - 2) / 2\n\n  const max_unsigned = (1n << (BigInt(size) * 8n)) - 1n\n  const max_signed = max_unsigned >> 1n\n\n  if (value <= max_signed) return value\n  return value - max_unsigned - 1n\n}\n\nexport declare namespace toBigInt {\n  type Options = {\n    /** Whether or not the number of a signed representation. */\n    signed?: boolean | undefined\n    /** Size (in bytes) of the hex value. */\n    size?: number | undefined\n  }\n\n  type ErrorType = internal.assertSize.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Decodes a {@link ox#Hex.Hex} value into a boolean.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.toBoolean('0x01')\n * // @log: true\n *\n * Hex.toBoolean('0x0000000000000000000000000000000000000000000000000000000000000001', { size: 32 })\n * // @log: true\n * ```\n *\n * @param hex - The {@link ox#Hex.Hex} value to decode.\n * @param options - Options.\n * @returns The decoded boolean.\n */\nexport function toBoolean(hex: Hex, options: toBoolean.Options = {}): boolean {\n  if (options.size) internal.assertSize(hex, options.size)\n  const hex_ = trimLeft(hex)\n  if (hex_ === '0x') return false\n  if (hex_ === '0x1') return true\n  throw new InvalidHexBooleanError(hex)\n}\n\nexport declare namespace toBoolean {\n  type Options = {\n    /** Size (in bytes) of the hex value. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | internal.assertSize.ErrorType\n    | trimLeft.ErrorType\n    | InvalidHexBooleanError\n    | Errors.GlobalErrorType\n}\n\n/**\n * Decodes a {@link ox#Hex.Hex} value into a {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * const data = Hex.toBytes('0x48656c6c6f20776f726c6421')\n * // @log: Uint8Array([72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33])\n * ```\n *\n * @param hex - The {@link ox#Hex.Hex} value to decode.\n * @param options - Options.\n * @returns The decoded {@link ox#Bytes.Bytes}.\n */\nexport function toBytes(hex: Hex, options: toBytes.Options = {}): Bytes.Bytes {\n  return Bytes.fromHex(hex, options)\n}\n\nexport declare namespace toBytes {\n  type Options = {\n    /** Size (in bytes) of the hex value. */\n    size?: number | undefined\n  }\n\n  type ErrorType = Bytes.fromHex.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Decodes a {@link ox#Hex.Hex} value into a number.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.toNumber('0x1a4')\n * // @log: 420\n *\n * Hex.toNumber('0x00000000000000000000000000000000000000000000000000000000000001a4', { size: 32 })\n * // @log: 420\n * ```\n *\n * @param hex - The {@link ox#Hex.Hex} value to decode.\n * @param options - Options.\n * @returns The decoded number.\n */\nexport function toNumber(hex: Hex, options: toNumber.Options = {}): number {\n  const { signed, size } = options\n  if (!signed && !size) return Number(hex)\n  return Number(toBigInt(hex, options))\n}\n\nexport declare namespace toNumber {\n  type Options = toBigInt.Options\n\n  type ErrorType = toBigInt.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Decodes a {@link ox#Hex.Hex} value into a string.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.toString('0x48656c6c6f20576f726c6421')\n * // @log: 'Hello world!'\n *\n * Hex.toString('0x48656c6c6f20576f726c64210000000000000000000000000000000000000000', {\n *  size: 32,\n * })\n * // @log: 'Hello world'\n * ```\n *\n * @param hex - The {@link ox#Hex.Hex} value to decode.\n * @param options - Options.\n * @returns The decoded string.\n */\nexport function toString(hex: Hex, options: toString.Options = {}): string {\n  const { size } = options\n\n  let bytes = Bytes.fromHex(hex)\n  if (size) {\n    internal_bytes.assertSize(bytes, size)\n    bytes = Bytes.trimRight(bytes)\n  }\n  return new TextDecoder().decode(bytes)\n}\n\nexport declare namespace toString {\n  type Options = {\n    /** Size (in bytes) of the hex value. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | internal_bytes.assertSize.ErrorType\n    | Bytes.fromHex.ErrorType\n    | Bytes.trimRight.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Checks if the given value is {@link ox#Hex.Hex}.\n *\n * @example\n * ```ts twoslash\n * import { Bytes, Hex } from 'ox'\n *\n * Hex.validate('0xdeadbeef')\n * // @log: true\n *\n * Hex.validate(Bytes.from([1, 2, 3]))\n * // @log: false\n * ```\n *\n * @param value - The value to check.\n * @param options - Options.\n * @returns `true` if the value is a {@link ox#Hex.Hex}, `false` otherwise.\n */\nexport function validate(\n  value: unknown,\n  options: validate.Options = {},\n): value is Hex {\n  const { strict = false } = options\n  try {\n    assert(value, { strict })\n    return true\n  } catch {\n    return false\n  }\n}\n\nexport declare namespace validate {\n  type Options = {\n    /** Checks if the {@link ox#Hex.Hex} value contains invalid hexadecimal characters. @default false */\n    strict?: boolean | undefined\n  }\n\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Thrown when the provided integer is out of range, and cannot be represented as a hex value.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.fromNumber(420182738912731283712937129)\n * // @error: Hex.IntegerOutOfRangeError: Number \\`4.2018273891273126e+26\\` is not in safe unsigned integer range (`0` to `9007199254740991`)\n * ```\n */\nexport class IntegerOutOfRangeError extends Errors.BaseError {\n  override readonly name = 'Hex.IntegerOutOfRangeError'\n\n  constructor({\n    max,\n    min,\n    signed,\n    size,\n    value,\n  }: {\n    max?: string | undefined\n    min: string\n    signed?: boolean | undefined\n    size?: number | undefined\n    value: string\n  }) {\n    super(\n      `Number \\`${value}\\` is not in safe${\n        size ? ` ${size * 8}-bit` : ''\n      }${signed ? ' signed' : ' unsigned'} integer range ${max ? `(\\`${min}\\` to \\`${max}\\`)` : `(above \\`${min}\\`)`}`,\n    )\n  }\n}\n\n/**\n * Thrown when the provided hex value cannot be represented as a boolean.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.toBoolean('0xa')\n * // @error: Hex.InvalidHexBooleanError: Hex value `\"0xa\"` is not a valid boolean.\n * // @error: The hex value must be `\"0x0\"` (false) or `\"0x1\"` (true).\n * ```\n */\nexport class InvalidHexBooleanError extends Errors.BaseError {\n  override readonly name = 'Hex.InvalidHexBooleanError'\n\n  constructor(hex: Hex) {\n    super(`Hex value \\`\"${hex}\"\\` is not a valid boolean.`, {\n      metaMessages: [\n        'The hex value must be `\"0x0\"` (false) or `\"0x1\"` (true).',\n      ],\n    })\n  }\n}\n\n/**\n * Thrown when the provided value is not a valid hex type.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.assert(1)\n * // @error: Hex.InvalidHexTypeError: Value `1` of type `number` is an invalid hex type.\n * ```\n */\nexport class InvalidHexTypeError extends Errors.BaseError {\n  override readonly name = 'Hex.InvalidHexTypeError'\n\n  constructor(value: unknown) {\n    super(\n      `Value \\`${typeof value === 'object' ? Json.stringify(value) : value}\\` of type \\`${typeof value}\\` is an invalid hex type.`,\n      {\n        metaMessages: ['Hex types must be represented as `\"0x${string}\"`.'],\n      },\n    )\n  }\n}\n\n/**\n * Thrown when the provided hex value is invalid.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.assert('0x0123456789abcdefg')\n * // @error: Hex.InvalidHexValueError: Value `0x0123456789abcdefg` is an invalid hex value.\n * // @error: Hex values must start with `\"0x\"` and contain only hexadecimal characters (0-9, a-f, A-F).\n * ```\n */\nexport class InvalidHexValueError extends Errors.BaseError {\n  override readonly name = 'Hex.InvalidHexValueError'\n\n  constructor(value: unknown) {\n    super(`Value \\`${value}\\` is an invalid hex value.`, {\n      metaMessages: [\n        'Hex values must start with `\"0x\"` and contain only hexadecimal characters (0-9, a-f, A-F).',\n      ],\n    })\n  }\n}\n\n/**\n * Thrown when the provided hex value is an odd length.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.fromHex('0xabcde')\n * // @error: Hex.InvalidLengthError: Hex value `\"0xabcde\"` is an odd length (5 nibbles).\n * ```\n */\nexport class InvalidLengthError extends Errors.BaseError {\n  override readonly name = 'Hex.InvalidLengthError'\n\n  constructor(value: Hex) {\n    super(\n      `Hex value \\`\"${value}\"\\` is an odd length (${value.length - 2} nibbles).`,\n      {\n        metaMessages: ['It must be an even length.'],\n      },\n    )\n  }\n}\n\n/**\n * Thrown when the size of the value exceeds the expected max size.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.fromString('Hello World!', { size: 8 })\n * // @error: Hex.SizeOverflowError: Size cannot exceed `8` bytes. Given size: `12` bytes.\n * ```\n */\nexport class SizeOverflowError extends Errors.BaseError {\n  override readonly name = 'Hex.SizeOverflowError'\n\n  constructor({ givenSize, maxSize }: { givenSize: number; maxSize: number }) {\n    super(\n      `Size cannot exceed \\`${maxSize}\\` bytes. Given size: \\`${givenSize}\\` bytes.`,\n    )\n  }\n}\n\n/**\n * Thrown when the slice offset exceeds the bounds of the value.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.slice('0x0123456789', 6)\n * // @error: Hex.SliceOffsetOutOfBoundsError: Slice starting at offset `6` is out-of-bounds (size: `5`).\n * ```\n */\nexport class SliceOffsetOutOfBoundsError extends Errors.BaseError {\n  override readonly name = 'Hex.SliceOffsetOutOfBoundsError'\n\n  constructor({\n    offset,\n    position,\n    size,\n  }: { offset: number; position: 'start' | 'end'; size: number }) {\n    super(\n      `Slice ${\n        position === 'start' ? 'starting' : 'ending'\n      } at offset \\`${offset}\\` is out-of-bounds (size: \\`${size}\\`).`,\n    )\n  }\n}\n\n/**\n * Thrown when the size of the value exceeds the pad size.\n *\n * @example\n * ```ts twoslash\n * import { Hex } from 'ox'\n *\n * Hex.padLeft('0x1a4e12a45a21323123aaa87a897a897a898a6567a578a867a98778a667a85a875a87a6a787a65a675a6a9', 32)\n * // @error: Hex.SizeExceedsPaddingSizeError: Hex size (`43`) exceeds padding size (`32`).\n * ```\n */\nexport class SizeExceedsPaddingSizeError extends Errors.BaseError {\n  override readonly name = 'Hex.SizeExceedsPaddingSizeError'\n\n  constructor({\n    size,\n    targetSize,\n    type,\n  }: {\n    size: number\n    targetSize: number\n    type: 'Hex' | 'Bytes'\n  }) {\n    super(\n      `${type.charAt(0).toUpperCase()}${type\n        .slice(1)\n        .toLowerCase()} size (\\`${size}\\`) exceeds padding size (\\`${targetSize}\\`).`,\n    )\n  }\n}\n","import type { Bytes } from '../Bytes.js'\nimport * as Errors from '../Errors.js'\n\n/** @internal */\nexport type Cursor = {\n  bytes: Bytes\n  dataView: DataView\n  position: number\n  positionReadCount: Map<number, number>\n  recursiveReadCount: number\n  recursiveReadLimit: number\n  remaining: number\n  assertReadLimit(position?: number): void\n  assertPosition(position: number): void\n  decrementPosition(offset: number): void\n  getReadCount(position?: number): number\n  incrementPosition(offset: number): void\n  inspectByte(position?: number): Bytes[number]\n  inspectBytes(length: number, position?: number): Bytes\n  inspectUint8(position?: number): number\n  inspectUint16(position?: number): number\n  inspectUint24(position?: number): number\n  inspectUint32(position?: number): number\n  pushByte(byte: Bytes[number]): void\n  pushBytes(bytes: Bytes): void\n  pushUint8(value: number): void\n  pushUint16(value: number): void\n  pushUint24(value: number): void\n  pushUint32(value: number): void\n  readByte(): Bytes[number]\n  readBytes(length: number, size?: number): Bytes\n  readUint8(): number\n  readUint16(): number\n  readUint24(): number\n  readUint32(): number\n  setPosition(position: number): () => void\n  _touch(): void\n}\n\nconst staticCursor: Cursor = {\n  bytes: new Uint8Array(),\n  dataView: new DataView(new ArrayBuffer(0)),\n  position: 0,\n  positionReadCount: new Map(),\n  recursiveReadCount: 0,\n  recursiveReadLimit: Number.POSITIVE_INFINITY,\n  assertReadLimit() {\n    if (this.recursiveReadCount >= this.recursiveReadLimit)\n      throw new RecursiveReadLimitExceededError({\n        count: this.recursiveReadCount + 1,\n        limit: this.recursiveReadLimit,\n      })\n  },\n  assertPosition(position) {\n    if (position < 0 || position > this.bytes.length - 1)\n      throw new PositionOutOfBoundsError({\n        length: this.bytes.length,\n        position,\n      })\n  },\n  decrementPosition(offset) {\n    if (offset < 0) throw new NegativeOffsetError({ offset })\n    const position = this.position - offset\n    this.assertPosition(position)\n    this.position = position\n  },\n  getReadCount(position) {\n    return this.positionReadCount.get(position || this.position) || 0\n  },\n  incrementPosition(offset) {\n    if (offset < 0) throw new NegativeOffsetError({ offset })\n    const position = this.position + offset\n    this.assertPosition(position)\n    this.position = position\n  },\n  inspectByte(position_) {\n    const position = position_ ?? this.position\n    this.assertPosition(position)\n    return this.bytes[position]!\n  },\n  inspectBytes(length, position_) {\n    const position = position_ ?? this.position\n    this.assertPosition(position + length - 1)\n    return this.bytes.subarray(position, position + length)\n  },\n  inspectUint8(position_) {\n    const position = position_ ?? this.position\n    this.assertPosition(position)\n    return this.bytes[position]!\n  },\n  inspectUint16(position_) {\n    const position = position_ ?? this.position\n    this.assertPosition(position + 1)\n    return this.dataView.getUint16(position)\n  },\n  inspectUint24(position_) {\n    const position = position_ ?? this.position\n    this.assertPosition(position + 2)\n    return (\n      (this.dataView.getUint16(position) << 8) +\n      this.dataView.getUint8(position + 2)\n    )\n  },\n  inspectUint32(position_) {\n    const position = position_ ?? this.position\n    this.assertPosition(position + 3)\n    return this.dataView.getUint32(position)\n  },\n  pushByte(byte: Bytes[number]) {\n    this.assertPosition(this.position)\n    this.bytes[this.position] = byte\n    this.position++\n  },\n  pushBytes(bytes: Bytes) {\n    this.assertPosition(this.position + bytes.length - 1)\n    this.bytes.set(bytes, this.position)\n    this.position += bytes.length\n  },\n  pushUint8(value: number) {\n    this.assertPosition(this.position)\n    this.bytes[this.position] = value\n    this.position++\n  },\n  pushUint16(value: number) {\n    this.assertPosition(this.position + 1)\n    this.dataView.setUint16(this.position, value)\n    this.position += 2\n  },\n  pushUint24(value: number) {\n    this.assertPosition(this.position + 2)\n    this.dataView.setUint16(this.position, value >> 8)\n    this.dataView.setUint8(this.position + 2, value & ~4294967040)\n    this.position += 3\n  },\n  pushUint32(value: number) {\n    this.assertPosition(this.position + 3)\n    this.dataView.setUint32(this.position, value)\n    this.position += 4\n  },\n  readByte() {\n    this.assertReadLimit()\n    this._touch()\n    const value = this.inspectByte()\n    this.position++\n    return value\n  },\n  readBytes(length, size) {\n    this.assertReadLimit()\n    this._touch()\n    const value = this.inspectBytes(length)\n    this.position += size ?? length\n    return value\n  },\n  readUint8() {\n    this.assertReadLimit()\n    this._touch()\n    const value = this.inspectUint8()\n    this.position += 1\n    return value\n  },\n  readUint16() {\n    this.assertReadLimit()\n    this._touch()\n    const value = this.inspectUint16()\n    this.position += 2\n    return value\n  },\n  readUint24() {\n    this.assertReadLimit()\n    this._touch()\n    const value = this.inspectUint24()\n    this.position += 3\n    return value\n  },\n  readUint32() {\n    this.assertReadLimit()\n    this._touch()\n    const value = this.inspectUint32()\n    this.position += 4\n    return value\n  },\n  get remaining() {\n    return this.bytes.length - this.position\n  },\n  setPosition(position) {\n    const oldPosition = this.position\n    this.assertPosition(position)\n    this.position = position\n    return () => (this.position = oldPosition)\n  },\n  _touch() {\n    if (this.recursiveReadLimit === Number.POSITIVE_INFINITY) return\n    const count = this.getReadCount()\n    this.positionReadCount.set(this.position, count + 1)\n    if (count > 0) this.recursiveReadCount++\n  },\n}\n\n/** @internal */\nexport function create(\n  bytes: Bytes,\n  { recursiveReadLimit = 8_192 }: create.Config = {},\n): Cursor {\n  const cursor: Cursor = Object.create(staticCursor)\n  cursor.bytes = bytes\n  cursor.dataView = new DataView(\n    bytes.buffer,\n    bytes.byteOffset,\n    bytes.byteLength,\n  )\n  cursor.positionReadCount = new Map()\n  cursor.recursiveReadLimit = recursiveReadLimit\n  return cursor\n}\n\n/** @internal */\nexport declare namespace create {\n  type Config = { recursiveReadLimit?: number | undefined }\n\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/** @internal */\nexport class NegativeOffsetError extends Errors.BaseError {\n  override readonly name = 'Cursor.NegativeOffsetError'\n\n  constructor({ offset }: { offset: number }) {\n    super(`Offset \\`${offset}\\` cannot be negative.`)\n  }\n}\n\n/** @internal */\nexport class PositionOutOfBoundsError extends Errors.BaseError {\n  override readonly name = 'Cursor.PositionOutOfBoundsError'\n\n  constructor({ length, position }: { length: number; position: number }) {\n    super(\n      `Position \\`${position}\\` is out of bounds (\\`0 < position < ${length}\\`).`,\n    )\n  }\n}\n\n/** @internal */\nexport class RecursiveReadLimitExceededError extends Errors.BaseError {\n  override readonly name = 'Cursor.RecursiveReadLimitExceededError'\n\n  constructor({ count, limit }: { count: number; limit: number }) {\n    super(\n      `Recursive read limit of \\`${limit}\\` exceeded (recursive read count: \\`${count}\\`).`,\n    )\n  }\n}\n","/**\n * SHA2 hash function. A.k.a. sha256, sha384, sha512, sha512_224, sha512_256.\n * SHA256 is the fastest hash implementable in JS, even faster than Blake3.\n * Check out [RFC 4634](https://datatracker.ietf.org/doc/html/rfc4634) and\n * [FIPS 180-4](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf).\n * @module\n */\nimport { Chi, HashMD, Maj, SHA224_IV, SHA256_IV, SHA384_IV, SHA512_IV } from './_md.ts';\nimport * as u64 from './_u64.ts';\nimport { type CHash, clean, createHasher, rotr } from './utils.ts';\n\n/**\n * Round constants:\n * First 32 bits of fractional parts of the cube roots of the first 64 primes 2..311)\n */\n// prettier-ignore\nconst SHA256_K = /* @__PURE__ */ Uint32Array.from([\n  0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n  0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n  0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n  0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n  0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n  0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n  0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n  0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2\n]);\n\n/** Reusable temporary buffer. \"W\" comes straight from spec. */\nconst SHA256_W = /* @__PURE__ */ new Uint32Array(64);\nexport class SHA256 extends HashMD<SHA256> {\n  // We cannot use array here since array allows indexing by variable\n  // which means optimizer/compiler cannot use registers.\n  protected A: number = SHA256_IV[0] | 0;\n  protected B: number = SHA256_IV[1] | 0;\n  protected C: number = SHA256_IV[2] | 0;\n  protected D: number = SHA256_IV[3] | 0;\n  protected E: number = SHA256_IV[4] | 0;\n  protected F: number = SHA256_IV[5] | 0;\n  protected G: number = SHA256_IV[6] | 0;\n  protected H: number = SHA256_IV[7] | 0;\n\n  constructor(outputLen: number = 32) {\n    super(64, outputLen, 8, false);\n  }\n  protected get(): [number, number, number, number, number, number, number, number] {\n    const { A, B, C, D, E, F, G, H } = this;\n    return [A, B, C, D, E, F, G, H];\n  }\n  // prettier-ignore\n  protected set(\n    A: number, B: number, C: number, D: number, E: number, F: number, G: number, H: number\n  ): void {\n    this.A = A | 0;\n    this.B = B | 0;\n    this.C = C | 0;\n    this.D = D | 0;\n    this.E = E | 0;\n    this.F = F | 0;\n    this.G = G | 0;\n    this.H = H | 0;\n  }\n  protected process(view: DataView, offset: number): void {\n    // Extend the first 16 words into the remaining 48 words w[16..63] of the message schedule array\n    for (let i = 0; i < 16; i++, offset += 4) SHA256_W[i] = view.getUint32(offset, false);\n    for (let i = 16; i < 64; i++) {\n      const W15 = SHA256_W[i - 15];\n      const W2 = SHA256_W[i - 2];\n      const s0 = rotr(W15, 7) ^ rotr(W15, 18) ^ (W15 >>> 3);\n      const s1 = rotr(W2, 17) ^ rotr(W2, 19) ^ (W2 >>> 10);\n      SHA256_W[i] = (s1 + SHA256_W[i - 7] + s0 + SHA256_W[i - 16]) | 0;\n    }\n    // Compression function main loop, 64 rounds\n    let { A, B, C, D, E, F, G, H } = this;\n    for (let i = 0; i < 64; i++) {\n      const sigma1 = rotr(E, 6) ^ rotr(E, 11) ^ rotr(E, 25);\n      const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;\n      const sigma0 = rotr(A, 2) ^ rotr(A, 13) ^ rotr(A, 22);\n      const T2 = (sigma0 + Maj(A, B, C)) | 0;\n      H = G;\n      G = F;\n      F = E;\n      E = (D + T1) | 0;\n      D = C;\n      C = B;\n      B = A;\n      A = (T1 + T2) | 0;\n    }\n    // Add the compressed chunk to the current hash value\n    A = (A + this.A) | 0;\n    B = (B + this.B) | 0;\n    C = (C + this.C) | 0;\n    D = (D + this.D) | 0;\n    E = (E + this.E) | 0;\n    F = (F + this.F) | 0;\n    G = (G + this.G) | 0;\n    H = (H + this.H) | 0;\n    this.set(A, B, C, D, E, F, G, H);\n  }\n  protected roundClean(): void {\n    clean(SHA256_W);\n  }\n  destroy(): void {\n    this.set(0, 0, 0, 0, 0, 0, 0, 0);\n    clean(this.buffer);\n  }\n}\n\nexport class SHA224 extends SHA256 {\n  protected A: number = SHA224_IV[0] | 0;\n  protected B: number = SHA224_IV[1] | 0;\n  protected C: number = SHA224_IV[2] | 0;\n  protected D: number = SHA224_IV[3] | 0;\n  protected E: number = SHA224_IV[4] | 0;\n  protected F: number = SHA224_IV[5] | 0;\n  protected G: number = SHA224_IV[6] | 0;\n  protected H: number = SHA224_IV[7] | 0;\n  constructor() {\n    super(28);\n  }\n}\n\n// SHA2-512 is slower than sha256 in js because u64 operations are slow.\n\n// Round contants\n// First 32 bits of the fractional parts of the cube roots of the first 80 primes 2..409\n// prettier-ignore\nconst K512 = /* @__PURE__ */ (() => u64.split([\n  '0x428a2f98d728ae22', '0x7137449123ef65cd', '0xb5c0fbcfec4d3b2f', '0xe9b5dba58189dbbc',\n  '0x3956c25bf348b538', '0x59f111f1b605d019', '0x923f82a4af194f9b', '0xab1c5ed5da6d8118',\n  '0xd807aa98a3030242', '0x12835b0145706fbe', '0x243185be4ee4b28c', '0x550c7dc3d5ffb4e2',\n  '0x72be5d74f27b896f', '0x80deb1fe3b1696b1', '0x9bdc06a725c71235', '0xc19bf174cf692694',\n  '0xe49b69c19ef14ad2', '0xefbe4786384f25e3', '0x0fc19dc68b8cd5b5', '0x240ca1cc77ac9c65',\n  '0x2de92c6f592b0275', '0x4a7484aa6ea6e483', '0x5cb0a9dcbd41fbd4', '0x76f988da831153b5',\n  '0x983e5152ee66dfab', '0xa831c66d2db43210', '0xb00327c898fb213f', '0xbf597fc7beef0ee4',\n  '0xc6e00bf33da88fc2', '0xd5a79147930aa725', '0x06ca6351e003826f', '0x142929670a0e6e70',\n  '0x27b70a8546d22ffc', '0x2e1b21385c26c926', '0x4d2c6dfc5ac42aed', '0x53380d139d95b3df',\n  '0x650a73548baf63de', '0x766a0abb3c77b2a8', '0x81c2c92e47edaee6', '0x92722c851482353b',\n  '0xa2bfe8a14cf10364', '0xa81a664bbc423001', '0xc24b8b70d0f89791', '0xc76c51a30654be30',\n  '0xd192e819d6ef5218', '0xd69906245565a910', '0xf40e35855771202a', '0x106aa07032bbd1b8',\n  '0x19a4c116b8d2d0c8', '0x1e376c085141ab53', '0x2748774cdf8eeb99', '0x34b0bcb5e19b48a8',\n  '0x391c0cb3c5c95a63', '0x4ed8aa4ae3418acb', '0x5b9cca4f7763e373', '0x682e6ff3d6b2b8a3',\n  '0x748f82ee5defb2fc', '0x78a5636f43172f60', '0x84c87814a1f0ab72', '0x8cc702081a6439ec',\n  '0x90befffa23631e28', '0xa4506cebde82bde9', '0xbef9a3f7b2c67915', '0xc67178f2e372532b',\n  '0xca273eceea26619c', '0xd186b8c721c0c207', '0xeada7dd6cde0eb1e', '0xf57d4f7fee6ed178',\n  '0x06f067aa72176fba', '0x0a637dc5a2c898a6', '0x113f9804bef90dae', '0x1b710b35131c471b',\n  '0x28db77f523047d84', '0x32caab7b40c72493', '0x3c9ebe0a15c9bebc', '0x431d67c49c100d4c',\n  '0x4cc5d4becb3e42b6', '0x597f299cfc657e2a', '0x5fcb6fab3ad6faec', '0x6c44198c4a475817'\n].map(n => BigInt(n))))();\nconst SHA512_Kh = /* @__PURE__ */ (() => K512[0])();\nconst SHA512_Kl = /* @__PURE__ */ (() => K512[1])();\n\n// Reusable temporary buffers\nconst SHA512_W_H = /* @__PURE__ */ new Uint32Array(80);\nconst SHA512_W_L = /* @__PURE__ */ new Uint32Array(80);\n\nexport class SHA512 extends HashMD<SHA512> {\n  // We cannot use array here since array allows indexing by variable\n  // which means optimizer/compiler cannot use registers.\n  // h -- high 32 bits, l -- low 32 bits\n  protected Ah: number = SHA512_IV[0] | 0;\n  protected Al: number = SHA512_IV[1] | 0;\n  protected Bh: number = SHA512_IV[2] | 0;\n  protected Bl: number = SHA512_IV[3] | 0;\n  protected Ch: number = SHA512_IV[4] | 0;\n  protected Cl: number = SHA512_IV[5] | 0;\n  protected Dh: number = SHA512_IV[6] | 0;\n  protected Dl: number = SHA512_IV[7] | 0;\n  protected Eh: number = SHA512_IV[8] | 0;\n  protected El: number = SHA512_IV[9] | 0;\n  protected Fh: number = SHA512_IV[10] | 0;\n  protected Fl: number = SHA512_IV[11] | 0;\n  protected Gh: number = SHA512_IV[12] | 0;\n  protected Gl: number = SHA512_IV[13] | 0;\n  protected Hh: number = SHA512_IV[14] | 0;\n  protected Hl: number = SHA512_IV[15] | 0;\n\n  constructor(outputLen: number = 64) {\n    super(128, outputLen, 16, false);\n  }\n  // prettier-ignore\n  protected get(): [\n    number, number, number, number, number, number, number, number,\n    number, number, number, number, number, number, number, number\n  ] {\n    const { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;\n    return [Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl];\n  }\n  // prettier-ignore\n  protected set(\n    Ah: number, Al: number, Bh: number, Bl: number, Ch: number, Cl: number, Dh: number, Dl: number,\n    Eh: number, El: number, Fh: number, Fl: number, Gh: number, Gl: number, Hh: number, Hl: number\n  ): void {\n    this.Ah = Ah | 0;\n    this.Al = Al | 0;\n    this.Bh = Bh | 0;\n    this.Bl = Bl | 0;\n    this.Ch = Ch | 0;\n    this.Cl = Cl | 0;\n    this.Dh = Dh | 0;\n    this.Dl = Dl | 0;\n    this.Eh = Eh | 0;\n    this.El = El | 0;\n    this.Fh = Fh | 0;\n    this.Fl = Fl | 0;\n    this.Gh = Gh | 0;\n    this.Gl = Gl | 0;\n    this.Hh = Hh | 0;\n    this.Hl = Hl | 0;\n  }\n  protected process(view: DataView, offset: number): void {\n    // Extend the first 16 words into the remaining 64 words w[16..79] of the message schedule array\n    for (let i = 0; i < 16; i++, offset += 4) {\n      SHA512_W_H[i] = view.getUint32(offset);\n      SHA512_W_L[i] = view.getUint32((offset += 4));\n    }\n    for (let i = 16; i < 80; i++) {\n      // s0 := (w[i-15] rightrotate 1) xor (w[i-15] rightrotate 8) xor (w[i-15] rightshift 7)\n      const W15h = SHA512_W_H[i - 15] | 0;\n      const W15l = SHA512_W_L[i - 15] | 0;\n      const s0h = u64.rotrSH(W15h, W15l, 1) ^ u64.rotrSH(W15h, W15l, 8) ^ u64.shrSH(W15h, W15l, 7);\n      const s0l = u64.rotrSL(W15h, W15l, 1) ^ u64.rotrSL(W15h, W15l, 8) ^ u64.shrSL(W15h, W15l, 7);\n      // s1 := (w[i-2] rightrotate 19) xor (w[i-2] rightrotate 61) xor (w[i-2] rightshift 6)\n      const W2h = SHA512_W_H[i - 2] | 0;\n      const W2l = SHA512_W_L[i - 2] | 0;\n      const s1h = u64.rotrSH(W2h, W2l, 19) ^ u64.rotrBH(W2h, W2l, 61) ^ u64.shrSH(W2h, W2l, 6);\n      const s1l = u64.rotrSL(W2h, W2l, 19) ^ u64.rotrBL(W2h, W2l, 61) ^ u64.shrSL(W2h, W2l, 6);\n      // SHA256_W[i] = s0 + s1 + SHA256_W[i - 7] + SHA256_W[i - 16];\n      const SUMl = u64.add4L(s0l, s1l, SHA512_W_L[i - 7], SHA512_W_L[i - 16]);\n      const SUMh = u64.add4H(SUMl, s0h, s1h, SHA512_W_H[i - 7], SHA512_W_H[i - 16]);\n      SHA512_W_H[i] = SUMh | 0;\n      SHA512_W_L[i] = SUMl | 0;\n    }\n    let { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;\n    // Compression function main loop, 80 rounds\n    for (let i = 0; i < 80; i++) {\n      // S1 := (e rightrotate 14) xor (e rightrotate 18) xor (e rightrotate 41)\n      const sigma1h = u64.rotrSH(Eh, El, 14) ^ u64.rotrSH(Eh, El, 18) ^ u64.rotrBH(Eh, El, 41);\n      const sigma1l = u64.rotrSL(Eh, El, 14) ^ u64.rotrSL(Eh, El, 18) ^ u64.rotrBL(Eh, El, 41);\n      //const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;\n      const CHIh = (Eh & Fh) ^ (~Eh & Gh);\n      const CHIl = (El & Fl) ^ (~El & Gl);\n      // T1 = H + sigma1 + Chi(E, F, G) + SHA512_K[i] + SHA512_W[i]\n      // prettier-ignore\n      const T1ll = u64.add5L(Hl, sigma1l, CHIl, SHA512_Kl[i], SHA512_W_L[i]);\n      const T1h = u64.add5H(T1ll, Hh, sigma1h, CHIh, SHA512_Kh[i], SHA512_W_H[i]);\n      const T1l = T1ll | 0;\n      // S0 := (a rightrotate 28) xor (a rightrotate 34) xor (a rightrotate 39)\n      const sigma0h = u64.rotrSH(Ah, Al, 28) ^ u64.rotrBH(Ah, Al, 34) ^ u64.rotrBH(Ah, Al, 39);\n      const sigma0l = u64.rotrSL(Ah, Al, 28) ^ u64.rotrBL(Ah, Al, 34) ^ u64.rotrBL(Ah, Al, 39);\n      const MAJh = (Ah & Bh) ^ (Ah & Ch) ^ (Bh & Ch);\n      const MAJl = (Al & Bl) ^ (Al & Cl) ^ (Bl & Cl);\n      Hh = Gh | 0;\n      Hl = Gl | 0;\n      Gh = Fh | 0;\n      Gl = Fl | 0;\n      Fh = Eh | 0;\n      Fl = El | 0;\n      ({ h: Eh, l: El } = u64.add(Dh | 0, Dl | 0, T1h | 0, T1l | 0));\n      Dh = Ch | 0;\n      Dl = Cl | 0;\n      Ch = Bh | 0;\n      Cl = Bl | 0;\n      Bh = Ah | 0;\n      Bl = Al | 0;\n      const All = u64.add3L(T1l, sigma0l, MAJl);\n      Ah = u64.add3H(All, T1h, sigma0h, MAJh);\n      Al = All | 0;\n    }\n    // Add the compressed chunk to the current hash value\n    ({ h: Ah, l: Al } = u64.add(this.Ah | 0, this.Al | 0, Ah | 0, Al | 0));\n    ({ h: Bh, l: Bl } = u64.add(this.Bh | 0, this.Bl | 0, Bh | 0, Bl | 0));\n    ({ h: Ch, l: Cl } = u64.add(this.Ch | 0, this.Cl | 0, Ch | 0, Cl | 0));\n    ({ h: Dh, l: Dl } = u64.add(this.Dh | 0, this.Dl | 0, Dh | 0, Dl | 0));\n    ({ h: Eh, l: El } = u64.add(this.Eh | 0, this.El | 0, Eh | 0, El | 0));\n    ({ h: Fh, l: Fl } = u64.add(this.Fh | 0, this.Fl | 0, Fh | 0, Fl | 0));\n    ({ h: Gh, l: Gl } = u64.add(this.Gh | 0, this.Gl | 0, Gh | 0, Gl | 0));\n    ({ h: Hh, l: Hl } = u64.add(this.Hh | 0, this.Hl | 0, Hh | 0, Hl | 0));\n    this.set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl);\n  }\n  protected roundClean(): void {\n    clean(SHA512_W_H, SHA512_W_L);\n  }\n  destroy(): void {\n    clean(this.buffer);\n    this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n  }\n}\n\nexport class SHA384 extends SHA512 {\n  protected Ah: number = SHA384_IV[0] | 0;\n  protected Al: number = SHA384_IV[1] | 0;\n  protected Bh: number = SHA384_IV[2] | 0;\n  protected Bl: number = SHA384_IV[3] | 0;\n  protected Ch: number = SHA384_IV[4] | 0;\n  protected Cl: number = SHA384_IV[5] | 0;\n  protected Dh: number = SHA384_IV[6] | 0;\n  protected Dl: number = SHA384_IV[7] | 0;\n  protected Eh: number = SHA384_IV[8] | 0;\n  protected El: number = SHA384_IV[9] | 0;\n  protected Fh: number = SHA384_IV[10] | 0;\n  protected Fl: number = SHA384_IV[11] | 0;\n  protected Gh: number = SHA384_IV[12] | 0;\n  protected Gl: number = SHA384_IV[13] | 0;\n  protected Hh: number = SHA384_IV[14] | 0;\n  protected Hl: number = SHA384_IV[15] | 0;\n\n  constructor() {\n    super(48);\n  }\n}\n\n/**\n * Truncated SHA512/256 and SHA512/224.\n * SHA512_IV is XORed with 0xa5a5a5a5a5a5a5a5, then used as \"intermediary\" IV of SHA512/t.\n * Then t hashes string to produce result IV.\n * See `test/misc/sha2-gen-iv.js`.\n */\n\n/** SHA512/224 IV */\nconst T224_IV = /* @__PURE__ */ Uint32Array.from([\n  0x8c3d37c8, 0x19544da2, 0x73e19966, 0x89dcd4d6, 0x1dfab7ae, 0x32ff9c82, 0x679dd514, 0x582f9fcf,\n  0x0f6d2b69, 0x7bd44da8, 0x77e36f73, 0x04c48942, 0x3f9d85a8, 0x6a1d36c8, 0x1112e6ad, 0x91d692a1,\n]);\n\n/** SHA512/256 IV */\nconst T256_IV = /* @__PURE__ */ Uint32Array.from([\n  0x22312194, 0xfc2bf72c, 0x9f555fa3, 0xc84c64c2, 0x2393b86b, 0x6f53b151, 0x96387719, 0x5940eabd,\n  0x96283ee2, 0xa88effe3, 0xbe5e1e25, 0x53863992, 0x2b0199fc, 0x2c85b8aa, 0x0eb72ddc, 0x81c52ca2,\n]);\n\nexport class SHA512_224 extends SHA512 {\n  protected Ah: number = T224_IV[0] | 0;\n  protected Al: number = T224_IV[1] | 0;\n  protected Bh: number = T224_IV[2] | 0;\n  protected Bl: number = T224_IV[3] | 0;\n  protected Ch: number = T224_IV[4] | 0;\n  protected Cl: number = T224_IV[5] | 0;\n  protected Dh: number = T224_IV[6] | 0;\n  protected Dl: number = T224_IV[7] | 0;\n  protected Eh: number = T224_IV[8] | 0;\n  protected El: number = T224_IV[9] | 0;\n  protected Fh: number = T224_IV[10] | 0;\n  protected Fl: number = T224_IV[11] | 0;\n  protected Gh: number = T224_IV[12] | 0;\n  protected Gl: number = T224_IV[13] | 0;\n  protected Hh: number = T224_IV[14] | 0;\n  protected Hl: number = T224_IV[15] | 0;\n\n  constructor() {\n    super(28);\n  }\n}\n\nexport class SHA512_256 extends SHA512 {\n  protected Ah: number = T256_IV[0] | 0;\n  protected Al: number = T256_IV[1] | 0;\n  protected Bh: number = T256_IV[2] | 0;\n  protected Bl: number = T256_IV[3] | 0;\n  protected Ch: number = T256_IV[4] | 0;\n  protected Cl: number = T256_IV[5] | 0;\n  protected Dh: number = T256_IV[6] | 0;\n  protected Dl: number = T256_IV[7] | 0;\n  protected Eh: number = T256_IV[8] | 0;\n  protected El: number = T256_IV[9] | 0;\n  protected Fh: number = T256_IV[10] | 0;\n  protected Fl: number = T256_IV[11] | 0;\n  protected Gh: number = T256_IV[12] | 0;\n  protected Gl: number = T256_IV[13] | 0;\n  protected Hh: number = T256_IV[14] | 0;\n  protected Hl: number = T256_IV[15] | 0;\n\n  constructor() {\n    super(32);\n  }\n}\n\n/**\n * SHA2-256 hash function from RFC 4634.\n *\n * It is the fastest JS hash, even faster than Blake3.\n * To break sha256 using birthday attack, attackers need to try 2^128 hashes.\n * BTC network is doing 2^70 hashes/sec (2^95 hashes/year) as per 2025.\n */\nexport const sha256: CHash = /* @__PURE__ */ createHasher(() => new SHA256());\n/** SHA2-224 hash function from RFC 4634 */\nexport const sha224: CHash = /* @__PURE__ */ createHasher(() => new SHA224());\n\n/** SHA2-512 hash function from RFC 4634. */\nexport const sha512: CHash = /* @__PURE__ */ createHasher(() => new SHA512());\n/** SHA2-384 hash function from RFC 4634. */\nexport const sha384: CHash = /* @__PURE__ */ createHasher(() => new SHA384());\n\n/**\n * SHA2-512/256 \"truncated\" hash function, with improved resistance to length extension attacks.\n * See the paper on [truncated SHA512](https://eprint.iacr.org/2010/548.pdf).\n */\nexport const sha512_256: CHash = /* @__PURE__ */ createHasher(() => new SHA512_256());\n/**\n * SHA2-512/224 \"truncated\" hash function, with improved resistance to length extension attacks.\n * See the paper on [truncated SHA512](https://eprint.iacr.org/2010/548.pdf).\n */\nexport const sha512_224: CHash = /* @__PURE__ */ createHasher(() => new SHA512_224());\n","/**\n * RIPEMD-160 legacy hash function.\n * https://homes.esat.kuleuven.be/~bosselae/ripemd160.html\n * https://homes.esat.kuleuven.be/~bosselae/ripemd160/pdf/AB-9601/AB-9601.pdf\n * @module\n * @deprecated\n */\nimport { RIPEMD160 as RIPEMD160n, ripemd160 as ripemd160n } from './legacy.ts';\n/** @deprecated Use import from `noble/hashes/legacy` module */\nexport const RIPEMD160: typeof RIPEMD160n = RIPEMD160n;\n/** @deprecated Use import from `noble/hashes/legacy` module */\nexport const ripemd160: typeof ripemd160n = ripemd160n;\n","/**\n * PDPServer - Consolidated interface for all PDP server (Curio) HTTP operations\n *\n * This combines functionality for:\n * - Data set management (create, add pieces, status checks)\n * - Piece uploads\n * - Piece downloads\n * - Piece discovery\n *\n * @example\n * ```typescript\n * import { PDPServer } from '@filoz/synapse-sdk/pdp'\n * import { PDPAuthHelper } from '@filoz/synapse-sdk/pdp'\n *\n * const authHelper = new PDPAuthHelper(warmStorageAddress, signer)\n * const pdpServer = new PDPServer(authHelper, 'https://pdp.provider.com')\n *\n * // Create a data set\n * const { txHash } = await pdpServer.createDataSet(serviceProvider, clientDataSetId)\n *\n * // Upload a piece\n * const { pieceCid, size } = await pdpServer.uploadPiece(data)\n *\n * // Download a piece\n * const data = await pdpServer.downloadPiece(pieceCid, size)\n * ```\n */\n\nimport * as Piece from '@filoz/synapse-core/piece'\nimport { asPieceCID, downloadAndValidate } from '@filoz/synapse-core/piece'\nimport * as SP from '@filoz/synapse-core/sp'\nimport { randU256 } from '@filoz/synapse-core/utils'\nimport { ethers } from 'ethers'\nimport type { Hex } from 'viem'\nimport type { DataSetData, MetadataEntry, PieceCID } from '../types.ts'\nimport { validateDataSetMetadata, validatePieceMetadata } from '../utils/metadata.ts'\nimport { constructPieceUrl } from '../utils/piece.ts'\nimport type { PDPAuthHelper } from './auth.ts'\nimport {\n  validateDataSetCreationStatusResponse,\n  validatePieceAdditionStatusResponse,\n  validatePieceStatusResponse,\n} from './validation.ts'\n\n/**\n * Response from creating a data set\n */\nexport interface CreateDataSetResponse {\n  /** Transaction hash for the data set creation */\n  txHash: string\n  /** URL to check creation status */\n  statusUrl: string\n}\n\n/**\n * Response from checking data set creation status\n */\nexport interface DataSetCreationStatusResponse {\n  /** Transaction hash that created the data set */\n  createMessageHash: string\n  /** Whether the data set has been created on-chain */\n  dataSetCreated: boolean\n  /** Service label that created the data set */\n  service: string\n  /** Transaction status (pending, confirmed, failed) */\n  txStatus: string\n  /** Whether the transaction was successful (null if still pending) */\n  ok: boolean | null\n  /** The server's reported ID for this data set (only available after creation) */\n  dataSetId?: number\n}\n\n/**\n * Response from adding pieces to a data set\n */\nexport interface AddPiecesResponse {\n  /** Success message from the server */\n  message: string\n  /** Transaction hash for the piece addition (optional - new servers only) */\n  txHash: string\n  /** URL to check piece addition status (optional - new servers only) */\n  statusUrl: string\n}\n\n/**\n * Response from finding a piece\n */\nexport interface FindPieceResponse {\n  /** The piece CID that was found */\n  pieceCid: PieceCID\n}\n\n/**\n * Response from checking piece indexing and IPNI status\n */\nexport interface PieceStatusResponse {\n  /** The piece CID */\n  pieceCid: string\n  /** Current processing status */\n  status: string\n  /** Whether the piece has been indexed */\n  indexed: boolean\n  /** Whether the piece has been advertised to IPNI */\n  advertised: boolean\n  /**\n   * Whether the piece has been retrieved\n   * This does not necessarily mean it was retrieved by a particular indexer,\n   * only that the PDP server witnessed a retrieval event. Care should be\n   * taken when interpreting this field.\n   */\n  retrieved: boolean\n  /** Timestamp when the piece was retrieved (optional) */\n  retrievedAt?: string\n}\n\n/**\n * Response from checking piece addition status\n */\nexport interface PieceAdditionStatusResponse {\n  /** Transaction hash for the piece addition */\n  txHash: string\n  /** Transaction status (pending, confirmed, failed) */\n  txStatus: string\n  /** The data set ID */\n  dataSetId: number\n  /** Number of pieces being added */\n  pieceCount: number\n  /** Whether the add message was successful (null if pending) */\n  addMessageOk: boolean | null\n  /** Piece IDs assigned after confirmation */\n  confirmedPieceIds?: number[]\n}\n\n/**\n * Options for uploading a piece\n */\nexport interface UploadPieceOptions {\n  /** Optional progress callback */\n  onProgress?: (bytesUploaded: number) => void\n  /** Optional pre-calculated PieceCID to skip CommP calculation (BYO PieceCID, it will be checked by the server) */\n  pieceCid?: PieceCID\n  /** Optional AbortSignal to cancel the upload */\n  signal?: AbortSignal\n}\n\n/**\n * Input for adding pieces to a data set\n */\nexport interface PDPAddPiecesInput {\n  pieces: PDPPieces[]\n  extraData: string\n}\n\nexport interface PDPPieces {\n  pieceCid: string\n  subPieces: {\n    subPieceCid: string\n  }[]\n}\n\nexport interface PDPCreateAndAddInput {\n  recordKeeper: string\n  pieces: PDPPieces[]\n  extraData: string\n}\n\nexport class PDPServer {\n  private readonly _serviceURL: string\n  private readonly _authHelper: PDPAuthHelper | null\n\n  /**\n   * Create a new PDPServer instance\n   * @param authHelper - PDPAuthHelper instance for signing operations\n   * @param serviceURL - The PDP service URL (e.g., https://pdp.provider.com)\n   */\n  constructor(authHelper: PDPAuthHelper | null, serviceURL: string) {\n    if (serviceURL.trim() === '') {\n      throw new Error('PDP service URL is required')\n    }\n    // Remove trailing slash from URL\n    this._serviceURL = serviceURL.replace(/\\/$/, '')\n    this._authHelper = authHelper\n  }\n\n  /**\n   * Create a new data set on the PDP server\n   * @param clientDataSetId - Unique ID for the client's dataset\n   * @param payee - Address that will receive payments (service provider)\n   * @param payer - Address that will pay for the storage (client)\n   * @param metadata - Metadata entries for the data set (key-value pairs)\n   * @param recordKeeper - Address of the Warm Storage contract\n   * @returns Promise that resolves with transaction hash and status URL\n   */\n  async createDataSet(\n    clientDataSetId: bigint,\n    payee: string,\n    payer: string,\n    metadata: MetadataEntry[],\n    recordKeeper: string\n  ): Promise<CreateDataSetResponse> {\n    // Validate metadata against contract limits\n    validateDataSetMetadata(metadata)\n\n    // Generate the EIP-712 signature for data set creation\n    const authData = await this.getAuthHelper().signCreateDataSet(clientDataSetId, payee, metadata)\n\n    // Prepare the extra data for the contract call\n    // This needs to match the DataSetCreateData struct in Warm Storage contract\n    const extraData = this._encodeDataSetCreateData({\n      payer,\n      clientDataSetId,\n      metadata,\n      signature: authData.signature,\n    })\n\n    return SP.createDataSet({\n      endpoint: this._serviceURL,\n      recordKeeper: recordKeeper as Hex,\n      extraData: `0x${extraData}`,\n    })\n  }\n\n  /**\n   * Creates a data set and adds pieces to it in a combined operation.\n   * Users can poll the status of the operation using the returned data set status URL.\n   * After which the user can use the returned transaction hash and data set ID to check the status of the piece addition.\n   * @param clientDataSetId  - Unique ID for the client's dataset\n   * @param payee - Address that will receive payments (service provider)\n   * @param payer - Address that will pay for the storage (client)\n   * @param recordKeeper - Address of the Warm Storage contract\n   * @param pieceDataArray - Array of piece data containing PieceCID CIDs and raw sizes\n   * @param metadata - Optional metadata for dataset and each of the pieces.\n   * @returns Promise that resolves with transaction hash and status URL\n   */\n  async createAndAddPieces(\n    clientDataSetId: bigint,\n    payee: string,\n    payer: string,\n    recordKeeper: string,\n    pieceDataArray: PieceCID[] | string[],\n    metadata: {\n      dataset?: MetadataEntry[]\n      pieces?: MetadataEntry[][]\n    }\n  ): Promise<CreateDataSetResponse> {\n    // Validate metadata against contract limits\n    if (metadata.dataset == null) {\n      metadata.dataset = []\n    }\n    validateDataSetMetadata(metadata.dataset)\n    metadata.pieces = PDPServer._processAddPiecesInputs(pieceDataArray, metadata.pieces)\n\n    // Generate the EIP-712 signature for data set creation\n    const createAuthData = await this.getAuthHelper().signCreateDataSet(clientDataSetId, payee, metadata.dataset)\n\n    // Prepare the extra data for the contract call\n    // This needs to match the DataSetCreateData struct in Warm Storage contract\n    const createExtraData = this._encodeDataSetCreateData({\n      payer,\n      clientDataSetId,\n      metadata: metadata.dataset,\n      signature: createAuthData.signature,\n    })\n\n    // Generate a random nonce for replay protection\n    const nonce = randU256()\n\n    const addAuthData = await this.getAuthHelper().signAddPieces(\n      clientDataSetId,\n      nonce,\n      pieceDataArray, // Pass PieceData[] directly to auth helper\n      metadata.pieces\n    )\n\n    const addExtraData = this._encodeAddPiecesExtraData({\n      nonce,\n      signature: addAuthData.signature,\n      metadata: metadata.pieces,\n    })\n\n    const abiCoder = ethers.AbiCoder.defaultAbiCoder()\n    const encoded = abiCoder.encode(['bytes', 'bytes'], [`0x${createExtraData}`, `0x${addExtraData}`])\n\n    return SP.createDataSetAndAddPieces({\n      endpoint: this._serviceURL,\n      recordKeeper: recordKeeper as Hex,\n      extraData: encoded as Hex,\n      pieces: pieceDataArray.map(asPieceCID).filter((t) => t != null),\n    })\n  }\n\n  private static _processAddPiecesInputs(\n    pieceDataArray: PieceCID[] | string[],\n    metadata?: MetadataEntry[][]\n  ): MetadataEntry[][] {\n    if (pieceDataArray.length === 0) {\n      throw new Error('At least one piece must be provided')\n    }\n\n    if (metadata != null) {\n      if (metadata.length !== pieceDataArray.length) {\n        throw new Error(`Metadata length (${metadata.length}) must match pieces length (${pieceDataArray.length})`)\n      }\n      for (let i = 0; i < metadata.length; i++) {\n        if (metadata[i] != null && metadata[i].length > 0) {\n          try {\n            validatePieceMetadata(metadata[i])\n          } catch (error: any) {\n            throw new Error(`Piece ${i} metadata validation failed: ${error.message}`)\n          }\n        }\n      }\n    }\n\n    // Validate all PieceCIDs\n    for (const pieceData of pieceDataArray) {\n      const pieceCid = asPieceCID(pieceData)\n      if (pieceCid == null) {\n        throw new Error(`Invalid PieceCID: ${String(pieceData)}`)\n      }\n    }\n    // If no metadata provided, create empty arrays for each piece\n    const finalMetadata = metadata ?? pieceDataArray.map(() => [])\n    return finalMetadata\n  }\n\n  /**\n   * Add pieces to an existing data set\n   * @param dataSetId - The ID of the data set to add pieces to\n   * @param clientDataSetId - The client's dataset ID used when creating the data set\n   * @param pieceDataArray - Array of piece data containing PieceCID CIDs and raw sizes\n   * @param metadata - Optional metadata for each piece (array of arrays, one per piece)\n   * @returns Promise that resolves when the pieces are added (201 Created)\n   * @throws Error if any CID is invalid\n   *\n   * @example\n   * ```typescript\n   * const pieceData = ['bafkzcibcd...']\n   * const metadata = [[{ key: 'snapshotDate', value: '20250711' }]]\n   * await pdpTool.addPieces(dataSetId, clientDataSetId, pieceData, metadata)\n   * ```\n   */\n  async addPieces(\n    dataSetId: number,\n    clientDataSetId: bigint,\n    pieceDataArray: PieceCID[] | string[],\n    metadata?: MetadataEntry[][]\n  ): Promise<AddPiecesResponse> {\n    const finalMetadata = PDPServer._processAddPiecesInputs(pieceDataArray, metadata)\n\n    // Generate a random nonce for replay protection\n    const nonce = randU256()\n\n    // Generate the EIP-712 signature for adding pieces\n    const authData = await this.getAuthHelper().signAddPieces(\n      clientDataSetId,\n      nonce,\n      pieceDataArray, // Pass PieceData[] directly to auth helper\n      finalMetadata\n    )\n\n    // Prepare the extra data for the contract call\n    // This needs to match what the Warm Storage contract expects for addPieces\n    const extraData = this._encodeAddPiecesExtraData({\n      nonce,\n      signature: authData.signature,\n      metadata: finalMetadata,\n    })\n\n    const { txHash, statusUrl } = await SP.addPieces({\n      endpoint: this._serviceURL,\n      dataSetId: BigInt(dataSetId),\n      pieces: pieceDataArray.map(asPieceCID).filter((t) => t != null),\n      extraData: `0x${extraData}`,\n    })\n    return {\n      message: `Pieces added to data set ID ${dataSetId} successfully`,\n      txHash,\n      statusUrl,\n    }\n  }\n\n  /**\n   * Check the status of a data set creation\n   * @param txHash - Transaction hash from createDataSet\n   * @returns Promise that resolves with the creation status\n   */\n  async getDataSetCreationStatus(txHash: string): Promise<DataSetCreationStatusResponse> {\n    const response = await fetch(`${this._serviceURL}/pdp/data-sets/created/${txHash}`, {\n      method: 'GET',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n    })\n\n    if (response.status === 404) {\n      throw new Error(`Data set creation not found for transaction hash: ${txHash}`)\n    }\n\n    if (response.status !== 200) {\n      const errorText = await response.text()\n      throw new Error(\n        `Failed to get data set creation status: ${response.status} ${response.statusText} - ${errorText}`\n      )\n    }\n\n    const data = await response.json()\n    return validateDataSetCreationStatusResponse(data)\n  }\n\n  /**\n   * Check the status of a piece addition transaction\n   * @param dataSetId - The data set ID\n   * @param txHash - Transaction hash from addPieces\n   * @returns Promise that resolves with the addition status\n   */\n  async getPieceAdditionStatus(dataSetId: number, txHash: string): Promise<PieceAdditionStatusResponse> {\n    const response = await fetch(`${this._serviceURL}/pdp/data-sets/${dataSetId}/pieces/added/${txHash}`, {\n      method: 'GET',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n    })\n\n    if (response.status === 404) {\n      throw new Error(`Piece addition not found for transaction: ${txHash}`)\n    }\n\n    if (response.status !== 200) {\n      const errorText = await response.text()\n      throw new Error(`Failed to get piece addition status: ${response.status} ${response.statusText} - ${errorText}`)\n    }\n\n    const data = await response.json()\n    return validatePieceAdditionStatusResponse(data)\n  }\n\n  /**\n   * Find a piece by PieceCID and size\n   * @param pieceCid - The PieceCID CID (as string or PieceCID object)\n   * @returns Piece information if found\n   */\n  async findPiece(pieceCid: string | PieceCID): Promise<FindPieceResponse> {\n    const parsedPieceCid = asPieceCID(pieceCid)\n    if (parsedPieceCid == null) {\n      throw new Error(`Invalid PieceCID: ${String(pieceCid)}`)\n    }\n\n    const piece = await SP.findPiece({\n      endpoint: this._serviceURL,\n      pieceCid: parsedPieceCid,\n    })\n    return {\n      pieceCid: piece,\n    }\n  }\n\n  /**\n   * Get indexing and IPNI status for a piece\n   *\n   * TODO: not used anywhere, remove?\n   *\n   * @param pieceCid - The PieceCID CID (as string or PieceCID object)\n   * @returns Piece status information including indexing and IPNI advertisement status\n   * @throws Error if piece not found or doesn't belong to service (404)\n   */\n  async getPieceStatus(pieceCid: string | PieceCID): Promise<PieceStatusResponse> {\n    const parsedPieceCid = asPieceCID(pieceCid)\n    if (parsedPieceCid == null) {\n      throw new Error(`Invalid PieceCID: ${String(pieceCid)}`)\n    }\n\n    const response = await fetch(`${this._serviceURL}/pdp/piece/${parsedPieceCid.toString()}/status`, {\n      method: 'GET',\n      headers: {\n        Accept: 'application/json',\n      },\n    })\n\n    if (response.status === 404) {\n      const errorText = await response.text()\n      throw new Error(`Piece not found or does not belong to service: ${errorText}`)\n    }\n\n    if (!response.ok) {\n      const errorText = await response.text()\n      throw new Error(`Failed to get piece status: ${response.status} ${response.statusText} - ${errorText}`)\n    }\n\n    const data = await response.json()\n    return validatePieceStatusResponse(data)\n  }\n\n  /**\n   * Upload a piece to the PDP server using the commp-last protocol.\n   *\n   * Accepts data as Uint8Array, AsyncIterable<Uint8Array>, or ReadableStream<Uint8Array>.\n   * For optimal performance with non-trivial sizes, prefer streaming types (AsyncIterable or ReadableStream)\n   * to avoid memory pressure and blocking behavior. See SIZE_CONSTANTS.MAX_UPLOAD_SIZE\n   * documentation for detailed guidance.\n   *\n   * @param data - The data to upload (Uint8Array, AsyncIterable, or ReadableStream)\n   * @param options - Optional upload options\n   */\n  async uploadPiece(\n    data: Uint8Array | AsyncIterable<Uint8Array> | ReadableStream<Uint8Array>,\n    options?: UploadPieceOptions\n  ): Promise<SP.UploadPieceResponse> {\n    if (data instanceof Uint8Array) {\n      // Check hard limit\n      if (data.length > Piece.MAX_UPLOAD_SIZE) {\n        throw new Error(\n          `Upload size ${data.length} exceeds maximum ${Piece.MAX_UPLOAD_SIZE} bytes (1 GiB with fr32 expansion)`\n        )\n      }\n\n      // Convert to async iterable with chunking\n      const iterable = Piece.uint8ArrayToAsyncIterable(data)\n\n      return SP.uploadPieceStreaming({\n        endpoint: this._serviceURL,\n        data: iterable,\n        size: data.length, // Known size for Content-Length\n        onProgress: options?.onProgress,\n        pieceCid: options?.pieceCid,\n        signal: options?.signal,\n      })\n    } else {\n      // AsyncIterable or ReadableStream path - no size limit check here (checked during streaming)\n      return SP.uploadPieceStreaming({\n        endpoint: this._serviceURL,\n        data,\n        // size unknown for streams\n        onProgress: options?.onProgress,\n        pieceCid: options?.pieceCid,\n        signal: options?.signal,\n      })\n    }\n  }\n\n  /**\n   * Download a piece from a service provider\n   * @param pieceCid - The PieceCID CID of the piece\n   * @returns The downloaded data\n   */\n  async downloadPiece(pieceCid: string | PieceCID): Promise<Uint8Array> {\n    const parsedPieceCid = asPieceCID(pieceCid)\n    if (parsedPieceCid == null) {\n      throw new Error(`Invalid PieceCID: ${String(pieceCid)}`)\n    }\n\n    // Use the retrieval endpoint configured at construction time\n    const downloadUrl = constructPieceUrl(this._serviceURL, parsedPieceCid)\n\n    const response = await fetch(downloadUrl)\n\n    // Use the shared download and validation function\n    return await downloadAndValidate(response, parsedPieceCid)\n  }\n\n  /**\n   * Get data set details from the PDP server\n   * @param dataSetId - The ID of the data set to fetch\n   * @returns Promise that resolves with data set data\n   */\n  async getDataSet(dataSetId: number): Promise<DataSetData> {\n    const data = await SP.getDataSet({\n      endpoint: this._serviceURL,\n      dataSetId: BigInt(dataSetId),\n    })\n\n    return {\n      id: data.id,\n      pieces: data.pieces.map((piece) => {\n        const pieceCid = Piece.parse(piece.pieceCid)\n        return {\n          pieceId: piece.pieceId,\n          pieceCid: pieceCid,\n          subPieceCid: pieceCid,\n          subPieceOffset: piece.subPieceOffset,\n        }\n      }),\n      nextChallengeEpoch: data.nextChallengeEpoch,\n    }\n  }\n\n  /**\n   * Delete a piece from a data set\n   * @param dataSetId - The ID of dataset to delete\n   * @param clientDataSetId - Client dataset ID of the dataset to delete\n   * @param pieceID -  The ID of the piece to delete\n   * @returns Promise for transaction hash of the delete operation\n   */\n  async deletePiece(dataSetId: number, clientDataSetId: bigint, pieceID: number): Promise<string> {\n    const authData = await this.getAuthHelper().signSchedulePieceRemovals(clientDataSetId, [BigInt(pieceID)])\n\n    const { txHash } = await SP.deletePiece({\n      endpoint: this._serviceURL,\n      dataSetId: BigInt(dataSetId),\n      pieceId: BigInt(pieceID),\n      extraData: ethers.AbiCoder.defaultAbiCoder().encode(['bytes'], [authData.signature]) as Hex,\n    })\n    return txHash\n  }\n\n  /**\n   * Encode DataSetCreateData for extraData field\n   * This matches the Solidity struct DataSetCreateData in Warm Storage contract\n   */\n  private _encodeDataSetCreateData(data: {\n    payer: string\n    clientDataSetId: bigint\n    metadata: MetadataEntry[]\n    signature: string\n  }): string {\n    // Ensure signature has 0x prefix\n    const signature = data.signature.startsWith('0x') ? data.signature : `0x${data.signature}`\n\n    // ABI encode the struct as a tuple\n    // DataSetCreateData struct:\n    // - address payer\n    // - uint256 clientDataSetId\n    // - string[] metadataKeys\n    // - string[] metadataValues\n    // - bytes signature\n    const keys = data.metadata.map((item) => item.key)\n    const values = data.metadata.map((item) => item.value)\n    const abiCoder = ethers.AbiCoder.defaultAbiCoder()\n    const encoded = abiCoder.encode(\n      ['address', 'uint256', 'string[]', 'string[]', 'bytes'],\n      [data.payer, data.clientDataSetId, keys, values, signature]\n    )\n\n    // Return hex string without 0x prefix (since we add it in the calling code)\n    return encoded.slice(2)\n  }\n\n  /**\n   * Encode AddPieces extraData for the addPieces operation\n   * Format: (uint256 nonce, string[][] metadataKeys, string[][] metadataValues, bytes signature)\n   */\n  private _encodeAddPiecesExtraData(data: { nonce: bigint; signature: string; metadata: MetadataEntry[][] }): string {\n    // Ensure signature has 0x prefix\n    const signature = data.signature.startsWith('0x') ? data.signature : `0x${data.signature}`\n    const keys = data.metadata.map((item) => item.map((item) => item.key))\n    const values = data.metadata.map((item) => item.map((item) => item.value))\n\n    // ABI encode as (uint256 nonce, string[][] metadataKeys, string[][] metadataValues, bytes signature)\n    const abiCoder = ethers.AbiCoder.defaultAbiCoder()\n    const encoded = abiCoder.encode(\n      ['uint256', 'string[][]', 'string[][]', 'bytes'],\n      [data.nonce, keys, values, signature]\n    )\n\n    // Return hex string without 0x prefix (since we add it in the calling code)\n    return encoded.slice(2)\n  }\n\n  /**\n   * Ping the service provider to check connectivity\n   * @returns Promise that resolves if provider is reachable (200 response)\n   * @throws Error if provider is not reachable or returns non-200 status\n   */\n  async ping(): Promise<void> {\n    const url = `${this._serviceURL}/pdp/ping`\n    const response = await fetch(url, {\n      method: 'GET',\n      headers: {},\n    })\n\n    if (response.status !== 200) {\n      const errorText = await response.text().catch(() => 'Unknown error')\n      throw new Error(`Provider ping failed: ${response.status} ${response.statusText} - ${errorText}`)\n    }\n  }\n\n  /**\n   * Get the service URL for this PDPServer instance\n   * @returns The service URL\n   */\n  getServiceURL(): string {\n    return this._serviceURL\n  }\n\n  getAuthHelper(): PDPAuthHelper {\n    if (this._authHelper == null) {\n      throw new Error('AuthHelper is not available for an operation that requires signing')\n    }\n    return this._authHelper\n  }\n}\n","import * as API from './api.js'\nimport { NODE_SIZE as Size } from './constant.js'\n\nexport { Size }\n\n/**\n * @param {number[]} bytes\n */\nexport const of = (...bytes) => from(bytes)\n\n/**\n * @param {Iterable<number>} bytes\n * @returns {API.MerkleTreeNode}\n */\nexport const from = (bytes) => {\n  /* c8 ignore next 7 */\n  if (bytes instanceof Uint8Array) {\n    if (bytes.length > Size) {\n      return bytes.subarray(0, Size)\n    } else if (bytes.length == Size) {\n      return bytes\n    }\n  }\n\n  const node = new Uint8Array(Size)\n  node.set([...bytes])\n  return node\n}\n\nexport const empty = () => EMPTY\n\nconst EMPTY = from(new Uint8Array(Size).fill(0))\nObject.freeze(EMPTY.buffer)\n","import * as API from './api.js'\n\n/**\n * Returns the base 2 logarithm of the given `n`, rounded down.\n *\n * @param {API.uint64} n\n * @returns {number}\n */\nexport const log2Floor = (n) => {\n  let result = 0n\n  while ((n >>= 1n)) result++\n  return Number(result)\n}\n\n/**\n * Return the integer logarithm with ceiling for 64 bit unsigned ints.\n *\n * @param {API.uint64} n\n */\nexport const log2Ceil = (n) => (n <= 1n ? 0 : log2Floor(BigInt(n) - 1n) + 1)\n\n/**\n * @param {API.uint64} n\n */\nexport const trailingZeros64 = (n) => {\n  if (n === 0n) {\n    return 64\n  }\n\n  let count = 0\n  while ((n & 1n) === 0n) {\n    n >>= 1n\n    count++\n  }\n\n  return count\n}\n\n/**\n * @param {API.uint64} value\n */\nexport const onesCount64 = (value) => {\n  let count = 0\n  const mask = 1n\n\n  for (let i = 0n; i < 64n; i++) {\n    if ((value & (mask << i)) !== 0n) {\n      count++\n    }\n  }\n\n  return count\n}\n\n/**\n * @param {API.uint64} n\n * @returns {API.uint64}\n */\nexport const pow2 = (n) => 1n << n\n","import * as API from '../api.js'\nimport { Size as NodeSize } from '../node.js'\nimport * as Proof from '../proof.js'\nexport { computeNode } from '../proof.js'\n\n// The value is an unsigned, 32-bit integer that is always numerically greater\n// than the highest index in the array. This means our tree can represent a\n// piece up to 128 GiB in size.\nexport const MAX_LEAF_COUNT = 2 ** 32 - 1\n\n/**\n * Allocates a tree for a given amount of leafs.\n *\n * The construction rounds the amount of leafs up to the nearest two-power with\n * zeroed nodes to ensure that the tree is perfect and hence all internal node's\n * have well-defined children.\n *\n * @param {number} leafs\n */\nexport function allocate(leafs) {\n  const adjustedLeafs = 2 ** Math.ceil(Math.log2(leafs))\n\n  if (adjustedLeafs > MAX_LEAF_COUNT) {\n    throw new RangeError(\n      `too many leafs ${adjustedLeafs} exceeds ${MAX_LEAF_COUNT} limit`\n    )\n  }\n\n  const height = Math.ceil(Math.log2(adjustedLeafs))\n  const nodes = new Array(height + 1)\n\n  for (const level of nodes.keys()) {\n    nodes[level] = new Array(1 << level)\n  }\n\n  return new PieceTree({ nodes, height })\n}\n\n/**\n * @param {API.TreeData} tree\n */\nconst depth = (tree) => {\n  return tree.nodes.length\n}\n\n/**\n *\n * @param {API.TreeData} tree\n * @returns {API.MerkleTreeNode}\n */\nexport const root = (tree) => {\n  return tree.nodes[0][0]\n}\n\n/**\n * @param {Uint8Array} source\n * @returns {API.MerkleTreeNode[]}\n */\nexport const split = (source) => {\n  const count = source.length / NodeSize\n  const chunks = new Array(count)\n  for (let n = 0; n < count; n++) {\n    const offset = n * NodeSize\n    const chunk = source.subarray(offset, offset + NodeSize)\n    chunks[n] = chunk\n  }\n  return chunks\n}\n\n/**\n * @param {API.Fr23Padded} source\n */\nexport const build = (source) => fromChunks(split(source))\n\n/**\n * @param {API.MerkleTreeNode[]} chunks\n */\nexport const fromChunks = (chunks) => {\n  if (chunks.length === 0) {\n    throw new RangeError('Empty source')\n  }\n\n  const leafs = chunks //await Promise.all(chunks.map(truncatedHash))\n  return fromLeafs(leafs)\n}\n\n/**\n * @param {API.MerkleTreeNode[]} leafs\n * @returns {API.PieceTree}\n */\nexport const fromLeafs = (leafs) => {\n  const tree = allocate(leafs.length)\n  // Set the padded leaf nodes\n  tree.nodes[depth(tree) - 1] = padLeafs(leafs)\n  let parentNodes = tree.nodes[depth(tree) - 1]\n  // Construct the Merkle tree bottom-up, starting from the leafs\n  // Note the -1 due to 0-indexing the root level\n  for (let level = depth(tree) - 2; level >= 0; level--) {\n    /** @type {API.MerkleTreeNode[]} */\n    const currentLevel = new Array(Math.ceil(parentNodes.length / 2))\n    // Traverse the level left to right\n    for (let i = 0; i + 1 < parentNodes.length; i = i + 2) {\n      currentLevel[Math.floor(i / 2)] = Proof.computeNode(\n        parentNodes[i],\n        parentNodes[i + 1]\n      )\n    }\n    tree.nodes[level] = currentLevel\n    parentNodes = currentLevel\n  }\n\n  return new PieceTree(tree)\n}\n\n/**\n * @param {API.MerkleTreeNode[]} leafs\n * @returns {API.MerkleTreeNode[]}\n */\nexport const padLeafs = (leafs) => {\n  const paddingAmount = (1 << Math.ceil(Math.log2(leafs.length))) - leafs.length\n  // arrays are zeroed by default in JS\n  const paddingLeafs = new Array(paddingAmount)\n\n  return [...leafs, ...paddingLeafs]\n}\n\n/**\n * @implements {API.PieceTree}\n */\nclass PieceTree {\n  /**\n   * @param {object} data\n   * @param {API.MerkleTreeNode[][]} data.nodes\n   * @param {number} data.height\n   */\n  constructor({ nodes, height }) {\n    this.nodes = nodes\n    this.height = height\n  }\n\n  get root() {\n    return root(this)\n  }\n  get leafs() {\n    const { nodes } = this\n    return nodes[nodes.length - 1]\n  }\n  get leafCount() {\n    return 2 ** this.height\n  }\n  /**\n   *\n   * @param {number} level\n   * @param {number} index\n   */\n  node(level, index) {\n    const { nodes } = this\n    return nodes[level][index]\n  }\n}\n","/**\n * Internal Merkle-Damgard hash utils.\n * @module\n */\nimport { type Input, Hash, abytes, aexists, aoutput, clean, createView, toBytes } from './utils.ts';\n\n/** Polyfill for Safari 14. https://caniuse.com/mdn-javascript_builtins_dataview_setbiguint64 */\nexport function setBigUint64(\n  view: DataView,\n  byteOffset: number,\n  value: bigint,\n  isLE: boolean\n): void {\n  if (typeof view.setBigUint64 === 'function') return view.setBigUint64(byteOffset, value, isLE);\n  const _32n = BigInt(32);\n  const _u32_max = BigInt(0xffffffff);\n  const wh = Number((value >> _32n) & _u32_max);\n  const wl = Number(value & _u32_max);\n  const h = isLE ? 4 : 0;\n  const l = isLE ? 0 : 4;\n  view.setUint32(byteOffset + h, wh, isLE);\n  view.setUint32(byteOffset + l, wl, isLE);\n}\n\n/** Choice: a ? b : c */\nexport function Chi(a: number, b: number, c: number): number {\n  return (a & b) ^ (~a & c);\n}\n\n/** Majority function, true if any two inputs is true. */\nexport function Maj(a: number, b: number, c: number): number {\n  return (a & b) ^ (a & c) ^ (b & c);\n}\n\n/**\n * Merkle-Damgard hash construction base class.\n * Could be used to create MD5, RIPEMD, SHA1, SHA2.\n */\nexport abstract class HashMD<T extends HashMD<T>> extends Hash<T> {\n  protected abstract process(buf: DataView, offset: number): void;\n  protected abstract get(): number[];\n  protected abstract set(...args: number[]): void;\n  abstract destroy(): void;\n  protected abstract roundClean(): void;\n\n  readonly blockLen: number;\n  readonly outputLen: number;\n  readonly padOffset: number;\n  readonly isLE: boolean;\n\n  // For partial updates less than block size\n  protected buffer: Uint8Array;\n  protected view: DataView;\n  protected finished = false;\n  protected length = 0;\n  protected pos = 0;\n  protected destroyed = false;\n\n  constructor(blockLen: number, outputLen: number, padOffset: number, isLE: boolean) {\n    super();\n    this.blockLen = blockLen;\n    this.outputLen = outputLen;\n    this.padOffset = padOffset;\n    this.isLE = isLE;\n    this.buffer = new Uint8Array(blockLen);\n    this.view = createView(this.buffer);\n  }\n  update(data: Input): this {\n    aexists(this);\n    data = toBytes(data);\n    abytes(data);\n    const { view, buffer, blockLen } = this;\n    const len = data.length;\n    for (let pos = 0; pos < len; ) {\n      const take = Math.min(blockLen - this.pos, len - pos);\n      // Fast path: we have at least one block in input, cast it to view and process\n      if (take === blockLen) {\n        const dataView = createView(data);\n        for (; blockLen <= len - pos; pos += blockLen) this.process(dataView, pos);\n        continue;\n      }\n      buffer.set(data.subarray(pos, pos + take), this.pos);\n      this.pos += take;\n      pos += take;\n      if (this.pos === blockLen) {\n        this.process(view, 0);\n        this.pos = 0;\n      }\n    }\n    this.length += data.length;\n    this.roundClean();\n    return this;\n  }\n  digestInto(out: Uint8Array): void {\n    aexists(this);\n    aoutput(out, this);\n    this.finished = true;\n    // Padding\n    // We can avoid allocation of buffer for padding completely if it\n    // was previously not allocated here. But it won't change performance.\n    const { buffer, view, blockLen, isLE } = this;\n    let { pos } = this;\n    // append the bit '1' to the message\n    buffer[pos++] = 0b10000000;\n    clean(this.buffer.subarray(pos));\n    // we have less than padOffset left in buffer, so we cannot put length in\n    // current block, need process it and pad again\n    if (this.padOffset > blockLen - pos) {\n      this.process(view, 0);\n      pos = 0;\n    }\n    // Pad until full block byte with zeros\n    for (let i = pos; i < blockLen; i++) buffer[i] = 0;\n    // Note: sha512 requires length to be 128bit integer, but length in JS will overflow before that\n    // You need to write around 2 exabytes (u64_max / 8 / (1024**6)) for this to happen.\n    // So we just write lowest 64 bits of that value.\n    setBigUint64(view, blockLen - 8, BigInt(this.length * 8), isLE);\n    this.process(view, 0);\n    const oview = createView(out);\n    const len = this.outputLen;\n    // NOTE: we do division by 4 later, which should be fused in single op with modulo by JIT\n    if (len % 4) throw new Error('_sha2: outputLen should be aligned to 32bit');\n    const outLen = len / 4;\n    const state = this.get();\n    if (outLen > state.length) throw new Error('_sha2: outputLen bigger than state');\n    for (let i = 0; i < outLen; i++) oview.setUint32(4 * i, state[i], isLE);\n  }\n  digest(): Uint8Array {\n    const { buffer, outputLen } = this;\n    this.digestInto(buffer);\n    const res = buffer.slice(0, outputLen);\n    this.destroy();\n    return res;\n  }\n  _cloneInto(to?: T): T {\n    to ||= new (this.constructor as any)() as T;\n    to.set(...this.get());\n    const { blockLen, buffer, length, finished, destroyed, pos } = this;\n    to.destroyed = destroyed;\n    to.finished = finished;\n    to.length = length;\n    to.pos = pos;\n    if (length % blockLen) to.buffer.set(buffer);\n    return to;\n  }\n  clone(): T {\n    return this._cloneInto();\n  }\n}\n\n/**\n * Initial SHA-2 state: fractional parts of square roots of first 16 primes 2..53.\n * Check out `test/misc/sha2-gen-iv.js` for recomputation guide.\n */\n\n/** Initial SHA256 state. Bits 0..32 of frac part of sqrt of primes 2..19 */\nexport const SHA256_IV: Uint32Array = /* @__PURE__ */ Uint32Array.from([\n  0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19,\n]);\n\n/** Initial SHA224 state. Bits 32..64 of frac part of sqrt of primes 23..53 */\nexport const SHA224_IV: Uint32Array = /* @__PURE__ */ Uint32Array.from([\n  0xc1059ed8, 0x367cd507, 0x3070dd17, 0xf70e5939, 0xffc00b31, 0x68581511, 0x64f98fa7, 0xbefa4fa4,\n]);\n\n/** Initial SHA384 state. Bits 0..64 of frac part of sqrt of primes 23..53 */\nexport const SHA384_IV: Uint32Array = /* @__PURE__ */ Uint32Array.from([\n  0xcbbb9d5d, 0xc1059ed8, 0x629a292a, 0x367cd507, 0x9159015a, 0x3070dd17, 0x152fecd8, 0xf70e5939,\n  0x67332667, 0xffc00b31, 0x8eb44a87, 0x68581511, 0xdb0c2e0d, 0x64f98fa7, 0x47b5481d, 0xbefa4fa4,\n]);\n\n/** Initial SHA512 state. Bits 0..64 of frac part of sqrt of primes 2..19 */\nexport const SHA512_IV: Uint32Array = /* @__PURE__ */ Uint32Array.from([\n  0x6a09e667, 0xf3bcc908, 0xbb67ae85, 0x84caa73b, 0x3c6ef372, 0xfe94f82b, 0xa54ff53a, 0x5f1d36f1,\n  0x510e527f, 0xade682d1, 0x9b05688c, 0x2b3e6c1f, 0x1f83d9ab, 0xfb41bd6b, 0x5be0cd19, 0x137e2179,\n]);\n","import type { Address, Hex } from 'viem'\nimport { pad } from 'viem'\n\n/**\n * Convert capability arrays to object map\n * @param keys - Array of capability keys\n * @param values - Array of capability values\n * @returns Object map of capabilities\n */\nexport function capabilitiesListToObject(keys: readonly string[], values: readonly Hex[]): Record<string, Hex> {\n  const capabilities: Record<string, Hex> = {}\n  for (let i = 0; i < keys.length; i++) {\n    capabilities[keys[i]] = values[i]\n  }\n  return capabilities\n}\n\n/**\n * Matches the behavior of `address(uint160(BigEndian.decode(values[i])))`\n */\nexport function decodeAddressCapability(capabilityValue: Hex): Address {\n  if (capabilityValue.length > 66) {\n    return '0x0000000000000000000000000000000000000000'\n  }\n  if (capabilityValue.length > 42) {\n    return `0x${capabilityValue.slice(-40)}`\n  }\n  if (capabilityValue.length < 42) {\n    return pad(capabilityValue, { size: 20 })\n  }\n  return capabilityValue\n}\n","import type {\n  AbiParameter,\n  AbiParameterKind,\n  AbiParametersToPrimitiveTypes,\n  AbiParameterToPrimitiveType,\n} from 'abitype'\nimport * as AbiParameters from '../AbiParameters.js'\nimport * as Address from '../Address.js'\nimport * as Bytes from '../Bytes.js'\nimport * as Errors from '../Errors.js'\nimport * as Hex from '../Hex.js'\nimport { integerRegex } from '../Solidity.js'\nimport type * as Cursor from './cursor.js'\nimport type { Compute, IsNarrowable, UnionToIntersection } from './types.js'\n\n/** @internal */\nexport type ParameterToPrimitiveType<\n  abiParameter extends AbiParameter | { name: string; type: unknown },\n  abiParameterKind extends AbiParameterKind = AbiParameterKind,\n> = AbiParameterToPrimitiveType<abiParameter, abiParameterKind>\n\n/** @internal */\nexport type PreparedParameter = { dynamic: boolean; encoded: Hex.Hex }\n\n/** @internal */\nexport type ToObject<\n  parameters extends readonly AbiParameter[],\n  kind extends AbiParameterKind = AbiParameterKind,\n> = IsNarrowable<parameters, AbiParameters.AbiParameters> extends true\n  ? Compute<\n      UnionToIntersection<\n        {\n          [index in keyof parameters]: parameters[index] extends {\n            name: infer name extends string\n          }\n            ? {\n                [key in name]: AbiParameterToPrimitiveType<\n                  parameters[index],\n                  kind\n                >\n              }\n            : {\n                [key in index]: AbiParameterToPrimitiveType<\n                  parameters[index],\n                  kind\n                >\n              }\n        }[number]\n      >\n    >\n  : unknown\n\n/** @internal */\nexport type ToPrimitiveTypes<\n  abiParameters extends readonly AbiParameter[],\n  abiParameterKind extends AbiParameterKind = AbiParameterKind,\n> = AbiParametersToPrimitiveTypes<abiParameters, abiParameterKind>\n\n/** @internal */\nexport type Tuple = ParameterToPrimitiveType<TupleAbiParameter>\n\n/** @internal */\nexport function decodeParameter(\n  cursor: Cursor.Cursor,\n  param: AbiParameters.Parameter,\n  options: { checksumAddress?: boolean | undefined; staticPosition: number },\n) {\n  const { checksumAddress, staticPosition } = options\n  const arrayComponents = getArrayComponents(param.type)\n  if (arrayComponents) {\n    const [length, type] = arrayComponents\n    return decodeArray(\n      cursor,\n      { ...param, type },\n      { checksumAddress, length, staticPosition },\n    )\n  }\n  if (param.type === 'tuple')\n    return decodeTuple(cursor, param as TupleAbiParameter, {\n      checksumAddress,\n      staticPosition,\n    })\n  if (param.type === 'address')\n    return decodeAddress(cursor, { checksum: checksumAddress })\n  if (param.type === 'bool') return decodeBool(cursor)\n  if (param.type.startsWith('bytes'))\n    return decodeBytes(cursor, param, { staticPosition })\n  if (param.type.startsWith('uint') || param.type.startsWith('int'))\n    return decodeNumber(cursor, param)\n  if (param.type === 'string') return decodeString(cursor, { staticPosition })\n  throw new AbiParameters.InvalidTypeError(param.type)\n}\n\nexport declare namespace decodeParameter {\n  type ErrorType =\n    | decodeArray.ErrorType\n    | decodeTuple.ErrorType\n    | decodeAddress.ErrorType\n    | decodeBool.ErrorType\n    | decodeBytes.ErrorType\n    | decodeNumber.ErrorType\n    | decodeString.ErrorType\n    | AbiParameters.InvalidTypeError\n    | Errors.GlobalErrorType\n}\n\nconst sizeOfLength = 32\nconst sizeOfOffset = 32\n\n/** @internal */\nexport function decodeAddress(\n  cursor: Cursor.Cursor,\n  options: { checksum?: boolean | undefined } = {},\n) {\n  const { checksum = false } = options\n  const value = cursor.readBytes(32)\n  const wrap = (address: Hex.Hex) =>\n    checksum ? Address.checksum(address) : address\n  return [wrap(Hex.fromBytes(Bytes.slice(value, -20))), 32]\n}\n\nexport declare namespace decodeAddress {\n  type ErrorType =\n    | Hex.fromBytes.ErrorType\n    | Bytes.slice.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function decodeArray(\n  cursor: Cursor.Cursor,\n  param: AbiParameters.Parameter,\n  options: {\n    checksumAddress?: boolean | undefined\n    length: number | null\n    staticPosition: number\n  },\n) {\n  const { checksumAddress, length, staticPosition } = options\n\n  // If the length of the array is not known in advance (dynamic array),\n  // this means we will need to wonder off to the pointer and decode.\n  if (!length) {\n    // Dealing with a dynamic type, so get the offset of the array data.\n    const offset = Bytes.toNumber(cursor.readBytes(sizeOfOffset))\n\n    // Start is the static position of current slot + offset.\n    const start = staticPosition + offset\n    const startOfData = start + sizeOfLength\n\n    // Get the length of the array from the offset.\n    cursor.setPosition(start)\n    const length = Bytes.toNumber(cursor.readBytes(sizeOfLength))\n\n    // Check if the array has any dynamic children.\n    const dynamicChild = hasDynamicChild(param)\n\n    let consumed = 0\n    const value: unknown[] = []\n    for (let i = 0; i < length; ++i) {\n      // If any of the children is dynamic, then all elements will be offset pointer, thus size of one slot (32 bytes).\n      // Otherwise, elements will be the size of their encoding (consumed bytes).\n      cursor.setPosition(startOfData + (dynamicChild ? i * 32 : consumed))\n      const [data, consumed_] = decodeParameter(cursor, param, {\n        checksumAddress,\n        staticPosition: startOfData,\n      })\n      consumed += consumed_\n      value.push(data)\n    }\n\n    // As we have gone wondering, restore to the original position + next slot.\n    cursor.setPosition(staticPosition + 32)\n    return [value, 32]\n  }\n\n  // If the length of the array is known in advance,\n  // and the length of an element deeply nested in the array is not known,\n  // we need to decode the offset of the array data.\n  if (hasDynamicChild(param)) {\n    // Dealing with dynamic types, so get the offset of the array data.\n    const offset = Bytes.toNumber(cursor.readBytes(sizeOfOffset))\n\n    // Start is the static position of current slot + offset.\n    const start = staticPosition + offset\n\n    const value: unknown[] = []\n    for (let i = 0; i < length; ++i) {\n      // Move cursor along to the next slot (next offset pointer).\n      cursor.setPosition(start + i * 32)\n      const [data] = decodeParameter(cursor, param, {\n        checksumAddress,\n        staticPosition: start,\n      })\n      value.push(data)\n    }\n\n    // As we have gone wondering, restore to the original position + next slot.\n    cursor.setPosition(staticPosition + 32)\n    return [value, 32]\n  }\n\n  // If the length of the array is known in advance and the array is deeply static,\n  // then we can just decode each element in sequence.\n  let consumed = 0\n  const value: unknown[] = []\n  for (let i = 0; i < length; ++i) {\n    const [data, consumed_] = decodeParameter(cursor, param, {\n      checksumAddress,\n      staticPosition: staticPosition + consumed,\n    })\n    consumed += consumed_\n    value.push(data)\n  }\n  return [value, consumed]\n}\n\nexport declare namespace decodeArray {\n  type ErrorType = Bytes.toNumber.ErrorType | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function decodeBool(cursor: Cursor.Cursor) {\n  return [Bytes.toBoolean(cursor.readBytes(32), { size: 32 }), 32]\n}\n\nexport declare namespace decodeBool {\n  type ErrorType = Bytes.toBoolean.ErrorType | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function decodeBytes(\n  cursor: Cursor.Cursor,\n  param: AbiParameters.Parameter,\n  { staticPosition }: { staticPosition: number },\n) {\n  const [_, size] = param.type.split('bytes')\n  if (!size) {\n    // Dealing with dynamic types, so get the offset of the bytes data.\n    const offset = Bytes.toNumber(cursor.readBytes(32))\n\n    // Set position of the cursor to start of bytes data.\n    cursor.setPosition(staticPosition + offset)\n\n    const length = Bytes.toNumber(cursor.readBytes(32))\n\n    // If there is no length, we have zero data.\n    if (length === 0) {\n      // As we have gone wondering, restore to the original position + next slot.\n      cursor.setPosition(staticPosition + 32)\n      return ['0x', 32]\n    }\n\n    const data = cursor.readBytes(length)\n\n    // As we have gone wondering, restore to the original position + next slot.\n    cursor.setPosition(staticPosition + 32)\n    return [Hex.fromBytes(data), 32]\n  }\n\n  const value = Hex.fromBytes(cursor.readBytes(Number.parseInt(size, 10), 32))\n  return [value, 32]\n}\n\nexport declare namespace decodeBytes {\n  type ErrorType =\n    | Hex.fromBytes.ErrorType\n    | Bytes.toNumber.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function decodeNumber(\n  cursor: Cursor.Cursor,\n  param: AbiParameters.Parameter,\n) {\n  const signed = param.type.startsWith('int')\n  const size = Number.parseInt(param.type.split('int')[1] || '256', 10)\n  const value = cursor.readBytes(32)\n  return [\n    size > 48\n      ? Bytes.toBigInt(value, { signed })\n      : Bytes.toNumber(value, { signed }),\n    32,\n  ]\n}\n\nexport declare namespace decodeNumber {\n  type ErrorType =\n    | Bytes.toNumber.ErrorType\n    | Bytes.toBigInt.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport type TupleAbiParameter = AbiParameters.Parameter & {\n  components: readonly AbiParameters.Parameter[]\n}\n\n/** @internal */\nexport function decodeTuple(\n  cursor: Cursor.Cursor,\n  param: TupleAbiParameter,\n  options: { checksumAddress?: boolean | undefined; staticPosition: number },\n) {\n  const { checksumAddress, staticPosition } = options\n\n  // Tuples can have unnamed components (i.e. they are arrays), so we must\n  // determine whether the tuple is named or unnamed. In the case of a named\n  // tuple, the value will be an object where each property is the name of the\n  // component. In the case of an unnamed tuple, the value will be an array.\n  const hasUnnamedChild =\n    param.components.length === 0 || param.components.some(({ name }) => !name)\n\n  // Initialize the value to an object or an array, depending on whether the\n  // tuple is named or unnamed.\n  const value: any = hasUnnamedChild ? [] : {}\n  let consumed = 0\n\n  // If the tuple has a dynamic child, we must first decode the offset to the\n  // tuple data.\n  if (hasDynamicChild(param)) {\n    // Dealing with dynamic types, so get the offset of the tuple data.\n    const offset = Bytes.toNumber(cursor.readBytes(sizeOfOffset))\n\n    // Start is the static position of referencing slot + offset.\n    const start = staticPosition + offset\n\n    for (let i = 0; i < param.components.length; ++i) {\n      const component = param.components[i]!\n      cursor.setPosition(start + consumed)\n      const [data, consumed_] = decodeParameter(cursor, component, {\n        checksumAddress,\n        staticPosition: start,\n      })\n      consumed += consumed_\n      value[hasUnnamedChild ? i : component?.name!] = data\n    }\n\n    // As we have gone wondering, restore to the original position + next slot.\n    cursor.setPosition(staticPosition + 32)\n    return [value, 32]\n  }\n\n  // If the tuple has static children, we can just decode each component\n  // in sequence.\n  for (let i = 0; i < param.components.length; ++i) {\n    const component = param.components[i]!\n    const [data, consumed_] = decodeParameter(cursor, component, {\n      checksumAddress,\n      staticPosition,\n    })\n    value[hasUnnamedChild ? i : component?.name!] = data\n    consumed += consumed_\n  }\n  return [value, consumed]\n}\n\nexport declare namespace decodeTuple {\n  type ErrorType = Bytes.toNumber.ErrorType | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function decodeString(\n  cursor: Cursor.Cursor,\n  { staticPosition }: { staticPosition: number },\n) {\n  // Get offset to start of string data.\n  const offset = Bytes.toNumber(cursor.readBytes(32))\n\n  // Start is the static position of current slot + offset.\n  const start = staticPosition + offset\n  cursor.setPosition(start)\n\n  const length = Bytes.toNumber(cursor.readBytes(32))\n\n  // If there is no length, we have zero data (empty string).\n  if (length === 0) {\n    cursor.setPosition(staticPosition + 32)\n    return ['', 32]\n  }\n\n  const data = cursor.readBytes(length, 32)\n  const value = Bytes.toString(Bytes.trimLeft(data))\n\n  // As we have gone wondering, restore to the original position + next slot.\n  cursor.setPosition(staticPosition + 32)\n\n  return [value, 32]\n}\n\nexport declare namespace decodeString {\n  type ErrorType =\n    | Bytes.toNumber.ErrorType\n    | Bytes.toString.ErrorType\n    | Bytes.trimLeft.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function prepareParameters<\n  const parameters extends AbiParameters.AbiParameters,\n>({\n  checksumAddress,\n  parameters,\n  values,\n}: {\n  checksumAddress?: boolean | undefined\n  parameters: parameters\n  values: parameters extends AbiParameters.AbiParameters\n    ? ToPrimitiveTypes<parameters>\n    : never\n}) {\n  const preparedParameters: PreparedParameter[] = []\n  for (let i = 0; i < parameters.length; i++) {\n    preparedParameters.push(\n      prepareParameter({\n        checksumAddress,\n        parameter: parameters[i]!,\n        value: values[i],\n      }),\n    )\n  }\n  return preparedParameters\n}\n\n/** @internal */\nexport declare namespace prepareParameters {\n  type ErrorType = prepareParameter.ErrorType | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function prepareParameter<\n  const parameter extends AbiParameters.Parameter,\n>({\n  checksumAddress = false,\n  parameter: parameter_,\n  value,\n}: {\n  parameter: parameter\n  value: parameter extends AbiParameters.Parameter\n    ? ParameterToPrimitiveType<parameter>\n    : never\n  checksumAddress?: boolean | undefined\n}): PreparedParameter {\n  const parameter = parameter_ as AbiParameters.Parameter\n\n  const arrayComponents = getArrayComponents(parameter.type)\n  if (arrayComponents) {\n    const [length, type] = arrayComponents\n    return encodeArray(value, {\n      checksumAddress,\n      length,\n      parameter: {\n        ...parameter,\n        type,\n      },\n    })\n  }\n  if (parameter.type === 'tuple') {\n    return encodeTuple(value as unknown as Tuple, {\n      checksumAddress,\n      parameter: parameter as TupleAbiParameter,\n    })\n  }\n  if (parameter.type === 'address') {\n    return encodeAddress(value as unknown as Hex.Hex, {\n      checksum: checksumAddress,\n    })\n  }\n  if (parameter.type === 'bool') {\n    return encodeBoolean(value as unknown as boolean)\n  }\n  if (parameter.type.startsWith('uint') || parameter.type.startsWith('int')) {\n    const signed = parameter.type.startsWith('int')\n    const [, , size = '256'] = integerRegex.exec(parameter.type) ?? []\n    return encodeNumber(value as unknown as number, {\n      signed,\n      size: Number(size),\n    })\n  }\n  if (parameter.type.startsWith('bytes')) {\n    return encodeBytes(value as unknown as Hex.Hex, { type: parameter.type })\n  }\n  if (parameter.type === 'string') {\n    return encodeString(value as unknown as string)\n  }\n  throw new AbiParameters.InvalidTypeError(parameter.type)\n}\n\n/** @internal */\nexport declare namespace prepareParameter {\n  type ErrorType =\n    | encodeArray.ErrorType\n    | encodeTuple.ErrorType\n    | encodeAddress.ErrorType\n    | encodeBoolean.ErrorType\n    | encodeBytes.ErrorType\n    | encodeString.ErrorType\n    | AbiParameters.InvalidTypeError\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function encode(preparedParameters: PreparedParameter[]): Hex.Hex {\n  // 1. Compute the size of the static part of the parameters.\n  let staticSize = 0\n  for (let i = 0; i < preparedParameters.length; i++) {\n    const { dynamic, encoded } = preparedParameters[i]!\n    if (dynamic) staticSize += 32\n    else staticSize += Hex.size(encoded)\n  }\n\n  // 2. Split the parameters into static and dynamic parts.\n  const staticParameters: Hex.Hex[] = []\n  const dynamicParameters: Hex.Hex[] = []\n  let dynamicSize = 0\n  for (let i = 0; i < preparedParameters.length; i++) {\n    const { dynamic, encoded } = preparedParameters[i]!\n    if (dynamic) {\n      staticParameters.push(\n        Hex.fromNumber(staticSize + dynamicSize, { size: 32 }),\n      )\n      dynamicParameters.push(encoded)\n      dynamicSize += Hex.size(encoded)\n    } else {\n      staticParameters.push(encoded)\n    }\n  }\n\n  // 3. Concatenate static and dynamic parts.\n  return Hex.concat(...staticParameters, ...dynamicParameters)\n}\n\n/** @internal */\nexport declare namespace encode {\n  type ErrorType =\n    | Hex.concat.ErrorType\n    | Hex.fromNumber.ErrorType\n    | Hex.size.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function encodeAddress(\n  value: Hex.Hex,\n  options: { checksum: boolean },\n): PreparedParameter {\n  const { checksum = false } = options\n  Address.assert(value, { strict: checksum })\n  return {\n    dynamic: false,\n    encoded: Hex.padLeft(value.toLowerCase() as Hex.Hex),\n  }\n}\n\n/** @internal */\nexport declare namespace encodeAddress {\n  type ErrorType =\n    | Address.assert.ErrorType\n    | Hex.padLeft.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function encodeArray<const parameter extends AbiParameters.Parameter>(\n  value: ParameterToPrimitiveType<parameter>,\n  options: {\n    checksumAddress?: boolean | undefined\n    length: number | null\n    parameter: parameter\n  },\n): PreparedParameter {\n  const { checksumAddress, length, parameter } = options\n\n  const dynamic = length === null\n\n  if (!Array.isArray(value)) throw new AbiParameters.InvalidArrayError(value)\n  if (!dynamic && value.length !== length)\n    throw new AbiParameters.ArrayLengthMismatchError({\n      expectedLength: length!,\n      givenLength: value.length,\n      type: `${parameter.type}[${length}]`,\n    })\n\n  let dynamicChild = false\n  const preparedParameters: PreparedParameter[] = []\n  for (let i = 0; i < value.length; i++) {\n    const preparedParam = prepareParameter({\n      checksumAddress,\n      parameter,\n      value: value[i],\n    })\n    if (preparedParam.dynamic) dynamicChild = true\n    preparedParameters.push(preparedParam)\n  }\n\n  if (dynamic || dynamicChild) {\n    const data = encode(preparedParameters)\n    if (dynamic) {\n      const length = Hex.fromNumber(preparedParameters.length, { size: 32 })\n      return {\n        dynamic: true,\n        encoded:\n          preparedParameters.length > 0 ? Hex.concat(length, data) : length,\n      }\n    }\n    if (dynamicChild) return { dynamic: true, encoded: data }\n  }\n  return {\n    dynamic: false,\n    encoded: Hex.concat(...preparedParameters.map(({ encoded }) => encoded)),\n  }\n}\n\n/** @internal */\nexport declare namespace encodeArray {\n  type ErrorType =\n    | AbiParameters.InvalidArrayError\n    | AbiParameters.ArrayLengthMismatchError\n    | Hex.concat.ErrorType\n    | Hex.fromNumber.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function encodeBytes(\n  value: Hex.Hex,\n  { type }: { type: string },\n): PreparedParameter {\n  const [, parametersize] = type.split('bytes')\n  const bytesSize = Hex.size(value)\n  if (!parametersize) {\n    let value_ = value\n    // If the size is not divisible by 32 bytes, pad the end\n    // with empty bytes to the ceiling 32 bytes.\n    if (bytesSize % 32 !== 0)\n      value_ = Hex.padRight(value_, Math.ceil((value.length - 2) / 2 / 32) * 32)\n    return {\n      dynamic: true,\n      encoded: Hex.concat(\n        Hex.padLeft(Hex.fromNumber(bytesSize, { size: 32 })),\n        value_,\n      ),\n    }\n  }\n  if (bytesSize !== Number.parseInt(parametersize, 10))\n    throw new AbiParameters.BytesSizeMismatchError({\n      expectedSize: Number.parseInt(parametersize, 10),\n      value,\n    })\n  return { dynamic: false, encoded: Hex.padRight(value) }\n}\n\n/** @internal */\nexport declare namespace encodeBytes {\n  type ErrorType =\n    | Hex.padLeft.ErrorType\n    | Hex.padRight.ErrorType\n    | Hex.fromNumber.ErrorType\n    | Hex.slice.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function encodeBoolean(value: boolean): PreparedParameter {\n  if (typeof value !== 'boolean')\n    throw new Errors.BaseError(\n      `Invalid boolean value: \"${value}\" (type: ${typeof value}). Expected: \\`true\\` or \\`false\\`.`,\n    )\n  return { dynamic: false, encoded: Hex.padLeft(Hex.fromBoolean(value)) }\n}\n\n/** @internal */\nexport declare namespace encodeBoolean {\n  type ErrorType =\n    | Hex.padLeft.ErrorType\n    | Hex.fromBoolean.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function encodeNumber(\n  value: number,\n  { signed, size }: { signed: boolean; size: number },\n): PreparedParameter {\n  if (typeof size === 'number') {\n    const max = 2n ** (BigInt(size) - (signed ? 1n : 0n)) - 1n\n    const min = signed ? -max - 1n : 0n\n    if (value > max || value < min)\n      throw new Hex.IntegerOutOfRangeError({\n        max: max.toString(),\n        min: min.toString(),\n        signed,\n        size: size / 8,\n        value: value.toString(),\n      })\n  }\n  return {\n    dynamic: false,\n    encoded: Hex.fromNumber(value, {\n      size: 32,\n      signed,\n    }),\n  }\n}\n\n/** @internal */\nexport declare namespace encodeNumber {\n  type ErrorType = Hex.fromNumber.ErrorType | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function encodeString(value: string): PreparedParameter {\n  const hexValue = Hex.fromString(value)\n  const partsLength = Math.ceil(Hex.size(hexValue) / 32)\n  const parts: Hex.Hex[] = []\n  for (let i = 0; i < partsLength; i++) {\n    parts.push(Hex.padRight(Hex.slice(hexValue, i * 32, (i + 1) * 32)))\n  }\n  return {\n    dynamic: true,\n    encoded: Hex.concat(\n      Hex.padRight(Hex.fromNumber(Hex.size(hexValue), { size: 32 })),\n      ...parts,\n    ),\n  }\n}\n\n/** @internal */\nexport declare namespace encodeString {\n  type ErrorType =\n    | Hex.fromNumber.ErrorType\n    | Hex.padRight.ErrorType\n    | Hex.slice.ErrorType\n    | Hex.size.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function encodeTuple<\n  const parameter extends AbiParameters.Parameter & {\n    components: readonly AbiParameters.Parameter[]\n  },\n>(\n  value: ParameterToPrimitiveType<parameter>,\n  options: {\n    checksumAddress?: boolean | undefined\n    parameter: parameter\n  },\n): PreparedParameter {\n  const { checksumAddress, parameter } = options\n\n  let dynamic = false\n  const preparedParameters: PreparedParameter[] = []\n  for (let i = 0; i < parameter.components.length; i++) {\n    const param_ = parameter.components[i]!\n    const index = Array.isArray(value) ? i : param_.name\n    const preparedParam = prepareParameter({\n      checksumAddress,\n      parameter: param_,\n      value: (value as any)[index!] as readonly unknown[],\n    })\n    preparedParameters.push(preparedParam)\n    if (preparedParam.dynamic) dynamic = true\n  }\n  return {\n    dynamic,\n    encoded: dynamic\n      ? encode(preparedParameters)\n      : Hex.concat(...preparedParameters.map(({ encoded }) => encoded)),\n  }\n}\n\n/** @internal */\nexport declare namespace encodeTuple {\n  type ErrorType = Hex.concat.ErrorType | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function getArrayComponents(\n  type: string,\n): [length: number | null, innerType: string] | undefined {\n  const matches = type.match(/^(.*)\\[(\\d+)?\\]$/)\n  return matches\n    ? // Return `null` if the array is dynamic.\n      [matches[2]! ? Number(matches[2]!) : null, matches[1]!]\n    : undefined\n}\n\n/** @internal */\nexport function hasDynamicChild(param: AbiParameters.Parameter) {\n  const { type } = param\n  if (type === 'string') return true\n  if (type === 'bytes') return true\n  if (type.endsWith('[]')) return true\n\n  if (type === 'tuple') return (param as any).components?.some(hasDynamicChild)\n\n  const arrayComponents = getArrayComponents(param.type)\n  if (\n    arrayComponents &&\n    hasDynamicChild({\n      ...param,\n      type: arrayComponents[1],\n    } as AbiParameters.Parameter)\n  )\n    return true\n\n  return false\n}\n","import type { MetadataEntry } from '../types.ts'\nimport { METADATA_KEYS } from './constants.ts'\n\n// Metadata size and count limits from the contract\nexport const METADATA_LIMITS = {\n  MAX_KEY_LENGTH: 32,\n  MAX_VALUE_LENGTH: 128,\n  MAX_KEYS_PER_DATASET: 10,\n  MAX_KEYS_PER_PIECE: 5,\n}\n\n/**\n * Converts a metadata object to an ordered array of MetadataEntry objects.\n * Keys are sorted alphabetically for deterministic ordering.\n *\n * @param metadata - The metadata object to convert\n * @returns Array of MetadataEntry objects with sorted keys\n */\nexport function objectToEntries(metadata: Record<string, string>): MetadataEntry[] {\n  return Object.entries(metadata)\n    .sort(([a], [b]) => a.localeCompare(b)) // Deterministic ordering for signing\n    .map(([key, value]) => ({ key, value }))\n}\n\n/**\n * Converts an array of MetadataEntry objects to a prototype-safe object.\n * Uses Object.create(null) to avoid prototype pollution risks.\n *\n * @param entries - Array of MetadataEntry objects\n * @returns A prototype-safe Record<string, string>\n */\nexport function entriesToObject(entries: MetadataEntry[]): Record<string, string> {\n  const obj: Record<string, string> = Object.create(null)\n  for (const { key, value } of entries) {\n    obj[key] = value\n  }\n  return obj\n}\n\n/**\n * Validates metadata for data set creation against contract limits.\n * Accepts both MetadataEntry[] and Record<string, string> formats.\n * Throws descriptive errors if validation fails.\n *\n * @param metadata - The metadata to validate (array or object)\n * @throws Error if metadata exceeds contract limits\n */\nexport function validateDataSetMetadata(metadata: MetadataEntry[] | Record<string, string>): void {\n  // Convert to array format for validation\n  const metadataArray = Array.isArray(metadata) ? metadata : objectToEntries(metadata)\n  if (metadataArray.length > METADATA_LIMITS.MAX_KEYS_PER_DATASET) {\n    throw new Error(\n      `Too many metadata keys for data set: ${metadataArray.length} (max: ${METADATA_LIMITS.MAX_KEYS_PER_DATASET})`\n    )\n  }\n\n  for (const { key, value } of metadataArray) {\n    if (key.length > METADATA_LIMITS.MAX_KEY_LENGTH) {\n      throw new Error(\n        `Metadata key \"${key}\" exceeds max length: ${key.length} bytes (max: ${METADATA_LIMITS.MAX_KEY_LENGTH})`\n      )\n    }\n    if (value.length > METADATA_LIMITS.MAX_VALUE_LENGTH) {\n      throw new Error(\n        `Metadata value for key \"${key}\" exceeds max length: ${value.length} bytes (max: ${METADATA_LIMITS.MAX_VALUE_LENGTH})`\n      )\n    }\n  }\n}\n\n/**\n * Validates metadata for piece addition against contract limits.\n * Accepts both MetadataEntry[] and Record<string, string> formats.\n * Throws descriptive errors if validation fails.\n *\n * @param metadata - The metadata to validate (array or object)\n * @throws Error if metadata exceeds contract limits\n */\nexport function validatePieceMetadata(metadata: MetadataEntry[] | Record<string, string>): void {\n  // Convert to array format for validation\n  const metadataArray = Array.isArray(metadata) ? metadata : objectToEntries(metadata)\n  if (metadataArray.length > METADATA_LIMITS.MAX_KEYS_PER_PIECE) {\n    throw new Error(\n      `Too many metadata keys for piece: ${metadataArray.length} (max: ${METADATA_LIMITS.MAX_KEYS_PER_PIECE})`\n    )\n  }\n\n  for (const { key, value } of metadataArray) {\n    if (key.length > METADATA_LIMITS.MAX_KEY_LENGTH) {\n      throw new Error(\n        `Metadata key \"${key}\" exceeds max length: ${key.length} bytes (max: ${METADATA_LIMITS.MAX_KEY_LENGTH})`\n      )\n    }\n    if (value.length > METADATA_LIMITS.MAX_VALUE_LENGTH) {\n      throw new Error(\n        `Metadata value for key \"${key}\" exceeds max length: ${value.length} bytes (max: ${METADATA_LIMITS.MAX_VALUE_LENGTH})`\n      )\n    }\n  }\n}\n\n/**\n * Checks if a data set's metadata exactly matches the requested metadata.\n *\n * The data set must contain exactly the same keys and values as requested.\n * Order doesn't matter, but the sets must be identical.\n *\n * @param dataSetMetadata - The metadata from the data set\n * @param requestedMetadata - The metadata requirements to match\n * @returns true if metadata sets are exactly equal (same keys and values)\n */\nexport function metadataMatches(\n  dataSetMetadata: Record<string, string>,\n  requestedMetadata: Record<string, string>\n): boolean {\n  const dataSetKeys = Object.keys(dataSetMetadata)\n  const requestedKeys = Object.keys(requestedMetadata)\n\n  if (dataSetKeys.length !== requestedKeys.length) {\n    return false\n  }\n\n  if (requestedKeys.length === 0) {\n    return true\n  }\n\n  for (const key of requestedKeys) {\n    if (dataSetMetadata[key] !== requestedMetadata[key]) {\n      return false\n    }\n  }\n\n  return true\n}\n\n/**\n * Combines metadata object with withCDN flag, ensuring consistent behavior.\n * If withCDN is true, adds the withCDN key only if not already present.\n * If withCDN is false or undefined, returns metadata unchanged.\n *\n * @param metadata - Base metadata object (can be empty)\n * @param withCDN - Whether to include CDN flag\n * @returns Combined metadata object\n */\nexport function combineMetadata(metadata: Record<string, string> = {}, withCDN?: boolean): Record<string, string> {\n  // If no CDN preference or already has withCDN key, return as-is\n  if (withCDN == null || METADATA_KEYS.WITH_CDN in metadata) {\n    return metadata\n  }\n\n  // Add withCDN key only if explicitly requested\n  if (withCDN) {\n    return { ...metadata, [METADATA_KEYS.WITH_CDN]: '' }\n  }\n\n  return metadata\n}\n\n/**\n * Converts a boolean withCDN flag to metadata format for backward compatibility.\n *\n * @param withCDN - Whether to request CDN support\n * @returns MetadataEntry array with withCDN key if true, empty array if false\n */\nexport function withCDNToMetadata(withCDN: boolean): MetadataEntry[] {\n  if (withCDN) {\n    return [{ key: METADATA_KEYS.WITH_CDN, value: '' }]\n  }\n  return []\n}\n","export type MetadataEntry = {\n  readonly key: string\n  readonly value: string\n}\n\n/**\n * The metadata array is a tuple of two arrays: the keys and the values.\n * Return type from the getAllDataSetMetadata function.\n *\n * @example ['key1', 'key2'], ['value1', 'value2']\n */\nexport type MetadataArray = readonly [readonly string[], readonly string[]]\n\nexport type MetadataObject = Record<string, string>\n\n// Metadata size and count limits from the contract\nexport const METADATA_LIMITS = {\n  MAX_KEY_LENGTH: 32,\n  MAX_VALUE_LENGTH: 128,\n  MAX_KEYS_PER_DATASET: 10,\n  MAX_KEYS_PER_PIECE: 5,\n}\n\nexport function metadataArrayToObject(metadataArray: MetadataArray): Record<string, string> {\n  const [keys, values] = metadataArray\n  const metadata: Record<string, string> = {} as Record<string, string>\n  for (let i = 0; i < keys.length; i++) {\n    if (keys[i] === 'withCDN') {\n      continue\n    }\n    if (keys[i] === 'withIPFSIndexing') {\n      continue\n    }\n    if (keys[i] === 'ipfsRootCID') {\n      continue\n    }\n    metadata[keys[i]] = values[i]\n  }\n  return metadata\n}\n\nexport interface MetadataDataSetInternal {\n  cdn?: boolean\n}\n\nexport interface MetadataPieceInternal {\n  ipni?: boolean\n  ipfsRootCID?: string\n}\n/**\n * Convert a dataset metadata object to an array of metadata entries to be signed.\n *\n * @param metadataObject\n * @param metadataInternal\n * @returns\n */\nexport function datasetMetadataObjectToEntry(\n  metadataObject?: MetadataObject,\n  metadataInternal?: MetadataDataSetInternal\n): MetadataEntry[] {\n  const obj = {\n    ...(metadataObject ?? {}),\n    ...(metadataInternal?.cdn ? { withCDN: '' } : {}),\n  }\n  const entries = Object.entries(obj)\n    .sort((a, b) => a[0].localeCompare(b[0]))\n    .map(([key, value]) => ({ key, value }))\n\n  if (entries.length > METADATA_LIMITS.MAX_KEYS_PER_DATASET) {\n    throw new Error('Metadata exceeds the maximum number of keys per data set')\n  }\n\n  for (const entry of entries) {\n    if (entry.key.length > METADATA_LIMITS.MAX_KEY_LENGTH) {\n      throw new Error('Metadata key exceeds the maximum length')\n    }\n    if (entry.value.length > METADATA_LIMITS.MAX_VALUE_LENGTH) {\n      throw new Error('Metadata value exceeds the maximum length')\n    }\n  }\n\n  return entries\n}\n\n/**\n * Convert a dataset metadata object to an array of metadata entries to be signed.\n *\n * @param metadataObject\n * @param metadataInternal\n * @returns\n */\nexport function pieceMetadataObjectToEntry(\n  metadataObject?: MetadataObject,\n  metadataInternal?: MetadataPieceInternal\n): MetadataEntry[] {\n  const obj = {\n    ...(metadataObject ?? {}),\n    ...(metadataInternal?.ipni ? { withIPNI: '' } : {}),\n    ...(metadataInternal?.ipfsRootCID ? { ipfsRootCID: metadataInternal.ipfsRootCID } : {}),\n  }\n  const entries = Object.entries(obj)\n    .sort((a, b) => a[0].localeCompare(b[0]))\n    .map(([key, value]) => ({ key, value }))\n\n  if (entries.length > METADATA_LIMITS.MAX_KEYS_PER_PIECE) {\n    throw new Error('Metadata exceeds the maximum number of keys per piece')\n  }\n\n  for (const entry of entries) {\n    if (entry.key.length > METADATA_LIMITS.MAX_KEY_LENGTH) {\n      throw new Error('Metadata key exceeds the maximum length')\n    }\n    if (entry.value.length > METADATA_LIMITS.MAX_VALUE_LENGTH) {\n      throw new Error('Metadata value exceeds the maximum length')\n    }\n  }\n\n  return entries\n}\n","/**\n * Network utilities for Filecoin network detection and validation\n */\n\nimport type { ethers } from 'ethers'\nimport type { FilecoinNetworkType } from '../types.ts'\nimport { CHAIN_IDS } from './constants.ts'\nimport { createError } from './index.ts'\n\n/**\n * Extract and validate FilecoinNetworkType from an ethers Provider\n *\n * Uses chainId for network detection since the actual network name from ethers\n * will be something like \"Filecoin Calibration Testnet\" rather than just \"calibration\".\n *\n * @param provider - Ethers provider to get network from\n * @returns Promise resolving to validated FilecoinNetworkType\n * @throws Error if the network is not supported\n */\nexport async function getFilecoinNetworkType(provider: ethers.Provider): Promise<FilecoinNetworkType> {\n  try {\n    const network = await provider.getNetwork()\n    const chainId = Number(network.chainId)\n\n    if (chainId === CHAIN_IDS.mainnet) {\n      return 'mainnet'\n    } else if (chainId === CHAIN_IDS.calibration) {\n      return 'calibration'\n    } else {\n      throw createError(\n        'NetworkUtils',\n        'getFilecoinNetworkType',\n        `Unsupported network: chain ID ${chainId}. Only Filecoin mainnet (${CHAIN_IDS.mainnet}) and calibration (${CHAIN_IDS.calibration}) are supported.`\n      )\n    }\n  } catch (error) {\n    if (error instanceof Error && error.message.includes('Unsupported network')) {\n      throw error // Re-throw our own error\n    }\n    throw createError(\n      'NetworkUtils',\n      'getFilecoinNetworkType',\n      `Failed to detect network: ${error instanceof Error ? error.message : String(error)}`\n    )\n  }\n}\n","import * as abitype from 'abitype'\nimport * as Address from './Address.js'\nimport * as Bytes from './Bytes.js'\nimport * as Errors from './Errors.js'\nimport * as Hex from './Hex.js'\nimport * as internal from './internal/abiParameters.js'\nimport * as Cursor from './internal/cursor.js'\nimport * as Solidity from './Solidity.js'\n\n/** Root type for ABI parameters. */\nexport type AbiParameters = readonly abitype.AbiParameter[]\n\n/** A parameter on an {@link ox#AbiParameters.AbiParameters}. */\nexport type Parameter = abitype.AbiParameter\n\n/** A packed ABI type. */\nexport type PackedAbiType =\n  | abitype.SolidityAddress\n  | abitype.SolidityBool\n  | abitype.SolidityBytes\n  | abitype.SolidityInt\n  | abitype.SolidityString\n  | abitype.SolidityArrayWithoutTuple\n\n/**\n * Decodes ABI-encoded data into its respective primitive values based on ABI Parameters.\n *\n * @example\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * const data = AbiParameters.decode(\n *   AbiParameters.from(['string', 'uint', 'bool']),\n *   '0x000000000000000000000000000000000000000000000000000000000000006000000000000000000000000000000000000000000000000000000000000001a4000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000057761676d69000000000000000000000000000000000000000000000000000000',\n * )\n * // @log: ['wagmi', 420n, true]\n * ```\n *\n * @example\n * ### JSON Parameters\n *\n * You can pass **JSON ABI** Parameters:\n *\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * const data = AbiParameters.decode(\n *   [\n *     { name: 'x', type: 'string' },\n *     { name: 'y', type: 'uint' },\n *     { name: 'z', type: 'bool' },\n *   ],\n *   '0x000000000000000000000000000000000000000000000000000000000000006000000000000000000000000000000000000000000000000000000000000001a4000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000057761676d69000000000000000000000000000000000000000000000000000000',\n * )\n * // @log: ['wagmi', 420n, true]\n * ```\n *\n * @param parameters - The set of ABI parameters to decode, in the shape of the `inputs` or `outputs` attribute of an ABI Item. These parameters must include valid [ABI types](https://docs.soliditylang.org/en/latest/types.html).\n * @param data - ABI encoded data.\n * @param options - Decoding options.\n * @returns Array of decoded values.\n */\nexport function decode<\n  const parameters extends AbiParameters,\n  as extends 'Object' | 'Array' = 'Array',\n>(\n  parameters: parameters,\n  data: Bytes.Bytes | Hex.Hex,\n  options?: decode.Options<as>,\n): decode.ReturnType<parameters, as>\n\n// eslint-disable-next-line jsdoc/require-jsdoc\nexport function decode(\n  parameters: AbiParameters,\n  data: Bytes.Bytes | Hex.Hex,\n  options: {\n    as?: 'Array' | 'Object' | undefined\n    checksumAddress?: boolean | undefined\n  } = {},\n): readonly unknown[] | Record<string, unknown> {\n  const { as = 'Array', checksumAddress = false } = options\n\n  const bytes = typeof data === 'string' ? Bytes.fromHex(data) : data\n  const cursor = Cursor.create(bytes)\n\n  if (Bytes.size(bytes) === 0 && parameters.length > 0)\n    throw new ZeroDataError()\n  if (Bytes.size(bytes) && Bytes.size(bytes) < 32)\n    throw new DataSizeTooSmallError({\n      data: typeof data === 'string' ? data : Hex.fromBytes(data),\n      parameters: parameters as readonly Parameter[],\n      size: Bytes.size(bytes),\n    })\n\n  let consumed = 0\n  const values: any = as === 'Array' ? [] : {}\n  for (let i = 0; i < parameters.length; ++i) {\n    const param = parameters[i] as Parameter\n    cursor.setPosition(consumed)\n    const [data, consumed_] = internal.decodeParameter(cursor, param, {\n      checksumAddress,\n      staticPosition: 0,\n    })\n    consumed += consumed_\n    if (as === 'Array') values.push(data)\n    else values[param.name ?? i] = data\n  }\n  return values\n}\n\nexport declare namespace decode {\n  type Options<as extends 'Object' | 'Array'> = {\n    /**\n     * Whether the decoded values should be returned as an `Object` or `Array`.\n     *\n     * @default \"Array\"\n     */\n    as?: as | 'Object' | 'Array' | undefined\n    /**\n     * Whether decoded addresses should be checksummed.\n     *\n     * @default false\n     */\n    checksumAddress?: boolean | undefined\n  }\n\n  type ReturnType<\n    parameters extends AbiParameters = AbiParameters,\n    as extends 'Object' | 'Array' = 'Array',\n  > = parameters extends readonly []\n    ? as extends 'Object'\n      ? {}\n      : []\n    : as extends 'Object'\n      ? internal.ToObject<parameters>\n      : internal.ToPrimitiveTypes<parameters>\n\n  type ErrorType =\n    | Bytes.fromHex.ErrorType\n    | internal.decodeParameter.ErrorType\n    | ZeroDataError\n    | DataSizeTooSmallError\n    | Errors.GlobalErrorType\n}\n\n/**\n * Encodes primitive values into ABI encoded data as per the [Application Binary Interface (ABI) Specification](https://docs.soliditylang.org/en/latest/abi-spec).\n *\n * @example\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * const data = AbiParameters.encode(\n *   AbiParameters.from(['string', 'uint', 'bool']),\n *   ['wagmi', 420n, true],\n * )\n * ```\n *\n * @example\n * ### JSON Parameters\n *\n * Specify **JSON ABI** Parameters as schema:\n *\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * const data = AbiParameters.encode(\n *   [\n *     { type: 'string', name: 'name' },\n *     { type: 'uint', name: 'age' },\n *     { type: 'bool', name: 'isOwner' },\n *   ],\n *   ['wagmi', 420n, true],\n * )\n * ```\n *\n * @param parameters - The set of ABI parameters to encode, in the shape of the `inputs` or `outputs` attribute of an ABI Item. These parameters must include valid [ABI types](https://docs.soliditylang.org/en/latest/types.html).\n * @param values - The set of primitive values that correspond to the ABI types defined in `parameters`.\n * @returns ABI encoded data.\n */\nexport function encode<\n  const parameters extends AbiParameters | readonly unknown[],\n>(\n  parameters: parameters,\n  values: parameters extends AbiParameters\n    ? internal.ToPrimitiveTypes<parameters>\n    : never,\n  options?: encode.Options,\n): Hex.Hex {\n  const { checksumAddress = false } = options ?? {}\n\n  if (parameters.length !== values.length)\n    throw new LengthMismatchError({\n      expectedLength: parameters.length as number,\n      givenLength: values.length as any,\n    })\n  // Prepare the parameters to determine dynamic types to encode.\n  const preparedParameters = internal.prepareParameters({\n    checksumAddress,\n    parameters: parameters as readonly Parameter[],\n    values: values as any,\n  })\n  const data = internal.encode(preparedParameters)\n  if (data.length === 0) return '0x'\n  return data\n}\n\nexport declare namespace encode {\n  type ErrorType =\n    | LengthMismatchError\n    | internal.encode.ErrorType\n    | internal.prepareParameters.ErrorType\n    | Errors.GlobalErrorType\n\n  type Options = {\n    /**\n     * Whether addresses should be checked against their checksum.\n     *\n     * @default false\n     */\n    checksumAddress?: boolean | undefined\n  }\n}\n\n/**\n * Encodes an array of primitive values to a [packed ABI encoding](https://docs.soliditylang.org/en/latest/abi-spec.html#non-standard-packed-mode).\n *\n * @example\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * const encoded = AbiParameters.encodePacked(\n *   ['address', 'string'],\n *   ['0xd8da6bf26964af9d7eed9e03e53415d37aa96045', 'hello world'],\n * )\n * // @log: '0xd8da6bf26964af9d7eed9e03e53415d37aa9604568656c6c6f20776f726c64'\n * ```\n *\n * @param types - Set of ABI types to pack encode.\n * @param values - The set of primitive values that correspond to the ABI types defined in `types`.\n * @returns The encoded packed data.\n */\nexport function encodePacked<\n  const packedAbiTypes extends readonly PackedAbiType[] | readonly unknown[],\n>(types: packedAbiTypes, values: encodePacked.Values<packedAbiTypes>): Hex.Hex {\n  if (types.length !== values.length)\n    throw new LengthMismatchError({\n      expectedLength: types.length as number,\n      givenLength: values.length as number,\n    })\n\n  const data: Hex.Hex[] = []\n  for (let i = 0; i < (types as unknown[]).length; i++) {\n    const type = types[i]\n    const value = values[i]\n    data.push(encodePacked.encode(type, value))\n  }\n  return Hex.concat(...data)\n}\n\nexport namespace encodePacked {\n  export type ErrorType =\n    | Hex.concat.ErrorType\n    | LengthMismatchError\n    | Errors.GlobalErrorType\n\n  export type Values<\n    packedAbiTypes extends readonly PackedAbiType[] | readonly unknown[],\n  > = {\n    [key in keyof packedAbiTypes]: packedAbiTypes[key] extends abitype.AbiType\n      ? abitype.AbiParameterToPrimitiveType<{ type: packedAbiTypes[key] }>\n      : unknown\n  }\n\n  // eslint-disable-next-line jsdoc/require-jsdoc\n  export function encode<const packedAbiType extends PackedAbiType | unknown>(\n    type: packedAbiType,\n    value: Values<[packedAbiType]>[0],\n    isArray = false,\n  ): Hex.Hex {\n    if (type === 'address') {\n      const address = value as Address.Address\n      Address.assert(address)\n      return Hex.padLeft(\n        address.toLowerCase() as Hex.Hex,\n        isArray ? 32 : 0,\n      ) as Address.Address\n    }\n    if (type === 'string') return Hex.fromString(value as string)\n    if (type === 'bytes') return value as Hex.Hex\n    if (type === 'bool')\n      return Hex.padLeft(Hex.fromBoolean(value as boolean), isArray ? 32 : 1)\n\n    const intMatch = (type as string).match(Solidity.integerRegex)\n    if (intMatch) {\n      const [_type, baseType, bits = '256'] = intMatch\n      const size = Number.parseInt(bits, 10) / 8\n      return Hex.fromNumber(value as number, {\n        size: isArray ? 32 : size,\n        signed: baseType === 'int',\n      })\n    }\n\n    const bytesMatch = (type as string).match(Solidity.bytesRegex)\n    if (bytesMatch) {\n      const [_type, size] = bytesMatch\n      if (Number.parseInt(size!, 10) !== ((value as Hex.Hex).length - 2) / 2)\n        throw new BytesSizeMismatchError({\n          expectedSize: Number.parseInt(size!, 10),\n          value: value as Hex.Hex,\n        })\n      return Hex.padRight(value as Hex.Hex, isArray ? 32 : 0) as Hex.Hex\n    }\n\n    const arrayMatch = (type as string).match(Solidity.arrayRegex)\n    if (arrayMatch && Array.isArray(value)) {\n      const [_type, childType] = arrayMatch\n      const data: Hex.Hex[] = []\n      for (let i = 0; i < value.length; i++) {\n        data.push(encode(childType, value[i], true))\n      }\n      if (data.length === 0) return '0x'\n      return Hex.concat(...data)\n    }\n\n    throw new InvalidTypeError(type as string)\n  }\n}\n\n/**\n * Formats {@link ox#AbiParameters.AbiParameters} into **Human Readable ABI Parameters**.\n *\n * @example\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * const formatted = AbiParameters.format([\n *   {\n *     name: 'spender',\n *     type: 'address',\n *   },\n *   {\n *     name: 'amount',\n *     type: 'uint256',\n *   },\n * ])\n *\n * formatted\n * //    ^?\n *\n *\n * ```\n *\n * @param parameters - The ABI Parameters to format.\n * @returns The formatted ABI Parameters  .\n */\nexport function format<\n  const parameters extends readonly [\n    Parameter | abitype.AbiEventParameter,\n    ...(readonly (Parameter | abitype.AbiEventParameter)[]),\n  ],\n>(\n  parameters:\n    | parameters\n    | readonly [\n        Parameter | abitype.AbiEventParameter,\n        ...(readonly (Parameter | abitype.AbiEventParameter)[]),\n      ],\n): abitype.FormatAbiParameters<parameters> {\n  return abitype.formatAbiParameters(parameters)\n}\n\nexport declare namespace format {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Parses arbitrary **JSON ABI Parameters** or **Human Readable ABI Parameters** into typed {@link ox#AbiParameters.AbiParameters}.\n *\n * @example\n * ### JSON Parameters\n *\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * const parameters = AbiParameters.from([\n *   {\n *     name: 'spender',\n *     type: 'address',\n *   },\n *   {\n *     name: 'amount',\n *     type: 'uint256',\n *   },\n * ])\n *\n * parameters\n * //^?\n *\n *\n *\n *\n *\n *\n *\n * ```\n *\n * @example\n * ### Human Readable Parameters\n *\n * Human Readable ABI Parameters can be parsed into a typed {@link ox#AbiParameters.AbiParameters}:\n *\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * const parameters = AbiParameters.from('address spender, uint256 amount')\n *\n * parameters\n * //^?\n *\n *\n *\n *\n *\n *\n *\n * ```\n *\n * @example\n * It is possible to specify `struct`s along with your definitions:\n *\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * const parameters = AbiParameters.from([\n *   'struct Foo { address spender; uint256 amount; }', // [!code hl]\n *   'Foo foo, address bar',\n * ])\n *\n * parameters\n * //^?\n *\n *\n *\n *\n *\n *\n *\n *\n *\n *\n *\n *\n * ```\n *\n *\n *\n * @param parameters - The ABI Parameters to parse.\n * @returns The typed ABI Parameters.\n */\nexport function from<\n  const parameters extends AbiParameters | string | readonly string[],\n>(\n  parameters: parameters | AbiParameters | string | readonly string[],\n): from.ReturnType<parameters> {\n  if (Array.isArray(parameters) && typeof parameters[0] === 'string')\n    return abitype.parseAbiParameters(parameters) as never\n  if (typeof parameters === 'string')\n    return abitype.parseAbiParameters(parameters) as never\n  return parameters as never\n}\n\nexport declare namespace from {\n  type ReturnType<\n    parameters extends AbiParameters | string | readonly string[],\n  > = parameters extends string\n    ? abitype.ParseAbiParameters<parameters>\n    : parameters extends readonly string[]\n      ? abitype.ParseAbiParameters<parameters>\n      : parameters\n\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Throws when the data size is too small for the given parameters.\n *\n * @example\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * AbiParameters.decode([{ type: 'uint256' }], '0x010f')\n * //                                             ↑ ❌ 2 bytes\n * // @error: AbiParameters.DataSizeTooSmallError: Data size of 2 bytes is too small for given parameters.\n * // @error: Params: (uint256)\n * // @error: Data:   0x010f (2 bytes)\n * ```\n *\n * ### Solution\n *\n * Pass a valid data size.\n *\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * AbiParameters.decode([{ type: 'uint256' }], '0x00000000000000000000000000000000000000000000000000000000000010f')\n * //                                             ↑ ✅ 32 bytes\n * ```\n */\nexport class DataSizeTooSmallError extends Errors.BaseError {\n  override readonly name = 'AbiParameters.DataSizeTooSmallError'\n  constructor({\n    data,\n    parameters,\n    size,\n  }: { data: Hex.Hex; parameters: readonly Parameter[]; size: number }) {\n    super(`Data size of ${size} bytes is too small for given parameters.`, {\n      metaMessages: [\n        `Params: (${abitype.formatAbiParameters(parameters as readonly [Parameter])})`,\n        `Data:   ${data} (${size} bytes)`,\n      ],\n    })\n  }\n}\n\n/**\n * Throws when zero data is provided, but data is expected.\n *\n * @example\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * AbiParameters.decode([{ type: 'uint256' }], '0x')\n * //                                           ↑ ❌ zero data\n * // @error: AbiParameters.DataSizeTooSmallError: Data size of 2 bytes is too small for given parameters.\n * // @error: Params: (uint256)\n * // @error: Data:   0x010f (2 bytes)\n * ```\n *\n * ### Solution\n *\n * Pass valid data.\n *\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * AbiParameters.decode([{ type: 'uint256' }], '0x00000000000000000000000000000000000000000000000000000000000010f')\n * //                                             ↑ ✅ 32 bytes\n * ```\n */\nexport class ZeroDataError extends Errors.BaseError {\n  override readonly name = 'AbiParameters.ZeroDataError'\n  constructor() {\n    super('Cannot decode zero data (\"0x\") with ABI parameters.')\n  }\n}\n\n/**\n * The length of the array value does not match the length specified in the corresponding ABI parameter.\n *\n * ### Example\n *\n * ```ts twoslash\n * // @noErrors\n * import { AbiParameters } from 'ox'\n * // ---cut---\n * AbiParameters.encode(AbiParameters.from('uint256[3]'), [[69n, 420n]])\n * //                                               ↑ expected: 3  ↑ ❌ length: 2\n * // @error: AbiParameters.ArrayLengthMismatchError: ABI encoding array length mismatch\n * // @error: for type `uint256[3]`. Expected: `3`. Given: `2`.\n * ```\n *\n * ### Solution\n *\n * Pass an array of the correct length.\n *\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n * // ---cut---\n * AbiParameters.encode(AbiParameters.from(['uint256[3]']), [[69n, 420n, 69n]])\n * //                                                         ↑ ✅ length: 3\n * ```\n */\nexport class ArrayLengthMismatchError extends Errors.BaseError {\n  override readonly name = 'AbiParameters.ArrayLengthMismatchError'\n  constructor({\n    expectedLength,\n    givenLength,\n    type,\n  }: { expectedLength: number; givenLength: number; type: string }) {\n    super(\n      `Array length mismatch for type \\`${type}\\`. Expected: \\`${expectedLength}\\`. Given: \\`${givenLength}\\`.`,\n    )\n  }\n}\n\n/**\n * The size of the bytes value does not match the size specified in the corresponding ABI parameter.\n *\n * ### Example\n *\n * ```ts twoslash\n * // @noErrors\n * import { AbiParameters } from 'ox'\n * // ---cut---\n * AbiParameters.encode(AbiParameters.from('bytes8'), [['0xdeadbeefdeadbeefdeadbeef']])\n * //                                            ↑ expected: 8 bytes  ↑ ❌ size: 12 bytes\n * // @error: BytesSizeMismatchError: Size of bytes \"0xdeadbeefdeadbeefdeadbeef\"\n * // @error: (bytes12) does not match expected size (bytes8).\n * ```\n *\n * ### Solution\n *\n * Pass a bytes value of the correct size.\n *\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n * // ---cut---\n * AbiParameters.encode(AbiParameters.from(['bytes8']), ['0xdeadbeefdeadbeef'])\n * //                                                       ↑ ✅ size: 8 bytes\n * ```\n */\nexport class BytesSizeMismatchError extends Errors.BaseError {\n  override readonly name = 'AbiParameters.BytesSizeMismatchError'\n  constructor({\n    expectedSize,\n    value,\n  }: { expectedSize: number; value: Hex.Hex }) {\n    super(\n      `Size of bytes \"${value}\" (bytes${Hex.size(\n        value,\n      )}) does not match expected size (bytes${expectedSize}).`,\n    )\n  }\n}\n\n/**\n * The length of the values to encode does not match the length of the ABI parameters.\n *\n * ### Example\n *\n * ```ts twoslash\n * // @noErrors\n * import { AbiParameters } from 'ox'\n * // ---cut---\n * AbiParameters.encode(AbiParameters.from(['string', 'uint256']), ['hello'])\n * // @error: LengthMismatchError: ABI encoding params/values length mismatch.\n * // @error: Expected length (params): 2\n * // @error: Given length (values): 1\n * ```\n *\n * ### Solution\n *\n * Pass the correct number of values to encode.\n *\n * ### Solution\n *\n * Pass a [valid ABI type](https://docs.soliditylang.org/en/develop/abi-spec.html#types).\n */\nexport class LengthMismatchError extends Errors.BaseError {\n  override readonly name = 'AbiParameters.LengthMismatchError'\n  constructor({\n    expectedLength,\n    givenLength,\n  }: { expectedLength: number; givenLength: number }) {\n    super(\n      [\n        'ABI encoding parameters/values length mismatch.',\n        `Expected length (parameters): ${expectedLength}`,\n        `Given length (values): ${givenLength}`,\n      ].join('\\n'),\n    )\n  }\n}\n\n/**\n * The value provided is not a valid array as specified in the corresponding ABI parameter.\n *\n * ### Example\n *\n * ```ts twoslash\n * // @noErrors\n * import { AbiParameters } from 'ox'\n * // ---cut---\n * AbiParameters.encode(AbiParameters.from(['uint256[3]']), [69])\n * ```\n *\n * ### Solution\n *\n * Pass an array value.\n */\nexport class InvalidArrayError extends Errors.BaseError {\n  override readonly name = 'AbiParameters.InvalidArrayError'\n  constructor(value: unknown) {\n    super(`Value \\`${value}\\` is not a valid array.`)\n  }\n}\n\n/**\n * Throws when the ABI parameter type is invalid.\n *\n * @example\n * ```ts twoslash\n * import { AbiParameters } from 'ox'\n *\n * AbiParameters.decode([{ type: 'lol' }], '0x00000000000000000000000000000000000000000000000000000000000010f')\n * //                             ↑ ❌ invalid type\n * // @error: AbiParameters.InvalidTypeError: Type `lol` is not a valid ABI Type.\n * ```\n */\nexport class InvalidTypeError extends Errors.BaseError {\n  override readonly name = 'AbiParameters.InvalidTypeError'\n  constructor(type: string) {\n    super(`Type \\`${type}\\` is not a valid ABI Type.`)\n  }\n}\n","/**\n * Utilities for hex, bytes, CSPRNG.\n * @module\n */\n/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n\n// We use WebCrypto aka globalThis.crypto, which exists in browsers and node.js 16+.\n// node.js versions earlier than v19 don't declare it in global scope.\n// For node.js, package.json#exports field mapping rewrites import\n// from `crypto` to `cryptoNode`, which imports native module.\n// Makes the utils un-importable in browsers without a bundler.\n// Once node.js 18 is deprecated (2025-04-30), we can just drop the import.\nimport { crypto } from '@noble/hashes/crypto';\n\n/** Checks if something is Uint8Array. Be careful: nodejs Buffer will return true. */\nexport function isBytes(a: unknown): a is Uint8Array {\n  return a instanceof Uint8Array || (ArrayBuffer.isView(a) && a.constructor.name === 'Uint8Array');\n}\n\n/** Asserts something is positive integer. */\nexport function anumber(n: number): void {\n  if (!Number.isSafeInteger(n) || n < 0) throw new Error('positive integer expected, got ' + n);\n}\n\n/** Asserts something is Uint8Array. */\nexport function abytes(b: Uint8Array | undefined, ...lengths: number[]): void {\n  if (!isBytes(b)) throw new Error('Uint8Array expected');\n  if (lengths.length > 0 && !lengths.includes(b.length))\n    throw new Error('Uint8Array expected of length ' + lengths + ', got length=' + b.length);\n}\n\n/** Asserts something is hash */\nexport function ahash(h: IHash): void {\n  if (typeof h !== 'function' || typeof h.create !== 'function')\n    throw new Error('Hash should be wrapped by utils.createHasher');\n  anumber(h.outputLen);\n  anumber(h.blockLen);\n}\n\n/** Asserts a hash instance has not been destroyed / finished */\nexport function aexists(instance: any, checkFinished = true): void {\n  if (instance.destroyed) throw new Error('Hash instance has been destroyed');\n  if (checkFinished && instance.finished) throw new Error('Hash#digest() has already been called');\n}\n\n/** Asserts output is properly-sized byte array */\nexport function aoutput(out: any, instance: any): void {\n  abytes(out);\n  const min = instance.outputLen;\n  if (out.length < min) {\n    throw new Error('digestInto() expects output buffer of length at least ' + min);\n  }\n}\n\n/** Generic type encompassing 8/16/32-byte arrays - but not 64-byte. */\n// prettier-ignore\nexport type TypedArray = Int8Array | Uint8ClampedArray | Uint8Array |\n  Uint16Array | Int16Array | Uint32Array | Int32Array;\n\n/** Cast u8 / u16 / u32 to u8. */\nexport function u8(arr: TypedArray): Uint8Array {\n  return new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);\n}\n\n/** Cast u8 / u16 / u32 to u32. */\nexport function u32(arr: TypedArray): Uint32Array {\n  return new Uint32Array(arr.buffer, arr.byteOffset, Math.floor(arr.byteLength / 4));\n}\n\n/** Zeroize a byte array. Warning: JS provides no guarantees. */\nexport function clean(...arrays: TypedArray[]): void {\n  for (let i = 0; i < arrays.length; i++) {\n    arrays[i].fill(0);\n  }\n}\n\n/** Create DataView of an array for easy byte-level manipulation. */\nexport function createView(arr: TypedArray): DataView {\n  return new DataView(arr.buffer, arr.byteOffset, arr.byteLength);\n}\n\n/** The rotate right (circular right shift) operation for uint32 */\nexport function rotr(word: number, shift: number): number {\n  return (word << (32 - shift)) | (word >>> shift);\n}\n\n/** The rotate left (circular left shift) operation for uint32 */\nexport function rotl(word: number, shift: number): number {\n  return (word << shift) | ((word >>> (32 - shift)) >>> 0);\n}\n\n/** Is current platform little-endian? Most are. Big-Endian platform: IBM */\nexport const isLE: boolean = /* @__PURE__ */ (() =>\n  new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44)();\n\n/** The byte swap operation for uint32 */\nexport function byteSwap(word: number): number {\n  return (\n    ((word << 24) & 0xff000000) |\n    ((word << 8) & 0xff0000) |\n    ((word >>> 8) & 0xff00) |\n    ((word >>> 24) & 0xff)\n  );\n}\n/** Conditionally byte swap if on a big-endian platform */\nexport const swap8IfBE: (n: number) => number = isLE\n  ? (n: number) => n\n  : (n: number) => byteSwap(n);\n\n/** @deprecated */\nexport const byteSwapIfBE: typeof swap8IfBE = swap8IfBE;\n/** In place byte swap for Uint32Array */\nexport function byteSwap32(arr: Uint32Array): Uint32Array {\n  for (let i = 0; i < arr.length; i++) {\n    arr[i] = byteSwap(arr[i]);\n  }\n  return arr;\n}\n\nexport const swap32IfBE: (u: Uint32Array) => Uint32Array = isLE\n  ? (u: Uint32Array) => u\n  : byteSwap32;\n\n// Built-in hex conversion https://caniuse.com/mdn-javascript_builtins_uint8array_fromhex\nconst hasHexBuiltin: boolean = /* @__PURE__ */ (() =>\n  // @ts-ignore\n  typeof Uint8Array.from([]).toHex === 'function' && typeof Uint8Array.fromHex === 'function')();\n\n// Array where index 0xf0 (240) is mapped to string 'f0'\nconst hexes = /* @__PURE__ */ Array.from({ length: 256 }, (_, i) =>\n  i.toString(16).padStart(2, '0')\n);\n\n/**\n * Convert byte array to hex string. Uses built-in function, when available.\n * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'\n */\nexport function bytesToHex(bytes: Uint8Array): string {\n  abytes(bytes);\n  // @ts-ignore\n  if (hasHexBuiltin) return bytes.toHex();\n  // pre-caching improves the speed 6x\n  let hex = '';\n  for (let i = 0; i < bytes.length; i++) {\n    hex += hexes[bytes[i]];\n  }\n  return hex;\n}\n\n// We use optimized technique to convert hex string to byte array\nconst asciis = { _0: 48, _9: 57, A: 65, F: 70, a: 97, f: 102 } as const;\nfunction asciiToBase16(ch: number): number | undefined {\n  if (ch >= asciis._0 && ch <= asciis._9) return ch - asciis._0; // '2' => 50-48\n  if (ch >= asciis.A && ch <= asciis.F) return ch - (asciis.A - 10); // 'B' => 66-(65-10)\n  if (ch >= asciis.a && ch <= asciis.f) return ch - (asciis.a - 10); // 'b' => 98-(97-10)\n  return;\n}\n\n/**\n * Convert hex string to byte array. Uses built-in function, when available.\n * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])\n */\nexport function hexToBytes(hex: string): Uint8Array {\n  if (typeof hex !== 'string') throw new Error('hex string expected, got ' + typeof hex);\n  // @ts-ignore\n  if (hasHexBuiltin) return Uint8Array.fromHex(hex);\n  const hl = hex.length;\n  const al = hl / 2;\n  if (hl % 2) throw new Error('hex string expected, got unpadded hex of length ' + hl);\n  const array = new Uint8Array(al);\n  for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {\n    const n1 = asciiToBase16(hex.charCodeAt(hi));\n    const n2 = asciiToBase16(hex.charCodeAt(hi + 1));\n    if (n1 === undefined || n2 === undefined) {\n      const char = hex[hi] + hex[hi + 1];\n      throw new Error('hex string expected, got non-hex character \"' + char + '\" at index ' + hi);\n    }\n    array[ai] = n1 * 16 + n2; // multiply first octet, e.g. 'a3' => 10*16+3 => 160 + 3 => 163\n  }\n  return array;\n}\n\n/**\n * There is no setImmediate in browser and setTimeout is slow.\n * Call of async fn will return Promise, which will be fullfiled only on\n * next scheduler queue processing step and this is exactly what we need.\n */\nexport const nextTick = async (): Promise<void> => {};\n\n/** Returns control to thread each 'tick' ms to avoid blocking. */\nexport async function asyncLoop(\n  iters: number,\n  tick: number,\n  cb: (i: number) => void\n): Promise<void> {\n  let ts = Date.now();\n  for (let i = 0; i < iters; i++) {\n    cb(i);\n    // Date.now() is not monotonic, so in case if clock goes backwards we return return control too\n    const diff = Date.now() - ts;\n    if (diff >= 0 && diff < tick) continue;\n    await nextTick();\n    ts += diff;\n  }\n}\n\n// Global symbols, but ts doesn't see them: https://github.com/microsoft/TypeScript/issues/31535\ndeclare const TextEncoder: any;\ndeclare const TextDecoder: any;\n\n/**\n * Converts string to bytes using UTF8 encoding.\n * @example utf8ToBytes('abc') // Uint8Array.from([97, 98, 99])\n */\nexport function utf8ToBytes(str: string): Uint8Array {\n  if (typeof str !== 'string') throw new Error('string expected');\n  return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809\n}\n\n/**\n * Converts bytes to string using UTF8 encoding.\n * @example bytesToUtf8(Uint8Array.from([97, 98, 99])) // 'abc'\n */\nexport function bytesToUtf8(bytes: Uint8Array): string {\n  return new TextDecoder().decode(bytes);\n}\n\n/** Accepted input of hash functions. Strings are converted to byte arrays. */\nexport type Input = string | Uint8Array;\n/**\n * Normalizes (non-hex) string or Uint8Array to Uint8Array.\n * Warning: when Uint8Array is passed, it would NOT get copied.\n * Keep in mind for future mutable operations.\n */\nexport function toBytes(data: Input): Uint8Array {\n  if (typeof data === 'string') data = utf8ToBytes(data);\n  abytes(data);\n  return data;\n}\n\n/** KDFs can accept string or Uint8Array for user convenience. */\nexport type KDFInput = string | Uint8Array;\n/**\n * Helper for KDFs: consumes uint8array or string.\n * When string is passed, does utf8 decoding, using TextDecoder.\n */\nexport function kdfInputToBytes(data: KDFInput): Uint8Array {\n  if (typeof data === 'string') data = utf8ToBytes(data);\n  abytes(data);\n  return data;\n}\n\n/** Copies several Uint8Arrays into one. */\nexport function concatBytes(...arrays: Uint8Array[]): Uint8Array {\n  let sum = 0;\n  for (let i = 0; i < arrays.length; i++) {\n    const a = arrays[i];\n    abytes(a);\n    sum += a.length;\n  }\n  const res = new Uint8Array(sum);\n  for (let i = 0, pad = 0; i < arrays.length; i++) {\n    const a = arrays[i];\n    res.set(a, pad);\n    pad += a.length;\n  }\n  return res;\n}\n\ntype EmptyObj = {};\nexport function checkOpts<T1 extends EmptyObj, T2 extends EmptyObj>(\n  defaults: T1,\n  opts?: T2\n): T1 & T2 {\n  if (opts !== undefined && {}.toString.call(opts) !== '[object Object]')\n    throw new Error('options should be object or undefined');\n  const merged = Object.assign(defaults, opts);\n  return merged as T1 & T2;\n}\n\n/** Hash interface. */\nexport type IHash = {\n  (data: Uint8Array): Uint8Array;\n  blockLen: number;\n  outputLen: number;\n  create: any;\n};\n\n/** For runtime check if class implements interface */\nexport abstract class Hash<T extends Hash<T>> {\n  abstract blockLen: number; // Bytes per block\n  abstract outputLen: number; // Bytes in output\n  abstract update(buf: Input): this;\n  // Writes digest into buf\n  abstract digestInto(buf: Uint8Array): void;\n  abstract digest(): Uint8Array;\n  /**\n   * Resets internal state. Makes Hash instance unusable.\n   * Reset is impossible for keyed hashes if key is consumed into state. If digest is not consumed\n   * by user, they will need to manually call `destroy()` when zeroing is necessary.\n   */\n  abstract destroy(): void;\n  /**\n   * Clones hash instance. Unsafe: doesn't check whether `to` is valid. Can be used as `clone()`\n   * when no options are passed.\n   * Reasons to use `_cloneInto` instead of clone: 1) performance 2) reuse instance => all internal\n   * buffers are overwritten => causes buffer overwrite which is used for digest in some cases.\n   * There are no guarantees for clean-up because it's impossible in JS.\n   */\n  abstract _cloneInto(to?: T): T;\n  // Safe version that clones internal state\n  abstract clone(): T;\n}\n\n/**\n * XOF: streaming API to read digest in chunks.\n * Same as 'squeeze' in keccak/k12 and 'seek' in blake3, but more generic name.\n * When hash used in XOF mode it is up to user to call '.destroy' afterwards, since we cannot\n * destroy state, next call can require more bytes.\n */\nexport type HashXOF<T extends Hash<T>> = Hash<T> & {\n  xof(bytes: number): Uint8Array; // Read 'bytes' bytes from digest stream\n  xofInto(buf: Uint8Array): Uint8Array; // read buf.length bytes from digest stream into buf\n};\n\n/** Hash function */\nexport type CHash = ReturnType<typeof createHasher>;\n/** Hash function with output */\nexport type CHashO = ReturnType<typeof createOptHasher>;\n/** XOF with output */\nexport type CHashXO = ReturnType<typeof createXOFer>;\n\n/** Wraps hash function, creating an interface on top of it */\nexport function createHasher<T extends Hash<T>>(\n  hashCons: () => Hash<T>\n): {\n  (msg: Input): Uint8Array;\n  outputLen: number;\n  blockLen: number;\n  create(): Hash<T>;\n} {\n  const hashC = (msg: Input): Uint8Array => hashCons().update(toBytes(msg)).digest();\n  const tmp = hashCons();\n  hashC.outputLen = tmp.outputLen;\n  hashC.blockLen = tmp.blockLen;\n  hashC.create = () => hashCons();\n  return hashC;\n}\n\nexport function createOptHasher<H extends Hash<H>, T extends Object>(\n  hashCons: (opts?: T) => Hash<H>\n): {\n  (msg: Input, opts?: T): Uint8Array;\n  outputLen: number;\n  blockLen: number;\n  create(opts?: T): Hash<H>;\n} {\n  const hashC = (msg: Input, opts?: T): Uint8Array => hashCons(opts).update(toBytes(msg)).digest();\n  const tmp = hashCons({} as T);\n  hashC.outputLen = tmp.outputLen;\n  hashC.blockLen = tmp.blockLen;\n  hashC.create = (opts?: T) => hashCons(opts);\n  return hashC;\n}\n\nexport function createXOFer<H extends HashXOF<H>, T extends Object>(\n  hashCons: (opts?: T) => HashXOF<H>\n): {\n  (msg: Input, opts?: T): Uint8Array;\n  outputLen: number;\n  blockLen: number;\n  create(opts?: T): HashXOF<H>;\n} {\n  const hashC = (msg: Input, opts?: T): Uint8Array => hashCons(opts).update(toBytes(msg)).digest();\n  const tmp = hashCons({} as T);\n  hashC.outputLen = tmp.outputLen;\n  hashC.blockLen = tmp.blockLen;\n  hashC.create = (opts?: T) => hashCons(opts);\n  return hashC;\n}\nexport const wrapConstructor: typeof createHasher = createHasher;\nexport const wrapConstructorWithOpts: typeof createOptHasher = createOptHasher;\nexport const wrapXOFConstructorWithOpts: typeof createXOFer = createXOFer;\n\n/** Cryptographically secure PRNG. Uses internal OS-level `crypto.getRandomValues`. */\nexport function randomBytes(bytesLength = 32): Uint8Array {\n  if (crypto && typeof crypto.getRandomValues === 'function') {\n    return crypto.getRandomValues(new Uint8Array(bytesLength));\n  }\n  // Legacy Node.js compatibility\n  if (crypto && typeof crypto.randomBytes === 'function') {\n    return Uint8Array.from(crypto.randomBytes(bytesLength));\n  }\n  throw new Error('crypto.getRandomValues must be defined');\n}\n","/**\n * Internal webcrypto alias.\n * We prefer WebCrypto aka globalThis.crypto, which exists in node.js 16+.\n * Falls back to Node.js built-in crypto for Node.js <=v14.\n * See utils.ts for details.\n * @module\n */\n// @ts-ignore\nimport * as nc from 'node:crypto';\nexport const crypto: any =\n  nc && typeof nc === 'object' && 'webcrypto' in nc\n    ? (nc.webcrypto as any)\n    : nc && typeof nc === 'object' && 'randomBytes' in nc\n      ? nc\n      : undefined;\n","import { baseX } from './base.js'\n\nexport const base58btc = baseX({\n  name: 'base58btc',\n  prefix: 'z',\n  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'\n})\n\nexport const base58flickr = baseX({\n  name: 'base58flickr',\n  prefix: 'Z',\n  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'\n})\n","import * as API from './api.js'\n\nimport * as Bytes from 'multiformats/bytes'\nimport { Size as NodeSize } from './node.js'\nimport { CBOR, SHA256 } from './ipld.js'\n\n/**\n * @param {API.ProofData} proof\n * @returns {API.MerkleTreePath}\n */\nexport const path = ([, path]) => path\n\n/**\n * @param {API.ProofData} proof\n * @returns {API.uint64}\n */\nexport const offset = ([offset]) => offset\n\n/**\n * @param {API.ProofData} proof\n * @returns {number}\n */\nexport const depth = (proof) => path(proof).length\n\n/**\n * Verifies that `proof` proves that `claim.node` is contained by\n * the `claim.tree` merkle tree.\n *\n * @param {API.ProofData} proof\n * @param {object} claim\n * @param {API.MerkleTreeNode} claim.tree\n * @param {API.MerkleTreeNode} claim.node\n * @returns {API.Result<{}, Error>}\n */\nexport const verify = (proof, { tree, node }) => {\n  const computedRoot = resolveRoot(proof, node)\n  if (computedRoot.error) {\n    return { error: new Error(`computing root: ${computedRoot.error.message}`) }\n  }\n\n  if (!Bytes.equals(computedRoot.ok, tree)) {\n    return {\n      error: new Error('inclusion proof does not lead to the same root'),\n    }\n  }\n  return { ok: {} }\n}\n\nconst MAX_DEPTH = 63\n\n/**\n * Resolves the root of the merkle tree from given proof and node that root\n * supposedly includes. It does so by computing parent node from provided node\n * and node in the proof path, then combining that with the next node in the\n * path and so on until the root is reached. Function may return an error if\n * proof path is too long or if proof offset falls out of bounds.\n *\n * @param {API.ProofData} proof\n * @param {API.MerkleTreeNode} node\n * @returns {API.Result<API.MerkleTreeNode, RangeError>}\n */\nexport function resolveRoot(proof, node) {\n  if (depth(proof) > MAX_DEPTH) {\n    return {\n      error: new RangeError(\n        'merkle proofs with depths greater than 63 are not supported'\n      ),\n    }\n  }\n\n  let position = offset(proof)\n  if (position >> BigInt(depth(proof)) !== 0n) {\n    return { error: new RangeError('offset greater than width of the tree') }\n  }\n\n  let top = node\n  let right = 0n\n\n  for (const node of path(proof)) {\n    right =  position & 1n\n    position = position >> 1n\n    top = right === 1n ? computeNode(node, top) : computeNode(top, node)\n  }\n\n  return { ok: top }\n}\n\n/**\n * @param {Uint8Array} payload\n * @param {object} [options]\n * @param {API.SyncMultihashHasher<API.SHA256_CODE>} [options.hasher]\n * @returns {API.MerkleTreeNode}\n */\nexport function truncatedHash(payload, options = {}) {\n  const hasher = options.hasher || SHA256\n  const { digest } = hasher.digest(payload)\n  return truncate(digest)\n}\n\n/**\n * @param {API.MerkleTreeNode} left\n * @param {API.MerkleTreeNode} right\n * @param {object} [options]\n * @param {API.SyncMultihashHasher<API.SHA256_CODE>} [options.hasher]\n * @returns {API.MerkleTreeNode}\n */\nexport const computeNode = (left, right, options) => {\n  const payload = new Uint8Array(left.length + right.length)\n  payload.set(left, 0)\n  payload.set(right, left.length)\n  return truncatedHash(payload, options)\n}\n\n/**\n * @param {API.MerkleTreeNode} node\n * @returns {API.MerkleTreeNode}\n */\nexport function truncate(node) {\n  node[NodeSize - 1] &= 0b00111111\n  return node\n}\n\n/**\n * Takes data model and returns an IPLD View of it.\n *\n * @param {object} source\n * @param {API.uint64} source.offset\n * @param {API.MerkleTreePath} source.path\n * @returns {API.ProofData}\n */\nexport const create = ({ offset, path }) => [offset, path]\n\n/**\n * Takes proof in somewhat arbitrary form and returns a proof data.\n *\n * @param {API.IntoProofData} source\n * @returns {API.ProofData}\n */\nexport const from = (source) => {\n  const [offset, path] = Array.isArray(source)\n    ? source\n    : [source.offset, source.path]\n\n  return create({ offset: BigInt(offset), path })\n}\n\n/**\n * @param {number} height - Height of the merkle tree\n * @param {number} level - Level of the node in the merkle tree\n * @param {API.uint64} index - Index of the node in the level\n */\nexport const validateLevelIndex = (height, level, index) => {\n  if (level < 0) {\n    throw new RangeError('level can not be negative')\n  }\n\n  if (level > height) {\n    throw new RangeError(`level too high: ${level} >= ${height}`)\n  }\n\n  if (index > (1 << (height - level)) - 1) {\n    throw new RangeError(\n      `index too large for level: idx ${index}, level ${level} : ${\n        (1 << (height - level)) - 1\n      }`\n    )\n  }\n}\n","import { erc20Abi } from 'viem'\n\nexport { erc20Abi as erc20 } from 'viem'\n\n/**\n * ERC20 ABI with Permit extension\n * @see https://eips.ethereum.org/EIPS/eip-2612\n */\nexport const erc20WithPermit = [\n  ...erc20Abi,\n  ...[\n    {\n      type: 'function',\n      stateMutability: 'view',\n      name: 'nonces',\n      inputs: [{ name: 'owner', type: 'address' }],\n      outputs: [{ name: '', type: 'uint256' }],\n    },\n    {\n      type: 'function',\n      stateMutability: 'view',\n      name: 'version',\n      inputs: [],\n      outputs: [{ name: '', type: 'string' }],\n    },\n  ],\n] as const\n","/**\n * SHA2-256 a.k.a. sha256. In JS, it is the fastest hash, even faster than Blake3.\n *\n * To break sha256 using birthday attack, attackers need to try 2^128 hashes.\n * BTC network is doing 2^70 hashes/sec (2^95 hashes/year) as per 2025.\n *\n * Check out [FIPS 180-4](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf).\n * @module\n * @deprecated\n */\nimport {\n  SHA224 as SHA224n,\n  sha224 as sha224n,\n  SHA256 as SHA256n,\n  sha256 as sha256n,\n} from './sha2.ts';\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const SHA256: typeof SHA256n = SHA256n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const sha256: typeof sha256n = sha256n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const SHA224: typeof SHA224n = SHA224n;\n/** @deprecated Use import from `noble/hashes/sha2` module */\nexport const sha224: typeof sha224n = sha224n;\n","import { TypedData } from 'ox'\nimport { keccak256, stringToHex } from 'viem'\n\n/**\n * EIP-712 Type definitions for PDP operations verified by WarmStorage.\n */\nexport const EIP712_TYPES = {\n  MetadataEntry: [\n    { name: 'key', type: 'string' },\n    { name: 'value', type: 'string' },\n  ],\n  CreateDataSet: [\n    { name: 'clientDataSetId', type: 'uint256' },\n    { name: 'payee', type: 'address' },\n    { name: 'metadata', type: 'MetadataEntry[]' },\n  ],\n  Cid: [{ name: 'data', type: 'bytes' }],\n  PieceMetadata: [\n    { name: 'pieceIndex', type: 'uint256' },\n    { name: 'metadata', type: 'MetadataEntry[]' },\n  ],\n  AddPieces: [\n    { name: 'clientDataSetId', type: 'uint256' },\n    { name: 'nonce', type: 'uint256' },\n    { name: 'pieceData', type: 'Cid[]' },\n    { name: 'pieceMetadata', type: 'PieceMetadata[]' },\n  ],\n  SchedulePieceRemovals: [\n    { name: 'clientDataSetId', type: 'uint256' },\n    { name: 'pieceIds', type: 'uint256[]' },\n  ],\n  DeleteDataSet: [{ name: 'clientDataSetId', type: 'uint256' }],\n}\n\nexport const EIP712_ENCODED_TYPES: Record<string, string> = {}\nexport const EIP712_TYPE_HASHES: Record<string, string> = {}\n\nfor (const typeName in EIP712_TYPES) {\n  const encodedType = TypedData.encodeType({\n    types: EIP712_TYPES,\n    primaryType: typeName,\n  })\n  EIP712_ENCODED_TYPES[typeName] = encodedType\n  EIP712_TYPE_HASHES[typeName] = keccak256(stringToHex(encodedType))\n}\n","/**\n * PDPVerifier - Direct interaction with the PDPVerifier contract\n *\n * This is a low-level utility for interacting with the PDPVerifier contract.\n * It provides protocol-level operations without business logic.\n *\n * @example\n * ```typescript\n * import { PDPVerifier } from '@filoz/synapse-sdk/pdp'\n * import { ethers } from 'ethers'\n *\n * const provider = new ethers.JsonRpcProvider(rpcUrl)\n * const pdpVerifier = new PDPVerifier(provider, contractAddress)\n *\n * // Check if a data set is live\n * const isLive = await pdpVerifier.dataSetLive(dataSetId)\n * console.log(`Data set ${dataSetId} is ${isLive ? 'live' : 'not live'}`)\n * ```\n */\n\nimport { hexToPieceCID } from '@filoz/synapse-core/piece'\nimport { ethers } from 'ethers'\nimport type { PieceCID } from '../types.ts'\nimport { CONTRACT_ABIS, createError } from '../utils/index.ts'\n\nexport class PDPVerifier {\n  private readonly _provider: ethers.Provider\n  private readonly _contractAddress: string\n  private readonly _contract: ethers.Contract\n\n  constructor(provider: ethers.Provider, contractAddress: string) {\n    this._provider = provider\n    this._contractAddress = contractAddress\n    this._contract = new ethers.Contract(this._contractAddress, CONTRACT_ABIS.PDP_VERIFIER, this._provider)\n  }\n\n  /**\n   * Check if a data set is live\n   * @param dataSetId - The PDPVerifier data set ID\n   * @returns Whether the data set exists and is live\n   */\n  async dataSetLive(dataSetId: number): Promise<boolean> {\n    return await this._contract.dataSetLive(dataSetId)\n  }\n\n  /**\n   * Get the next piece ID for a data set\n   * @param dataSetId - The PDPVerifier data set ID\n   * @returns The next piece ID (which equals the current piece count)\n   */\n  async getNextPieceId(dataSetId: number): Promise<number> {\n    const nextPieceId = await this._contract.getNextPieceId(dataSetId)\n    return Number(nextPieceId)\n  }\n\n  /**\n   * Get the data set listener (record keeper)\n   * @param dataSetId - The PDPVerifier data set ID\n   * @returns The address of the listener contract\n   */\n  async getDataSetListener(dataSetId: number): Promise<string> {\n    return await this._contract.getDataSetListener(dataSetId)\n  }\n\n  /**\n   * Get the data set storage provider addresses\n   * @param dataSetId - The PDPVerifier data set ID\n   * @returns Object with current storage provider and proposed storage provider\n   */\n  async getDataSetStorageProvider(\n    dataSetId: number\n  ): Promise<{ storageProvider: string; proposedStorageProvider: string }> {\n    const [storageProvider, proposedStorageProvider] = await this._contract.getDataSetStorageProvider(dataSetId)\n    return { storageProvider, proposedStorageProvider }\n  }\n\n  /**\n   * Get the leaf count for a data set\n   * @param dataSetId - The PDPVerifier data set ID\n   * @returns The number of leaves in the data set\n   */\n  async getDataSetLeafCount(dataSetId: number): Promise<number> {\n    const leafCount = await this._contract.getDataSetLeafCount(dataSetId)\n    return Number(leafCount)\n  }\n\n  /**\n   * Extract data set ID from a transaction receipt by looking for DataSetCreated events\n   * @param receipt - Transaction receipt\n   * @returns Data set ID if found, null otherwise\n   */\n  extractDataSetIdFromReceipt(receipt: ethers.TransactionReceipt): number | null {\n    try {\n      // Parse logs looking for DataSetCreated event\n      for (const log of receipt.logs) {\n        try {\n          const parsedLog = this._contract.interface.parseLog({\n            topics: log.topics,\n            data: log.data,\n          })\n\n          if (parsedLog != null && parsedLog.name === 'DataSetCreated') {\n            return Number(parsedLog.args.setId)\n          }\n        } catch {\n          // ignore error\n        }\n      }\n\n      return null\n    } catch (error) {\n      throw new Error(\n        `Failed to extract data set ID from receipt: ${error instanceof Error ? error.message : String(error)}`\n      )\n    }\n  }\n\n  /**\n   * Get active pieces for a data set with pagination\n   * @param dataSetId - The PDPVerifier data set ID\n   * @param options - Optional configuration object\n   * @param options.offset - The offset to start from (default: 0)\n   * @param options.limit - The maximum number of pieces to return (default: 100)\n   * @param options.signal - Optional AbortSignal to cancel the operation\n   * @returns Object containing pieces, piece IDs, raw sizes, and hasMore flag\n   */\n  async getActivePieces(\n    dataSetId: number,\n    options?: {\n      offset?: number\n      limit?: number\n      signal?: AbortSignal\n    }\n  ): Promise<{\n    pieces: Array<{ pieceCid: PieceCID; pieceId: number }>\n    hasMore: boolean\n  }> {\n    const offset = options?.offset ?? 0\n    const limit = options?.limit ?? 100\n    const signal = options?.signal\n\n    if (signal?.aborted) {\n      throw new Error('Operation aborted')\n    }\n\n    const result = await this._contract.getActivePieces(dataSetId, offset, limit)\n\n    return {\n      pieces: result[0].map((piece: { data: string }, index: number) => {\n        try {\n          return {\n            pieceCid: hexToPieceCID(piece.data),\n            pieceId: Number(result[1][index]),\n          }\n        } catch (error) {\n          throw createError(\n            'PDPVerifier',\n            'getActivePieces',\n            `Failed to convert piece data to PieceCID: ${error instanceof Error ? error.message : String(error)}`,\n            error\n          )\n        }\n      }),\n      hasMore: Boolean(result[2]),\n    }\n  }\n\n  /**\n   * Get the PDPVerifier contract address for the current network\n   */\n  getContractAddress(): string {\n    return this._contract.target as string\n  }\n}\n","/**\n * Time and size constants\n */\nexport const TIME_CONSTANTS = {\n  /**\n   * Duration of each epoch in seconds on Filecoin\n   */\n  EPOCH_DURATION: 30,\n\n  /**\n   * Number of epochs in a day (24 hours * 60 minutes * 2 epochs per minute)\n   */\n  EPOCHS_PER_DAY: 2880n,\n\n  /**\n   * Number of epochs in a month (30 days)\n   */\n  EPOCHS_PER_MONTH: 86400n, // 30 * 2880\n\n  /**\n   * Number of days in a month (used for pricing calculations)\n   */\n  DAYS_PER_MONTH: 30n,\n\n  /**\n   * Default lockup period in days\n   */\n  DEFAULT_LOCKUP_DAYS: 10n,\n} as const\n\n/**\n * Data size constants\n */\nexport const SIZE_CONSTANTS = {\n  /**\n   * Bytes in 1 KiB\n   */\n  KiB: 1024n,\n\n  /**\n   * Bytes in 1 MiB\n   */\n  MiB: 1n << 20n,\n\n  /**\n   * Bytes in 1 GiB\n   */\n  GiB: 1n << 30n,\n\n  /**\n   * Bytes in 1 TiB\n   */\n  TiB: 1n << 40n,\n\n  /**\n   * Bytes in 1 PiB\n   */\n  PiB: 1n << 50n,\n\n  /**\n   * Maximum upload size (200 MiB)\n   * Current limitation for PDP uploads\n   */\n  MAX_UPLOAD_SIZE: 200 * 1024 * 1024,\n\n  /**\n   * Minimum upload size (127 bytes)\n   * PieceCIDv2 calculation requires at least 127 bytes payload\n   */\n  MIN_UPLOAD_SIZE: 127,\n\n  /**\n   * Default number of uploads to batch together in a single addPieces transaction\n   * This balances gas efficiency with reasonable transaction sizes\n   */\n  DEFAULT_UPLOAD_BATCH_SIZE: 32,\n} as const\n\nexport const LOCKUP_PERIOD = 30n * TIME_CONSTANTS.EPOCHS_PER_DAY\n","import {getExponentialParts, isExponential} from './helpers';\n\n/**\n * Converts exponential notation to a human readable string\n * @param {number|string|Array} num - number or array of its parts\n * @return {string}\n */\nexport default function fromExponential(num) {\n    const eParts = getExponentialParts(num);\n    if (!isExponential(eParts)) {\n        return eParts[0];\n    }\n\n    const sign = eParts[0][0] === '-' ? '-' : '';\n    const digits = eParts[0].replace(/^-/, '');\n    const digitsParts = digits.split('.');\n    const wholeDigits = digitsParts[0];\n    const fractionDigits = digitsParts[1] || '';\n    let e = Number(eParts[1]);\n\n    if (e === 0) {\n        return `${sign + wholeDigits}.${fractionDigits}`;\n    } else if (e < 0) {\n        // move dot to the left\n        const countWholeAfterTransform = wholeDigits.length + e;\n        if (countWholeAfterTransform > 0) {\n            // transform whole to fraction\n            const wholeDigitsAfterTransform = wholeDigits.substr(0, countWholeAfterTransform);\n            const wholeDigitsTransformedToFraction = wholeDigits.substr(countWholeAfterTransform);\n            return `${sign + wholeDigitsAfterTransform}.${wholeDigitsTransformedToFraction}${fractionDigits}`;\n        } else {\n            // not enough whole digits: prepend with fractional zeros\n\n            // first e goes to dotted zero\n            let zeros = '0.';\n            e = countWholeAfterTransform;\n            while (e) {\n                zeros += '0';\n                e += 1;\n            }\n            return sign + zeros + wholeDigits + fractionDigits;\n        }\n    } else {\n        // move dot to the right\n        const countFractionAfterTransform = fractionDigits.length - e;\n        if (countFractionAfterTransform > 0) {\n            // transform fraction to whole\n            // countTransformedFractionToWhole = e\n            const fractionDigitsAfterTransform = fractionDigits.substr(e);\n            const fractionDigitsTransformedToWhole = fractionDigits.substr(0, e);\n            return `${sign + wholeDigits + fractionDigitsTransformedToWhole}.${fractionDigitsAfterTransform}`;\n        } else {\n            // not enough fractions: append whole zeros\n            let zerosCount = -countFractionAfterTransform;\n            let zeros = '';\n            while (zerosCount) {\n                zeros += '0';\n                zerosCount -= 1;\n            }\n            return sign + wholeDigits + fractionDigits + zeros;\n        }\n    }\n}\n","/**\n\nSHA1 (RFC 3174), MD5 (RFC 1321) and RIPEMD160 (RFC 2286) legacy, weak hash functions.\nDon't use them in a new protocol. What \"weak\" means:\n\n- Collisions can be made with 2^18 effort in MD5, 2^60 in SHA1, 2^80 in RIPEMD160.\n- No practical pre-image attacks (only theoretical, 2^123.4)\n- HMAC seems kinda ok: https://datatracker.ietf.org/doc/html/rfc6151\n * @module\n */\nimport { Chi, HashMD, Maj } from './_md.ts';\nimport { type CHash, clean, createHasher, rotl } from './utils.ts';\n\n/** Initial SHA1 state */\nconst SHA1_IV = /* @__PURE__ */ Uint32Array.from([\n  0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0,\n]);\n\n// Reusable temporary buffer\nconst SHA1_W = /* @__PURE__ */ new Uint32Array(80);\n\n/** SHA1 legacy hash class. */\nexport class SHA1 extends HashMD<SHA1> {\n  private A = SHA1_IV[0] | 0;\n  private B = SHA1_IV[1] | 0;\n  private C = SHA1_IV[2] | 0;\n  private D = SHA1_IV[3] | 0;\n  private E = SHA1_IV[4] | 0;\n\n  constructor() {\n    super(64, 20, 8, false);\n  }\n  protected get(): [number, number, number, number, number] {\n    const { A, B, C, D, E } = this;\n    return [A, B, C, D, E];\n  }\n  protected set(A: number, B: number, C: number, D: number, E: number): void {\n    this.A = A | 0;\n    this.B = B | 0;\n    this.C = C | 0;\n    this.D = D | 0;\n    this.E = E | 0;\n  }\n  protected process(view: DataView, offset: number): void {\n    for (let i = 0; i < 16; i++, offset += 4) SHA1_W[i] = view.getUint32(offset, false);\n    for (let i = 16; i < 80; i++)\n      SHA1_W[i] = rotl(SHA1_W[i - 3] ^ SHA1_W[i - 8] ^ SHA1_W[i - 14] ^ SHA1_W[i - 16], 1);\n    // Compression function main loop, 80 rounds\n    let { A, B, C, D, E } = this;\n    for (let i = 0; i < 80; i++) {\n      let F, K;\n      if (i < 20) {\n        F = Chi(B, C, D);\n        K = 0x5a827999;\n      } else if (i < 40) {\n        F = B ^ C ^ D;\n        K = 0x6ed9eba1;\n      } else if (i < 60) {\n        F = Maj(B, C, D);\n        K = 0x8f1bbcdc;\n      } else {\n        F = B ^ C ^ D;\n        K = 0xca62c1d6;\n      }\n      const T = (rotl(A, 5) + F + E + K + SHA1_W[i]) | 0;\n      E = D;\n      D = C;\n      C = rotl(B, 30);\n      B = A;\n      A = T;\n    }\n    // Add the compressed chunk to the current hash value\n    A = (A + this.A) | 0;\n    B = (B + this.B) | 0;\n    C = (C + this.C) | 0;\n    D = (D + this.D) | 0;\n    E = (E + this.E) | 0;\n    this.set(A, B, C, D, E);\n  }\n  protected roundClean(): void {\n    clean(SHA1_W);\n  }\n  destroy(): void {\n    this.set(0, 0, 0, 0, 0);\n    clean(this.buffer);\n  }\n}\n\n/** SHA1 (RFC 3174) legacy hash function. It was cryptographically broken. */\nexport const sha1: CHash = /* @__PURE__ */ createHasher(() => new SHA1());\n\n/** Per-round constants */\nconst p32 = /* @__PURE__ */ Math.pow(2, 32);\nconst K = /* @__PURE__ */ Array.from({ length: 64 }, (_, i) =>\n  Math.floor(p32 * Math.abs(Math.sin(i + 1)))\n);\n\n/** md5 initial state: same as sha1, but 4 u32 instead of 5. */\nconst MD5_IV = /* @__PURE__ */ SHA1_IV.slice(0, 4);\n\n// Reusable temporary buffer\nconst MD5_W = /* @__PURE__ */ new Uint32Array(16);\n/** MD5 legacy hash class. */\nexport class MD5 extends HashMD<MD5> {\n  private A = MD5_IV[0] | 0;\n  private B = MD5_IV[1] | 0;\n  private C = MD5_IV[2] | 0;\n  private D = MD5_IV[3] | 0;\n\n  constructor() {\n    super(64, 16, 8, true);\n  }\n  protected get(): [number, number, number, number] {\n    const { A, B, C, D } = this;\n    return [A, B, C, D];\n  }\n  protected set(A: number, B: number, C: number, D: number): void {\n    this.A = A | 0;\n    this.B = B | 0;\n    this.C = C | 0;\n    this.D = D | 0;\n  }\n  protected process(view: DataView, offset: number): void {\n    for (let i = 0; i < 16; i++, offset += 4) MD5_W[i] = view.getUint32(offset, true);\n    // Compression function main loop, 64 rounds\n    let { A, B, C, D } = this;\n    for (let i = 0; i < 64; i++) {\n      let F, g, s;\n      if (i < 16) {\n        F = Chi(B, C, D);\n        g = i;\n        s = [7, 12, 17, 22];\n      } else if (i < 32) {\n        F = Chi(D, B, C);\n        g = (5 * i + 1) % 16;\n        s = [5, 9, 14, 20];\n      } else if (i < 48) {\n        F = B ^ C ^ D;\n        g = (3 * i + 5) % 16;\n        s = [4, 11, 16, 23];\n      } else {\n        F = C ^ (B | ~D);\n        g = (7 * i) % 16;\n        s = [6, 10, 15, 21];\n      }\n      F = F + A + K[i] + MD5_W[g];\n      A = D;\n      D = C;\n      C = B;\n      B = B + rotl(F, s[i % 4]);\n    }\n    // Add the compressed chunk to the current hash value\n    A = (A + this.A) | 0;\n    B = (B + this.B) | 0;\n    C = (C + this.C) | 0;\n    D = (D + this.D) | 0;\n    this.set(A, B, C, D);\n  }\n  protected roundClean(): void {\n    clean(MD5_W);\n  }\n  destroy(): void {\n    this.set(0, 0, 0, 0);\n    clean(this.buffer);\n  }\n}\n\n/**\n * MD5 (RFC 1321) legacy hash function. It was cryptographically broken.\n * MD5 architecture is similar to SHA1, with some differences:\n * - Reduced output length: 16 bytes (128 bit) instead of 20\n * - 64 rounds, instead of 80\n * - Little-endian: could be faster, but will require more code\n * - Non-linear index selection: huge speed-up for unroll\n * - Per round constants: more memory accesses, additional speed-up for unroll\n */\nexport const md5: CHash = /* @__PURE__ */ createHasher(() => new MD5());\n\n// RIPEMD-160\n\nconst Rho160 = /* @__PURE__ */ Uint8Array.from([\n  7, 4, 13, 1, 10, 6, 15, 3, 12, 0, 9, 5, 2, 14, 11, 8,\n]);\nconst Id160 = /* @__PURE__ */ (() => Uint8Array.from(new Array(16).fill(0).map((_, i) => i)))();\nconst Pi160 = /* @__PURE__ */ (() => Id160.map((i) => (9 * i + 5) % 16))();\nconst idxLR = /* @__PURE__ */ (() => {\n  const L = [Id160];\n  const R = [Pi160];\n  const res = [L, R];\n  for (let i = 0; i < 4; i++) for (let j of res) j.push(j[i].map((k) => Rho160[k]));\n  return res;\n})();\nconst idxL = /* @__PURE__ */ (() => idxLR[0])();\nconst idxR = /* @__PURE__ */ (() => idxLR[1])();\n// const [idxL, idxR] = idxLR;\n\nconst shifts160 = /* @__PURE__ */ [\n  [11, 14, 15, 12, 5, 8, 7, 9, 11, 13, 14, 15, 6, 7, 9, 8],\n  [12, 13, 11, 15, 6, 9, 9, 7, 12, 15, 11, 13, 7, 8, 7, 7],\n  [13, 15, 14, 11, 7, 7, 6, 8, 13, 14, 13, 12, 5, 5, 6, 9],\n  [14, 11, 12, 14, 8, 6, 5, 5, 15, 12, 15, 14, 9, 9, 8, 6],\n  [15, 12, 13, 13, 9, 5, 8, 6, 14, 11, 12, 11, 8, 6, 5, 5],\n].map((i) => Uint8Array.from(i));\nconst shiftsL160 = /* @__PURE__ */ idxL.map((idx, i) => idx.map((j) => shifts160[i][j]));\nconst shiftsR160 = /* @__PURE__ */ idxR.map((idx, i) => idx.map((j) => shifts160[i][j]));\nconst Kl160 = /* @__PURE__ */ Uint32Array.from([\n  0x00000000, 0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xa953fd4e,\n]);\nconst Kr160 = /* @__PURE__ */ Uint32Array.from([\n  0x50a28be6, 0x5c4dd124, 0x6d703ef3, 0x7a6d76e9, 0x00000000,\n]);\n// It's called f() in spec.\nfunction ripemd_f(group: number, x: number, y: number, z: number): number {\n  if (group === 0) return x ^ y ^ z;\n  if (group === 1) return (x & y) | (~x & z);\n  if (group === 2) return (x | ~y) ^ z;\n  if (group === 3) return (x & z) | (y & ~z);\n  return x ^ (y | ~z);\n}\n// Reusable temporary buffer\nconst BUF_160 = /* @__PURE__ */ new Uint32Array(16);\nexport class RIPEMD160 extends HashMD<RIPEMD160> {\n  private h0 = 0x67452301 | 0;\n  private h1 = 0xefcdab89 | 0;\n  private h2 = 0x98badcfe | 0;\n  private h3 = 0x10325476 | 0;\n  private h4 = 0xc3d2e1f0 | 0;\n\n  constructor() {\n    super(64, 20, 8, true);\n  }\n  protected get(): [number, number, number, number, number] {\n    const { h0, h1, h2, h3, h4 } = this;\n    return [h0, h1, h2, h3, h4];\n  }\n  protected set(h0: number, h1: number, h2: number, h3: number, h4: number): void {\n    this.h0 = h0 | 0;\n    this.h1 = h1 | 0;\n    this.h2 = h2 | 0;\n    this.h3 = h3 | 0;\n    this.h4 = h4 | 0;\n  }\n  protected process(view: DataView, offset: number): void {\n    for (let i = 0; i < 16; i++, offset += 4) BUF_160[i] = view.getUint32(offset, true);\n    // prettier-ignore\n    let al = this.h0 | 0, ar = al,\n        bl = this.h1 | 0, br = bl,\n        cl = this.h2 | 0, cr = cl,\n        dl = this.h3 | 0, dr = dl,\n        el = this.h4 | 0, er = el;\n\n    // Instead of iterating 0 to 80, we split it into 5 groups\n    // And use the groups in constants, functions, etc. Much simpler\n    for (let group = 0; group < 5; group++) {\n      const rGroup = 4 - group;\n      const hbl = Kl160[group], hbr = Kr160[group]; // prettier-ignore\n      const rl = idxL[group], rr = idxR[group]; // prettier-ignore\n      const sl = shiftsL160[group], sr = shiftsR160[group]; // prettier-ignore\n      for (let i = 0; i < 16; i++) {\n        const tl = (rotl(al + ripemd_f(group, bl, cl, dl) + BUF_160[rl[i]] + hbl, sl[i]) + el) | 0;\n        al = el, el = dl, dl = rotl(cl, 10) | 0, cl = bl, bl = tl; // prettier-ignore\n      }\n      // 2 loops are 10% faster\n      for (let i = 0; i < 16; i++) {\n        const tr = (rotl(ar + ripemd_f(rGroup, br, cr, dr) + BUF_160[rr[i]] + hbr, sr[i]) + er) | 0;\n        ar = er, er = dr, dr = rotl(cr, 10) | 0, cr = br, br = tr; // prettier-ignore\n      }\n    }\n    // Add the compressed chunk to the current hash value\n    this.set(\n      (this.h1 + cl + dr) | 0,\n      (this.h2 + dl + er) | 0,\n      (this.h3 + el + ar) | 0,\n      (this.h4 + al + br) | 0,\n      (this.h0 + bl + cr) | 0\n    );\n  }\n  protected roundClean(): void {\n    clean(BUF_160);\n  }\n  destroy(): void {\n    this.destroyed = true;\n    clean(this.buffer);\n    this.set(0, 0, 0, 0, 0);\n  }\n}\n\n/**\n * RIPEMD-160 - a legacy hash function from 1990s.\n * * https://homes.esat.kuleuven.be/~bosselae/ripemd160.html\n * * https://homes.esat.kuleuven.be/~bosselae/ripemd160/pdf/AB-9601/AB-9601.pdf\n */\nexport const ripemd160: CHash = /* @__PURE__ */ createHasher(() => new RIPEMD160());\n","/**\n * SHA3 (keccak) hash function, based on a new \"Sponge function\" design.\n * Different from older hashes, the internal state is bigger than output size.\n *\n * Check out [FIPS-202](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.202.pdf),\n * [Website](https://keccak.team/keccak.html),\n * [the differences between SHA-3 and Keccak](https://crypto.stackexchange.com/questions/15727/what-are-the-key-differences-between-the-draft-sha-3-standard-and-the-keccak-sub).\n *\n * Check out `sha3-addons` module for cSHAKE, k12, and others.\n * @module\n */\nimport { rotlBH, rotlBL, rotlSH, rotlSL, split } from './_u64.ts';\n// prettier-ignore\nimport {\n  abytes, aexists, anumber, aoutput,\n  clean, createHasher, createXOFer, Hash,\n  swap32IfBE,\n  toBytes, u32,\n  type CHash, type CHashXO, type HashXOF, type Input\n} from './utils.ts';\n\n// No __PURE__ annotations in sha3 header:\n// EVERYTHING is in fact used on every export.\n// Various per round constants calculations\nconst _0n = BigInt(0);\nconst _1n = BigInt(1);\nconst _2n = BigInt(2);\nconst _7n = BigInt(7);\nconst _256n = BigInt(256);\nconst _0x71n = BigInt(0x71);\nconst SHA3_PI: number[] = [];\nconst SHA3_ROTL: number[] = [];\nconst _SHA3_IOTA: bigint[] = [];\nfor (let round = 0, R = _1n, x = 1, y = 0; round < 24; round++) {\n  // Pi\n  [x, y] = [y, (2 * x + 3 * y) % 5];\n  SHA3_PI.push(2 * (5 * y + x));\n  // Rotational\n  SHA3_ROTL.push((((round + 1) * (round + 2)) / 2) % 64);\n  // Iota\n  let t = _0n;\n  for (let j = 0; j < 7; j++) {\n    R = ((R << _1n) ^ ((R >> _7n) * _0x71n)) % _256n;\n    if (R & _2n) t ^= _1n << ((_1n << /* @__PURE__ */ BigInt(j)) - _1n);\n  }\n  _SHA3_IOTA.push(t);\n}\nconst IOTAS = split(_SHA3_IOTA, true);\nconst SHA3_IOTA_H = IOTAS[0];\nconst SHA3_IOTA_L = IOTAS[1];\n\n// Left rotation (without 0, 32, 64)\nconst rotlH = (h: number, l: number, s: number) => (s > 32 ? rotlBH(h, l, s) : rotlSH(h, l, s));\nconst rotlL = (h: number, l: number, s: number) => (s > 32 ? rotlBL(h, l, s) : rotlSL(h, l, s));\n\n/** `keccakf1600` internal function, additionally allows to adjust round count. */\nexport function keccakP(s: Uint32Array, rounds: number = 24): void {\n  const B = new Uint32Array(5 * 2);\n  // NOTE: all indices are x2 since we store state as u32 instead of u64 (bigints to slow in js)\n  for (let round = 24 - rounds; round < 24; round++) {\n    // Theta θ\n    for (let x = 0; x < 10; x++) B[x] = s[x] ^ s[x + 10] ^ s[x + 20] ^ s[x + 30] ^ s[x + 40];\n    for (let x = 0; x < 10; x += 2) {\n      const idx1 = (x + 8) % 10;\n      const idx0 = (x + 2) % 10;\n      const B0 = B[idx0];\n      const B1 = B[idx0 + 1];\n      const Th = rotlH(B0, B1, 1) ^ B[idx1];\n      const Tl = rotlL(B0, B1, 1) ^ B[idx1 + 1];\n      for (let y = 0; y < 50; y += 10) {\n        s[x + y] ^= Th;\n        s[x + y + 1] ^= Tl;\n      }\n    }\n    // Rho (ρ) and Pi (π)\n    let curH = s[2];\n    let curL = s[3];\n    for (let t = 0; t < 24; t++) {\n      const shift = SHA3_ROTL[t];\n      const Th = rotlH(curH, curL, shift);\n      const Tl = rotlL(curH, curL, shift);\n      const PI = SHA3_PI[t];\n      curH = s[PI];\n      curL = s[PI + 1];\n      s[PI] = Th;\n      s[PI + 1] = Tl;\n    }\n    // Chi (χ)\n    for (let y = 0; y < 50; y += 10) {\n      for (let x = 0; x < 10; x++) B[x] = s[y + x];\n      for (let x = 0; x < 10; x++) s[y + x] ^= ~B[(x + 2) % 10] & B[(x + 4) % 10];\n    }\n    // Iota (ι)\n    s[0] ^= SHA3_IOTA_H[round];\n    s[1] ^= SHA3_IOTA_L[round];\n  }\n  clean(B);\n}\n\n/** Keccak sponge function. */\nexport class Keccak extends Hash<Keccak> implements HashXOF<Keccak> {\n  protected state: Uint8Array;\n  protected pos = 0;\n  protected posOut = 0;\n  protected finished = false;\n  protected state32: Uint32Array;\n  protected destroyed = false;\n\n  public blockLen: number;\n  public suffix: number;\n  public outputLen: number;\n  protected enableXOF = false;\n  protected rounds: number;\n\n  // NOTE: we accept arguments in bytes instead of bits here.\n  constructor(\n    blockLen: number,\n    suffix: number,\n    outputLen: number,\n    enableXOF = false,\n    rounds: number = 24\n  ) {\n    super();\n    this.blockLen = blockLen;\n    this.suffix = suffix;\n    this.outputLen = outputLen;\n    this.enableXOF = enableXOF;\n    this.rounds = rounds;\n    // Can be passed from user as dkLen\n    anumber(outputLen);\n    // 1600 = 5x5 matrix of 64bit.  1600 bits === 200 bytes\n    // 0 < blockLen < 200\n    if (!(0 < blockLen && blockLen < 200))\n      throw new Error('only keccak-f1600 function is supported');\n    this.state = new Uint8Array(200);\n    this.state32 = u32(this.state);\n  }\n  clone(): Keccak {\n    return this._cloneInto();\n  }\n  protected keccak(): void {\n    swap32IfBE(this.state32);\n    keccakP(this.state32, this.rounds);\n    swap32IfBE(this.state32);\n    this.posOut = 0;\n    this.pos = 0;\n  }\n  update(data: Input): this {\n    aexists(this);\n    data = toBytes(data);\n    abytes(data);\n    const { blockLen, state } = this;\n    const len = data.length;\n    for (let pos = 0; pos < len; ) {\n      const take = Math.min(blockLen - this.pos, len - pos);\n      for (let i = 0; i < take; i++) state[this.pos++] ^= data[pos++];\n      if (this.pos === blockLen) this.keccak();\n    }\n    return this;\n  }\n  protected finish(): void {\n    if (this.finished) return;\n    this.finished = true;\n    const { state, suffix, pos, blockLen } = this;\n    // Do the padding\n    state[pos] ^= suffix;\n    if ((suffix & 0x80) !== 0 && pos === blockLen - 1) this.keccak();\n    state[blockLen - 1] ^= 0x80;\n    this.keccak();\n  }\n  protected writeInto(out: Uint8Array): Uint8Array {\n    aexists(this, false);\n    abytes(out);\n    this.finish();\n    const bufferOut = this.state;\n    const { blockLen } = this;\n    for (let pos = 0, len = out.length; pos < len; ) {\n      if (this.posOut >= blockLen) this.keccak();\n      const take = Math.min(blockLen - this.posOut, len - pos);\n      out.set(bufferOut.subarray(this.posOut, this.posOut + take), pos);\n      this.posOut += take;\n      pos += take;\n    }\n    return out;\n  }\n  xofInto(out: Uint8Array): Uint8Array {\n    // Sha3/Keccak usage with XOF is probably mistake, only SHAKE instances can do XOF\n    if (!this.enableXOF) throw new Error('XOF is not possible for this instance');\n    return this.writeInto(out);\n  }\n  xof(bytes: number): Uint8Array {\n    anumber(bytes);\n    return this.xofInto(new Uint8Array(bytes));\n  }\n  digestInto(out: Uint8Array): Uint8Array {\n    aoutput(out, this);\n    if (this.finished) throw new Error('digest() was already called');\n    this.writeInto(out);\n    this.destroy();\n    return out;\n  }\n  digest(): Uint8Array {\n    return this.digestInto(new Uint8Array(this.outputLen));\n  }\n  destroy(): void {\n    this.destroyed = true;\n    clean(this.state);\n  }\n  _cloneInto(to?: Keccak): Keccak {\n    const { blockLen, suffix, outputLen, rounds, enableXOF } = this;\n    to ||= new Keccak(blockLen, suffix, outputLen, enableXOF, rounds);\n    to.state32.set(this.state32);\n    to.pos = this.pos;\n    to.posOut = this.posOut;\n    to.finished = this.finished;\n    to.rounds = rounds;\n    // Suffix can change in cSHAKE\n    to.suffix = suffix;\n    to.outputLen = outputLen;\n    to.enableXOF = enableXOF;\n    to.destroyed = this.destroyed;\n    return to;\n  }\n}\n\nconst gen = (suffix: number, blockLen: number, outputLen: number) =>\n  createHasher(() => new Keccak(blockLen, suffix, outputLen));\n\n/** SHA3-224 hash function. */\nexport const sha3_224: CHash = /* @__PURE__ */ (() => gen(0x06, 144, 224 / 8))();\n/** SHA3-256 hash function. Different from keccak-256. */\nexport const sha3_256: CHash = /* @__PURE__ */ (() => gen(0x06, 136, 256 / 8))();\n/** SHA3-384 hash function. */\nexport const sha3_384: CHash = /* @__PURE__ */ (() => gen(0x06, 104, 384 / 8))();\n/** SHA3-512 hash function. */\nexport const sha3_512: CHash = /* @__PURE__ */ (() => gen(0x06, 72, 512 / 8))();\n\n/** keccak-224 hash function. */\nexport const keccak_224: CHash = /* @__PURE__ */ (() => gen(0x01, 144, 224 / 8))();\n/** keccak-256 hash function. Different from SHA3-256. */\nexport const keccak_256: CHash = /* @__PURE__ */ (() => gen(0x01, 136, 256 / 8))();\n/** keccak-384 hash function. */\nexport const keccak_384: CHash = /* @__PURE__ */ (() => gen(0x01, 104, 384 / 8))();\n/** keccak-512 hash function. */\nexport const keccak_512: CHash = /* @__PURE__ */ (() => gen(0x01, 72, 512 / 8))();\n\nexport type ShakeOpts = { dkLen?: number };\n\nconst genShake = (suffix: number, blockLen: number, outputLen: number) =>\n  createXOFer<HashXOF<Keccak>, ShakeOpts>(\n    (opts: ShakeOpts = {}) =>\n      new Keccak(blockLen, suffix, opts.dkLen === undefined ? outputLen : opts.dkLen, true)\n  );\n\n/** SHAKE128 XOF with 128-bit security. */\nexport const shake128: CHashXO = /* @__PURE__ */ (() => genShake(0x1f, 168, 128 / 8))();\n/** SHAKE256 XOF with 256-bit security. */\nexport const shake256: CHashXO = /* @__PURE__ */ (() => genShake(0x1f, 136, 256 / 8))();\n","import type * as Errors from '../Errors.js'\nimport * as Hex from '../Hex.js'\n\n/** @internal */\nexport function assertSize(hex: Hex.Hex, size_: number): void {\n  if (Hex.size(hex) > size_)\n    throw new Hex.SizeOverflowError({\n      givenSize: Hex.size(hex),\n      maxSize: size_,\n    })\n}\n\n/** @internal */\nexport declare namespace assertSize {\n  type ErrorType =\n    | Hex.size.ErrorType\n    | Hex.SizeOverflowError\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function assertStartOffset(value: Hex.Hex, start?: number | undefined) {\n  if (typeof start === 'number' && start > 0 && start > Hex.size(value) - 1)\n    throw new Hex.SliceOffsetOutOfBoundsError({\n      offset: start,\n      position: 'start',\n      size: Hex.size(value),\n    })\n}\n\nexport declare namespace assertStartOffset {\n  type ErrorType =\n    | Hex.SliceOffsetOutOfBoundsError\n    | Hex.size.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function assertEndOffset(\n  value: Hex.Hex,\n  start?: number | undefined,\n  end?: number | undefined,\n) {\n  if (\n    typeof start === 'number' &&\n    typeof end === 'number' &&\n    Hex.size(value) !== end - start\n  ) {\n    throw new Hex.SliceOffsetOutOfBoundsError({\n      offset: end,\n      position: 'end',\n      size: Hex.size(value),\n    })\n  }\n}\n\nexport declare namespace assertEndOffset {\n  type ErrorType =\n    | Hex.SliceOffsetOutOfBoundsError\n    | Hex.size.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function pad(hex_: Hex.Hex, options: pad.Options = {}) {\n  const { dir, size = 32 } = options\n\n  if (size === 0) return hex_\n\n  const hex = hex_.replace('0x', '')\n  if (hex.length > size * 2)\n    throw new Hex.SizeExceedsPaddingSizeError({\n      size: Math.ceil(hex.length / 2),\n      targetSize: size,\n      type: 'Hex',\n    })\n\n  return `0x${hex[dir === 'right' ? 'padEnd' : 'padStart'](size * 2, '0')}` as Hex.Hex\n}\n\n/** @internal */\nexport declare namespace pad {\n  type Options = {\n    dir?: 'left' | 'right' | undefined\n    size?: number | undefined\n  }\n  type ErrorType = Hex.SizeExceedsPaddingSizeError | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function trim(\n  value: Hex.Hex,\n  options: trim.Options = {},\n): trim.ReturnType {\n  const { dir = 'left' } = options\n\n  let data = value.replace('0x', '')\n\n  let sliceLength = 0\n  for (let i = 0; i < data.length - 1; i++) {\n    if (data[dir === 'left' ? i : data.length - i - 1]!.toString() === '0')\n      sliceLength++\n    else break\n  }\n  data =\n    dir === 'left'\n      ? data.slice(sliceLength)\n      : data.slice(0, data.length - sliceLength)\n\n  if (data === '0') return '0x'\n  if (dir === 'right' && data.length % 2 === 1) return `0x${data}0`\n  return `0x${data}` as trim.ReturnType\n}\n\n/** @internal */\nexport declare namespace trim {\n  type Options = {\n    dir?: 'left' | 'right' | undefined\n  }\n\n  type ReturnType = Hex.Hex\n\n  type ErrorType = Errors.GlobalErrorType\n}\n","import { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\nimport * as negint from './1negint.js'\nimport * as bytes from './2bytes.js'\nimport * as string from './3string.js'\nimport * as array from './4array.js'\nimport * as map from './5map.js'\nimport * as tag from './6tag.js'\nimport * as float from './7float.js'\nimport { decodeErrPrefix } from './common.js'\nimport { fromArray } from './byte-utils.js'\n\n/**\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n */\nfunction invalidMinor (data, pos, minor) {\n  throw new Error(`${decodeErrPrefix} encountered invalid minor (${minor}) for major ${data[pos] >>> 5}`)\n}\n\n/**\n * @param {string} msg\n * @returns {()=>any}\n */\nfunction errorer (msg) {\n  return () => { throw new Error(`${decodeErrPrefix} ${msg}`) }\n}\n\n/** @type {((data:Uint8Array, pos:number, minor:number, options?:DecodeOptions) => any)[]} */\nexport const jump = []\n\n// unsigned integer, 0x00..0x17 (0..23)\nfor (let i = 0; i <= 0x17; i++) {\n  jump[i] = invalidMinor // uint.decodeUintCompact, handled by quick[]\n}\njump[0x18] = uint.decodeUint8 // unsigned integer, one-byte uint8_t follows\njump[0x19] = uint.decodeUint16 // unsigned integer, two-byte uint16_t follows\njump[0x1a] = uint.decodeUint32 // unsigned integer, four-byte uint32_t follows\njump[0x1b] = uint.decodeUint64 // unsigned integer, eight-byte uint64_t follows\njump[0x1c] = invalidMinor\njump[0x1d] = invalidMinor\njump[0x1e] = invalidMinor\njump[0x1f] = invalidMinor\n// negative integer, -1-0x00..-1-0x17 (-1..-24)\nfor (let i = 0x20; i <= 0x37; i++) {\n  jump[i] = invalidMinor // negintDecode, handled by quick[]\n}\njump[0x38] = negint.decodeNegint8 // negative integer, -1-n one-byte uint8_t for n follows\njump[0x39] = negint.decodeNegint16 // negative integer, -1-n two-byte uint16_t for n follows\njump[0x3a] = negint.decodeNegint32 // negative integer, -1-n four-byte uint32_t for follows\njump[0x3b] = negint.decodeNegint64 // negative integer, -1-n eight-byte uint64_t for follows\njump[0x3c] = invalidMinor\njump[0x3d] = invalidMinor\njump[0x3e] = invalidMinor\njump[0x3f] = invalidMinor\n// byte string, 0x00..0x17 bytes follow\nfor (let i = 0x40; i <= 0x57; i++) {\n  jump[i] = bytes.decodeBytesCompact\n}\njump[0x58] = bytes.decodeBytes8 // byte string, one-byte uint8_t for n, and then n bytes follow\njump[0x59] = bytes.decodeBytes16 // byte string, two-byte uint16_t for n, and then n bytes follow\njump[0x5a] = bytes.decodeBytes32 // byte string, four-byte uint32_t for n, and then n bytes follow\njump[0x5b] = bytes.decodeBytes64 // byte string, eight-byte uint64_t for n, and then n bytes follow\njump[0x5c] = invalidMinor\njump[0x5d] = invalidMinor\njump[0x5e] = invalidMinor\njump[0x5f] = errorer('indefinite length bytes/strings are not supported') // byte string, byte strings follow, terminated by \"break\"\n// UTF-8 string 0x00..0x17 bytes follow\nfor (let i = 0x60; i <= 0x77; i++) {\n  jump[i] = string.decodeStringCompact\n}\njump[0x78] = string.decodeString8 // UTF-8 string, one-byte uint8_t for n, and then n bytes follow\njump[0x79] = string.decodeString16 // UTF-8 string, two-byte uint16_t for n, and then n bytes follow\njump[0x7a] = string.decodeString32 // UTF-8 string, four-byte uint32_t for n, and then n bytes follow\njump[0x7b] = string.decodeString64 // UTF-8 string, eight-byte uint64_t for n, and then n bytes follow\njump[0x7c] = invalidMinor\njump[0x7d] = invalidMinor\njump[0x7e] = invalidMinor\njump[0x7f] = errorer('indefinite length bytes/strings are not supported') // UTF-8 strings follow, terminated by \"break\"\n// array, 0x00..0x17 data items follow\nfor (let i = 0x80; i <= 0x97; i++) {\n  jump[i] = array.decodeArrayCompact\n}\njump[0x98] = array.decodeArray8 // array, one-byte uint8_t for n, and then n data items follow\njump[0x99] = array.decodeArray16 // array, two-byte uint16_t for n, and then n data items follow\njump[0x9a] = array.decodeArray32 // array, four-byte uint32_t for n, and then n data items follow\njump[0x9b] = array.decodeArray64 // array, eight-byte uint64_t for n, and then n data items follow\njump[0x9c] = invalidMinor\njump[0x9d] = invalidMinor\njump[0x9e] = invalidMinor\njump[0x9f] = array.decodeArrayIndefinite // array, data items follow, terminated by \"break\"\n// map, 0x00..0x17 pairs of data items follow\nfor (let i = 0xa0; i <= 0xb7; i++) {\n  jump[i] = map.decodeMapCompact\n}\njump[0xb8] = map.decodeMap8 // map, one-byte uint8_t for n, and then n pairs of data items follow\njump[0xb9] = map.decodeMap16 // map, two-byte uint16_t for n, and then n pairs of data items follow\njump[0xba] = map.decodeMap32 // map, four-byte uint32_t for n, and then n pairs of data items follow\njump[0xbb] = map.decodeMap64 // map, eight-byte uint64_t for n, and then n pairs of data items follow\njump[0xbc] = invalidMinor\njump[0xbd] = invalidMinor\njump[0xbe] = invalidMinor\njump[0xbf] = map.decodeMapIndefinite // map, pairs of data items follow, terminated by \"break\"\n// tags\nfor (let i = 0xc0; i <= 0xd7; i++) {\n  jump[i] = tag.decodeTagCompact\n}\njump[0xd8] = tag.decodeTag8\njump[0xd9] = tag.decodeTag16\njump[0xda] = tag.decodeTag32\njump[0xdb] = tag.decodeTag64\njump[0xdc] = invalidMinor\njump[0xdd] = invalidMinor\njump[0xde] = invalidMinor\njump[0xdf] = invalidMinor\n// 0xe0..0xf3 simple values, unsupported\nfor (let i = 0xe0; i <= 0xf3; i++) {\n  jump[i] = errorer('simple values are not supported')\n}\njump[0xf4] = invalidMinor // false, handled by quick[]\njump[0xf5] = invalidMinor // true, handled by quick[]\njump[0xf6] = invalidMinor // null, handled by quick[]\njump[0xf7] = float.decodeUndefined // undefined\njump[0xf8] = errorer('simple values are not supported') // simple value, one byte follows, unsupported\njump[0xf9] = float.decodeFloat16 // half-precision float (two-byte IEEE 754)\njump[0xfa] = float.decodeFloat32 // single-precision float (four-byte IEEE 754)\njump[0xfb] = float.decodeFloat64 // double-precision float (eight-byte IEEE 754)\njump[0xfc] = invalidMinor\njump[0xfd] = invalidMinor\njump[0xfe] = invalidMinor\njump[0xff] = float.decodeBreak // \"break\" stop code\n\n/** @type {Token[]} */\nexport const quick = []\n// ints <24\nfor (let i = 0; i < 24; i++) {\n  quick[i] = new Token(Type.uint, i, 1)\n}\n// negints >= -24\nfor (let i = -1; i >= -24; i--) {\n  quick[31 - i] = new Token(Type.negint, i, 1)\n}\n// empty bytes\nquick[0x40] = new Token(Type.bytes, new Uint8Array(0), 1)\n// empty string\nquick[0x60] = new Token(Type.string, '', 1)\n// empty list\nquick[0x80] = new Token(Type.array, 0, 1)\n// empty map\nquick[0xa0] = new Token(Type.map, 0, 1)\n// false\nquick[0xf4] = new Token(Type.false, false, 1)\n// true\nquick[0xf5] = new Token(Type.true, true, 1)\n// null\nquick[0xf6] = new Token(Type.null, null, 1)\n\n/**\n * @param {Token} token\n * @returns {Uint8Array|undefined}\n */\nexport function quickEncodeToken (token) {\n  switch (token.type) {\n    case Type.false:\n      return fromArray([0xf4])\n    case Type.true:\n      return fromArray([0xf5])\n    case Type.null:\n      return fromArray([0xf6])\n    case Type.bytes:\n      if (!token.value.length) {\n        return fromArray([0x40])\n      }\n      return\n    case Type.string:\n      if (token.value === '') {\n        return fromArray([0x60])\n      }\n      return\n    case Type.array:\n      if (token.value === 0) {\n        return fromArray([0x80])\n      }\n      /* c8 ignore next 2 */\n      // shouldn't be possible if this were called when there was only one token\n      return\n    case Type.map:\n      if (token.value === 0) {\n        return fromArray([0xa0])\n      }\n      /* c8 ignore next 2 */\n      // shouldn't be possible if this were called when there was only one token\n      return\n    case Type.uint:\n      if (token.value < 24) {\n        return fromArray([Number(token.value)])\n      }\n      return\n    case Type.negint:\n      if (token.value >= -24) {\n        return fromArray([31 - Number(token.value)])\n      }\n  }\n}\n","/**\n * Isomorphic signals\n *\n * @module\n */\n\n/**\n * Combines an array of AbortSignals into a single signal that is aborted when any signal is\n *\n * @param {Iterable<AbortSignal | undefined>} signals - The signals to combine\n * @returns {AbortSignal} - The combined signal\n */\nexport function anySignal(signals) {\n  const controller = new AbortController()\n\n  for (const signal of signals) {\n    if (signal && 'aborted' in signal && 'reason' in signal) {\n      if (signal.aborted) {\n        controller.abort(signal.reason)\n        return signal\n      }\n\n      signal.addEventListener('abort', () => controller.abort(signal.reason), {\n        signal: controller.signal,\n        once: true,\n      })\n    }\n  }\n\n  return controller.signal\n}\n","import { getVersion } from './internal/errors.js'\n\nexport type GlobalErrorType<name extends string = 'Error'> = Error & {\n  name: name\n}\n\n/**\n * Base error class inherited by all errors thrown by ox.\n *\n * @example\n * ```ts\n * import { Errors } from 'ox'\n * throw new Errors.BaseError('An error occurred')\n * ```\n */\nexport class BaseError<\n  cause extends Error | undefined = undefined,\n> extends Error {\n  details: string\n  docs?: string | undefined\n  docsPath?: string | undefined\n  shortMessage: string\n  version?: string | undefined\n\n  override cause: cause\n  override name = 'BaseError'\n\n  constructor(shortMessage: string, options: BaseError.Options<cause> = {}) {\n    const details = (() => {\n      if (options.cause instanceof BaseError) {\n        if (options.cause.details) return options.cause.details\n        if (options.cause.shortMessage) return options.cause.shortMessage\n      }\n      if (\n        options.cause &&\n        'details' in options.cause &&\n        typeof options.cause.details === 'string'\n      )\n        return options.cause.details\n      if (options.cause?.message) return options.cause.message\n      return options.details!\n    })()\n    const docsPath = (() => {\n      if (options.cause instanceof BaseError)\n        return options.cause.docsPath || options.docsPath\n      return options.docsPath\n    })()\n\n    const docsBaseUrl = options.docsOrigin ?? 'https://oxlib.sh'\n    const docs = `${docsBaseUrl}${docsPath ?? ''}`\n\n    const message = [\n      shortMessage || 'An error occurred.',\n      ...(options.metaMessages ? ['', ...options.metaMessages] : []),\n      ...(details || docsPath || options.version\n        ? [\n            '',\n            details ? `Details: ${details}` : undefined,\n            docsPath ? `See: ${docs}` : undefined,\n            options.version ? `Version: ${options.version}` : undefined,\n          ]\n        : []),\n    ]\n      .filter((x) => typeof x === 'string')\n      .join('\\n')\n\n    super(message, options.cause ? { cause: options.cause } : undefined)\n\n    this.cause = options.cause as any\n    this.details = details\n    this.docs = docs\n    this.docsPath = docsPath\n    this.shortMessage = shortMessage\n    this.version = options.version ?? `ox@${getVersion()}`\n  }\n\n  walk(): Error\n  walk(fn: (err: unknown) => boolean): Error | null\n  walk(fn?: any): any {\n    return walk(this, fn)\n  }\n}\n\nexport declare namespace BaseError {\n  type Options<cause extends Error | undefined = Error | undefined> = {\n    cause?: cause | undefined\n    details?: string | undefined\n    docsOrigin?: string | undefined\n    docsPath?: string | undefined\n    metaMessages?: (string | undefined)[] | undefined\n    version?: string | undefined\n  }\n}\n\n/** @internal */\nfunction walk(\n  err: unknown,\n  fn?: ((err: unknown) => boolean) | undefined,\n): unknown {\n  if (fn?.(err)) return err\n  if (err && typeof err === 'object' && 'cause' in err && err.cause)\n    return walk(err.cause, fn)\n  return fn ? null : err\n}\n","import { base32 } from './bases/base32.js'\nimport { base36 } from './bases/base36.js'\nimport { base58btc } from './bases/base58.js'\nimport { coerce } from './bytes.js'\nimport * as Digest from './hashes/digest.js'\nimport * as varint from './varint.js'\nimport type * as API from './link/interface.js'\n\n// This way TS will also expose all the types from module\nexport * from './link/interface.js'\n\nexport function format <T extends API.Link<unknown, number, number, API.Version>, Prefix extends string> (link: T, base?: API.MultibaseEncoder<Prefix>): API.ToString<T, Prefix> {\n  const { bytes, version } = link\n  switch (version) {\n    case 0:\n      return toStringV0(\n        bytes,\n        baseCache(link),\n        base as API.MultibaseEncoder<'z'> ?? base58btc.encoder\n      )\n    default:\n      return toStringV1(\n        bytes,\n        baseCache(link),\n        (base ?? base32.encoder) as API.MultibaseEncoder<Prefix>\n      )\n  }\n}\n\nexport function toJSON <Link extends API.UnknownLink> (link: Link): API.LinkJSON<Link> {\n  return {\n    '/': format(link)\n  }\n}\n\nexport function fromJSON <Link extends API.UnknownLink> (json: API.LinkJSON<Link>): CID<unknown, number, number, API.Version> {\n  return CID.parse(json['/'])\n}\n\nconst cache = new WeakMap<API.UnknownLink, Map<string, string>>()\n\nfunction baseCache (cid: API.UnknownLink): Map<string, string> {\n  const baseCache = cache.get(cid)\n  if (baseCache == null) {\n    const baseCache = new Map()\n    cache.set(cid, baseCache)\n    return baseCache\n  }\n  return baseCache\n}\n\nexport class CID<Data = unknown, Format extends number = number, Alg extends number = number, Version extends API.Version = API.Version> implements API.Link<Data, Format, Alg, Version> {\n  readonly code: Format\n  readonly version: Version\n  readonly multihash: API.MultihashDigest<Alg>\n  readonly bytes: Uint8Array\n  readonly '/': Uint8Array\n\n  /**\n   * @param version - Version of the CID\n   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv\n   * @param multihash - (Multi)hash of the of the content.\n   */\n  constructor (version: Version, code: Format, multihash: API.MultihashDigest<Alg>, bytes: Uint8Array) {\n    this.code = code\n    this.version = version\n    this.multihash = multihash\n    this.bytes = bytes\n\n    // flag to serializers that this is a CID and\n    // should be treated specially\n    this['/'] = bytes\n  }\n\n  /**\n   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`\n   * please either use `CID.asCID(cid)` or switch to new signalling mechanism\n   *\n   * @deprecated\n   */\n  get asCID (): this {\n    return this\n  }\n\n  // ArrayBufferView\n  get byteOffset (): number {\n    return this.bytes.byteOffset\n  }\n\n  // ArrayBufferView\n  get byteLength (): number {\n    return this.bytes.byteLength\n  }\n\n  toV0 (): CID<Data, API.DAG_PB, API.SHA_256, 0> {\n    switch (this.version) {\n      case 0: {\n        return this as CID<Data, API.DAG_PB, API.SHA_256, 0>\n      }\n      case 1: {\n        const { code, multihash } = this\n\n        if (code !== DAG_PB_CODE) {\n          throw new Error('Cannot convert a non dag-pb CID to CIDv0')\n        }\n\n        // sha2-256\n        if (multihash.code !== SHA_256_CODE) {\n          throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0')\n        }\n\n        return (\n          CID.createV0(\n            multihash as API.MultihashDigest<API.SHA_256>\n          )\n        )\n      }\n      default: {\n        throw Error(\n          `Can not convert CID version ${this.version} to version 0. This is a bug please report`\n        )\n      }\n    }\n  }\n\n  toV1 (): CID<Data, Format, Alg, 1> {\n    switch (this.version) {\n      case 0: {\n        const { code, digest } = this.multihash\n        const multihash = Digest.create(code, digest)\n        return (\n          CID.createV1(this.code, multihash)\n        )\n      }\n      case 1: {\n        return this as CID<Data, Format, Alg, 1>\n      }\n      default: {\n        throw Error(\n          `Can not convert CID version ${this.version} to version 1. This is a bug please report`\n        )\n      }\n    }\n  }\n\n  equals (other: unknown): other is CID<Data, Format, Alg, Version> {\n    return CID.equals(this, other)\n  }\n\n  static equals <Data, Format extends number, Alg extends number, Version extends API.Version>(self: API.Link<Data, Format, Alg, Version>, other: unknown): other is CID {\n    const unknown = other as { code?: unknown, version?: unknown, multihash?: unknown }\n    return (\n      unknown != null &&\n      self.code === unknown.code &&\n      self.version === unknown.version &&\n      Digest.equals(self.multihash, unknown.multihash)\n    )\n  }\n\n  toString (base?: API.MultibaseEncoder<string>): string {\n    return format(this, base)\n  }\n\n  toJSON (): API.LinkJSON<this> {\n    return { '/': format(this) }\n  }\n\n  link (): this {\n    return this\n  }\n\n  readonly [Symbol.toStringTag] = 'CID';\n\n  // Legacy\n\n  [Symbol.for('nodejs.util.inspect.custom')] (): string {\n    return `CID(${this.toString()})`\n  }\n\n  /**\n   * Takes any input `value` and returns a `CID` instance if it was\n   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`\n   * it will return value back. If `value` is not instance of this CID\n   * class, but is compatible CID it will return new instance of this\n   * `CID` class. Otherwise returns null.\n   *\n   * This allows two different incompatible versions of CID library to\n   * co-exist and interop as long as binary interface is compatible.\n   */\n  static asCID <Data, Format extends number, Alg extends number, Version extends API.Version, U>(input: API.Link<Data, Format, Alg, Version> | U): CID<Data, Format, Alg, Version> | null {\n    if (input == null) {\n      return null\n    }\n\n    const value = input as any\n    if (value instanceof CID) {\n      // If value is instance of CID then we're all set.\n      return value\n    } else if ((value['/'] != null && value['/'] === value.bytes) || value.asCID === value) {\n      // If value isn't instance of this CID class but `this.asCID === this` or\n      // `value['/'] === value.bytes` is true it is CID instance coming from a\n      // different implementation (diff version or duplicate). In that case we\n      // rebase it to this `CID` implementation so caller is guaranteed to get\n      // instance with expected API.\n      const { version, code, multihash, bytes } = value\n      return new CID(\n        version,\n        code,\n        multihash as API.MultihashDigest<Alg>,\n        bytes ?? encodeCID(version, code, multihash.bytes)\n      )\n    } else if (value[cidSymbol] === true) {\n      // If value is a CID from older implementation that used to be tagged via\n      // symbol we still rebase it to the this `CID` implementation by\n      // delegating that to a constructor.\n      const { version, multihash, code } = value\n      const digest = Digest.decode(multihash) as API.MultihashDigest<Alg>\n      return CID.create(version, code, digest)\n    } else {\n      // Otherwise value is not a CID (or an incompatible version of it) in\n      // which case we return `null`.\n      return null\n    }\n  }\n\n  /**\n   * @param version - Version of the CID\n   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv\n   * @param digest - (Multi)hash of the of the content.\n   */\n  static create <Data, Format extends number, Alg extends number, Version extends API.Version>(version: Version, code: Format, digest: API.MultihashDigest<Alg>): CID<Data, Format, Alg, Version> {\n    if (typeof code !== 'number') {\n      throw new Error('String codecs are no longer supported')\n    }\n\n    if (!(digest.bytes instanceof Uint8Array)) {\n      throw new Error('Invalid digest')\n    }\n\n    switch (version) {\n      case 0: {\n        if (code !== DAG_PB_CODE) {\n          throw new Error(\n            `Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`\n          )\n        } else {\n          return new CID(version, code, digest, digest.bytes)\n        }\n      }\n      case 1: {\n        const bytes = encodeCID(version, code, digest.bytes)\n        return new CID(version, code, digest, bytes)\n      }\n      default: {\n        throw new Error('Invalid version')\n      }\n    }\n  }\n\n  /**\n   * Simplified version of `create` for CIDv0.\n   */\n  static createV0 <T = unknown>(digest: API.MultihashDigest<typeof SHA_256_CODE>): CID<T, typeof DAG_PB_CODE, typeof SHA_256_CODE, 0> {\n    return CID.create(0, DAG_PB_CODE, digest)\n  }\n\n  /**\n   * Simplified version of `create` for CIDv1.\n   *\n   * @param code - Content encoding format code.\n   * @param digest - Multihash of the content.\n   */\n  static createV1 <Data, Code extends number, Alg extends number>(code: Code, digest: API.MultihashDigest<Alg>): CID<Data, Code, Alg, 1> {\n    return CID.create(1, code, digest)\n  }\n\n  /**\n   * Decoded a CID from its binary representation. The byte array must contain\n   * only the CID with no additional bytes.\n   *\n   * An error will be thrown if the bytes provided do not contain a valid\n   * binary representation of a CID.\n   */\n  static decode <Data, Code extends number, Alg extends number, Version extends API.Version>(bytes: API.ByteView<API.Link<Data, Code, Alg, Version>>): CID<Data, Code, Alg, Version> {\n    const [cid, remainder] = CID.decodeFirst(bytes)\n    if (remainder.length !== 0) {\n      throw new Error('Incorrect length')\n    }\n    return cid\n  }\n\n  /**\n   * Decoded a CID from its binary representation at the beginning of a byte\n   * array.\n   *\n   * Returns an array with the first element containing the CID and the second\n   * element containing the remainder of the original byte array. The remainder\n   * will be a zero-length byte array if the provided bytes only contained a\n   * binary CID representation.\n   */\n  static decodeFirst <T, C extends number, A extends number, V extends API.Version>(bytes: API.ByteView<API.Link<T, C, A, V>>): [CID<T, C, A, V>, Uint8Array] {\n    const specs = CID.inspectBytes(bytes)\n    const prefixSize = specs.size - specs.multihashSize\n    const multihashBytes = coerce(\n      bytes.subarray(prefixSize, prefixSize + specs.multihashSize)\n    )\n    if (multihashBytes.byteLength !== specs.multihashSize) {\n      throw new Error('Incorrect length')\n    }\n    const digestBytes = multihashBytes.subarray(\n      specs.multihashSize - specs.digestSize\n    )\n    const digest = new Digest.Digest(\n      specs.multihashCode,\n      specs.digestSize,\n      digestBytes,\n      multihashBytes\n    )\n    const cid =\n      specs.version === 0\n        ? CID.createV0(digest as API.MultihashDigest<API.SHA_256>)\n        : CID.createV1(specs.codec, digest)\n    return [cid as CID<T, C, A, V>, bytes.subarray(specs.size)]\n  }\n\n  /**\n   * Inspect the initial bytes of a CID to determine its properties.\n   *\n   * Involves decoding up to 4 varints. Typically this will require only 4 to 6\n   * bytes but for larger multicodec code values and larger multihash digest\n   * lengths these varints can be quite large. It is recommended that at least\n   * 10 bytes be made available in the `initialBytes` argument for a complete\n   * inspection.\n   */\n  static inspectBytes <T, C extends number, A extends number, V extends API.Version>(initialBytes: API.ByteView<API.Link<T, C, A, V>>): { version: V, codec: C, multihashCode: A, digestSize: number, multihashSize: number, size: number } {\n    let offset = 0\n    const next = (): number => {\n      const [i, length] = varint.decode(initialBytes.subarray(offset))\n      offset += length\n      return i\n    }\n\n    let version = next() as V\n    let codec = DAG_PB_CODE as C\n    if (version as number === 18) {\n      // CIDv0\n      version = 0 as V\n      offset = 0\n    } else {\n      codec = next() as C\n    }\n\n    if (version !== 0 && version !== 1) {\n      throw new RangeError(`Invalid CID version ${version}`)\n    }\n\n    const prefixSize = offset\n    const multihashCode = next() as A // multihash code\n    const digestSize = next() // multihash length\n    const size = offset + digestSize\n    const multihashSize = size - prefixSize\n\n    return { version, codec, multihashCode, digestSize, multihashSize, size }\n  }\n\n  /**\n   * Takes cid in a string representation and creates an instance. If `base`\n   * decoder is not provided will use a default from the configuration. It will\n   * throw an error if encoding of the CID is not compatible with supplied (or\n   * a default decoder).\n   */\n  static parse <Prefix extends string, Data, Code extends number, Alg extends number, Version extends API.Version>(source: API.ToString<API.Link<Data, Code, Alg, Version>, Prefix>, base?: API.MultibaseDecoder<Prefix>): CID<Data, Code, Alg, Version> {\n    const [prefix, bytes] = parseCIDtoBytes(source, base)\n\n    const cid = CID.decode(bytes)\n\n    if (cid.version === 0 && source[0] !== 'Q') {\n      throw Error('Version 0 CID string must not include multibase prefix')\n    }\n\n    // Cache string representation to avoid computing it on `this.toString()`\n    baseCache(cid).set(prefix, source)\n\n    return cid\n  }\n}\n\nfunction parseCIDtoBytes <Prefix extends string, Data, Code extends number, Alg extends number, Version extends API.Version> (source: API.ToString<API.Link<Data, Code, Alg, Version>, Prefix>, base?: API.MultibaseDecoder<Prefix>): [Prefix, API.ByteView<API.Link<Data, Code, Alg, Version>>] {\n  switch (source[0]) {\n    // CIDv0 is parsed differently\n    case 'Q': {\n      const decoder = base ?? base58btc\n      return [\n        base58btc.prefix as Prefix,\n        decoder.decode(`${base58btc.prefix}${source}`)\n      ]\n    }\n    case base58btc.prefix: {\n      const decoder = base ?? base58btc\n      return [base58btc.prefix as Prefix, decoder.decode(source)]\n    }\n    case base32.prefix: {\n      const decoder = base ?? base32\n      return [base32.prefix as Prefix, decoder.decode(source)]\n    }\n    case base36.prefix: {\n      const decoder = base ?? base36\n      return [base36.prefix as Prefix, decoder.decode(source)]\n    }\n    default: {\n      if (base == null) {\n        throw Error(\n          'To parse non base32, base36 or base58btc encoded CID multibase decoder must be provided'\n        )\n      }\n      return [source[0] as Prefix, base.decode(source)]\n    }\n  }\n}\n\nfunction toStringV0 (bytes: Uint8Array, cache: Map<string, string>, base: API.MultibaseEncoder<'z'>): string {\n  const { prefix } = base\n  if (prefix !== base58btc.prefix) {\n    throw Error(`Cannot string encode V0 in ${base.name} encoding`)\n  }\n\n  const cid = cache.get(prefix)\n  if (cid == null) {\n    const cid = base.encode(bytes).slice(1)\n    cache.set(prefix, cid)\n    return cid\n  } else {\n    return cid\n  }\n}\n\nfunction toStringV1 <Prefix extends string> (bytes: Uint8Array, cache: Map<string, string>, base: API.MultibaseEncoder<Prefix>): string {\n  const { prefix } = base\n  const cid = cache.get(prefix)\n  if (cid == null) {\n    const cid = base.encode(bytes)\n    cache.set(prefix, cid)\n    return cid\n  } else {\n    return cid\n  }\n}\n\nconst DAG_PB_CODE = 0x70\nconst SHA_256_CODE = 0x12\n\nfunction encodeCID (version: API.Version, code: number, multihash: Uint8Array): Uint8Array {\n  const codeOffset = varint.encodingLength(version)\n  const hashOffset = codeOffset + varint.encodingLength(code)\n  const bytes = new Uint8Array(hashOffset + multihash.byteLength)\n  varint.encodeTo(version, bytes, 0)\n  varint.encodeTo(code, bytes, codeOffset)\n  bytes.set(multihash, hashOffset)\n  return bytes\n}\n\nconst cidSymbol = Symbol.for('@ipld/js-cid/CID')\n","//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// Errors\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x0000000000000000000000000000000000000000)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x0000000000000000000000000000000000000000)\n */\nexport const errorsAbi = [\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'field',\n        internalType: 'enum Errors.AddressField',\n        type: 'uint8',\n      },\n    ],\n    name: 'AddressAlreadySet',\n  },\n  { type: 'error', inputs: [], name: 'AtLeastOnePriceMustBeNonZero' },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'CDNPaymentAlreadyTerminated',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'CacheMissPaymentAlreadyTerminated',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'expectedPayer', internalType: 'address', type: 'address' },\n      { name: 'caller', internalType: 'address', type: 'address' },\n    ],\n    name: 'CallerNotPayer',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'expectedPayer', internalType: 'address', type: 'address' },\n      { name: 'expectedPayee', internalType: 'address', type: 'address' },\n      { name: 'caller', internalType: 'address', type: 'address' },\n    ],\n    name: 'CallerNotPayerOrPayee',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'CallerNotPayments',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'windowStart', internalType: 'uint256', type: 'uint256' },\n      { name: 'nowBlock', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ChallengeWindowTooEarly',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'clientDataSetId', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ClientDataSetAlreadyRegistered',\n  },\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'commissionType',\n        internalType: 'enum Errors.CommissionType',\n        type: 'uint8',\n      },\n      { name: 'max', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'CommissionExceedsMaximum',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'DataSetNotFoundForRail',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'DataSetNotRegistered',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'DataSetPaymentAlreadyTerminated',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pdpEndEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'currentBlock', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'DataSetPaymentBeyondEndEpoch',\n  },\n  { type: 'error', inputs: [], name: 'DivisionByZero' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'key', internalType: 'string', type: 'string' },\n    ],\n    name: 'DuplicateMetadataKey',\n  },\n  { type: 'error', inputs: [], name: 'ExtraDataRequired' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'actualSize', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowedSize', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ExtraDataTooLarge',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'FilBeamServiceNotConfigured',\n  },\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n    ],\n    name: 'InsufficientCapabilitiesForProduct',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'minimumRequired', internalType: 'uint256', type: 'uint256' },\n      { name: 'available', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientFundsForMinimumRate',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'lockupAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupUsage', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'minimumLockupRequired',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'InsufficientLockupAllowance',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'maxLockupPeriod', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'requiredLockupPeriod',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'InsufficientMaxLockupPeriod',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'rateAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'rateUsage', internalType: 'uint256', type: 'uint256' },\n      { name: 'minimumRateRequired', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientRateAllowance',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'minExpected', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidChallengeCount',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'minAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidChallengeEpoch',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'maxProvingPeriod', internalType: 'uint256', type: 'uint256' },\n      { name: 'challengeWindowSize', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidChallengeWindowSize',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'InvalidDataSetId',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'fromEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'toEpoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidEpochRange',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'length', internalType: 'uint256', type: 'uint256' }],\n    name: 'InvalidServiceDescriptionLength',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'length', internalType: 'uint256', type: 'uint256' }],\n    name: 'InvalidServiceNameLength',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'InvalidSignature',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expectedLength', internalType: 'uint256', type: 'uint256' },\n      { name: 'actualLength', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidSignatureLength',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'InvalidTopUpAmount',\n  },\n  { type: 'error', inputs: [], name: 'MaxProvingPeriodZero' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'metadataArrayCount', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceCount', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'MetadataArrayCountMismatch',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'keysLength', internalType: 'uint256', type: 'uint256' },\n      { name: 'valuesLength', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'MetadataKeyAndValueLengthMismatch',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'index', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'length', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'MetadataKeyExceedsMaxLength',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'index', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'length', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'MetadataValueExceedsMaxLength',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'periodDeadline', internalType: 'uint256', type: 'uint256' },\n      { name: 'nowBlock', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'NextProvingPeriodAlreadyCalled',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'NoPDPPaymentRail',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'OldServiceProviderMismatch',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'OnlyFilBeamControllerAllowed',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'OnlyPDPVerifierAllowed',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'OnlySelf',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n    ],\n    name: 'OperatorNotApproved',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pdpEndEpoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'PaymentRailsNotFinalized',\n  },\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'priceType',\n        internalType: 'enum Errors.PriceType',\n        type: 'uint8',\n      },\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'PriceExceedsMaximum',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProofAlreadySubmitted',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProviderAlreadyApproved',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProviderNotInApprovedList',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'provider', internalType: 'address', type: 'address' }],\n    name: 'ProviderNotRegistered',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProvingNotStarted',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProvingPeriodNotInitialized',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'deadline', internalType: 'uint256', type: 'uint256' },\n      { name: 'nowBlock', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ProvingPeriodPassed',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'RailNotAssociated',\n  },\n  { type: 'error', inputs: [], name: 'ServiceContractMustTerminateRail' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'keysLength', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'TooManyMetadataKeys',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'v', internalType: 'uint8', type: 'uint8' }],\n    name: 'UnsupportedSignatureV',\n  },\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'field',\n        internalType: 'enum Errors.AddressField',\n        type: 'uint8',\n      },\n    ],\n    name: 'ZeroAddress',\n  },\n] as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x0000000000000000000000000000000000000000)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x0000000000000000000000000000000000000000)\n */\nexport const errorsAddress = {\n  314: '0x0000000000000000000000000000000000000000',\n  314159: '0x0000000000000000000000000000000000000000',\n} as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x0000000000000000000000000000000000000000)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x0000000000000000000000000000000000000000)\n */\nexport const errorsConfig = { address: errorsAddress, abi: errorsAbi } as const\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// FilecoinPayV1\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x23b1e018F08BB982348b15a86ee926eEBf7F4DAa)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x09a0fDc2723fAd1A7b8e3e00eE5DF73841df55a0)\n */\nexport const filecoinPayV1Abi = [\n  { type: 'constructor', inputs: [], stateMutability: 'nonpayable' },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'COMMISSION_MAX_BPS',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'NETWORK_FEE_DENOMINATOR',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'NETWORK_FEE_NUMERATOR',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'owner', internalType: 'address', type: 'address' },\n    ],\n    name: 'accounts',\n    outputs: [\n      { name: 'funds', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupCurrent', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupRate', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupLastSettledAt', internalType: 'uint256', type: 'uint256' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n    ],\n    name: 'auctionInfo',\n    outputs: [\n      { name: 'startPrice', internalType: 'uint88', type: 'uint88' },\n      { name: 'startTime', internalType: 'uint168', type: 'uint168' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'recipient', internalType: 'address', type: 'address' },\n      { name: 'requested', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'burnForFees',\n    outputs: [],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'validator', internalType: 'address', type: 'address' },\n      { name: 'commissionRateBps', internalType: 'uint256', type: 'uint256' },\n      { name: 'serviceFeeRecipient', internalType: 'address', type: 'address' },\n    ],\n    name: 'createRail',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'deposit',\n    outputs: [],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC3009', type: 'address' },\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n      { name: 'validAfter', internalType: 'uint256', type: 'uint256' },\n      { name: 'validBefore', internalType: 'uint256', type: 'uint256' },\n      { name: 'nonce', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'v', internalType: 'uint8', type: 'uint8' },\n      { name: 'r', internalType: 'bytes32', type: 'bytes32' },\n      { name: 's', internalType: 'bytes32', type: 'bytes32' },\n    ],\n    name: 'depositWithAuthorization',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC3009', type: 'address' },\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n      { name: 'validAfter', internalType: 'uint256', type: 'uint256' },\n      { name: 'validBefore', internalType: 'uint256', type: 'uint256' },\n      { name: 'nonce', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'v', internalType: 'uint8', type: 'uint8' },\n      { name: 'r', internalType: 'bytes32', type: 'bytes32' },\n      { name: 's', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'rateAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxLockupPeriod', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'depositWithAuthorizationAndApproveOperator',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC3009', type: 'address' },\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n      { name: 'validAfter', internalType: 'uint256', type: 'uint256' },\n      { name: 'validBefore', internalType: 'uint256', type: 'uint256' },\n      { name: 'nonce', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'v', internalType: 'uint8', type: 'uint8' },\n      { name: 'r', internalType: 'bytes32', type: 'bytes32' },\n      { name: 's', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      {\n        name: 'rateAllowanceIncrease',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n      {\n        name: 'lockupAllowanceIncrease',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'depositWithAuthorizationAndIncreaseOperatorApproval',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n      { name: 'deadline', internalType: 'uint256', type: 'uint256' },\n      { name: 'v', internalType: 'uint8', type: 'uint8' },\n      { name: 'r', internalType: 'bytes32', type: 'bytes32' },\n      { name: 's', internalType: 'bytes32', type: 'bytes32' },\n    ],\n    name: 'depositWithPermit',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n      { name: 'deadline', internalType: 'uint256', type: 'uint256' },\n      { name: 'v', internalType: 'uint8', type: 'uint8' },\n      { name: 'r', internalType: 'bytes32', type: 'bytes32' },\n      { name: 's', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'rateAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxLockupPeriod', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'depositWithPermitAndApproveOperator',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n      { name: 'deadline', internalType: 'uint256', type: 'uint256' },\n      { name: 'v', internalType: 'uint8', type: 'uint8' },\n      { name: 'r', internalType: 'bytes32', type: 'bytes32' },\n      { name: 's', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      {\n        name: 'rateAllowanceIncrease',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n      {\n        name: 'lockupAllowanceIncrease',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'depositWithPermitAndIncreaseOperatorApproval',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'owner', internalType: 'address', type: 'address' },\n    ],\n    name: 'getAccountInfoIfSettled',\n    outputs: [\n      { name: 'fundedUntilEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'currentFunds', internalType: 'uint256', type: 'uint256' },\n      { name: 'availableFunds', internalType: 'uint256', type: 'uint256' },\n      { name: 'currentLockupRate', internalType: 'uint256', type: 'uint256' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getRail',\n    outputs: [\n      {\n        name: '',\n        internalType: 'struct FilecoinPayV1.RailView',\n        type: 'tuple',\n        components: [\n          { name: 'token', internalType: 'contract IERC20', type: 'address' },\n          { name: 'from', internalType: 'address', type: 'address' },\n          { name: 'to', internalType: 'address', type: 'address' },\n          { name: 'operator', internalType: 'address', type: 'address' },\n          { name: 'validator', internalType: 'address', type: 'address' },\n          { name: 'paymentRate', internalType: 'uint256', type: 'uint256' },\n          { name: 'lockupPeriod', internalType: 'uint256', type: 'uint256' },\n          { name: 'lockupFixed', internalType: 'uint256', type: 'uint256' },\n          { name: 'settledUpTo', internalType: 'uint256', type: 'uint256' },\n          { name: 'endEpoch', internalType: 'uint256', type: 'uint256' },\n          {\n            name: 'commissionRateBps',\n            internalType: 'uint256',\n            type: 'uint256',\n          },\n          {\n            name: 'serviceFeeRecipient',\n            internalType: 'address',\n            type: 'address',\n          },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'payee', internalType: 'address', type: 'address' },\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'offset', internalType: 'uint256', type: 'uint256' },\n      { name: 'limit', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getRailsForPayeeAndToken',\n    outputs: [\n      {\n        name: 'results',\n        internalType: 'struct FilecoinPayV1.RailInfo[]',\n        type: 'tuple[]',\n        components: [\n          { name: 'railId', internalType: 'uint256', type: 'uint256' },\n          { name: 'isTerminated', internalType: 'bool', type: 'bool' },\n          { name: 'endEpoch', internalType: 'uint256', type: 'uint256' },\n        ],\n      },\n      { name: 'nextOffset', internalType: 'uint256', type: 'uint256' },\n      { name: 'total', internalType: 'uint256', type: 'uint256' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'offset', internalType: 'uint256', type: 'uint256' },\n      { name: 'limit', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getRailsForPayerAndToken',\n    outputs: [\n      {\n        name: 'results',\n        internalType: 'struct FilecoinPayV1.RailInfo[]',\n        type: 'tuple[]',\n        components: [\n          { name: 'railId', internalType: 'uint256', type: 'uint256' },\n          { name: 'isTerminated', internalType: 'bool', type: 'bool' },\n          { name: 'endEpoch', internalType: 'uint256', type: 'uint256' },\n        ],\n      },\n      { name: 'nextOffset', internalType: 'uint256', type: 'uint256' },\n      { name: 'total', internalType: 'uint256', type: 'uint256' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getRateChangeQueueSize',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      {\n        name: 'rateAllowanceIncrease',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n      {\n        name: 'lockupAllowanceIncrease',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'increaseOperatorApproval',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'period', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupFixed', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'modifyRailLockup',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'newRate', internalType: 'uint256', type: 'uint256' },\n      { name: 'oneTimePayment', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'modifyRailPayment',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'client', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n    ],\n    name: 'operatorApprovals',\n    outputs: [\n      { name: 'isApproved', internalType: 'bool', type: 'bool' },\n      { name: 'rateAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'rateUsage', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupUsage', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxLockupPeriod', internalType: 'uint256', type: 'uint256' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'approved', internalType: 'bool', type: 'bool' },\n      { name: 'rateAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxLockupPeriod', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'setOperatorApproval',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'untilEpoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'settleRail',\n    outputs: [\n      { name: 'totalSettledAmount', internalType: 'uint256', type: 'uint256' },\n      { name: 'totalNetPayeeAmount', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'totalOperatorCommission',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n      { name: 'totalNetworkFee', internalType: 'uint256', type: 'uint256' },\n      { name: 'finalSettledEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'note', internalType: 'string', type: 'string' },\n    ],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'settleTerminatedRailWithoutValidation',\n    outputs: [\n      { name: 'totalSettledAmount', internalType: 'uint256', type: 'uint256' },\n      { name: 'totalNetPayeeAmount', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'totalOperatorCommission',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n      { name: 'totalNetworkFee', internalType: 'uint256', type: 'uint256' },\n      { name: 'finalSettledEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'note', internalType: 'string', type: 'string' },\n    ],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'terminateRail',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'withdraw',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'withdrawTo',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'token',\n        internalType: 'contract IERC20',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'owner',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'lockupCurrent',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'lockupRate',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'lockupLastSettledAt',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'AccountLockupSettled',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'token',\n        internalType: 'contract IERC20',\n        type: 'address',\n        indexed: true,\n      },\n      { name: 'from', internalType: 'address', type: 'address', indexed: true },\n      { name: 'to', internalType: 'address', type: 'address', indexed: true },\n      {\n        name: 'amount',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'DepositRecorded',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'token',\n        internalType: 'contract IERC20',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'client',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'operator',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      { name: 'approved', internalType: 'bool', type: 'bool', indexed: false },\n      {\n        name: 'rateAllowance',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'lockupAllowance',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'maxLockupPeriod',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'OperatorApprovalUpdated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'railId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'payer',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'payee',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'token',\n        internalType: 'contract IERC20',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'operator',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'validator',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'serviceFeeRecipient',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'commissionRateBps',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'RailCreated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'railId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n    ],\n    name: 'RailFinalized',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'railId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'oldLockupPeriod',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'newLockupPeriod',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'oldLockupFixed',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'newLockupFixed',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'RailLockupModified',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'railId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'netPayeeAmount',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'operatorCommission',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'networkFee',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'RailOneTimePaymentProcessed',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'railId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'oldRate',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'newRate',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'RailRateModified',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'railId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'totalSettledAmount',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'totalNetPayeeAmount',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'operatorCommission',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'networkFee',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'settledUpTo',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'RailSettled',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'railId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      { name: 'by', internalType: 'address', type: 'address', indexed: true },\n      {\n        name: 'endEpoch',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'RailTerminated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'token',\n        internalType: 'contract IERC20',\n        type: 'address',\n        indexed: true,\n      },\n      { name: 'from', internalType: 'address', type: 'address', indexed: true },\n      { name: 'to', internalType: 'address', type: 'address', indexed: true },\n      {\n        name: 'amount',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'WithdrawRecorded',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxSettlementEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'blockNumber', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'CannotModifyTerminatedRailBeyondEndEpoch',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowedEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'attemptedEpoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'CannotSettleFutureEpochs',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'requiredBlock', internalType: 'uint256', type: 'uint256' },\n      { name: 'currentBlock', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'CannotSettleTerminatedRailBeforeMaxEpoch',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'CommissionRateTooHigh',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'oldLockup', internalType: 'uint256', type: 'uint256' },\n      { name: 'currentLockup', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'CurrentLockupLessThanOldLockup',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'currentLockup', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupReduction', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientCurrentLockup',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'required', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientFundsForOneTimePayment',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'available', internalType: 'uint256', type: 'uint256' },\n      { name: 'required', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientFundsForSettlement',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'available', internalType: 'uint256', type: 'uint256' },\n      { name: 'required', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientLockupForSettlement',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'required', internalType: 'uint256', type: 'uint256' },\n      { name: 'sent', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientNativeTokenForBurn',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'available', internalType: 'uint256', type: 'uint256' },\n      { name: 'requested', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientUnlockedFunds',\n  },\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'nextRateChangeUntilEpoch',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n      { name: 'processedEpoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidRateChangeQueueState',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'actualPeriod', internalType: 'uint256', type: 'uint256' },\n      { name: 'actualLockupFixed', internalType: 'uint256', type: 'uint256' },\n      { name: 'attemptedPeriod', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'attemptedLockupFixed',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'InvalidTerminatedRailModification',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'account', internalType: 'address', type: 'address' },\n      { name: 'lockupCurrent', internalType: 'uint256', type: 'uint256' },\n      { name: 'fundsCurrent', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'LockupExceedsFundsInvariant',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'actualLockupFixed', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'attemptedLockupFixed',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'LockupFixedIncreaseNotAllowedDueToInsufficientFunds',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'expectedLockup', internalType: 'uint256', type: 'uint256' },\n      { name: 'actualLockup', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'LockupInconsistencyDuringRailFinalization',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'isSettled', internalType: 'bool', type: 'bool' },\n      { name: 'currentRate', internalType: 'uint256', type: 'uint256' },\n      { name: 'attemptedRate', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'LockupNotSettledRateChangeNotAllowed',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'actualLockupPeriod', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'attemptedLockupPeriod',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'LockupPeriodChangeNotAllowedDueToInsufficientFunds',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'maxAllowedPeriod', internalType: 'uint256', type: 'uint256' },\n      { name: 'requestedPeriod', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'LockupPeriodExceedsOperatorMaximum',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'paymentRate', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupRate', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'LockupRateInconsistent',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'lockupRate', internalType: 'uint256', type: 'uint256' },\n      { name: 'oldRate', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'LockupRateLessThanOldRate',\n  },\n  { type: 'error', inputs: [], name: 'MissingServiceFeeRecipient' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'required', internalType: 'uint256', type: 'uint256' },\n      { name: 'sent', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'MustSendExactNativeAmount',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'sent', internalType: 'uint256', type: 'uint256' }],\n    name: 'NativeTokenNotAccepted',\n  },\n  { type: 'error', inputs: [], name: 'NativeTokenNotSupported' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'to', internalType: 'address', type: 'address' },\n      { name: 'amount', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'NativeTransferFailed',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'expectedSettledUpTo', internalType: 'uint256', type: 'uint256' },\n      { name: 'actualSettledUpTo', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'NoProgressInSettlement',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'allowedClient', internalType: 'address', type: 'address' },\n      { name: 'allowedOperator', internalType: 'address', type: 'address' },\n      { name: 'caller', internalType: 'address', type: 'address' },\n    ],\n    name: 'NotAuthorizedToTerminateRail',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'available', internalType: 'uint256', type: 'uint256' },\n      { name: 'required', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'OneTimePaymentExceedsLockup',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'caller', internalType: 'address', type: 'address' },\n    ],\n    name: 'OnlyRailClientAllowed',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'caller', internalType: 'address', type: 'address' },\n    ],\n    name: 'OnlyRailOperatorAllowed',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'allowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'attemptedUsage', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'OperatorLockupAllowanceExceeded',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'from', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n    ],\n    name: 'OperatorNotApproved',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'allowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'attemptedUsage', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'OperatorRateAllowanceExceeded',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'x', internalType: 'uint256', type: 'uint256' },\n      { name: 'y', internalType: 'uint256', type: 'uint256' },\n      { name: 'denominator', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'PRBMath_MulDiv_Overflow',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'x', internalType: 'UD60x18', type: 'uint256' }],\n    name: 'PRBMath_UD60x18_Exp2_InputTooBig',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'RailAlreadyTerminated',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'RailInactiveOrSettled',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'RailNotTerminated',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'RateChangeNotAllowedOnTerminatedRail',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'nextUntilEpoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'RateChangeQueueNotEmpty',\n  },\n  { type: 'error', inputs: [], name: 'ReentrancyGuardReentrantCall' },\n  {\n    type: 'error',\n    inputs: [{ name: 'token', internalType: 'address', type: 'address' }],\n    name: 'SafeERC20FailedOperation',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'SignerMustBeMsgSender',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'attempted', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ValidatorModifiedAmountExceedsMaximum',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'allowedStart', internalType: 'uint256', type: 'uint256' },\n      { name: 'attemptedStart', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ValidatorSettledBeforeSegmentStart',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'allowedEnd', internalType: 'uint256', type: 'uint256' },\n      { name: 'attemptedEnd', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ValidatorSettledBeyondSegmentEnd',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'token', internalType: 'contract IERC20', type: 'address' },\n      { name: 'available', internalType: 'uint256', type: 'uint256' },\n      { name: 'requested', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'WithdrawAmountExceedsAccumulatedFees',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'varName', internalType: 'string', type: 'string' }],\n    name: 'ZeroAddressNotAllowed',\n  },\n] as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x23b1e018F08BB982348b15a86ee926eEBf7F4DAa)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x09a0fDc2723fAd1A7b8e3e00eE5DF73841df55a0)\n */\nexport const filecoinPayV1Address = {\n  314: '0x23b1e018F08BB982348b15a86ee926eEBf7F4DAa',\n  314159: '0x09a0fDc2723fAd1A7b8e3e00eE5DF73841df55a0',\n} as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x23b1e018F08BB982348b15a86ee926eEBf7F4DAa)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x09a0fDc2723fAd1A7b8e3e00eE5DF73841df55a0)\n */\nexport const filecoinPayV1Config = {\n  address: filecoinPayV1Address,\n  abi: filecoinPayV1Abi,\n} as const\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// FilecoinWarmStorageService\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x8408502033C418E1bbC97cE9ac48E5528F371A9f)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x02925630df557F957f70E112bA06e50965417CA0)\n */\nexport const filecoinWarmStorageServiceAbi = [\n  {\n    type: 'constructor',\n    inputs: [\n      { name: '_pdpVerifierAddress', internalType: 'address', type: 'address' },\n      {\n        name: '_paymentsContractAddress',\n        internalType: 'address',\n        type: 'address',\n      },\n      {\n        name: '_usdfc',\n        internalType: 'contract IERC20Metadata',\n        type: 'address',\n      },\n      {\n        name: '_filBeamBeneficiaryAddress',\n        internalType: 'address',\n        type: 'address',\n      },\n      {\n        name: '_serviceProviderRegistry',\n        internalType: 'contract ServiceProviderRegistry',\n        type: 'address',\n      },\n      {\n        name: '_sessionKeyRegistry',\n        internalType: 'contract SessionKeyRegistry',\n        type: 'address',\n      },\n    ],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'UPGRADE_INTERFACE_VERSION',\n    outputs: [{ name: '', internalType: 'string', type: 'string' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'VERSION',\n    outputs: [{ name: '', internalType: 'string', type: 'string' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'addApprovedProvider',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      {\n        name: 'plannedUpgrade',\n        internalType: 'struct FilecoinWarmStorageService.PlannedUpgrade',\n        type: 'tuple',\n        components: [\n          {\n            name: 'nextImplementation',\n            internalType: 'address',\n            type: 'address',\n          },\n          { name: 'afterEpoch', internalType: 'uint96', type: 'uint96' },\n        ],\n      },\n    ],\n    name: 'announcePlannedUpgrade',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'totalBytes', internalType: 'uint256', type: 'uint256' }],\n    name: 'calculateRatePerEpoch',\n    outputs: [\n      { name: 'storageRate', internalType: 'uint256', type: 'uint256' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: '_maxProvingPeriod', internalType: 'uint64', type: 'uint64' },\n      {\n        name: '_challengeWindowSize',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'configureProvingPeriod',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'serviceProvider', internalType: 'address', type: 'address' },\n      { name: 'extraData', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'dataSetCreated',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: '', internalType: 'uint256', type: 'uint256' },\n      { name: '', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'dataSetDeleted',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'eip712Domain',\n    outputs: [\n      { name: 'fields', internalType: 'bytes1', type: 'bytes1' },\n      { name: 'name', internalType: 'string', type: 'string' },\n      { name: 'version', internalType: 'string', type: 'string' },\n      { name: 'chainId', internalType: 'uint256', type: 'uint256' },\n      { name: 'verifyingContract', internalType: 'address', type: 'address' },\n      { name: 'salt', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'extensions', internalType: 'uint256[]', type: 'uint256[]' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'slot', internalType: 'bytes32', type: 'bytes32' }],\n    name: 'extsload',\n    outputs: [{ name: '', internalType: 'bytes32', type: 'bytes32' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'slot', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'size', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'extsloadStruct',\n    outputs: [{ name: '', internalType: 'bytes32[]', type: 'bytes32[]' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'filBeamBeneficiaryAddress',\n    outputs: [{ name: '', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getEffectiveRates',\n    outputs: [\n      { name: 'serviceFee', internalType: 'uint256', type: 'uint256' },\n      { name: 'spPayment', internalType: 'uint256', type: 'uint256' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'epoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getProvingPeriodForEpoch',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getServicePrice',\n    outputs: [\n      {\n        name: 'pricing',\n        internalType: 'struct FilecoinWarmStorageService.ServicePricing',\n        type: 'tuple',\n        components: [\n          {\n            name: 'pricePerTiBPerMonthNoCDN',\n            internalType: 'uint256',\n            type: 'uint256',\n          },\n          {\n            name: 'pricePerTiBCdnEgress',\n            internalType: 'uint256',\n            type: 'uint256',\n          },\n          {\n            name: 'pricePerTiBCacheMissEgress',\n            internalType: 'uint256',\n            type: 'uint256',\n          },\n          {\n            name: 'tokenAddress',\n            internalType: 'contract IERC20',\n            type: 'address',\n          },\n          { name: 'epochsPerMonth', internalType: 'uint256', type: 'uint256' },\n          {\n            name: 'minimumPricePerMonth',\n            internalType: 'uint256',\n            type: 'uint256',\n          },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: '_maxProvingPeriod', internalType: 'uint64', type: 'uint64' },\n      {\n        name: '_challengeWindowSize',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n      {\n        name: '_filBeamControllerAddress',\n        internalType: 'address',\n        type: 'address',\n      },\n      { name: '_name', internalType: 'string', type: 'string' },\n      { name: '_description', internalType: 'string', type: 'string' },\n    ],\n    name: 'initialize',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: '_viewContract', internalType: 'address', type: 'address' },\n    ],\n    name: 'migrate',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'challengeEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'leafCount', internalType: 'uint256', type: 'uint256' },\n      { name: '', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'nextProvingPeriod',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'owner',\n    outputs: [{ name: '', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'paymentsContractAddress',\n    outputs: [{ name: '', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'pdpVerifierAddress',\n    outputs: [{ name: '', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'firstAdded', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'pieceData',\n        internalType: 'struct Cids.Cid[]',\n        type: 'tuple[]',\n        components: [{ name: 'data', internalType: 'bytes', type: 'bytes' }],\n      },\n      { name: 'extraData', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'piecesAdded',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceIds', internalType: 'uint256[]', type: 'uint256[]' },\n      { name: 'extraData', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'piecesScheduledRemove',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: '', internalType: 'uint256', type: 'uint256' },\n      { name: '', internalType: 'uint256', type: 'uint256' },\n      { name: 'challengeCount', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'possessionProven',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'proxiableUUID',\n    outputs: [{ name: '', internalType: 'bytes32', type: 'bytes32' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'terminator', internalType: 'address', type: 'address' },\n      { name: 'endEpoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'railTerminated',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n      { name: 'index', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'removeApprovedProvider',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'renounceOwnership',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'serviceProviderRegistry',\n    outputs: [\n      {\n        name: '',\n        internalType: 'contract ServiceProviderRegistry',\n        type: 'address',\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'sessionKeyRegistry',\n    outputs: [\n      {\n        name: '',\n        internalType: 'contract SessionKeyRegistry',\n        type: 'address',\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: '_viewContract', internalType: 'address', type: 'address' },\n    ],\n    name: 'setViewContract',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'cdnAmount', internalType: 'uint256', type: 'uint256' },\n      { name: 'cacheMissAmount', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'settleFilBeamPaymentRails',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: '', internalType: 'uint256', type: 'uint256' },\n      { name: '', internalType: 'address', type: 'address' },\n      { name: '', internalType: 'address', type: 'address' },\n      { name: '', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'storageProviderChanged',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'terminateCDNService',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'terminateService',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'cdnAmountToAdd', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'cacheMissAmountToAdd',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'topUpCDNPaymentRails',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'newController', internalType: 'address', type: 'address' },\n    ],\n    name: 'transferFilBeamController',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'newOwner', internalType: 'address', type: 'address' }],\n    name: 'transferOwnership',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'newStoragePrice', internalType: 'uint256', type: 'uint256' },\n      { name: 'newMinimumRate', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'updatePricing',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'newCommissionBps', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'updateServiceCommission',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'newImplementation', internalType: 'address', type: 'address' },\n      { name: 'data', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'upgradeToAndCall',\n    outputs: [],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'usdfcTokenAddress',\n    outputs: [\n      { name: '', internalType: 'contract IERC20Metadata', type: 'address' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'railId', internalType: 'uint256', type: 'uint256' },\n      { name: 'proposedAmount', internalType: 'uint256', type: 'uint256' },\n      { name: 'fromEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'toEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: '', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'validatePayment',\n    outputs: [\n      {\n        name: 'result',\n        internalType: 'struct IValidator.ValidationResult',\n        type: 'tuple',\n        components: [\n          { name: 'modifiedAmount', internalType: 'uint256', type: 'uint256' },\n          { name: 'settleUpto', internalType: 'uint256', type: 'uint256' },\n          { name: 'note', internalType: 'string', type: 'string' },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'viewContractAddress',\n    outputs: [{ name: '', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'cdnAmountAdded',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'totalCdnLockup',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'cacheMissAmountAdded',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'totalCacheMissLockup',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'CDNPaymentRailsToppedUp',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'endEpoch',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'cacheMissRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'cdnRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'CDNPaymentTerminated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'caller',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'cacheMissRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'cdnRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'CDNServiceTerminated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'version',\n        internalType: 'string',\n        type: 'string',\n        indexed: false,\n      },\n      {\n        name: 'implementation',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n    ],\n    name: 'ContractUpgraded',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'providerId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'pdpRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'cacheMissRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'cdnRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'payer',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'serviceProvider',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'payee',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'metadataKeys',\n        internalType: 'string[]',\n        type: 'string[]',\n        indexed: false,\n      },\n      {\n        name: 'metadataValues',\n        internalType: 'string[]',\n        type: 'string[]',\n        indexed: false,\n      },\n    ],\n    name: 'DataSetCreated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'oldServiceProvider',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'newServiceProvider',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'DataSetServiceProviderChanged',\n  },\n  { type: 'event', anonymous: false, inputs: [], name: 'EIP712DomainChanged' },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'periodsFaulted',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'deadline',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'FaultRecord',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'oldController',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'newController',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n    ],\n    name: 'FilBeamControllerChanged',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      { name: 'name', internalType: 'string', type: 'string', indexed: false },\n      {\n        name: 'description',\n        internalType: 'string',\n        type: 'string',\n        indexed: false,\n      },\n    ],\n    name: 'FilecoinServiceDeployed',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'version',\n        internalType: 'uint64',\n        type: 'uint64',\n        indexed: false,\n      },\n    ],\n    name: 'Initialized',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'previousOwner',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'newOwner',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'OwnershipTransferred',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'endEpoch',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'pdpRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'PDPPaymentTerminated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'pieceId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'pieceCid',\n        internalType: 'struct Cids.Cid',\n        type: 'tuple',\n        components: [{ name: 'data', internalType: 'bytes', type: 'bytes' }],\n        indexed: false,\n      },\n      {\n        name: 'keys',\n        internalType: 'string[]',\n        type: 'string[]',\n        indexed: false,\n      },\n      {\n        name: 'values',\n        internalType: 'string[]',\n        type: 'string[]',\n        indexed: false,\n      },\n    ],\n    name: 'PieceAdded',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'storagePrice',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'minimumRate',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'PricingUpdated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'providerId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n    ],\n    name: 'ProviderApproved',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'providerId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n    ],\n    name: 'ProviderUnapproved',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'railId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'newRate',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'RailRateUpdated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'caller',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'dataSetId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'pdpRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'cacheMissRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'cdnRailId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'ServiceTerminated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'plannedUpgrade',\n        internalType: 'struct FilecoinWarmStorageService.PlannedUpgrade',\n        type: 'tuple',\n        components: [\n          {\n            name: 'nextImplementation',\n            internalType: 'address',\n            type: 'address',\n          },\n          { name: 'afterEpoch', internalType: 'uint96', type: 'uint96' },\n        ],\n        indexed: false,\n      },\n    ],\n    name: 'UpgradeAnnounced',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'implementation',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'Upgraded',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'viewContract',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'ViewContractSet',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'target', internalType: 'address', type: 'address' }],\n    name: 'AddressEmptyCode',\n  },\n  { type: 'error', inputs: [], name: 'AtLeastOnePriceMustBeNonZero' },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'CDNPaymentAlreadyTerminated',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'CacheMissPaymentAlreadyTerminated',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'expectedPayer', internalType: 'address', type: 'address' },\n      { name: 'caller', internalType: 'address', type: 'address' },\n    ],\n    name: 'CallerNotPayer',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'expectedPayer', internalType: 'address', type: 'address' },\n      { name: 'expectedPayee', internalType: 'address', type: 'address' },\n      { name: 'caller', internalType: 'address', type: 'address' },\n    ],\n    name: 'CallerNotPayerOrPayee',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'CallerNotPayments',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'windowStart', internalType: 'uint256', type: 'uint256' },\n      { name: 'nowBlock', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ChallengeWindowTooEarly',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'clientDataSetId', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ClientDataSetAlreadyRegistered',\n  },\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'commissionType',\n        internalType: 'enum Errors.CommissionType',\n        type: 'uint8',\n      },\n      { name: 'max', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'CommissionExceedsMaximum',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'DataSetNotFoundForRail',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'DataSetNotRegistered',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'DataSetPaymentAlreadyTerminated',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pdpEndEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'currentBlock', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'DataSetPaymentBeyondEndEpoch',\n  },\n  { type: 'error', inputs: [], name: 'DivisionByZero' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'key', internalType: 'string', type: 'string' },\n    ],\n    name: 'DuplicateMetadataKey',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'implementation', internalType: 'address', type: 'address' },\n    ],\n    name: 'ERC1967InvalidImplementation',\n  },\n  { type: 'error', inputs: [], name: 'ERC1967NonPayable' },\n  { type: 'error', inputs: [], name: 'ExtraDataRequired' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'actualSize', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowedSize', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ExtraDataTooLarge',\n  },\n  { type: 'error', inputs: [], name: 'FailedCall' },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'FilBeamServiceNotConfigured',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'minimumRequired', internalType: 'uint256', type: 'uint256' },\n      { name: 'available', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientFundsForMinimumRate',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'lockupAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'lockupUsage', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'minimumLockupRequired',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'InsufficientLockupAllowance',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'maxLockupPeriod', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'requiredLockupPeriod',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    name: 'InsufficientMaxLockupPeriod',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n      { name: 'rateAllowance', internalType: 'uint256', type: 'uint256' },\n      { name: 'rateUsage', internalType: 'uint256', type: 'uint256' },\n      { name: 'minimumRateRequired', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InsufficientRateAllowance',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'minExpected', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidChallengeCount',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'minAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidChallengeEpoch',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'maxProvingPeriod', internalType: 'uint256', type: 'uint256' },\n      { name: 'challengeWindowSize', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidChallengeWindowSize',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'InvalidDataSetId',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'fromEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'toEpoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'InvalidEpochRange',\n  },\n  { type: 'error', inputs: [], name: 'InvalidInitialization' },\n  {\n    type: 'error',\n    inputs: [{ name: 'length', internalType: 'uint256', type: 'uint256' }],\n    name: 'InvalidServiceDescriptionLength',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'length', internalType: 'uint256', type: 'uint256' }],\n    name: 'InvalidServiceNameLength',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'InvalidTopUpAmount',\n  },\n  { type: 'error', inputs: [], name: 'MaxProvingPeriodZero' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'metadataArrayCount', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceCount', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'MetadataArrayCountMismatch',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'keysLength', internalType: 'uint256', type: 'uint256' },\n      { name: 'valuesLength', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'MetadataKeyAndValueLengthMismatch',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'index', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'length', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'MetadataKeyExceedsMaxLength',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'index', internalType: 'uint256', type: 'uint256' },\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'length', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'MetadataValueExceedsMaxLength',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'periodDeadline', internalType: 'uint256', type: 'uint256' },\n      { name: 'nowBlock', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'NextProvingPeriodAlreadyCalled',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'NoPDPPaymentRail',\n  },\n  { type: 'error', inputs: [], name: 'NotInitializing' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'OnlyFilBeamControllerAllowed',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'expected', internalType: 'address', type: 'address' },\n      { name: 'actual', internalType: 'address', type: 'address' },\n    ],\n    name: 'OnlyPDPVerifierAllowed',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'operator', internalType: 'address', type: 'address' },\n    ],\n    name: 'OperatorNotApproved',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'owner', internalType: 'address', type: 'address' }],\n    name: 'OwnableInvalidOwner',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'account', internalType: 'address', type: 'address' }],\n    name: 'OwnableUnauthorizedAccount',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pdpEndEpoch', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'PaymentRailsNotFinalized',\n  },\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'priceType',\n        internalType: 'enum Errors.PriceType',\n        type: 'uint8',\n      },\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'actual', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'PriceExceedsMaximum',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProofAlreadySubmitted',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProviderAlreadyApproved',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProviderNotInApprovedList',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'provider', internalType: 'address', type: 'address' }],\n    name: 'ProviderNotRegistered',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProvingNotStarted',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'deadline', internalType: 'uint256', type: 'uint256' },\n      { name: 'nowBlock', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'ProvingPeriodPassed',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'RailNotAssociated',\n  },\n  { type: 'error', inputs: [], name: 'ServiceContractMustTerminateRail' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'maxAllowed', internalType: 'uint256', type: 'uint256' },\n      { name: 'keysLength', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'TooManyMetadataKeys',\n  },\n  { type: 'error', inputs: [], name: 'UUPSUnauthorizedCallContext' },\n  {\n    type: 'error',\n    inputs: [{ name: 'slot', internalType: 'bytes32', type: 'bytes32' }],\n    name: 'UUPSUnsupportedProxiableUUID',\n  },\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'field',\n        internalType: 'enum Errors.AddressField',\n        type: 'uint8',\n      },\n    ],\n    name: 'ZeroAddress',\n  },\n] as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x8408502033C418E1bbC97cE9ac48E5528F371A9f)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x02925630df557F957f70E112bA06e50965417CA0)\n */\nexport const filecoinWarmStorageServiceAddress = {\n  314: '0x8408502033C418E1bbC97cE9ac48E5528F371A9f',\n  314159: '0x02925630df557F957f70E112bA06e50965417CA0',\n} as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x8408502033C418E1bbC97cE9ac48E5528F371A9f)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x02925630df557F957f70E112bA06e50965417CA0)\n */\nexport const filecoinWarmStorageServiceConfig = {\n  address: filecoinWarmStorageServiceAddress,\n  abi: filecoinWarmStorageServiceAbi,\n} as const\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// FilecoinWarmStorageServiceStateView\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x9e4e6699d8F67dFc883d6b0A7344Bd56F7E80B46)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0xA5D87b04086B1d591026cCE10255351B5AA4689B)\n */\nexport const filecoinWarmStorageServiceStateViewAbi = [\n  {\n    type: 'constructor',\n    inputs: [\n      {\n        name: '_service',\n        internalType: 'contract FilecoinWarmStorageService',\n        type: 'address',\n      },\n    ],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'challengeWindow',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'payer', internalType: 'address', type: 'address' }],\n    name: 'clientDataSets',\n    outputs: [\n      { name: 'dataSetIds', internalType: 'uint256[]', type: 'uint256[]' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'payer', internalType: 'address', type: 'address' },\n      { name: 'nonce', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'clientNonces',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'filBeamControllerAddress',\n    outputs: [{ name: '', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getAllDataSetMetadata',\n    outputs: [\n      { name: 'keys', internalType: 'string[]', type: 'string[]' },\n      { name: 'values', internalType: 'string[]', type: 'string[]' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceId', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getAllPieceMetadata',\n    outputs: [\n      { name: 'keys', internalType: 'string[]', type: 'string[]' },\n      { name: 'values', internalType: 'string[]', type: 'string[]' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'offset', internalType: 'uint256', type: 'uint256' },\n      { name: 'limit', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getApprovedProviders',\n    outputs: [\n      { name: 'providerIds', internalType: 'uint256[]', type: 'uint256[]' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getApprovedProvidersLength',\n    outputs: [{ name: 'count', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getChallengesPerProof',\n    outputs: [{ name: '', internalType: 'uint64', type: 'uint64' }],\n    stateMutability: 'pure',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'client', internalType: 'address', type: 'address' }],\n    name: 'getClientDataSets',\n    outputs: [\n      {\n        name: 'infos',\n        internalType: 'struct FilecoinWarmStorageService.DataSetInfoView[]',\n        type: 'tuple[]',\n        components: [\n          { name: 'pdpRailId', internalType: 'uint256', type: 'uint256' },\n          { name: 'cacheMissRailId', internalType: 'uint256', type: 'uint256' },\n          { name: 'cdnRailId', internalType: 'uint256', type: 'uint256' },\n          { name: 'payer', internalType: 'address', type: 'address' },\n          { name: 'payee', internalType: 'address', type: 'address' },\n          { name: 'serviceProvider', internalType: 'address', type: 'address' },\n          { name: 'commissionBps', internalType: 'uint256', type: 'uint256' },\n          { name: 'clientDataSetId', internalType: 'uint256', type: 'uint256' },\n          { name: 'pdpEndEpoch', internalType: 'uint256', type: 'uint256' },\n          { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n          { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getCurrentPricingRates',\n    outputs: [\n      { name: 'storagePrice', internalType: 'uint256', type: 'uint256' },\n      { name: 'minimumRate', internalType: 'uint256', type: 'uint256' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getDataSet',\n    outputs: [\n      {\n        name: 'info',\n        internalType: 'struct FilecoinWarmStorageService.DataSetInfoView',\n        type: 'tuple',\n        components: [\n          { name: 'pdpRailId', internalType: 'uint256', type: 'uint256' },\n          { name: 'cacheMissRailId', internalType: 'uint256', type: 'uint256' },\n          { name: 'cdnRailId', internalType: 'uint256', type: 'uint256' },\n          { name: 'payer', internalType: 'address', type: 'address' },\n          { name: 'payee', internalType: 'address', type: 'address' },\n          { name: 'serviceProvider', internalType: 'address', type: 'address' },\n          { name: 'commissionBps', internalType: 'uint256', type: 'uint256' },\n          { name: 'clientDataSetId', internalType: 'uint256', type: 'uint256' },\n          { name: 'pdpEndEpoch', internalType: 'uint256', type: 'uint256' },\n          { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n          { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'key', internalType: 'string', type: 'string' },\n    ],\n    name: 'getDataSetMetadata',\n    outputs: [\n      { name: 'exists', internalType: 'bool', type: 'bool' },\n      { name: 'value', internalType: 'string', type: 'string' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'leafCount', internalType: 'uint256', type: 'uint256' }],\n    name: 'getDataSetSizeInBytes',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'pure',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getDataSetStatus',\n    outputs: [\n      {\n        name: 'status',\n        internalType: 'enum FilecoinWarmStorageService.DataSetStatus',\n        type: 'uint8',\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getMaxProvingPeriod',\n    outputs: [{ name: '', internalType: 'uint64', type: 'uint64' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getPDPConfig',\n    outputs: [\n      { name: 'maxProvingPeriod', internalType: 'uint64', type: 'uint64' },\n      { name: 'challengeWindowSize', internalType: 'uint256', type: 'uint256' },\n      { name: 'challengesPerProof', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'initChallengeWindowStart',\n        internalType: 'uint256',\n        type: 'uint256',\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceId', internalType: 'uint256', type: 'uint256' },\n      { name: 'key', internalType: 'string', type: 'string' },\n    ],\n    name: 'getPieceMetadata',\n    outputs: [\n      { name: 'exists', internalType: 'bool', type: 'bool' },\n      { name: 'value', internalType: 'string', type: 'string' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'isProviderApproved',\n    outputs: [{ name: '', internalType: 'bool', type: 'bool' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'nextPDPChallengeWindowStart',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'nextUpgrade',\n    outputs: [\n      { name: 'nextImplementation', internalType: 'address', type: 'address' },\n      { name: 'afterEpoch', internalType: 'uint96', type: 'uint96' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'dataSetId', internalType: 'uint256', type: 'uint256' },\n      { name: 'periodId', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'provenPeriods',\n    outputs: [{ name: '', internalType: 'bool', type: 'bool' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'provenThisPeriod',\n    outputs: [{ name: '', internalType: 'bool', type: 'bool' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'provingActivationEpoch',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'provingDeadline',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'railId', internalType: 'uint256', type: 'uint256' }],\n    name: 'railToDataSet',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'service',\n    outputs: [\n      {\n        name: '',\n        internalType: 'contract FilecoinWarmStorageService',\n        type: 'address',\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'serviceCommissionBps',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'dataSetId', internalType: 'uint256', type: 'uint256' }],\n    name: 'ProvingPeriodNotInitialized',\n  },\n] as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x9e4e6699d8F67dFc883d6b0A7344Bd56F7E80B46)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0xA5D87b04086B1d591026cCE10255351B5AA4689B)\n */\nexport const filecoinWarmStorageServiceStateViewAddress = {\n  314: '0x9e4e6699d8F67dFc883d6b0A7344Bd56F7E80B46',\n  314159: '0xA5D87b04086B1d591026cCE10255351B5AA4689B',\n} as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x9e4e6699d8F67dFc883d6b0A7344Bd56F7E80B46)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0xA5D87b04086B1d591026cCE10255351B5AA4689B)\n */\nexport const filecoinWarmStorageServiceStateViewConfig = {\n  address: filecoinWarmStorageServiceStateViewAddress,\n  abi: filecoinWarmStorageServiceStateViewAbi,\n} as const\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// PDPVerifier\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0xBADd0B92C1c71d02E7d520f64c0876538fa2557F)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x85e366Cf9DD2c0aE37E963d9556F5f4718d6417C)\n */\nexport const pdpVerifierAbi = [\n  { type: 'constructor', inputs: [], stateMutability: 'nonpayable' },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'MAX_ENQUEUED_REMOVALS',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'MAX_PIECE_SIZE_LOG2',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'NO_CHALLENGE_SCHEDULED',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'NO_PROVEN_EPOCH',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'UPGRADE_INTERFACE_VERSION',\n    outputs: [{ name: '', internalType: 'string', type: 'string' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'VERSION',\n    outputs: [{ name: '', internalType: 'string', type: 'string' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'listenerAddr', internalType: 'address', type: 'address' },\n      {\n        name: 'pieceData',\n        internalType: 'struct Cids.Cid[]',\n        type: 'tuple[]',\n        components: [{ name: 'data', internalType: 'bytes', type: 'bytes' }],\n      },\n      { name: 'extraData', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'addPieces',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'calculateProofFee',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'proofSize', internalType: 'uint256', type: 'uint256' }],\n    name: 'calculateProofFeeForSize',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'extraData', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'claimDataSetStorageProvider',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'listenerAddr', internalType: 'address', type: 'address' },\n      { name: 'extraData', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'createDataSet',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'dataSetLive',\n    outputs: [{ name: '', internalType: 'bool', type: 'bool' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'extraData', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'deleteDataSet',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'feeEffectiveTime',\n    outputs: [{ name: '', internalType: 'uint64', type: 'uint64' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'feePerTiB',\n    outputs: [{ name: '', internalType: 'uint96', type: 'uint96' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'leafIndexs', internalType: 'uint256[]', type: 'uint256[]' },\n    ],\n    name: 'findPieceIds',\n    outputs: [\n      {\n        name: '',\n        internalType: 'struct IPDPTypes.PieceIdAndOffset[]',\n        type: 'tuple[]',\n        components: [\n          { name: 'pieceId', internalType: 'uint256', type: 'uint256' },\n          { name: 'offset', internalType: 'uint256', type: 'uint256' },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getActivePieceCount',\n    outputs: [\n      { name: 'activeCount', internalType: 'uint256', type: 'uint256' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'offset', internalType: 'uint256', type: 'uint256' },\n      { name: 'limit', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getActivePieces',\n    outputs: [\n      {\n        name: 'pieces',\n        internalType: 'struct Cids.Cid[]',\n        type: 'tuple[]',\n        components: [{ name: 'data', internalType: 'bytes', type: 'bytes' }],\n      },\n      { name: 'pieceIds', internalType: 'uint256[]', type: 'uint256[]' },\n      { name: 'hasMore', internalType: 'bool', type: 'bool' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getChallengeFinality',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getChallengeRange',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getDataSetLastProvenEpoch',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getDataSetLeafCount',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getDataSetListener',\n    outputs: [{ name: '', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getDataSetStorageProvider',\n    outputs: [\n      { name: '', internalType: 'address', type: 'address' },\n      { name: '', internalType: 'address', type: 'address' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getNextChallengeEpoch',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getNextDataSetId',\n    outputs: [{ name: '', internalType: 'uint64', type: 'uint64' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getNextPieceId',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceId', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getPieceCid',\n    outputs: [\n      {\n        name: '',\n        internalType: 'struct Cids.Cid',\n        type: 'tuple',\n        components: [{ name: 'data', internalType: 'bytes', type: 'bytes' }],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceId', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getPieceLeafCount',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'epoch', internalType: 'uint256', type: 'uint256' }],\n    name: 'getRandomness',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'setId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getScheduledRemovals',\n    outputs: [{ name: '', internalType: 'uint256[]', type: 'uint256[]' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: '_challengeFinality', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'initialize',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'migrate',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'challengeEpoch', internalType: 'uint256', type: 'uint256' },\n      { name: 'extraData', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'nextProvingPeriod',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'owner',\n    outputs: [{ name: '', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceId', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'pieceChallengable',\n    outputs: [{ name: '', internalType: 'bool', type: 'bool' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceId', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'pieceLive',\n    outputs: [{ name: '', internalType: 'bool', type: 'bool' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'newStorageProvider', internalType: 'address', type: 'address' },\n    ],\n    name: 'proposeDataSetStorageProvider',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'proposedFeePerTiB',\n    outputs: [{ name: '', internalType: 'uint96', type: 'uint96' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'proofs',\n        internalType: 'struct IPDPTypes.Proof[]',\n        type: 'tuple[]',\n        components: [\n          { name: 'leaf', internalType: 'bytes32', type: 'bytes32' },\n          { name: 'proof', internalType: 'bytes32[]', type: 'bytes32[]' },\n        ],\n      },\n    ],\n    name: 'provePossession',\n    outputs: [],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'proxiableUUID',\n    outputs: [{ name: '', internalType: 'bytes32', type: 'bytes32' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'renounceOwnership',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'setId', internalType: 'uint256', type: 'uint256' },\n      { name: 'pieceIds', internalType: 'uint256[]', type: 'uint256[]' },\n      { name: 'extraData', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'schedulePieceDeletions',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'newOwner', internalType: 'address', type: 'address' }],\n    name: 'transferOwnership',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'newFeePerTiB', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'updateProofFee',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'newImplementation', internalType: 'address', type: 'address' },\n      { name: 'data', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'upgradeToAndCall',\n    outputs: [],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'version',\n        internalType: 'string',\n        type: 'string',\n        indexed: false,\n      },\n      {\n        name: 'implementation',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n    ],\n    name: 'ContractUpgraded',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'setId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'storageProvider',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'DataSetCreated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'setId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'deletedLeafCount',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'DataSetDeleted',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'setId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n    ],\n    name: 'DataSetEmpty',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'currentFee',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'newFee',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'effectiveTime',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'FeeUpdateProposed',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'version',\n        internalType: 'uint64',\n        type: 'uint64',\n        indexed: false,\n      },\n    ],\n    name: 'Initialized',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'setId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'challengeEpoch',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'leafCount',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n    ],\n    name: 'NextProvingPeriod',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'previousOwner',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'newOwner',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'OwnershipTransferred',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'setId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'pieceIds',\n        internalType: 'uint256[]',\n        type: 'uint256[]',\n        indexed: false,\n      },\n      {\n        name: 'pieceCids',\n        internalType: 'struct Cids.Cid[]',\n        type: 'tuple[]',\n        components: [{ name: 'data', internalType: 'bytes', type: 'bytes' }],\n        indexed: false,\n      },\n    ],\n    name: 'PiecesAdded',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'setId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'pieceIds',\n        internalType: 'uint256[]',\n        type: 'uint256[]',\n        indexed: false,\n      },\n    ],\n    name: 'PiecesRemoved',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'setId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'challenges',\n        internalType: 'struct IPDPTypes.PieceIdAndOffset[]',\n        type: 'tuple[]',\n        components: [\n          { name: 'pieceId', internalType: 'uint256', type: 'uint256' },\n          { name: 'offset', internalType: 'uint256', type: 'uint256' },\n        ],\n        indexed: false,\n      },\n    ],\n    name: 'PossessionProven',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'setId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      { name: 'fee', internalType: 'uint256', type: 'uint256', indexed: false },\n    ],\n    name: 'ProofFeePaid',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'setId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'oldStorageProvider',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'newStorageProvider',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'StorageProviderChanged',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'implementation',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'Upgraded',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'target', internalType: 'address', type: 'address' }],\n    name: 'AddressEmptyCode',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'implementation', internalType: 'address', type: 'address' },\n    ],\n    name: 'ERC1967InvalidImplementation',\n  },\n  { type: 'error', inputs: [], name: 'ERC1967NonPayable' },\n  { type: 'error', inputs: [], name: 'FailedCall' },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'idx', internalType: 'uint256', type: 'uint256' },\n      { name: 'msg', internalType: 'string', type: 'string' },\n    ],\n    name: 'IndexedError',\n  },\n  { type: 'error', inputs: [], name: 'InvalidInitialization' },\n  { type: 'error', inputs: [], name: 'NotInitializing' },\n  {\n    type: 'error',\n    inputs: [{ name: 'owner', internalType: 'address', type: 'address' }],\n    name: 'OwnableInvalidOwner',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'account', internalType: 'address', type: 'address' }],\n    name: 'OwnableUnauthorizedAccount',\n  },\n  { type: 'error', inputs: [], name: 'UUPSUnauthorizedCallContext' },\n  {\n    type: 'error',\n    inputs: [{ name: 'slot', internalType: 'bytes32', type: 'bytes32' }],\n    name: 'UUPSUnsupportedProxiableUUID',\n  },\n] as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0xBADd0B92C1c71d02E7d520f64c0876538fa2557F)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x85e366Cf9DD2c0aE37E963d9556F5f4718d6417C)\n */\nexport const pdpVerifierAddress = {\n  314: '0xBADd0B92C1c71d02E7d520f64c0876538fa2557F',\n  314159: '0x85e366Cf9DD2c0aE37E963d9556F5f4718d6417C',\n} as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0xBADd0B92C1c71d02E7d520f64c0876538fa2557F)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x85e366Cf9DD2c0aE37E963d9556F5f4718d6417C)\n */\nexport const pdpVerifierConfig = {\n  address: pdpVerifierAddress,\n  abi: pdpVerifierAbi,\n} as const\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// ServiceProviderRegistry\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0xf55dDbf63F1b55c3F1D4FA7e339a68AB7b64A5eB)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x839e5c9988e4e9977d40708d0094103c0839Ac9D)\n */\nexport const serviceProviderRegistryAbi = [\n  { type: 'constructor', inputs: [], stateMutability: 'nonpayable' },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'MAX_CAPABILITIES',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'MAX_CAPABILITY_KEY_LENGTH',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'MAX_CAPABILITY_VALUE_LENGTH',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'REGISTRATION_FEE',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'UPGRADE_INTERFACE_VERSION',\n    outputs: [{ name: '', internalType: 'string', type: 'string' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'VERSION',\n    outputs: [{ name: '', internalType: 'string', type: 'string' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n    ],\n    name: 'activeProductTypeProviderCount',\n    outputs: [{ name: 'count', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'activeProviderCount',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n      { name: 'capabilityKeys', internalType: 'string[]', type: 'string[]' },\n      { name: 'capabilityValues', internalType: 'bytes[]', type: 'bytes[]' },\n    ],\n    name: 'addProduct',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerAddress', internalType: 'address', type: 'address' },\n    ],\n    name: 'addressToProviderId',\n    outputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'eip712Domain',\n    outputs: [\n      { name: 'fields', internalType: 'bytes1', type: 'bytes1' },\n      { name: 'name', internalType: 'string', type: 'string' },\n      { name: 'version', internalType: 'string', type: 'string' },\n      { name: 'chainId', internalType: 'uint256', type: 'uint256' },\n      { name: 'verifyingContract', internalType: 'address', type: 'address' },\n      { name: 'salt', internalType: 'bytes32', type: 'bytes32' },\n      { name: 'extensions', internalType: 'uint256[]', type: 'uint256[]' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'offset', internalType: 'uint256', type: 'uint256' },\n      { name: 'limit', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getAllActiveProviders',\n    outputs: [\n      { name: 'providerIds', internalType: 'uint256[]', type: 'uint256[]' },\n      { name: 'hasMore', internalType: 'bool', type: 'bool' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n    ],\n    name: 'getAllProductCapabilities',\n    outputs: [\n      { name: 'isActive', internalType: 'bool', type: 'bool' },\n      { name: 'keys', internalType: 'string[]', type: 'string[]' },\n      { name: 'values', internalType: 'bytes[]', type: 'bytes[]' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getNextProviderId',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n      { name: 'keys', internalType: 'string[]', type: 'string[]' },\n    ],\n    name: 'getProductCapabilities',\n    outputs: [{ name: 'values', internalType: 'bytes[]', type: 'bytes[]' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getProvider',\n    outputs: [\n      {\n        name: 'info',\n        internalType: 'struct ServiceProviderRegistry.ServiceProviderInfoView',\n        type: 'tuple',\n        components: [\n          { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n          {\n            name: 'info',\n            internalType:\n              'struct ServiceProviderRegistryStorage.ServiceProviderInfo',\n            type: 'tuple',\n            components: [\n              {\n                name: 'serviceProvider',\n                internalType: 'address',\n                type: 'address',\n              },\n              { name: 'payee', internalType: 'address', type: 'address' },\n              { name: 'name', internalType: 'string', type: 'string' },\n              { name: 'description', internalType: 'string', type: 'string' },\n              { name: 'isActive', internalType: 'bool', type: 'bool' },\n            ],\n          },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerAddress', internalType: 'address', type: 'address' },\n    ],\n    name: 'getProviderByAddress',\n    outputs: [\n      {\n        name: 'info',\n        internalType: 'struct ServiceProviderRegistry.ServiceProviderInfoView',\n        type: 'tuple',\n        components: [\n          { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n          {\n            name: 'info',\n            internalType:\n              'struct ServiceProviderRegistryStorage.ServiceProviderInfo',\n            type: 'tuple',\n            components: [\n              {\n                name: 'serviceProvider',\n                internalType: 'address',\n                type: 'address',\n              },\n              { name: 'payee', internalType: 'address', type: 'address' },\n              { name: 'name', internalType: 'string', type: 'string' },\n              { name: 'description', internalType: 'string', type: 'string' },\n              { name: 'isActive', internalType: 'bool', type: 'bool' },\n            ],\n          },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'getProviderCount',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerAddress', internalType: 'address', type: 'address' },\n    ],\n    name: 'getProviderIdByAddress',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'getProviderPayee',\n    outputs: [{ name: 'payee', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n    ],\n    name: 'getProviderWithProduct',\n    outputs: [\n      {\n        name: '',\n        internalType:\n          'struct ServiceProviderRegistryStorage.ProviderWithProduct',\n        type: 'tuple',\n        components: [\n          { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n          {\n            name: 'providerInfo',\n            internalType:\n              'struct ServiceProviderRegistryStorage.ServiceProviderInfo',\n            type: 'tuple',\n            components: [\n              {\n                name: 'serviceProvider',\n                internalType: 'address',\n                type: 'address',\n              },\n              { name: 'payee', internalType: 'address', type: 'address' },\n              { name: 'name', internalType: 'string', type: 'string' },\n              { name: 'description', internalType: 'string', type: 'string' },\n              { name: 'isActive', internalType: 'bool', type: 'bool' },\n            ],\n          },\n          {\n            name: 'product',\n            internalType:\n              'struct ServiceProviderRegistryStorage.ServiceProduct',\n            type: 'tuple',\n            components: [\n              {\n                name: 'productType',\n                internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n                type: 'uint8',\n              },\n              {\n                name: 'capabilityKeys',\n                internalType: 'string[]',\n                type: 'string[]',\n              },\n              { name: 'isActive', internalType: 'bool', type: 'bool' },\n            ],\n          },\n          {\n            name: 'productCapabilityValues',\n            internalType: 'bytes[]',\n            type: 'bytes[]',\n          },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerIds', internalType: 'uint256[]', type: 'uint256[]' },\n    ],\n    name: 'getProvidersByIds',\n    outputs: [\n      {\n        name: 'providerInfos',\n        internalType:\n          'struct ServiceProviderRegistry.ServiceProviderInfoView[]',\n        type: 'tuple[]',\n        components: [\n          { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n          {\n            name: 'info',\n            internalType:\n              'struct ServiceProviderRegistryStorage.ServiceProviderInfo',\n            type: 'tuple',\n            components: [\n              {\n                name: 'serviceProvider',\n                internalType: 'address',\n                type: 'address',\n              },\n              { name: 'payee', internalType: 'address', type: 'address' },\n              { name: 'name', internalType: 'string', type: 'string' },\n              { name: 'description', internalType: 'string', type: 'string' },\n              { name: 'isActive', internalType: 'bool', type: 'bool' },\n            ],\n          },\n        ],\n      },\n      { name: 'validIds', internalType: 'bool[]', type: 'bool[]' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n      { name: 'onlyActive', internalType: 'bool', type: 'bool' },\n      { name: 'offset', internalType: 'uint256', type: 'uint256' },\n      { name: 'limit', internalType: 'uint256', type: 'uint256' },\n    ],\n    name: 'getProvidersByProductType',\n    outputs: [\n      {\n        name: 'result',\n        internalType:\n          'struct ServiceProviderRegistryStorage.PaginatedProviders',\n        type: 'tuple',\n        components: [\n          {\n            name: 'providers',\n            internalType:\n              'struct ServiceProviderRegistryStorage.ProviderWithProduct[]',\n            type: 'tuple[]',\n            components: [\n              { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n              {\n                name: 'providerInfo',\n                internalType:\n                  'struct ServiceProviderRegistryStorage.ServiceProviderInfo',\n                type: 'tuple',\n                components: [\n                  {\n                    name: 'serviceProvider',\n                    internalType: 'address',\n                    type: 'address',\n                  },\n                  { name: 'payee', internalType: 'address', type: 'address' },\n                  { name: 'name', internalType: 'string', type: 'string' },\n                  {\n                    name: 'description',\n                    internalType: 'string',\n                    type: 'string',\n                  },\n                  { name: 'isActive', internalType: 'bool', type: 'bool' },\n                ],\n              },\n              {\n                name: 'product',\n                internalType:\n                  'struct ServiceProviderRegistryStorage.ServiceProduct',\n                type: 'tuple',\n                components: [\n                  {\n                    name: 'productType',\n                    internalType:\n                      'enum ServiceProviderRegistryStorage.ProductType',\n                    type: 'uint8',\n                  },\n                  {\n                    name: 'capabilityKeys',\n                    internalType: 'string[]',\n                    type: 'string[]',\n                  },\n                  { name: 'isActive', internalType: 'bool', type: 'bool' },\n                ],\n              },\n              {\n                name: 'productCapabilityValues',\n                internalType: 'bytes[]',\n                type: 'bytes[]',\n              },\n            ],\n          },\n          { name: 'hasMore', internalType: 'bool', type: 'bool' },\n        ],\n      },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'initialize',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'isProviderActive',\n    outputs: [{ name: '', internalType: 'bool', type: 'bool' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'provider', internalType: 'address', type: 'address' }],\n    name: 'isRegisteredProvider',\n    outputs: [{ name: '', internalType: 'bool', type: 'bool' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'newVersion', internalType: 'string', type: 'string' }],\n    name: 'migrate',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'owner',\n    outputs: [{ name: '', internalType: 'address', type: 'address' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n      { name: 'key', internalType: 'string', type: 'string' },\n    ],\n    name: 'productCapabilities',\n    outputs: [{ name: 'value', internalType: 'bytes', type: 'bytes' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n    ],\n    name: 'productTypeProviderCount',\n    outputs: [{ name: 'count', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n    ],\n    name: 'providerHasProduct',\n    outputs: [{ name: '', internalType: 'bool', type: 'bool' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'providerId', internalType: 'uint256', type: 'uint256' },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n    ],\n    name: 'providerProducts',\n    outputs: [\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n      { name: 'isActive', internalType: 'bool', type: 'bool' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    name: 'providers',\n    outputs: [\n      { name: 'serviceProvider', internalType: 'address', type: 'address' },\n      { name: 'payee', internalType: 'address', type: 'address' },\n      { name: 'name', internalType: 'string', type: 'string' },\n      { name: 'description', internalType: 'string', type: 'string' },\n      { name: 'isActive', internalType: 'bool', type: 'bool' },\n    ],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'proxiableUUID',\n    outputs: [{ name: '', internalType: 'bytes32', type: 'bytes32' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'payee', internalType: 'address', type: 'address' },\n      { name: 'name', internalType: 'string', type: 'string' },\n      { name: 'description', internalType: 'string', type: 'string' },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n      { name: 'capabilityKeys', internalType: 'string[]', type: 'string[]' },\n      { name: 'capabilityValues', internalType: 'bytes[]', type: 'bytes[]' },\n    ],\n    name: 'registerProvider',\n    outputs: [{ name: 'providerId', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n    ],\n    name: 'removeProduct',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'removeProvider',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [],\n    name: 'renounceOwnership',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [{ name: 'newOwner', internalType: 'address', type: 'address' }],\n    name: 'transferOwnership',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n      { name: 'capabilityKeys', internalType: 'string[]', type: 'string[]' },\n      { name: 'capabilityValues', internalType: 'bytes[]', type: 'bytes[]' },\n    ],\n    name: 'updateProduct',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'name', internalType: 'string', type: 'string' },\n      { name: 'description', internalType: 'string', type: 'string' },\n    ],\n    name: 'updateProviderInfo',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'newImplementation', internalType: 'address', type: 'address' },\n      { name: 'data', internalType: 'bytes', type: 'bytes' },\n    ],\n    name: 'upgradeToAndCall',\n    outputs: [],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'version',\n        internalType: 'string',\n        type: 'string',\n        indexed: false,\n      },\n      {\n        name: 'implementation',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n    ],\n    name: 'ContractUpgraded',\n  },\n  { type: 'event', anonymous: false, inputs: [], name: 'EIP712DomainChanged' },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'version',\n        internalType: 'uint64',\n        type: 'uint64',\n        indexed: false,\n      },\n    ],\n    name: 'Initialized',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'previousOwner',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'newOwner',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'OwnershipTransferred',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'providerId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n        indexed: true,\n      },\n      {\n        name: 'serviceProvider',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'capabilityKeys',\n        internalType: 'string[]',\n        type: 'string[]',\n        indexed: false,\n      },\n      {\n        name: 'capabilityValues',\n        internalType: 'bytes[]',\n        type: 'bytes[]',\n        indexed: false,\n      },\n    ],\n    name: 'ProductAdded',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'providerId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n        indexed: true,\n      },\n    ],\n    name: 'ProductRemoved',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'providerId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n        indexed: true,\n      },\n      {\n        name: 'serviceProvider',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'capabilityKeys',\n        internalType: 'string[]',\n        type: 'string[]',\n        indexed: false,\n      },\n      {\n        name: 'capabilityValues',\n        internalType: 'bytes[]',\n        type: 'bytes[]',\n        indexed: false,\n      },\n    ],\n    name: 'ProductUpdated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'providerId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n    ],\n    name: 'ProviderInfoUpdated',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'providerId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n      {\n        name: 'serviceProvider',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'payee',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'ProviderRegistered',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'providerId',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: true,\n      },\n    ],\n    name: 'ProviderRemoved',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'implementation',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n    ],\n    name: 'Upgraded',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'target', internalType: 'address', type: 'address' }],\n    name: 'AddressEmptyCode',\n  },\n  {\n    type: 'error',\n    inputs: [\n      { name: 'implementation', internalType: 'address', type: 'address' },\n    ],\n    name: 'ERC1967InvalidImplementation',\n  },\n  { type: 'error', inputs: [], name: 'ERC1967NonPayable' },\n  { type: 'error', inputs: [], name: 'FailedCall' },\n  {\n    type: 'error',\n    inputs: [\n      {\n        name: 'productType',\n        internalType: 'enum ServiceProviderRegistryStorage.ProductType',\n        type: 'uint8',\n      },\n    ],\n    name: 'InsufficientCapabilitiesForProduct',\n  },\n  { type: 'error', inputs: [], name: 'InvalidInitialization' },\n  { type: 'error', inputs: [], name: 'NotInitializing' },\n  {\n    type: 'error',\n    inputs: [{ name: 'owner', internalType: 'address', type: 'address' }],\n    name: 'OwnableInvalidOwner',\n  },\n  {\n    type: 'error',\n    inputs: [{ name: 'account', internalType: 'address', type: 'address' }],\n    name: 'OwnableUnauthorizedAccount',\n  },\n  { type: 'error', inputs: [], name: 'UUPSUnauthorizedCallContext' },\n  {\n    type: 'error',\n    inputs: [{ name: 'slot', internalType: 'bytes32', type: 'bytes32' }],\n    name: 'UUPSUnsupportedProxiableUUID',\n  },\n] as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0xf55dDbf63F1b55c3F1D4FA7e339a68AB7b64A5eB)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x839e5c9988e4e9977d40708d0094103c0839Ac9D)\n */\nexport const serviceProviderRegistryAddress = {\n  314: '0xf55dDbf63F1b55c3F1D4FA7e339a68AB7b64A5eB',\n  314159: '0x839e5c9988e4e9977d40708d0094103c0839Ac9D',\n} as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0xf55dDbf63F1b55c3F1D4FA7e339a68AB7b64A5eB)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x839e5c9988e4e9977d40708d0094103c0839Ac9D)\n */\nexport const serviceProviderRegistryConfig = {\n  address: serviceProviderRegistryAddress,\n  abi: serviceProviderRegistryAbi,\n} as const\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// SessionKeyRegistry\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x74FD50525A958aF5d484601E252271f9625231aB)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x518411c2062E119Aaf7A8B12A2eDf9a939347655)\n */\nexport const sessionKeyRegistryAbi = [\n  {\n    type: 'function',\n    inputs: [\n      { name: 'user', internalType: 'address', type: 'address' },\n      { name: 'signer', internalType: 'address', type: 'address' },\n      { name: 'permission', internalType: 'bytes32', type: 'bytes32' },\n    ],\n    name: 'authorizationExpiry',\n    outputs: [{ name: '', internalType: 'uint256', type: 'uint256' }],\n    stateMutability: 'view',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'signer', internalType: 'address', type: 'address' },\n      { name: 'expiry', internalType: 'uint256', type: 'uint256' },\n      { name: 'permissions', internalType: 'bytes32[]', type: 'bytes32[]' },\n      { name: 'origin', internalType: 'string', type: 'string' },\n    ],\n    name: 'login',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'signer', internalType: 'address payable', type: 'address' },\n      { name: 'expiry', internalType: 'uint256', type: 'uint256' },\n      { name: 'permissions', internalType: 'bytes32[]', type: 'bytes32[]' },\n      { name: 'origin', internalType: 'string', type: 'string' },\n    ],\n    name: 'loginAndFund',\n    outputs: [],\n    stateMutability: 'payable',\n  },\n  {\n    type: 'function',\n    inputs: [\n      { name: 'signer', internalType: 'address', type: 'address' },\n      { name: 'permissions', internalType: 'bytes32[]', type: 'bytes32[]' },\n      { name: 'origin', internalType: 'string', type: 'string' },\n    ],\n    name: 'revoke',\n    outputs: [],\n    stateMutability: 'nonpayable',\n  },\n  {\n    type: 'event',\n    anonymous: false,\n    inputs: [\n      {\n        name: 'identity',\n        internalType: 'address',\n        type: 'address',\n        indexed: true,\n      },\n      {\n        name: 'signer',\n        internalType: 'address',\n        type: 'address',\n        indexed: false,\n      },\n      {\n        name: 'expiry',\n        internalType: 'uint256',\n        type: 'uint256',\n        indexed: false,\n      },\n      {\n        name: 'permissions',\n        internalType: 'bytes32[]',\n        type: 'bytes32[]',\n        indexed: false,\n      },\n      {\n        name: 'origin',\n        internalType: 'string',\n        type: 'string',\n        indexed: false,\n      },\n    ],\n    name: 'AuthorizationsUpdated',\n  },\n] as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x74FD50525A958aF5d484601E252271f9625231aB)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x518411c2062E119Aaf7A8B12A2eDf9a939347655)\n */\nexport const sessionKeyRegistryAddress = {\n  314: '0x74FD50525A958aF5d484601E252271f9625231aB',\n  314159: '0x518411c2062E119Aaf7A8B12A2eDf9a939347655',\n} as const\n\n/**\n * - [__View Contract on Filecoin Mainnet Filfox__](https://filfox.info/en/address/0x74FD50525A958aF5d484601E252271f9625231aB)\n * - [__View Contract on Filecoin Calibration Filscan__](https://calibration.filscan.io/address/0x518411c2062E119Aaf7A8B12A2eDf9a939347655)\n */\nexport const sessionKeyRegistryConfig = {\n  address: sessionKeyRegistryAddress,\n  abi: sessionKeyRegistryAbi,\n} as const\n","import {\n  type Chain,\n  type Client,\n  createClient,\n  type FallbackTransport,\n  type HttpTransport,\n  http,\n  type Transport,\n  type TransportConfig,\n  type WebSocketTransport,\n} from 'viem'\n/**\n * Create a Viem public client from a transport configuration\n */\nexport function clientFromTransport({\n  chain,\n  transportConfig,\n}: {\n  chain: Chain\n  transportConfig?: TransportConfig\n}): Client<Transport, Chain> {\n  return createClient({\n    chain,\n    transport: transportFromTransportConfig({ transportConfig }),\n  })\n}\n\n/**\n * Create a Viem public client from a transport configuration\n */\nexport function transportFromTransportConfig({ transportConfig }: { transportConfig?: TransportConfig }): Transport {\n  let transport: HttpTransport | WebSocketTransport | FallbackTransport = http()\n  if (transportConfig) {\n    switch (transportConfig.type) {\n      case 'http':\n        // @ts-expect-error\n        transport = http(transportConfig.url, transportConfig)\n        break\n      case 'webSocket':\n        // @ts-expect-error\n        transport = webSocket(transportConfig.getSocket(), transportConfig)\n        break\n      case 'fallback':\n        // @ts-expect-error\n        transport = fallback(transportConfig.transports, transportConfig)\n        break\n    }\n  }\n\n  return transport\n}\n","import * as API from './api.js'\nimport {\n  IN_BYTES_PER_QUAD,\n  IN_BITS_FR,\n  OUT_BITS_FR,\n  MIN_PAYLOAD_SIZE,\n} from './constant.js'\nimport * as ZeroPad from './zero-comm.js'\nimport { computeNode } from './proof.js'\nimport { split } from './piece/tree.js'\nimport { pad } from './fr32.js'\nimport { fromHeight as piceSizeFromHeight } from './piece/size/expanded.js'\nimport { Unpadded } from './piece/size.js'\nimport * as Digest from './digest.js'\nimport { varint } from 'multiformats'\n\nexport { Digest }\n\n/**\n * @see https://github.com/multiformats/multicodec/pull/331/files\n */\nexport const name = /** @type {const} */ (\n  'fr32-sha2-256-trunc254-padded-binary-tree'\n)\n\n/**\n * @type {API.MulticodecCode<0x1011, typeof name>}\n * @see https://github.com/multiformats/multicodec/pull/331/files\n */\nexport const code = 0x1011\n\n/**\n * Since first byte in the digest is the tree height, the maximum height is 255.\n *\n * @type {255}\n */\nexport const MAX_HEIGHT = 255\n\n/**\n * Max payload is determined by the maximum height of the tree, which is limited\n * by the int we could store in one byte. We calculate the max piece size\n * and derive max payload size that can would produce it after FR32 padding.\n */\nexport const MAX_PAYLOAD_SIZE =\n  (piceSizeFromHeight(MAX_HEIGHT) * BigInt(IN_BITS_FR)) / BigInt(OUT_BITS_FR)\n\n/**\n * Computes the digest of the given payload.\n *\n * @param {Uint8Array} payload\n * @returns {API.PieceDigest}\n */\nexport const digest = (payload) => {\n  const hasher = new Hasher()\n  hasher.write(payload)\n  return hasher.digest()\n}\n\n/**\n * Creates a streaming hasher that can be used to consumer larger streams\n * of data than it would be practical to load into memory all at once.\n *\n * @returns {API.StreamingHasher<typeof code, number, API.PieceDigest>}\n */\nexport const create = () => new Hasher()\n\n/**\n * @typedef {[API.MerkleTreeNode[], ...API.MerkleTreeNode[][]]} Layers\n *\n * @implements {API.StreamingHasher<typeof code, number, API.PieceDigest>}\n */\nclass Hasher {\n  constructor() {\n    /**\n     * The number of bytes consumed by the hasher.\n     *\n     * @private\n     */\n    this.bytesWritten = 0n\n\n    /**\n     * This buffer is used to accumulate bytes until we have enough to fill a\n     * quad.\n     *\n     * ⚠️ Note that you should never read bytes past {@link offset} as those\n     * are considered dirty and may contain garbage.\n     *\n     * @protected\n     */\n    this.buffer = new Uint8Array(IN_BYTES_PER_QUAD)\n\n    /**\n     * Offset is the number of bytes in we have written into the buffer. If\n     * offset is 0 it means that the buffer is effectively empty. When `offset`\n     * is equal to `this.buffer.length` we have a quad that can be processed.\n     *\n     * @protected\n     */\n    this.offset = 0\n\n    /**\n     * The layers of the tree. Each layer will contain either 0 or 1 nodes\n     * between writes. When we write into a hasher, if we have enough nodes\n     * leaves will be created and pushed into the `layers[0]` array, after\n     * which we flush and combine every two leafs into a node which is moved\n     * to the next layer. This process is repeated until we reach the top\n     * layer, leaving each layer either empty or with a single node.\n     *\n     * @type {Layers}\n     */\n    this.layers = [[]]\n  }\n\n  /**\n   * Return the total number of bytes written into the hasher. Calling\n   * {@link reset} will reset the hasher and the count will be reset to 0.\n   *\n   * @returns {bigint}\n   */\n  count() {\n    return this.bytesWritten\n  }\n\n  /**\n   * Computes the digest of all the data that has been written into this hasher.\n   * This method does not have side-effects, meaning that you can continue\n   * writing and call this method again to compute digest of all the data\n   * written from the very beginning.\n   */\n  digest() {\n    const bytes = new Uint8Array(Digest.MAX_SIZE)\n    const count = this.digestInto(bytes, 0, true)\n    return Digest.fromBytes(bytes.subarray(0, count))\n  }\n\n  /**\n   * Computes the digest and writes into the given buffer. You can provide\n   * optional `byteOffset` to write digest at that offset in the buffer. By\n   * default the multihash prefix will be written into the buffer, but you can\n   * opt-out by passing `false` as the `asMultihash` argument.\n   *\n   * @param {Uint8Array} output\n   * @param {number} [byteOffset]\n   * @param {boolean} asMultihash\n   */\n  digestInto(output, byteOffset = 0, asMultihash = true) {\n    const { buffer, layers, offset, bytesWritten } = this\n\n    // We do not want to mutate the layers, so we create a shallow copy of it\n    // which we will use to compute the root.\n    let [leaves, ...nodes] = layers\n\n    // If we have some bytes in the buffer we fill rest with zeros and compute\n    // leaves from it. Note that it is safe to mutate the buffer here as bytes\n    // past `offset` are considered dirty and should not be read.\n    if (offset > 0 || bytesWritten === 0n) {\n      leaves = [...leaves, ...split(pad(buffer.fill(0, offset)))]\n    }\n\n    const tree = build([leaves, ...nodes])\n    const height = tree.length - 1\n    const [root] = tree[height]\n    const padding = Number(Unpadded.toPadding(this.bytesWritten))\n\n    const paddingLength = varint.encodingLength(\n      /** @type {number & bigint} */ (padding)\n    )\n\n    let endOffset = byteOffset\n    // Write the multihash prefix if requested\n    if (asMultihash) {\n      varint.encodeTo(code, output, endOffset)\n      endOffset += Digest.TAG_SIZE\n\n      const size = paddingLength + Digest.HEIGHT_SIZE + Digest.ROOT_SIZE\n      const sizeLength = varint.encodingLength(size)\n      varint.encodeTo(size, output, endOffset)\n      endOffset += sizeLength\n    }\n\n    varint.encodeTo(padding, output, endOffset)\n    endOffset += paddingLength\n\n    // Write the tree height as the first byte of the digest\n    output[endOffset] = height\n    endOffset += 1\n\n    // Write the root as the remaining 32 bytes of the digest\n    output.set(root, endOffset)\n    endOffset += root.length\n\n    // Return number of bytes written\n    return endOffset - byteOffset\n  }\n  /**\n   * @param {Uint8Array} bytes\n   */\n  write(bytes) {\n    const { buffer, offset, layers } = this\n    const leaves = layers[0]\n    const { length } = bytes\n    // If we got no bytes there is nothing to do here\n    if (length === 0) {\n      return this\n      /* c8 ignore next 5 */\n    } else if (this.bytesWritten + BigInt(length) > MAX_PAYLOAD_SIZE) {\n      throw new RangeError(\n        `Writing ${length} bytes exceeds max payload size of ${MAX_PAYLOAD_SIZE}`\n      )\n    }\n    // If we do not have enough bytes to form a quad, just add append new bytes\n    // to the buffer and return.\n    else if (offset + length < buffer.length) {\n      buffer.set(bytes, offset)\n      this.offset += length\n      this.bytesWritten += BigInt(length)\n      return this\n    }\n    // Otherwise we first fill the buffer to form a quad and create some leaves.\n    // Then we slice remaining bytes into quads sized chunks and create leaves\n    // from them. If we have some bytes left we copy them into the buffer and\n    // flush to combining node pairs and propagate them up the tree.\n    else {\n      // Number of bytes required to fill the quad buffer\n      const bytesRequired = buffer.length - offset\n      // copy required bytes into the buffer and turn them into leaves\n      // which we push into the leaf layer.\n      buffer.set(bytes.subarray(0, bytesRequired), offset)\n      leaves.push(...split(pad(buffer)))\n\n      // Now we slice remaining bytes into quads, create leaves from them\n      // and push them into the leaf layer.\n      let readOffset = bytesRequired\n      while (readOffset + IN_BYTES_PER_QUAD < length) {\n        const quad = bytes.subarray(readOffset, readOffset + IN_BYTES_PER_QUAD)\n        leaves.push(...split(pad(quad)))\n        readOffset += IN_BYTES_PER_QUAD\n      }\n\n      // Whatever byte were left are copied into the buffer and we update\n      // the offset to reflect that.\n      this.buffer.set(bytes.subarray(readOffset), 0)\n      this.offset = length - readOffset\n\n      // We also update the total number of bytes written.\n      this.bytesWritten += BigInt(length)\n\n      // Now prune the layers to propagate all the new leaves up the tree.\n      prune(this.layers)\n\n      return this\n    }\n  }\n\n  /**\n   * Resets this hasher to its initial state so it could be recycled as new\n   * instance.\n   */\n  reset() {\n    this.offset = 0\n    this.bytesWritten = 0n\n    this.layers.length = 1\n    this.layers[0].length = 0\n    return this\n  }\n\n  /* c8 ignore next 3 */\n  dispose() {\n    this.reset()\n  }\n  get code() {\n    return code\n  }\n  get name() {\n    return name\n  }\n}\n\n/**\n * Prunes layers by combining node pairs into nodes in the next layer and\n * removing them from the layer that they were in. After pruning each layer\n * will end up with at most one node. New layers may be created in the process\n * when nodes from the top layer are combined.\n *\n * @param {Layers} layers\n */\nconst prune = (layers) => flush(layers, false)\n\n/**\n * Flushes all the nodes in layers by combining node pairs into nodes in the\n * next layer. Layers with only one node are combined with zero padded nodes\n * (corresponding to the level of the layer). Unlike {@link prune} combined\n * nodes are not removed and layers are copied instead of been mutated.\n *\n * @param {Layers} layers\n */\nconst build = (layers) => flush([...layers], true)\n\n/**\n * @param {Layers} layers\n * @param {boolean} build\n * @returns {Layers}\n */\nconst flush = (layers, build) => {\n  // Note it is important that we do not mutate any of the layers otherwise\n  // writing more data into the hasher and computing the digest will produce\n  // wrong results.\n  let level = 0\n  // We will walk up the tree until we reach the top layer. However, we may end\n  // up with creating new layers in the process, so we will keep track of the\n  while (level < layers.length) {\n    let next = layers[level + 1]\n    const layer = layers[level]\n\n    // If we have the odd number of nodes and we have not reached the top\n    // layer, we push a zero padding node corresponding to the current level.\n    if (build && layer.length % 2 > 0 && next) {\n      layer.push(ZeroPad.fromLevel(level))\n    }\n\n    level += 1\n\n    // If we have 0 nodes in the current layer we just move to the next one.\n\n    // If we have a next layer and we are building  will combine nodes from the current layer\n    next = next ? (build ? [...next] : next) : []\n    let index = 0\n    // Note that we have checked that we have an even number of nodes so\n    // we will never end up with an extra node when consuming two at a time.\n    while (index + 1 < layer.length) {\n      const node = computeNode(layer[index], layer[index + 1])\n\n      // we proactively delete nodes in order to free up a memory used.\n      delete layer[index]\n      delete layer[index + 1]\n\n      next.push(node)\n      index += 2\n    }\n\n    if (next.length) {\n      layers[level] = next\n    }\n\n    // we remove nodes that we have combined from the current layer to reduce\n    // memory overhead and move to the next layer.\n    layer.splice(0, index)\n  }\n\n  return layers\n}\n","import { varint } from 'multiformats'\nimport * as API from './api.js'\nimport {\n  IN_BYTES_PER_QUAD,\n  IN_BITS_FR,\n  OUT_BITS_FR,\n  MIN_PAYLOAD_SIZE,\n} from './constant.js'\nimport { SHA256 } from './ipld.js'\nimport { fromHeight as piceSizeFromHeight } from './piece/size/expanded.js'\n\n/**\n * @see https://github.com/multiformats/multicodec/pull/331/files\n */\nexport const name = /** @type {const} */ (\n  'fr32-sha2-256-trunc254-padded-binary-tree'\n)\n\n/**\n * @type {API.MulticodecCode<0x1011, typeof name>}\n * @see https://github.com/multiformats/multicodec/pull/331/files\n */\nexport const code = 0x1011\n\n/**\n * Varint is used to encode the tree height which is limited to 9 bytes.\n *\n * @see https://github.com/multiformats/unsigned-varint#practical-maximum-of-9-bytes-for-security\n */\nconst MAX_PADDING_SIZE = 9\n/**\n * One byte is used to store the tree height.\n */\nexport const HEIGHT_SIZE = 1\n\n/**\n * Amount of bytes used to store the tree root.\n */\nexport const ROOT_SIZE = SHA256.size\n\n/**\n * Size of the multihash digest in bytes.\n */\nexport const MAX_DIGEST_SIZE = MAX_PADDING_SIZE + HEIGHT_SIZE + SHA256.size\n\nexport const TAG_SIZE = varint.encodingLength(code)\n\n/**\n * Max size of the multihash in bytes\n */\nexport const MAX_SIZE =\n  TAG_SIZE + varint.encodingLength(MAX_DIGEST_SIZE) + MAX_DIGEST_SIZE\n\n/**\n * Since first byte in the digest is the tree height, the maximum height is 255.\n *\n * @type {255}\n */\nexport const MAX_HEIGHT = 255\n\n/**\n * Max payload is determined by the maximum height of the tree, which is limited\n * by the int we could store in one byte. We calculate the max piece size\n * and derive max payload size that can would produce it after FR32 padding.\n */\nexport const MAX_PAYLOAD_SIZE =\n  (piceSizeFromHeight(MAX_HEIGHT) * BigInt(IN_BITS_FR)) / BigInt(OUT_BITS_FR)\n\n/**\n * @param {API.Piece} piece\n * @returns {API.PieceDigest}\n */\nexport const fromPiece = ({ padding, height, root }) => {\n  const paddingLength = varint.encodingLength(Number(padding))\n  const size = paddingLength + HEIGHT_SIZE + ROOT_SIZE\n  const sizeLength = varint.encodingLength(size)\n\n  const multihashLength = TAG_SIZE + sizeLength + size\n\n  let offset = 0\n  const bytes = new Uint8Array(multihashLength)\n  varint.encodeTo(code, bytes, offset)\n  offset += TAG_SIZE\n\n  varint.encodeTo(size, bytes, offset)\n  offset += sizeLength\n\n  varint.encodeTo(Number(padding), bytes, offset)\n  offset += paddingLength\n\n  bytes[offset] = height\n  offset += HEIGHT_SIZE\n\n  bytes.set(root, offset)\n\n  return new Digest(bytes)\n}\n\n/**\n * @param {Uint8Array} bytes\n * @returns {API.PieceDigest}\n */\nexport const fromBytes = (bytes) => new Digest(bytes)\n\n/**\n * @param {object} input\n * @param {Uint8Array} input.digest\n */\nexport const toBytes = ({ digest }) => {\n  const SIZE_BYTE_LENGTH = varint.encodingLength(digest.length)\n\n  // number of bytes prefix will take up\n  const prefixByteLength = SIZE_BYTE_LENGTH + TAG_SIZE\n\n  // if digest is view within a buffer that has enough bytes in front to\n  // fit the prefix it may be already include a prefix in which case we\n  // will simply use a larger slice.\n  if (digest.byteOffset >= prefixByteLength) {\n    const bytes = new Uint8Array(\n      digest.buffer,\n      digest.byteOffset - prefixByteLength,\n      digest.byteOffset + digest.length\n    )\n\n    // if the prefix matches our bytes represent a multihash\n    const [tag, offset] = varint.decode(bytes)\n    if (tag === code && varint.decode(bytes, offset)[0] === digest.length) {\n      return bytes\n    }\n  }\n\n  const bytes = new Uint8Array(digest.length + prefixByteLength)\n  varint.encodeTo(code, bytes)\n  varint.encodeTo(digest.length, bytes, TAG_SIZE)\n  bytes.set(digest, prefixByteLength)\n\n  return bytes\n}\n\n/**\n * @param {object} input\n * @param {Uint8Array} input.digest\n */\nexport const height = ({ digest }) => {\n  const [, offset] = varint.decode(digest)\n  return digest[offset]\n}\n\n/**\n * @param {object} input\n * @param {Uint8Array} input.digest\n */\nexport const padding = ({ digest }) => {\n  const [padding] = varint.decode(digest)\n  return BigInt(padding)\n}\n\n/**\n * @param {object} input\n * @param {Uint8Array} input.digest\n */\nexport const root = ({ digest }) => {\n  const [, offset] = varint.decode(digest)\n  return digest.subarray(\n    offset + HEIGHT_SIZE,\n    offset + HEIGHT_SIZE + SHA256.size\n  )\n}\n\n/**\n * @implements {API.PieceDigest}\n */\nclass Digest {\n  /**\n   * @param {Uint8Array} bytes\n   */\n  constructor(bytes) {\n    this.bytes = bytes\n    const [tag] = varint.decode(bytes)\n    if (tag !== code) {\n      throw new RangeError(`Expected multihash with code ${code}`)\n    }\n\n    let offset = TAG_SIZE\n    const [size, length] = varint.decode(bytes, offset)\n    offset += length\n    const digest = bytes.subarray(offset)\n\n    if (digest.length !== size) {\n      throw new RangeError(\n        `Invalid multihash size expected ${offset + size} bytes, got ${\n          bytes.length\n        } bytes`\n      )\n    }\n\n    this.digest = digest\n  }\n  get name() {\n    return name\n  }\n  get code() {\n    return code\n  }\n  get size() {\n    return this.digest.length\n  }\n  get padding() {\n    return padding(this)\n  }\n  get height() {\n    return height(this)\n  }\n  get root() {\n    return root(this)\n  }\n}\n","import { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nexport function decodeTagCompact (_data, _pos, minor, _options) {\n  return new Token(Type.tag, minor, 1)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeTag8 (data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint8(data, pos + 1, options), 2)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeTag16 (data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint16(data, pos + 1, options), 3)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeTag32 (data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint32(data, pos + 1, options), 5)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeTag64 (data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint64(data, pos + 1, options), 9)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeTag (buf, token) {\n  uint.encodeUintValue(buf, Type.tag.majorEncoded, token.value)\n}\n\nencodeTag.compareTokens = uint.encodeUint.compareTokens\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeTag.encodedSize = function encodedSize (token) {\n  return uint.encodeUintValue.encodedSize(token.value)\n}\n","import { is } from './is.js'\nimport { Token, Type } from './token.js'\nimport { Bl } from './bl.js'\nimport { encodeErrPrefix } from './common.js'\nimport { quickEncodeToken } from './jump.js'\nimport { asU8A, compare } from './byte-utils.js'\n\nimport { encodeUint } from './0uint.js'\nimport { encodeNegint } from './1negint.js'\nimport { encodeBytes } from './2bytes.js'\nimport { encodeString } from './3string.js'\nimport { encodeArray } from './4array.js'\nimport { encodeMap } from './5map.js'\nimport { encodeTag } from './6tag.js'\nimport { encodeFloat } from './7float.js'\n\n/**\n * @typedef {import('../interface').EncodeOptions} EncodeOptions\n * @typedef {import('../interface').OptionalTypeEncoder} OptionalTypeEncoder\n * @typedef {import('../interface').Reference} Reference\n * @typedef {import('../interface').StrictTypeEncoder} StrictTypeEncoder\n * @typedef {import('../interface').TokenTypeEncoder} TokenTypeEncoder\n * @typedef {import('../interface').TokenOrNestedTokens} TokenOrNestedTokens\n */\n\n/** @type {EncodeOptions} */\nconst defaultEncodeOptions = {\n  float64: false,\n  mapSorter,\n  quickEncodeToken\n}\n\n/** @type {EncodeOptions} */\nexport const rfc8949EncodeOptions = Object.freeze({\n  float64: true,\n  mapSorter: rfc8949MapSorter,\n  quickEncodeToken\n})\n\n/** @returns {TokenTypeEncoder[]} */\nexport function makeCborEncoders () {\n  const encoders = []\n  encoders[Type.uint.major] = encodeUint\n  encoders[Type.negint.major] = encodeNegint\n  encoders[Type.bytes.major] = encodeBytes\n  encoders[Type.string.major] = encodeString\n  encoders[Type.array.major] = encodeArray\n  encoders[Type.map.major] = encodeMap\n  encoders[Type.tag.major] = encodeTag\n  encoders[Type.float.major] = encodeFloat\n  return encoders\n}\n\nconst cborEncoders = makeCborEncoders()\n\nconst buf = new Bl()\n\n/** @implements {Reference} */\nclass Ref {\n  /**\n   * @param {object|any[]} obj\n   * @param {Reference|undefined} parent\n   */\n  constructor (obj, parent) {\n    this.obj = obj\n    this.parent = parent\n  }\n\n  /**\n   * @param {object|any[]} obj\n   * @returns {boolean}\n   */\n  includes (obj) {\n    /** @type {Reference|undefined} */\n    let p = this\n    do {\n      if (p.obj === obj) {\n        return true\n      }\n    } while (p = p.parent) // eslint-disable-line\n    return false\n  }\n\n  /**\n   * @param {Reference|undefined} stack\n   * @param {object|any[]} obj\n   * @returns {Reference}\n   */\n  static createCheck (stack, obj) {\n    if (stack && stack.includes(obj)) {\n      throw new Error(`${encodeErrPrefix} object contains circular references`)\n    }\n    return new Ref(obj, stack)\n  }\n}\n\nconst simpleTokens = {\n  null: new Token(Type.null, null),\n  undefined: new Token(Type.undefined, undefined),\n  true: new Token(Type.true, true),\n  false: new Token(Type.false, false),\n  emptyArray: new Token(Type.array, 0),\n  emptyMap: new Token(Type.map, 0)\n}\n\n/** @type {{[typeName: string]: StrictTypeEncoder}} */\nconst typeEncoders = {\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  number (obj, _typ, _options, _refStack) {\n    if (!Number.isInteger(obj) || !Number.isSafeInteger(obj)) {\n      return new Token(Type.float, obj)\n    } else if (obj >= 0) {\n      return new Token(Type.uint, obj)\n    } else {\n      return new Token(Type.negint, obj)\n    }\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  bigint (obj, _typ, _options, _refStack) {\n    if (obj >= BigInt(0)) {\n      return new Token(Type.uint, obj)\n    } else {\n      return new Token(Type.negint, obj)\n    }\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  Uint8Array (obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, obj)\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  string (obj, _typ, _options, _refStack) {\n    return new Token(Type.string, obj)\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  boolean (obj, _typ, _options, _refStack) {\n    return obj ? simpleTokens.true : simpleTokens.false\n  },\n\n  /**\n   * @param {any} _obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  null (_obj, _typ, _options, _refStack) {\n    return simpleTokens.null\n  },\n\n  /**\n   * @param {any} _obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  undefined (_obj, _typ, _options, _refStack) {\n    return simpleTokens.undefined\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  ArrayBuffer (obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, new Uint8Array(obj))\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  DataView (obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength))\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} options\n   * @param {Reference} [refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  Array (obj, _typ, options, refStack) {\n    if (!obj.length) {\n      if (options.addBreakTokens === true) {\n        return [simpleTokens.emptyArray, new Token(Type.break)]\n      }\n      return simpleTokens.emptyArray\n    }\n    refStack = Ref.createCheck(refStack, obj)\n    const entries = []\n    let i = 0\n    for (const e of obj) {\n      entries[i++] = objectToTokens(e, options, refStack)\n    }\n    if (options.addBreakTokens) {\n      return [new Token(Type.array, obj.length), entries, new Token(Type.break)]\n    }\n    return [new Token(Type.array, obj.length), entries]\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} typ\n   * @param {EncodeOptions} options\n   * @param {Reference} [refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  Object (obj, typ, options, refStack) {\n    // could be an Object or a Map\n    const isMap = typ !== 'Object'\n    // it's slightly quicker to use Object.keys() than Object.entries()\n    const keys = isMap ? obj.keys() : Object.keys(obj)\n    const length = isMap ? obj.size : keys.length\n    if (!length) {\n      if (options.addBreakTokens === true) {\n        return [simpleTokens.emptyMap, new Token(Type.break)]\n      }\n      return simpleTokens.emptyMap\n    }\n    refStack = Ref.createCheck(refStack, obj)\n    /** @type {TokenOrNestedTokens[]} */\n    const entries = []\n    let i = 0\n    for (const key of keys) {\n      entries[i++] = [\n        objectToTokens(key, options, refStack),\n        objectToTokens(isMap ? obj.get(key) : obj[key], options, refStack)\n      ]\n    }\n    sortMapEntries(entries, options)\n    if (options.addBreakTokens) {\n      return [new Token(Type.map, length), entries, new Token(Type.break)]\n    }\n    return [new Token(Type.map, length), entries]\n  }\n}\n\ntypeEncoders.Map = typeEncoders.Object\ntypeEncoders.Buffer = typeEncoders.Uint8Array\nfor (const typ of 'Uint8Clamped Uint16 Uint32 Int8 Int16 Int32 BigUint64 BigInt64 Float32 Float64'.split(' ')) {\n  typeEncoders[`${typ}Array`] = typeEncoders.DataView\n}\n\n/**\n * @param {any} obj\n * @param {EncodeOptions} [options]\n * @param {Reference} [refStack]\n * @returns {TokenOrNestedTokens}\n */\nfunction objectToTokens (obj, options = {}, refStack) {\n  const typ = is(obj)\n  const customTypeEncoder = (options && options.typeEncoders && /** @type {OptionalTypeEncoder} */ options.typeEncoders[typ]) || typeEncoders[typ]\n  if (typeof customTypeEncoder === 'function') {\n    const tokens = customTypeEncoder(obj, typ, options, refStack)\n    if (tokens != null) {\n      return tokens\n    }\n  }\n  const typeEncoder = typeEncoders[typ]\n  if (!typeEncoder) {\n    throw new Error(`${encodeErrPrefix} unsupported type: ${typ}`)\n  }\n  return typeEncoder(obj, typ, options, refStack)\n}\n\n/*\nCBOR key sorting is a mess.\n\nThe canonicalisation recommendation from https://tools.ietf.org/html/rfc7049#section-3.9\nincludes the wording:\n\n> The keys in every map must be sorted lowest value to highest.\n> Sorting is performed on the bytes of the representation of the key\n> data items without paying attention to the 3/5 bit splitting for\n> major types.\n> ...\n>  *  If two keys have different lengths, the shorter one sorts\n      earlier;\n>  *  If two keys have the same length, the one with the lower value\n      in (byte-wise) lexical order sorts earlier.\n\n1. It is not clear what \"bytes of the representation of the key\" means: is it\n   the CBOR representation, or the binary representation of the object itself?\n   Consider the int and uint difference here.\n2. It is not clear what \"without paying attention to\" means: do we include it\n   and compare on that? Or do we omit the special prefix byte, (mostly) treating\n   the key in its plain binary representation form.\n\nThe FIDO 2.0: Client To Authenticator Protocol spec takes the original CBOR\nwording and clarifies it according to their understanding.\nhttps://fidoalliance.org/specs/fido-v2.0-rd-20170927/fido-client-to-authenticator-protocol-v2.0-rd-20170927.html#message-encoding\n\n> The keys in every map must be sorted lowest value to highest. Sorting is\n> performed on the bytes of the representation of the key data items without\n> paying attention to the 3/5 bit splitting for major types. The sorting rules\n> are:\n>  * If the major types are different, the one with the lower value in numerical\n>    order sorts earlier.\n>  * If two keys have different lengths, the shorter one sorts earlier;\n>  * If two keys have the same length, the one with the lower value in\n>    (byte-wise) lexical order sorts earlier.\n\nSome other implementations, such as borc, do a full encode then do a\nlength-first, byte-wise-second comparison:\nhttps://github.com/dignifiedquire/borc/blob/b6bae8b0bcde7c3976b0f0f0957208095c392a36/src/encoder.js#L358\nhttps://github.com/dignifiedquire/borc/blob/b6bae8b0bcde7c3976b0f0f0957208095c392a36/src/utils.js#L143-L151\n\nThis has the benefit of being able to easily handle arbitrary keys, including\ncomplex types (maps and arrays).\n\nWe'll opt for the FIDO approach, since it affords some efficies since we don't\nneed a full encode of each key to determine order and can defer to the types\nto determine how to most efficiently order their values (i.e. int and uint\nordering can be done on the numbers, no need for byte-wise, for example).\n\nRecommendation: stick to single key types or you'll get into trouble, and prefer\nstring keys because it's much simpler that way.\n*/\n\n/**\n * @param {TokenOrNestedTokens[]} entries\n * @param {EncodeOptions} options\n */\nfunction sortMapEntries (entries, options) {\n  if (options.mapSorter) {\n    entries.sort(options.mapSorter)\n  }\n}\n\n/**\n * @param {(Token|Token[])[]} e1\n * @param {(Token|Token[])[]} e2\n * @returns {number}\n */\nfunction mapSorter (e1, e2) {\n  // the key position ([0]) could have a single token or an array\n  // almost always it'll be a single token but complex key might get involved\n  /* c8 ignore next 2 */\n  const keyToken1 = Array.isArray(e1[0]) ? e1[0][0] : e1[0]\n  const keyToken2 = Array.isArray(e2[0]) ? e2[0][0] : e2[0]\n\n  // different key types\n  if (keyToken1.type !== keyToken2.type) {\n    return keyToken1.type.compare(keyToken2.type)\n  }\n\n  const major = keyToken1.type.major\n  // TODO: handle case where cmp === 0 but there are more keyToken e. complex type)\n  const tcmp = cborEncoders[major].compareTokens(keyToken1, keyToken2)\n  /* c8 ignore next 5 */\n  if (tcmp === 0) {\n    // duplicate key or complex type where the first token matched,\n    // i.e. a map or array and we're only comparing the opening token\n    console.warn('WARNING: complex key types used, CBOR key sorting guarantees are gone')\n  }\n  return tcmp\n}\n\n/**\n * @typedef {Token & { _keyBytes?: Uint8Array }} TokenEx\n *\n * @param {(Token|Token[])[]} e1\n * @param {(Token|Token[])[]} e2\n * @returns {number}\n */\nfunction rfc8949MapSorter (e1, e2) {\n  if (e1[0] instanceof Token && e2[0] instanceof Token) {\n    const t1 = /** @type {TokenEx} */ (e1[0])\n    const t2 = /** @type {TokenEx} */ (e2[0])\n\n    if (!t1._keyBytes) {\n      t1._keyBytes = encodeRfc8949(t1.value)\n    }\n\n    if (!t2._keyBytes) {\n      t2._keyBytes = encodeRfc8949(t2.value)\n    }\n\n    return compare(t1._keyBytes, t2._keyBytes)\n  }\n\n  throw new Error('rfc8949MapSorter: complex key types are not supported yet')\n}\n\n/**\n * @param {any} data\n * @returns {Uint8Array}\n */\nfunction encodeRfc8949 (data) {\n  return encodeCustom(data, cborEncoders, rfc8949EncodeOptions)\n}\n\n/**\n * @param {Bl} buf\n * @param {TokenOrNestedTokens} tokens\n * @param {TokenTypeEncoder[]} encoders\n * @param {EncodeOptions} options\n */\nfunction tokensToEncoded (buf, tokens, encoders, options) {\n  if (Array.isArray(tokens)) {\n    for (const token of tokens) {\n      tokensToEncoded(buf, token, encoders, options)\n    }\n  } else {\n    encoders[tokens.type.major](buf, tokens, options)\n  }\n}\n\n/**\n * @param {any} data\n * @param {TokenTypeEncoder[]} encoders\n * @param {EncodeOptions} options\n * @returns {Uint8Array}\n */\nfunction encodeCustom (data, encoders, options) {\n  const tokens = objectToTokens(data, options)\n  if (!Array.isArray(tokens) && options.quickEncodeToken) {\n    const quickBytes = options.quickEncodeToken(tokens)\n    if (quickBytes) {\n      return quickBytes\n    }\n    const encoder = encoders[tokens.type.major]\n    if (encoder.encodedSize) {\n      const size = encoder.encodedSize(tokens, options)\n      const buf = new Bl(size)\n      encoder(buf, tokens, options)\n      /* c8 ignore next 4 */\n      // this would be a problem with encodedSize() functions\n      if (buf.chunks.length !== 1) {\n        throw new Error(`Unexpected error: pre-calculated length for ${tokens} was wrong`)\n      }\n      return asU8A(buf.chunks[0])\n    }\n  }\n  buf.reset()\n  tokensToEncoded(buf, tokens, encoders, options)\n  return buf.toBytes(true)\n}\n\n/**\n * @param {any} data\n * @param {EncodeOptions} [options]\n * @returns {Uint8Array}\n */\nfunction encode (data, options) {\n  options = Object.assign({}, defaultEncodeOptions, options)\n  return encodeCustom(data, cborEncoders, options)\n}\n\nexport { objectToTokens, encode, encodeCustom, Ref }\n","import * as API from './api.js'\nimport {\n  OUT_BYTES_PER_QUAD,\n  FR_RATIO,\n  IN_BYTES_PER_QUAD,\n  MIN_PAYLOAD_SIZE,\n} from './constant.js'\n\n/**\n * Determine the additional bytes of zeroed padding to append to the\n * end of a resource of `size` length in order to fit within a pow2 piece while\n * leaving enough room for Fr32 padding (2 bits per 254).\n *\n * @param {number} payloadSize - The size of the payload.\n * @returns {number}\n */\nexport function toZeroPaddedSize(payloadSize) {\n  const size = Math.max(payloadSize, MIN_PAYLOAD_SIZE)\n  const highestBit = Math.floor(Math.log2(size))\n\n  const bound = Math.ceil(FR_RATIO * 2 ** (highestBit + 1))\n  // the size is either the closest pow2 number, or the next pow2 number if we\n  // don't have space for padding\n  return size <= bound ? bound : Math.ceil(FR_RATIO * 2 ** (highestBit + 2))\n}\n\n/**\n * Derives fr32 padded size from the source content size (that MUST be\n * multiples of {@link IN_BYTES_PER_QUAD}) in bytes.\n *\n * @param {number} size\n */\nexport const toPieceSize = (size) => toZeroPaddedSize(size) / FR_RATIO\n\n/**\n * Derives fr32 unpadded size from the Fr32 padded size in bytes.\n *\n * @param {number} size\n */\nexport const fromPieceSize = (size) => size * FR_RATIO\n\n/**\n * Takes source bytes that returns fr32 padded bytes.\n *\n * @param {Uint8Array} source\n * @param {Uint8Array} output\n * @returns {API.Fr23Padded}\n */\nexport const pad = (\n  source,\n  output = new Uint8Array(toPieceSize(source.length))\n) => {\n  const size = toZeroPaddedSize(source.byteLength)\n  // Calculate number of quads in the given source\n  const quadCount = size / IN_BYTES_PER_QUAD\n\n  // Cycle over four(4) 31-byte groups, leaving 1 byte in between:\n  // 31 + 1 + 31 + 1 + 31 + 1 + 31 = 127\n  for (let n = 0; n < quadCount; n++) {\n    const readOffset = n * IN_BYTES_PER_QUAD\n    const writeOffset = n * OUT_BYTES_PER_QUAD\n\n    // First 31 bytes + 6 bits are taken as-is (trimmed later)\n    output.set(source.subarray(readOffset, readOffset + 32), writeOffset)\n\n    // first 2-bit \"shim\" forced into the otherwise identical output\n    output[writeOffset + 31] &= 0b00111111\n\n    // copy next Fr32 preceded with the last two bits of the previous Fr32\n    for (let i = 32; i < 64; i++) {\n      output[writeOffset + i] =\n        (source[readOffset + i] << 2) | (source[readOffset + i - 1] >> 6)\n    }\n\n    // next 2-bit shim\n    output[writeOffset + 63] &= 0b00111111\n\n    for (let i = 64; i < 96; i++) {\n      output[writeOffset + i] =\n        (source[readOffset + i] << 4) | (source[readOffset + i - 1] >> 4)\n    }\n\n    // next 2-bit shim\n    output[writeOffset + 95] &= 0b00111111\n\n    for (let i = 96; i < 127; i++) {\n      output[writeOffset + i] =\n        (source[readOffset + i] << 6) | (source[readOffset + i - 1] >> 2)\n    }\n\n    // we shim last 2-bits by shifting the last byte by two bits\n    output[writeOffset + 127] = source[readOffset + 126] >> 2\n  }\n\n  return output\n}\n\n/**\n * @param {API.Fr23Padded} source\n * @param {Uint8Array} [out]\n */\nexport const unpad = (\n  source,\n  out = new Uint8Array(fromPieceSize(source.length))\n) => {\n  const chunks = source.length / 128\n  for (let chunk = 0; chunk < chunks; chunk++) {\n    const inOffNext = chunk * 128 + 1\n    const outOff = chunk * 127\n\n    let at = source[chunk * 128]\n\n    for (let i = 0; i < 32; i++) {\n      const next = source[i + inOffNext]\n\n      out[outOff + i] = at\n\n      at = next\n    }\n\n    out[outOff + 31] |= at << 6\n\n    for (let i = 32; i < 64; i++) {\n      const next = source[i + inOffNext]\n\n      out[outOff + i] = at >> 2\n      out[outOff + i] |= next << 6\n\n      at = next\n    }\n\n    out[outOff + 63] ^= (at << 6) ^ (at << 4)\n\n    for (let i = 64; i < 96; i++) {\n      const next = source[i + inOffNext]\n\n      out[outOff + i] = at >> 4\n      out[outOff + i] |= next << 4\n\n      at = next\n    }\n\n    out[outOff + 95] ^= (at << 4) ^ (at << 2)\n\n    for (let i = 96; i < 127; i++) {\n      const next = source[i + inOffNext]\n\n      out[outOff + i]\n      out[outOff + i] = at >> 6\n      out[outOff + i] |= next << 2\n\n      at = next\n    }\n  }\n\n  return out\n}\n","import * as API from './api.js'\nexport * as SHA256 from './ipld/sha256.js'\nexport * as CBOR from './ipld/cbor.js'\nimport * as Link from 'multiformats/link'\n\n/**\n * @template Layout\n * @template {API.MulticodecCode} Format\n * @template {API.MulticodecCode} Hash\n * @param {API.ByteView<Layout, Format>} bytes\n * @param {object} settings\n * @param {API.SyncMultihashHasher<Hash>} settings.hasher\n * @param {object} settings.codec\n * @param {Format} settings.codec.code\n * @returns {API.Link<Layout, Format, Hash>}\n */\nexport const createLink = (bytes, { hasher, codec }) => {\n  const digest = hasher.digest(bytes)\n  return Link.create(codec.code, digest)\n}\n","import * as API from '../../api.js'\nimport {\n  PADDED_BYTES_PER_QUAD,\n  EXPANDED_BYTES_PER_QUAD,\n  LEAFS_PER_QUAD,\n} from '../../constant.js'\nimport { log2Ceil } from '../../uint64.js'\nimport * as Padded from './padded.js'\n\n/**\n * Takes the {@link API.Piece} sizing details (height and padding) and\n * calculates original payload size.\n *\n * @param {object} piece\n * @param {number} piece.height\n * @param {API.uint64} piece.padding\n */\nexport const fromPiece = ({ height, padding }) =>\n  Padded.fromHeight(height) - padding\n\n/**\n * Takes arbitrary payload size and calculates 0-padding required to\n * produce a {@link API.PaddedSize}.\n *\n * @param {API.uint64} size\n */\nexport const toPadding = (size) => toPadded(size) - size\n\n/**\n * Takes arbitrary payload size and calculates size after required 0-padding.\n *\n * @param {API.uint64} size\n * @returns {API.PaddedSize}\n */\nexport const toPadded = (size) => toQauds(size) * PADDED_BYTES_PER_QUAD\n\n/**\n * Takes arbitrary payload size and calculates the piece size after required\n * 0-padding and FR32 expansion is applied.\n *\n * @param {API.uint64} size\n * @returns {API.PieceSize}\n */\nexport const toExpanded = (size) => toQauds(size) * EXPANDED_BYTES_PER_QUAD\n\n/**\n * Takes arbitrary payload size and calculates width of the piece tree (leaf\n * count) that will be required to represent it.\n *\n * @param {API.uint64} size\n */\nexport const toWidth = (size) => toQauds(size) * LEAFS_PER_QUAD\n\n/**\n * Takes arbitrary payload size and calculates height of the piece tree that will be required to represent it.\n *\n * @param {API.uint64} size\n */\nexport const toHeight = (size) => log2Ceil(toWidth(size))\n\n/**\n * Takes arbitrary payload size and calculates number of quads that will be\n * required to represent it.\n *\n * @param {API.uint64} size\n */\nconst toQauds = (size) => {\n  // Number of quads required to fit given payload size.\n  // Since bigint division truncates we add another quads shy of 1 number of\n  // bytes to round up.\n  const quadCount = (size + PADDED_BYTES_PER_QUAD - 1n) / PADDED_BYTES_PER_QUAD\n  // Next we we log2 then pow2 with some rounding to ensure that result\n  // is 2 ^ n.\n  return 2n ** BigInt(log2Ceil(quadCount))\n}\n","/* eslint-env es2020 */\n\nimport { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\nimport { decodeErrPrefix } from './common.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeNegint8 (data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - uint.readUint8(data, pos + 1, options), 2)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeNegint16 (data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - uint.readUint16(data, pos + 1, options), 3)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeNegint32 (data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - uint.readUint32(data, pos + 1, options), 5)\n}\n\nconst neg1b = BigInt(-1)\nconst pos1b = BigInt(1)\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeNegint64 (data, pos, _minor, options) {\n  const int = uint.readUint64(data, pos + 1, options)\n  if (typeof int !== 'bigint') {\n    const value = -1 - int\n    if (value >= Number.MIN_SAFE_INTEGER) {\n      return new Token(Type.negint, value, 9)\n    }\n  }\n  if (options.allowBigInt !== true) {\n    throw new Error(`${decodeErrPrefix} integers outside of the safe integer range are not supported`)\n  }\n  return new Token(Type.negint, neg1b - BigInt(int), 9)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeNegint (buf, token) {\n  const negint = token.value\n  const unsigned = (typeof negint === 'bigint' ? (negint * neg1b - pos1b) : (negint * -1 - 1))\n  uint.encodeUintValue(buf, token.type.majorEncoded, unsigned)\n}\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeNegint.encodedSize = function encodedSize (token) {\n  const negint = token.value\n  const unsigned = (typeof negint === 'bigint' ? (negint * neg1b - pos1b) : (negint * -1 - 1))\n  /* c8 ignore next 4 */\n  // handled by quickEncode, we shouldn't get here but it's included for completeness\n  if (unsigned < uint.uintBoundaries[0]) {\n    return 1\n  }\n  if (unsigned < uint.uintBoundaries[1]) {\n    return 2\n  }\n  if (unsigned < uint.uintBoundaries[2]) {\n    return 3\n  }\n  if (unsigned < uint.uintBoundaries[3]) {\n    return 5\n  }\n  return 9\n}\n\n/**\n * @param {Token} tok1\n * @param {Token} tok2\n * @returns {number}\n */\nencodeNegint.compareTokens = function compareTokens (tok1, tok2) {\n  // opposite of the uint comparison since we store the uint version in bytes\n  return tok1.value < tok2.value ? 1 : tok1.value > tok2.value ? -1 : /* c8 ignore next */ 0\n}\n","/**\n * PaymentsService - Consolidated interface for all Payments contract operations\n * along with some additional token related utilities.\n */\n\nimport { ethers } from 'ethers'\nimport type { RailInfo, SettlementResult, TokenAmount, TokenIdentifier } from '../types.ts'\nimport {\n  CHAIN_IDS,\n  CONTRACT_ABIS,\n  CONTRACT_ADDRESSES,\n  createError,\n  EIP2612_PERMIT_TYPES,\n  getCurrentEpoch,\n  getFilecoinNetworkType,\n  SETTLEMENT_FEE,\n  TIMING_CONSTANTS,\n  TOKENS,\n} from '../utils/index.ts'\n\n/**\n * Options for deposit operation\n */\nexport interface DepositOptions {\n  /** Optional recipient address (defaults to signer address if not provided) */\n  to?: string\n  /** Called when checking current allowance */\n  onAllowanceCheck?: (current: bigint, required: bigint) => void\n  /** Called when approval transaction is sent */\n  onApprovalTransaction?: (tx: ethers.TransactionResponse) => void\n  /** Called when approval is confirmed */\n  onApprovalConfirmed?: (receipt: ethers.TransactionReceipt) => void\n  /** Called before deposit transaction is sent */\n  onDepositStarting?: () => void\n}\n\nexport class PaymentsService {\n  private readonly _provider: ethers.Provider\n  private readonly _signer: ethers.Signer\n  private readonly _paymentsAddress: string\n  private readonly _usdfcAddress: string\n  private readonly _disableNonceManager: boolean\n  // Cached contract instances\n  private _usdfcContract: ethers.Contract | null = null\n  private _paymentsContract: ethers.Contract | null = null\n\n  /**\n   * @param provider - Direct provider instance for balance checks, nonce management, and epoch calculations\n   * @param signer - Signer instance for transaction signing (may be wrapped in NonceManager)\n   * @param paymentsAddress - Address of the Payments contract\n   * @param usdfcAddress - Address of the USDFC token contract\n   * @param disableNonceManager - When true, manually manages nonces using provider.getTransactionCount()\n   *\n   * Note: Both provider and signer are required for NonceManager compatibility. When NonceManager\n   * is disabled, we need direct provider access for reliable nonce management. Using signer.provider\n   * could interfere with NonceManager's internal state or behave differently with MetaMask/hardware wallets.\n   */\n  constructor(\n    provider: ethers.Provider,\n    signer: ethers.Signer,\n    paymentsAddress: string,\n    usdfcAddress: string,\n    disableNonceManager: boolean\n  ) {\n    this._provider = provider\n    this._signer = signer\n    this._paymentsAddress = paymentsAddress\n    this._usdfcAddress = usdfcAddress\n    this._disableNonceManager = disableNonceManager\n  }\n\n  /**\n   * Get cached USDFC contract instance or create new one\n   */\n  private _getUsdfcContract(): ethers.Contract {\n    if (this._usdfcContract == null) {\n      this._usdfcContract = new ethers.Contract(this._usdfcAddress, CONTRACT_ABIS.ERC20, this._signer)\n    }\n    return this._usdfcContract\n  }\n\n  /**\n   * Get cached payments contract instance or create new one\n   */\n  private _getPaymentsContract(): ethers.Contract {\n    if (this._paymentsContract == null) {\n      this._paymentsContract = new ethers.Contract(this._paymentsAddress, CONTRACT_ABIS.PAYMENTS, this._signer)\n    }\n    return this._paymentsContract\n  }\n\n  /**\n   * Generate EIP-2612 permit signature for USDFC token\n   * Handles balance check, domain creation, nonce retrieval, and signature generation\n   * Uses Multicall3 to batch RPC calls for efficiency\n   * @param amount - Amount to permit\n   * @param deadline - Unix timestamp (seconds) when the permit expires\n   * @param contextName - Context name for error messages (e.g., 'depositWithPermit')\n   * @returns Signature object\n   */\n  private async _getPermitSignature(amount: bigint, deadline: bigint, contextName: string): Promise<ethers.Signature> {\n    const signerAddress = await this._signer.getAddress()\n\n    // Get network type (validates network and makes single getNetwork() call internally)\n    const networkType = await getFilecoinNetworkType(this._provider)\n\n    // Derive chainId from network type\n    const chainId = CHAIN_IDS[networkType]\n\n    // Setup Multicall3 for batched RPC calls\n    const multicall3Address = CONTRACT_ADDRESSES.MULTICALL3[networkType]\n    const multicall = new ethers.Contract(multicall3Address, CONTRACT_ABIS.MULTICALL3, this._provider)\n\n    // Create interfaces for encoding/decoding\n    const erc20Interface = new ethers.Interface(CONTRACT_ABIS.ERC20)\n    const permitInterface = new ethers.Interface(CONTRACT_ABIS.ERC20_PERMIT)\n\n    // Prepare multicall batch: balanceOf, name, version (with fallback), nonces\n    const calls = [\n      {\n        target: this._usdfcAddress,\n        allowFailure: false,\n        callData: erc20Interface.encodeFunctionData('balanceOf', [signerAddress]),\n      },\n      {\n        target: this._usdfcAddress,\n        allowFailure: false,\n        callData: erc20Interface.encodeFunctionData('name'),\n      },\n      {\n        target: this._usdfcAddress,\n        allowFailure: true, // Allow failure for version, we'll fallback to '1'\n        callData: permitInterface.encodeFunctionData('version'),\n      },\n      {\n        target: this._usdfcAddress,\n        allowFailure: false,\n        callData: permitInterface.encodeFunctionData('nonces', [signerAddress]),\n      },\n    ]\n\n    // Execute multicall\n    let results: any[]\n    try {\n      results = await multicall.aggregate3.staticCall(calls)\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        contextName,\n        'Failed to fetch token information for permit. Ensure token contract is reachable.',\n        error\n      )\n    }\n\n    // Decode results\n    // Result 0: balanceOf\n    let usdfcBalance: bigint\n    try {\n      const decoded = erc20Interface.decodeFunctionResult('balanceOf', results[0].returnData)\n      usdfcBalance = decoded[0]\n    } catch (error) {\n      throw createError('PaymentsService', contextName, 'Failed to decode token balance.', error)\n    }\n\n    // Check balance\n    if (usdfcBalance < amount) {\n      throw createError(\n        'PaymentsService',\n        contextName,\n        `Insufficient USDFC: have ${usdfcBalance.toString()}, need ${amount.toString()}`\n      )\n    }\n\n    // Result 1: name\n    let tokenName: string\n    try {\n      const decoded = erc20Interface.decodeFunctionResult('name', results[1].returnData)\n      tokenName = decoded[0]\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        contextName,\n        'Failed to read token name for permit domain. Ensure token contract is reachable.',\n        error\n      )\n    }\n\n    // Result 2: version (with fallback)\n    let domainVersion = '1'\n    if (results[2].success) {\n      try {\n        const decoded = permitInterface.decodeFunctionResult('version', results[2].returnData)\n        const maybeVersion = decoded[0]\n        if (typeof maybeVersion === 'string' && maybeVersion.length > 0) {\n          domainVersion = maybeVersion\n        }\n      } catch {\n        // silently fallback to '1'\n      }\n    }\n\n    // Result 3: nonces\n    let nonce: bigint\n    try {\n      const decoded = permitInterface.decodeFunctionResult('nonces', results[3].returnData)\n      nonce = decoded[0]\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        contextName,\n        'Token does not appear to support EIP-2612 permit (nonces() unavailable).',\n        error\n      )\n    }\n\n    // Build EIP-2612 permit domain\n    const domain = {\n      name: tokenName,\n      version: domainVersion,\n      chainId,\n      verifyingContract: this._usdfcAddress,\n    }\n\n    // Create permit value\n    const value = {\n      owner: signerAddress,\n      spender: this._paymentsAddress,\n      value: amount,\n      nonce,\n      deadline,\n    }\n\n    // Sign typed data\n    let signatureHex: string\n    try {\n      signatureHex = await this._signer.signTypedData(domain, EIP2612_PERMIT_TYPES, value)\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        contextName,\n        'Failed to sign EIP-2612 permit. Ensure your wallet supports typed data signing.',\n        error\n      )\n    }\n\n    return ethers.Signature.from(signatureHex)\n  }\n\n  async balance(token: TokenIdentifier = TOKENS.USDFC): Promise<bigint> {\n    // For now, only support USDFC balance\n    if (token !== TOKENS.USDFC) {\n      throw createError(\n        'PaymentsService',\n        'payments contract balance check',\n        `Token \"${token}\" is not supported. Currently only USDFC token is supported for payments contract balance queries.`\n      )\n    }\n\n    const accountInfo = await this.accountInfo(token)\n    return accountInfo.availableFunds\n  }\n\n  /**\n   * Get detailed account information from the payments contract\n   * @param token - The token to get account info for (defaults to USDFC)\n   * @returns Account information including funds, lockup details, and available balance\n   */\n  async accountInfo(token: TokenIdentifier = TOKENS.USDFC): Promise<{\n    funds: bigint\n    lockupCurrent: bigint\n    lockupRate: bigint\n    lockupLastSettledAt: bigint\n    availableFunds: bigint\n  }> {\n    if (token !== TOKENS.USDFC) {\n      throw createError(\n        'PaymentsService',\n        'account info',\n        `Token \"${token}\" is not supported. Currently only USDFC token is supported.`\n      )\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    let accountData: any[]\n\n    try {\n      // Get account info from payments contract\n      accountData = await paymentsContract.accounts(this._usdfcAddress, signerAddress)\n    } catch (contractCallError) {\n      throw createError(\n        'PaymentsService',\n        'account info',\n        'Failed to read account information from payments contract. This could indicate the contract is not properly deployed, the ABI is incorrect, or there are network connectivity issues.',\n        contractCallError\n      )\n    }\n\n    // accountData returns: (uint256 funds, uint256 lockupCurrent, uint256 lockupRate, uint256 lockupLastSettledAt)\n    const [funds, lockupCurrent, lockupRate, lockupLastSettledAt] = accountData\n\n    // Calculate time-based lockup\n    const currentEpoch = await getCurrentEpoch(this._provider)\n    const epochsSinceSettlement = currentEpoch - BigInt(lockupLastSettledAt)\n    const actualLockup = BigInt(lockupCurrent) + BigInt(lockupRate) * epochsSinceSettlement\n\n    // Calculate available funds\n    const availableFunds = BigInt(funds) - actualLockup\n\n    return {\n      funds: BigInt(funds),\n      lockupCurrent: BigInt(lockupCurrent),\n      lockupRate: BigInt(lockupRate),\n      lockupLastSettledAt: BigInt(lockupLastSettledAt),\n      availableFunds: availableFunds > 0n ? availableFunds : 0n,\n    }\n  }\n\n  async walletBalance(token?: TokenIdentifier): Promise<bigint> {\n    // If no token specified or FIL is requested, return native wallet balance\n    if (token == null || token === TOKENS.FIL) {\n      try {\n        const address = await this._signer.getAddress()\n        const balance = await this._provider.getBalance(address)\n        return balance\n      } catch (error) {\n        throw createError(\n          'PaymentsService',\n          'wallet FIL balance check',\n          'Unable to retrieve FIL balance from wallet. This could be due to network connectivity issues, RPC endpoint problems, or wallet connection issues.',\n          error\n        )\n      }\n    }\n\n    // Handle ERC20 token balance\n    if (token === TOKENS.USDFC) {\n      try {\n        const address = await this._signer.getAddress()\n        const usdfcContract = this._getUsdfcContract()\n        const balance = await usdfcContract.balanceOf(address)\n        return balance\n      } catch (error) {\n        throw createError(\n          'PaymentsService',\n          'wallet USDFC balance check',\n          'Unexpected error while checking USDFC token balance in wallet.',\n          error\n        )\n      }\n    }\n\n    // For other tokens, throw error\n    throw createError(\n      'PaymentsService',\n      'wallet balance',\n      `Token \"${token}\" is not supported. Currently only FIL and USDFC tokens are supported.`\n    )\n  }\n\n  decimals(_token: TokenIdentifier = TOKENS.USDFC): number {\n    // Both FIL and USDFC use 18 decimals\n    return 18\n  }\n\n  /**\n   * Check the current ERC20 token allowance for a spender\n   * @param spender - The address to check allowance for\n   * @param token - The token to check allowance for (defaults to USDFC)\n   * @returns The current allowance amount as bigint\n   */\n  async allowance(spender: string, token: TokenIdentifier = TOKENS.USDFC): Promise<bigint> {\n    if (token !== TOKENS.USDFC) {\n      throw createError(\n        'PaymentsService',\n        'allowance',\n        `Token \"${token}\" is not supported. Currently only USDFC token is supported.`\n      )\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const usdfcContract = this._getUsdfcContract()\n\n    try {\n      const currentAllowance = await usdfcContract.allowance(signerAddress, spender)\n      return currentAllowance\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'allowance check',\n        'Failed to check token allowance. This could indicate network connectivity issues or an invalid spender address.',\n        error\n      )\n    }\n  }\n\n  /**\n   * Approve an ERC20 token spender\n   * @param spender - The address to approve as spender\n   * @param amount - The amount to approve\n   * @param token - The token to approve spending for (defaults to USDFC)\n   * @returns Transaction response object\n   */\n  async approve(\n    spender: string,\n    amount: TokenAmount,\n    token: TokenIdentifier = TOKENS.USDFC\n  ): Promise<ethers.TransactionResponse> {\n    if (token !== TOKENS.USDFC) {\n      throw createError(\n        'PaymentsService',\n        'approve',\n        `Token \"${token}\" is not supported. Currently only USDFC token is supported.`\n      )\n    }\n\n    const approveAmount = typeof amount === 'bigint' ? amount : BigInt(amount)\n    if (approveAmount < 0n) {\n      throw createError('PaymentsService', 'approve', 'Approval amount cannot be negative')\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const usdfcContract = this._getUsdfcContract()\n\n    // Only set explicit nonce if NonceManager is disabled\n    const txOptions: any = {}\n    if (this._disableNonceManager) {\n      const approvalNonce = await this._provider.getTransactionCount(signerAddress, 'pending')\n      txOptions.nonce = approvalNonce\n    }\n\n    try {\n      const approveTx = await usdfcContract.approve(spender, approveAmount, txOptions)\n      return approveTx\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'approve',\n        `Failed to approve ${spender} to spend ${approveAmount.toString()} ${token}`,\n        error\n      )\n    }\n  }\n\n  /**\n   * Approve a service contract to act as an operator for payment rails\n   * This allows the service contract (such as Warm Storage) to create and manage payment rails on behalf\n   * of the client\n   * @param service - The service contract address to approve\n   * @param rateAllowance - Maximum payment rate per epoch the operator can set\n   * @param lockupAllowance - Maximum lockup amount the operator can set\n   * @param maxLockupPeriod - Maximum lockup period in epochs the operator can set\n   * @param token - The token to approve for (defaults to USDFC)\n   * @returns Transaction response object\n   */\n  async approveService(\n    service: string,\n    rateAllowance: TokenAmount,\n    lockupAllowance: TokenAmount,\n    maxLockupPeriod: TokenAmount,\n    token: TokenIdentifier = TOKENS.USDFC\n  ): Promise<ethers.TransactionResponse> {\n    if (token !== TOKENS.USDFC) {\n      throw createError(\n        'PaymentsService',\n        'approveService',\n        `Token \"${token}\" is not supported. Currently only USDFC token is supported.`\n      )\n    }\n\n    const rateAllowanceBigint = typeof rateAllowance === 'bigint' ? rateAllowance : BigInt(rateAllowance)\n    const lockupAllowanceBigint = typeof lockupAllowance === 'bigint' ? lockupAllowance : BigInt(lockupAllowance)\n    const maxLockupPeriodBigint = typeof maxLockupPeriod === 'bigint' ? maxLockupPeriod : BigInt(maxLockupPeriod)\n\n    if (rateAllowanceBigint < 0n || lockupAllowanceBigint < 0n || maxLockupPeriodBigint < 0n) {\n      throw createError('PaymentsService', 'approveService', 'Allowance values cannot be negative')\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    // Only set explicit nonce if NonceManager is disabled\n    const txOptions: any = {}\n    if (this._disableNonceManager) {\n      const currentNonce = await this._provider.getTransactionCount(signerAddress, 'pending')\n      txOptions.nonce = currentNonce\n    }\n\n    try {\n      const approveTx = await paymentsContract.setOperatorApproval(\n        this._usdfcAddress,\n        service,\n        true, // approved\n        rateAllowanceBigint,\n        lockupAllowanceBigint,\n        maxLockupPeriodBigint,\n        txOptions\n      )\n      return approveTx\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'approveService',\n        `Failed to approve service ${service} as operator for ${token}`,\n        error\n      )\n    }\n  }\n\n  /**\n   * Revoke a service contract's operator approval\n   * @param service - The service contract address to revoke\n   * @param token - The token to revoke approval for (defaults to USDFC)\n   * @returns Transaction response object\n   */\n  async revokeService(service: string, token: TokenIdentifier = TOKENS.USDFC): Promise<ethers.TransactionResponse> {\n    if (token !== TOKENS.USDFC) {\n      throw createError(\n        'PaymentsService',\n        'revokeService',\n        `Token \"${token}\" is not supported. Currently only USDFC token is supported.`\n      )\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    // Only set explicit nonce if NonceManager is disabled\n    const txOptions: any = {}\n    if (this._disableNonceManager) {\n      const currentNonce = await this._provider.getTransactionCount(signerAddress, 'pending')\n      txOptions.nonce = currentNonce\n    }\n\n    try {\n      const revokeTx = await paymentsContract.setOperatorApproval(\n        this._usdfcAddress,\n        service,\n        false, // not approved\n        0n, // zero rate allowance\n        0n, // zero lockup allowance\n        0n, // zero max lockup period\n        txOptions\n      )\n      return revokeTx\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'revokeService',\n        `Failed to revoke service ${service} as operator for ${token}`,\n        error\n      )\n    }\n  }\n\n  /**\n   * Get the operator approval status and allowances for a service\n   * @param service - The service contract address to check\n   * @param token - The token to check approval for (defaults to USDFC)\n   * @returns Approval status and allowances\n   */\n  async serviceApproval(\n    service: string,\n    token: TokenIdentifier = TOKENS.USDFC\n  ): Promise<{\n    isApproved: boolean\n    rateAllowance: bigint\n    rateUsed: bigint\n    lockupAllowance: bigint\n    lockupUsed: bigint\n    maxLockupPeriod: bigint\n  }> {\n    if (token !== TOKENS.USDFC) {\n      throw createError(\n        'PaymentsService',\n        'serviceApproval',\n        `Token \"${token}\" is not supported. Currently only USDFC token is supported.`\n      )\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    try {\n      const approval = await paymentsContract.operatorApprovals(this._usdfcAddress, signerAddress, service)\n      return {\n        isApproved: approval[0],\n        rateAllowance: approval[1],\n        lockupAllowance: approval[2],\n        rateUsed: approval[3],\n        lockupUsed: approval[4],\n        maxLockupPeriod: approval[5],\n      }\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'serviceApproval',\n        `Failed to check service approval status for ${service}`,\n        error\n      )\n    }\n  }\n\n  async deposit(\n    amount: TokenAmount,\n    token: TokenIdentifier = TOKENS.USDFC,\n    options?: DepositOptions\n  ): Promise<ethers.TransactionResponse> {\n    // Only support USDFC for now\n    if (token !== TOKENS.USDFC) {\n      throw createError('PaymentsService', 'deposit', `Unsupported token: ${token}`)\n    }\n\n    const depositAmountBigint = typeof amount === 'bigint' ? amount : BigInt(amount)\n    if (depositAmountBigint <= 0n) {\n      throw createError('PaymentsService', 'deposit', 'Invalid amount')\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const depositTo = options?.to ?? signerAddress\n    const usdfcContract = this._getUsdfcContract()\n    const paymentsContract = this._getPaymentsContract()\n\n    // Check balance\n    const usdfcBalance = await usdfcContract.balanceOf(signerAddress)\n\n    if (usdfcBalance < depositAmountBigint) {\n      throw createError(\n        'PaymentsService',\n        'deposit',\n        `Insufficient USDFC: have ${BigInt(usdfcBalance).toString()}, need ${depositAmountBigint.toString()}`\n      )\n    }\n\n    // Check and update allowance if needed\n    const currentAllowance = await this.allowance(this._paymentsAddress, token)\n    options?.onAllowanceCheck?.(currentAllowance, depositAmountBigint)\n\n    if (currentAllowance < depositAmountBigint) {\n      // Golden path: automatically approve the exact amount needed\n      const approveTx = await this.approve(this._paymentsAddress, depositAmountBigint, token)\n      options?.onApprovalTransaction?.(approveTx)\n\n      // Wait for approval to be mined before proceeding\n      const approvalReceipt = await approveTx.wait(TIMING_CONSTANTS.TRANSACTION_CONFIRMATIONS)\n      if (approvalReceipt != null) {\n        options?.onApprovalConfirmed?.(approvalReceipt)\n      }\n    }\n\n    // Check if account has sufficient available balance (no frozen account check needed for deposits)\n\n    // Notify that deposit is starting\n    options?.onDepositStarting?.()\n\n    // Only set explicit nonce if NonceManager is disabled\n    const txOptions: any = {}\n    if (this._disableNonceManager) {\n      const currentNonce = await this._provider.getTransactionCount(signerAddress, 'pending')\n      txOptions.nonce = currentNonce\n    }\n\n    const depositTx = await paymentsContract.deposit(this._usdfcAddress, depositTo, depositAmountBigint, txOptions)\n\n    return depositTx\n  }\n\n  /**\n   * Deposit funds using ERC-2612 permit to approve and deposit in a single transaction\n   * This method creates an EIP-712 typed-data signature for the USDFC token's permit,\n   * then calls the Payments contract `depositWithPermit` to pull funds and credit the account.\n   *\n   * @param amount - Amount of USDFC to deposit (in base units)\n   * @param token - Token identifier (currently only USDFC is supported)\n   * @param deadline - Unix timestamp (seconds) when the permit expires. Defaults to now + 1 hour.\n   * @returns Transaction response object\n   */\n  async depositWithPermit(\n    amount: TokenAmount,\n    token: TokenIdentifier = TOKENS.USDFC,\n    deadline?: number | bigint\n  ): Promise<ethers.TransactionResponse> {\n    // Only support USDFC for now\n    if (token !== TOKENS.USDFC) {\n      throw createError('PaymentsService', 'depositWithPermit', `Unsupported token: ${token}`)\n    }\n\n    const depositAmountBigint = typeof amount === 'bigint' ? amount : BigInt(amount)\n    if (depositAmountBigint <= 0n) {\n      throw createError('PaymentsService', 'depositWithPermit', 'Invalid amount')\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    // Calculate deadline\n    const permitDeadline: bigint =\n      deadline == null\n        ? BigInt(Math.floor(Date.now() / 1000) + TIMING_CONSTANTS.PERMIT_DEADLINE_DURATION)\n        : BigInt(deadline)\n\n    // Get permit signature (includes balance check, domain, nonce, signing)\n    const signature = await this._getPermitSignature(depositAmountBigint, permitDeadline, 'depositWithPermit')\n\n    // Only set explicit nonce if NonceManager is disabled\n    const txOptions: any = {}\n    if (this._disableNonceManager) {\n      const currentNonce = await this._provider.getTransactionCount(signerAddress, 'pending')\n      txOptions.nonce = currentNonce\n    }\n\n    try {\n      const tx = await paymentsContract.depositWithPermit(\n        this._usdfcAddress,\n        signerAddress,\n        depositAmountBigint,\n        permitDeadline,\n        signature.v,\n        signature.r,\n        signature.s,\n        txOptions\n      )\n      return tx\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'depositWithPermit',\n        'Failed to execute depositWithPermit on Payments contract.',\n        error\n      )\n    }\n  }\n\n  /**\n   * Deposit funds using ERC-2612 permit and approve an operator in a single transaction\n   * This signs an EIP-712 permit for the USDFC token and calls the Payments contract\n   * function `depositWithPermitAndApproveOperator` which both deposits and sets operator approval.\n   *\n   * @param amount - Amount of USDFC to deposit (in base units)\n   * @param operator - Service/operator address to approve\n   * @param rateAllowance - Max payment rate per epoch operator can set\n   * @param lockupAllowance - Max lockup amount operator can set\n   * @param maxLockupPeriod - Max lockup period in epochs operator can set\n   * @param token - Token identifier (currently only USDFC supported)\n   * @param deadline - Unix timestamp (seconds) when the permit expires. Defaults to now + 1 hour.\n   * @returns Transaction response object\n   */\n  async depositWithPermitAndApproveOperator(\n    amount: TokenAmount,\n    operator: string,\n    rateAllowance: TokenAmount,\n    lockupAllowance: TokenAmount,\n    maxLockupPeriod: bigint,\n    token: TokenIdentifier = TOKENS.USDFC,\n    deadline?: number | bigint\n  ): Promise<ethers.TransactionResponse> {\n    // Only support USDFC for now\n    if (token !== TOKENS.USDFC) {\n      throw createError('PaymentsService', 'depositWithPermitAndApproveOperator', `Unsupported token: ${token}`)\n    }\n\n    const depositAmountBigint = typeof amount === 'bigint' ? amount : BigInt(amount)\n    if (depositAmountBigint <= 0n) {\n      throw createError('PaymentsService', 'depositWithPermitAndApproveOperator', 'Invalid amount')\n    }\n\n    const rateAllowanceBigint = typeof rateAllowance === 'bigint' ? rateAllowance : BigInt(rateAllowance)\n    const lockupAllowanceBigint = typeof lockupAllowance === 'bigint' ? lockupAllowance : BigInt(lockupAllowance)\n    const maxLockupPeriodBigint = typeof maxLockupPeriod === 'bigint' ? maxLockupPeriod : BigInt(maxLockupPeriod)\n    if (rateAllowanceBigint < 0n || lockupAllowanceBigint < 0n || maxLockupPeriodBigint < 0n) {\n      throw createError('PaymentsService', 'depositWithPermitAndApproveOperator', 'Allowance values cannot be negative')\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    // Calculate deadline\n    const permitDeadline: bigint =\n      deadline == null\n        ? BigInt(Math.floor(Date.now() / 1000) + TIMING_CONSTANTS.PERMIT_DEADLINE_DURATION)\n        : BigInt(deadline)\n\n    // Get permit signature (includes balance check, domain, nonce, signing)\n    const signature = await this._getPermitSignature(\n      depositAmountBigint,\n      permitDeadline,\n      'depositWithPermitAndApproveOperator'\n    )\n\n    // Only set explicit nonce if NonceManager is disabled\n    const txOptions: any = {}\n    if (this._disableNonceManager) {\n      const currentNonce = await this._provider.getTransactionCount(signerAddress, 'pending')\n      txOptions.nonce = currentNonce\n    }\n\n    try {\n      const tx = await paymentsContract.depositWithPermitAndApproveOperator(\n        this._usdfcAddress,\n        signerAddress,\n        depositAmountBigint,\n        permitDeadline,\n        signature.v,\n        signature.r,\n        signature.s,\n        operator,\n        rateAllowanceBigint,\n        lockupAllowanceBigint,\n        maxLockupPeriodBigint,\n        txOptions\n      )\n      return tx\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'depositWithPermitAndApproveOperator',\n        'Failed to execute depositWithPermitAndApproveOperator on Payments contract.',\n        error\n      )\n    }\n  }\n\n  async withdraw(amount: TokenAmount, token: TokenIdentifier = TOKENS.USDFC): Promise<ethers.TransactionResponse> {\n    // Only support USDFC for now\n    if (token !== TOKENS.USDFC) {\n      throw createError('PaymentsService', 'withdraw', `Unsupported token: ${token}`)\n    }\n\n    const withdrawAmountBigint = typeof amount === 'bigint' ? amount : BigInt(amount)\n\n    if (withdrawAmountBigint <= 0n) {\n      throw createError('PaymentsService', 'withdraw', 'Invalid amount')\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    // Check balance using the corrected accountInfo method\n    const accountInfo = await this.accountInfo(token)\n\n    if (accountInfo.availableFunds < withdrawAmountBigint) {\n      throw createError(\n        'PaymentsService',\n        'withdraw',\n        `Insufficient available balance: have ${accountInfo.availableFunds.toString()}, need ${withdrawAmountBigint.toString()}`\n      )\n    }\n\n    // Only set explicit nonce if NonceManager is disabled\n    const txOptions: any = {}\n    if (this._disableNonceManager) {\n      const currentNonce = await this._provider.getTransactionCount(signerAddress, 'pending')\n      txOptions.nonce = currentNonce\n    }\n\n    const tx = await paymentsContract.withdraw(this._usdfcAddress, withdrawAmountBigint, txOptions)\n\n    return tx\n  }\n\n  /**\n   * Settle a payment rail up to a specific epoch (sends a transaction)\n   * Note: This method automatically includes the required network fee (FIL) for burning\n   * @param railId - The rail ID to settle\n   * @param untilEpoch - The epoch to settle up to (must be <= current epoch; defaults to current).\n   *                     Can be used for partial settlements to a past epoch.\n   * @returns Transaction response object\n   * @throws Error if untilEpoch is in the future (contract reverts with CannotSettleFutureEpochs)\n   */\n  async settle(railId: number | bigint, untilEpoch?: number | bigint): Promise<ethers.TransactionResponse> {\n    const railIdBigint = typeof railId === 'bigint' ? railId : BigInt(railId)\n\n    const [signerAddress, currentEpoch] = await Promise.all([\n      this._signer.getAddress(),\n      untilEpoch == null ? getCurrentEpoch(this._provider) : Promise.resolve(null),\n    ])\n\n    const untilEpochBigint = untilEpoch == null ? (currentEpoch as bigint) : BigInt(untilEpoch)\n\n    const paymentsContract = this._getPaymentsContract()\n\n    // Only set explicit nonce if NonceManager is disabled\n    const txOptions: any = {\n      value: SETTLEMENT_FEE, // Include the settlement fee (NETWORK_FEE in contract) as msg.value\n    }\n    if (this._disableNonceManager) {\n      const currentNonce = await this._provider.getTransactionCount(signerAddress, 'pending')\n      txOptions.nonce = currentNonce\n    }\n\n    try {\n      const tx = await paymentsContract.settleRail(railIdBigint, untilEpochBigint, txOptions)\n      return tx\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'settle',\n        `Failed to settle rail ${railIdBigint.toString()} up to epoch ${untilEpochBigint.toString()}`,\n        error\n      )\n    }\n  }\n\n  /**\n   * Get the expected settlement amounts for a rail (read-only simulation)\n   * Note: The actual settlement will require a network fee (FIL) to be sent with the transaction\n   * @param railId - The rail ID to check\n   * @param untilEpoch - The epoch to settle up to (must be <= current epoch; defaults to current).\n   *                     Can be used to preview partial settlements to a past epoch.\n   * @returns Settlement result with amounts and details\n   */\n  async getSettlementAmounts(railId: number | bigint, untilEpoch?: number | bigint): Promise<SettlementResult> {\n    const railIdBigint = typeof railId === 'bigint' ? railId : BigInt(railId)\n\n    const currentEpoch = untilEpoch == null ? await getCurrentEpoch(this._provider) : null\n\n    const untilEpochBigint = untilEpoch == null ? (currentEpoch as bigint) : BigInt(untilEpoch)\n\n    const paymentsContract = this._getPaymentsContract()\n\n    try {\n      // Use staticCall to simulate the transaction and get the return values\n      // Include the settlement fee (NETWORK_FEE in contract) in the simulation\n      const result = await paymentsContract.settleRail.staticCall(railIdBigint, untilEpochBigint)\n\n      return {\n        totalSettledAmount: result[0],\n        totalNetPayeeAmount: result[1],\n        totalOperatorCommission: result[2],\n        totalNetworkFee: result[3],\n        finalSettledEpoch: result[4],\n        note: result[5],\n      }\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'getSettlementAmounts',\n        `Failed to get settlement amounts for rail ${railIdBigint.toString()} up to epoch ${untilEpochBigint.toString()}`,\n        error\n      )\n    }\n  }\n\n  /**\n   * Emergency settlement for terminated rails only - bypasses service contract validation\n   * This ensures payment even if the validator contract is buggy or unresponsive (pays in full)\n   * Can only be called by the client after the max settlement epoch has passed\n   * @param railId - The rail ID to settle\n   * @returns Transaction response object\n   */\n  async settleTerminatedRail(railId: number | bigint): Promise<ethers.TransactionResponse> {\n    const railIdBigint = typeof railId === 'bigint' ? railId : BigInt(railId)\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    // Only set explicit nonce if NonceManager is disabled\n    const txOptions: any = {}\n    if (this._disableNonceManager) {\n      const currentNonce = await this._provider.getTransactionCount(signerAddress, 'pending')\n      txOptions.nonce = currentNonce\n    }\n\n    try {\n      const tx = await paymentsContract.settleTerminatedRailWithoutValidation(railIdBigint, txOptions)\n      return tx\n    } catch (error) {\n      throw createError(\n        'PaymentsService',\n        'settleTerminatedRail',\n        `Failed to settle terminated rail ${railIdBigint.toString()}`,\n        error\n      )\n    }\n  }\n\n  /**\n   * Get detailed information about a specific rail\n   * @param railId - The rail ID to query\n   * @returns Rail information including all parameters and current state\n   * @throws Error if the rail doesn't exist or is inactive (contract reverts with RailInactiveOrSettled)\n   */\n  async getRail(railId: number | bigint): Promise<{\n    token: string\n    from: string\n    to: string\n    operator: string\n    validator: string\n    paymentRate: bigint\n    lockupPeriod: bigint\n    lockupFixed: bigint\n    settledUpTo: bigint\n    endEpoch: bigint\n    commissionRateBps: bigint\n    serviceFeeRecipient: string\n  }> {\n    const railIdBigint = typeof railId === 'bigint' ? railId : BigInt(railId)\n    const paymentsContract = this._getPaymentsContract()\n\n    try {\n      const rail = await paymentsContract.getRail(railIdBigint)\n      return {\n        token: rail.token,\n        from: rail.from,\n        to: rail.to,\n        operator: rail.operator,\n        validator: rail.validator,\n        paymentRate: rail.paymentRate,\n        lockupPeriod: rail.lockupPeriod,\n        lockupFixed: rail.lockupFixed,\n        settledUpTo: rail.settledUpTo,\n        endEpoch: rail.endEpoch,\n        commissionRateBps: rail.commissionRateBps,\n        serviceFeeRecipient: rail.serviceFeeRecipient,\n      }\n    } catch (error: any) {\n      // Contract reverts with RailInactiveOrSettled error if rail doesn't exist\n      if (error.message?.includes('RailInactiveOrSettled')) {\n        throw createError('PaymentsService', 'getRail', `Rail ${railIdBigint.toString()} does not exist or is inactive`)\n      }\n      throw createError('PaymentsService', 'getRail', `Failed to get rail ${railIdBigint.toString()}`, error)\n    }\n  }\n\n  /**\n   * Automatically settle a rail, detecting whether it's terminated or active\n   * This method checks the rail status and calls the appropriate settlement method:\n   * - For terminated rails: calls settleTerminatedRail()\n   * - For active rails: calls settle() with optional untilEpoch (requires settlement fee)\n   *\n   * @param railId - The rail ID to settle\n   * @param untilEpoch - The epoch to settle up to (must be <= current epoch for active rails; ignored for terminated rails)\n   * @returns Transaction response object\n   * @throws Error if rail doesn't exist (contract reverts with RailInactiveOrSettled) or other settlement errors\n   *\n   * @example\n   * ```javascript\n   * // Automatically detect and settle appropriately\n   * const tx = await synapse.payments.settleAuto(railId)\n   * await tx.wait()\n   *\n   * // For active rails, can specify epoch\n   * const tx = await synapse.payments.settleAuto(railId, specificEpoch)\n   * ```\n   */\n  async settleAuto(railId: number | bigint, untilEpoch?: number | bigint): Promise<ethers.TransactionResponse> {\n    const railIdBigint = typeof railId === 'bigint' ? railId : BigInt(railId)\n\n    // Get rail information to check if terminated\n    const rail = await this.getRail(railIdBigint)\n\n    // Check if rail is terminated (endEpoch > 0 means terminated)\n    if (rail.endEpoch > 0n) {\n      // Rail is terminated, use settleTerminatedRail\n      return await this.settleTerminatedRail(railIdBigint)\n    } else {\n      // Rail is active, use regular settle (requires settlement fee)\n      return await this.settle(railIdBigint, untilEpoch)\n    }\n  }\n\n  /**\n   * Get all rails where the wallet is the payer\n   * @param token - The token to filter by (defaults to USDFC)\n   * @returns Array of rail information\n   */\n  async getRailsAsPayer(token: TokenIdentifier = TOKENS.USDFC): Promise<RailInfo[]> {\n    if (token !== TOKENS.USDFC) {\n      throw createError(\n        'PaymentsService',\n        'getRailsAsPayer',\n        `Token \"${token}\" is not supported. Currently only USDFC token is supported.`\n      )\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    try {\n      const [rails] = await paymentsContract.getRailsForPayerAndToken(signerAddress, this._usdfcAddress, 0n, 0n)\n\n      return rails.map((rail: any) => ({\n        railId: Number(rail.railId),\n        isTerminated: rail.isTerminated,\n        endEpoch: Number(rail.endEpoch),\n      }))\n    } catch (error) {\n      throw createError('PaymentsService', 'getRailsAsPayer', 'Failed to get rails where wallet is payer', error)\n    }\n  }\n\n  /**\n   * Get all rails where the wallet is the payee\n   * @param token - The token to filter by (defaults to USDFC)\n   * @returns Array of rail information\n   */\n  async getRailsAsPayee(token: TokenIdentifier = TOKENS.USDFC): Promise<RailInfo[]> {\n    if (token !== TOKENS.USDFC) {\n      throw createError(\n        'PaymentsService',\n        'getRailsAsPayee',\n        `Token \"${token}\" is not supported. Currently only USDFC token is supported.`\n      )\n    }\n\n    const signerAddress = await this._signer.getAddress()\n    const paymentsContract = this._getPaymentsContract()\n\n    try {\n      const [rails] = await paymentsContract.getRailsForPayeeAndToken(signerAddress, this._usdfcAddress, 0n, 0n)\n\n      return rails.map((rail: any) => ({\n        railId: Number(rail.railId),\n        isTerminated: rail.isTerminated,\n        endEpoch: Number(rail.endEpoch),\n      }))\n    } catch (error) {\n      throw createError('PaymentsService', 'getRailsAsPayee', 'Failed to get rails where wallet is payee', error)\n    }\n  }\n}\n","import { coerce } from '../bytes.js'\nimport basex from '../vendor/base-x.js'\nimport type { BaseCodec, BaseDecoder, BaseEncoder, CombobaseDecoder, Multibase, MultibaseCodec, MultibaseDecoder, MultibaseEncoder, UnibaseDecoder } from './interface.js'\n\ninterface EncodeFn { (bytes: Uint8Array): string }\ninterface DecodeFn { (text: string): Uint8Array }\n\n/**\n * Class represents both BaseEncoder and MultibaseEncoder meaning it\n * can be used to encode to multibase or base encode without multibase\n * prefix.\n */\nclass Encoder<Base extends string, Prefix extends string> implements MultibaseEncoder<Prefix>, BaseEncoder {\n  readonly name: Base\n  readonly prefix: Prefix\n  readonly baseEncode: EncodeFn\n\n  constructor (name: Base, prefix: Prefix, baseEncode: EncodeFn) {\n    this.name = name\n    this.prefix = prefix\n    this.baseEncode = baseEncode\n  }\n\n  encode (bytes: Uint8Array): Multibase<Prefix> {\n    if (bytes instanceof Uint8Array) {\n      return `${this.prefix}${this.baseEncode(bytes)}`\n    } else {\n      throw Error('Unknown type, must be binary type')\n    }\n  }\n}\n\n/**\n * Class represents both BaseDecoder and MultibaseDecoder so it could be used\n * to decode multibases (with matching prefix) or just base decode strings\n * with corresponding base encoding.\n */\nclass Decoder<Base extends string, Prefix extends string> implements MultibaseDecoder<Prefix>, UnibaseDecoder<Prefix>, BaseDecoder {\n  readonly name: Base\n  readonly prefix: Prefix\n  readonly baseDecode: DecodeFn\n  private readonly prefixCodePoint: number\n\n  constructor (name: Base, prefix: Prefix, baseDecode: DecodeFn) {\n    this.name = name\n    this.prefix = prefix\n    const prefixCodePoint = prefix.codePointAt(0)\n    /* c8 ignore next 3 */\n    if (prefixCodePoint === undefined) {\n      throw new Error('Invalid prefix character')\n    }\n    this.prefixCodePoint = prefixCodePoint\n    this.baseDecode = baseDecode\n  }\n\n  decode (text: string): Uint8Array {\n    if (typeof text === 'string') {\n      if (text.codePointAt(0) !== this.prefixCodePoint) {\n        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)\n      }\n      return this.baseDecode(text.slice(this.prefix.length))\n    } else {\n      throw Error('Can only multibase decode strings')\n    }\n  }\n\n  or<OtherPrefix extends string> (decoder: UnibaseDecoder<OtherPrefix> | ComposedDecoder<OtherPrefix>): ComposedDecoder<Prefix | OtherPrefix> {\n    return or(this, decoder)\n  }\n}\n\ntype Decoders<Prefix extends string> = Record<Prefix, UnibaseDecoder<Prefix>>\n\nclass ComposedDecoder<Prefix extends string> implements MultibaseDecoder<Prefix>, CombobaseDecoder<Prefix> {\n  readonly decoders: Decoders<Prefix>\n\n  constructor (decoders: Decoders<Prefix>) {\n    this.decoders = decoders\n  }\n\n  or <OtherPrefix extends string> (decoder: UnibaseDecoder<OtherPrefix> | ComposedDecoder<OtherPrefix>): ComposedDecoder<Prefix | OtherPrefix> {\n    return or(this, decoder)\n  }\n\n  decode (input: string): Uint8Array {\n    const prefix = input[0] as Prefix\n    const decoder = this.decoders[prefix]\n    if (decoder != null) {\n      return decoder.decode(input)\n    } else {\n      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)\n    }\n  }\n}\n\nexport function or <L extends string, R extends string> (left: UnibaseDecoder<L> | CombobaseDecoder<L>, right: UnibaseDecoder<R> | CombobaseDecoder<R>): ComposedDecoder<L | R> {\n  return new ComposedDecoder({\n    ...(left.decoders ?? { [(left as UnibaseDecoder<L>).prefix]: left }),\n    ...(right.decoders ?? { [(right as UnibaseDecoder<R>).prefix]: right })\n  } as Decoders<L | R>)\n}\n\nexport class Codec<Base extends string, Prefix extends string> implements MultibaseCodec<Prefix>, MultibaseEncoder<Prefix>, MultibaseDecoder<Prefix>, BaseCodec, BaseEncoder, BaseDecoder {\n  readonly name: Base\n  readonly prefix: Prefix\n  readonly baseEncode: EncodeFn\n  readonly baseDecode: DecodeFn\n  readonly encoder: Encoder<Base, Prefix>\n  readonly decoder: Decoder<Base, Prefix>\n\n  constructor (name: Base, prefix: Prefix, baseEncode: EncodeFn, baseDecode: DecodeFn) {\n    this.name = name\n    this.prefix = prefix\n    this.baseEncode = baseEncode\n    this.baseDecode = baseDecode\n    this.encoder = new Encoder(name, prefix, baseEncode)\n    this.decoder = new Decoder(name, prefix, baseDecode)\n  }\n\n  encode (input: Uint8Array): string {\n    return this.encoder.encode(input)\n  }\n\n  decode (input: string): Uint8Array {\n    return this.decoder.decode(input)\n  }\n}\n\nexport function from <Base extends string, Prefix extends string> ({ name, prefix, encode, decode }: { name: Base, prefix: Prefix, encode: EncodeFn, decode: DecodeFn }): Codec<Base, Prefix> {\n  return new Codec(name, prefix, encode, decode)\n}\n\nexport function baseX <Base extends string, Prefix extends string> ({ name, prefix, alphabet }: { name: Base, prefix: Prefix, alphabet: string }): Codec<Base, Prefix> {\n  const { encode, decode } = basex(alphabet, name)\n  return from({\n    prefix,\n    name,\n    encode,\n    decode: (text: string): Uint8Array => coerce(decode(text))\n  })\n}\n\nfunction decode (string: string, alphabetIdx: Record<string, number>, bitsPerChar: number, name: string): Uint8Array {\n  // Count the padding bytes:\n  let end = string.length\n  while (string[end - 1] === '=') {\n    --end\n  }\n\n  // Allocate the output:\n  const out = new Uint8Array((end * bitsPerChar / 8) | 0)\n\n  // Parse the data:\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  let written = 0 // Next byte to write\n  for (let i = 0; i < end; ++i) {\n    // Read one character from the string:\n    const value = alphabetIdx[string[i]]\n    if (value === undefined) {\n      throw new SyntaxError(`Non-${name} character`)\n    }\n\n    // Append the bits to the buffer:\n    buffer = (buffer << bitsPerChar) | value\n    bits += bitsPerChar\n\n    // Write out some bits if the buffer has a byte's worth:\n    if (bits >= 8) {\n      bits -= 8\n      out[written++] = 0xff & (buffer >> bits)\n    }\n  }\n\n  // Verify that we have received just enough bits:\n  if (bits >= bitsPerChar || (0xff & (buffer << (8 - bits))) !== 0) {\n    throw new SyntaxError('Unexpected end of data')\n  }\n\n  return out\n}\n\nfunction encode (data: Uint8Array, alphabet: string, bitsPerChar: number): string {\n  const pad = alphabet[alphabet.length - 1] === '='\n  const mask = (1 << bitsPerChar) - 1\n  let out = ''\n\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  for (let i = 0; i < data.length; ++i) {\n    // Slurp data into the buffer:\n    buffer = (buffer << 8) | data[i]\n    bits += 8\n\n    // Write out as much as we can:\n    while (bits > bitsPerChar) {\n      bits -= bitsPerChar\n      out += alphabet[mask & (buffer >> bits)]\n    }\n  }\n\n  // Partial character:\n  if (bits !== 0) {\n    out += alphabet[mask & (buffer << (bitsPerChar - bits))]\n  }\n\n  // Add padding characters until we hit a byte boundary:\n  if (pad) {\n    while (((out.length * bitsPerChar) & 7) !== 0) {\n      out += '='\n    }\n  }\n\n  return out\n}\n\nfunction createAlphabetIdx (alphabet: string): Record<string, number> {\n  // Build the character lookup table:\n  const alphabetIdx: Record<string, number> = {}\n  for (let i = 0; i < alphabet.length; ++i) {\n    alphabetIdx[alphabet[i]] = i\n  }\n  return alphabetIdx\n}\n\n/**\n * RFC4648 Factory\n */\nexport function rfc4648 <Base extends string, Prefix extends string> ({ name, prefix, bitsPerChar, alphabet }: { name: Base, prefix: Prefix, bitsPerChar: number, alphabet: string }): Codec<Base, Prefix> {\n  const alphabetIdx = createAlphabetIdx(alphabet)\n  return from({\n    prefix,\n    name,\n    encode (input: Uint8Array): string {\n      return encode(input, alphabet, bitsPerChar)\n    },\n    decode (input: string): Uint8Array {\n      return decode(input, alphabetIdx, bitsPerChar, name)\n    }\n  })\n}\n","import * as API from '../../api.js'\nimport { log2Ceil, trailingZeros64 } from '../../uint64.js'\nimport {\n  PADDED_BYTES_PER_QUAD,\n  EXPANDED_BYTES_PER_QUAD,\n  LEAFS_PER_QUAD,\n} from '../../constant.js'\n\n/**\n * Validates that given `size` is a valid {@link API.UnpaddedPieceSize} and\n * returns {@link API.UnpaddedPieceSize} capturing the validation at the type\n * level. If given `size` is not a valid `UnpaddedPieceSize` throws an error.\n *\n * This function is a variation on {@link validate} that throws exceptions\n * instead of returning a {@link API.Result}.\n *\n * @param {number|API.uint64} size\n * @returns {API.PaddedSize}\n */\nexport const from = (size) => {\n  const result = tryFrom(size)\n  if (result.error) {\n    throw result.error\n  } else {\n    return result.ok\n  }\n}\n\n/**\n * Validates that given `size` is a valid {@link API.UnpaddedPieceSize} that is\n * a power of 2 multiple of 127. Returns {@link API.Result} with\n * `UnpaddedPieceSize` ok case and an Error in the error case.\n *\n * @param {API.uint64|number} input\n * @returns {API.Result<API.PaddedSize, Error>}\n */\nexport const tryFrom = (input) => {\n  const size = BigInt(input)\n  if (size < PADDED_BYTES_PER_QUAD) {\n    return {\n      error: new RangeError(\n        `Padded payload must contain at least ${PADDED_BYTES_PER_QUAD} bytes`\n      ),\n    }\n  }\n\n  if (size >> BigInt(trailingZeros64(size)) !== PADDED_BYTES_PER_QUAD) {\n    return {\n      error: new RangeError(\n        `Padded payload size must be (2ⁿ * ${PADDED_BYTES_PER_QUAD})`\n      ),\n    }\n  }\n\n  return { ok: size }\n}\n\n/**\n * @param {API.PieceSize} size\n * @returns {API.PaddedSize}\n */\nexport const fromExpanded = (size) => fromQuads(size / EXPANDED_BYTES_PER_QUAD)\n\n/**\n * Takes `{@link API.PaddedPieceSize}` and returns corresponding\n * {@link API.PieceSize}.\n *\n * Please note that this function does not validate the input size and\n * relies that type-checker will ensure that user passes valid unpadded\n * piece size created with {@link from} or {@link validate} functions.\n *\n *\n * @see https://github.com/filecoin-project/go-state-types/blob/master/abi/piece.go#L14-L16\n *\n * @param {API.PaddedSize} size\n * @returns {API.PieceSize}\n */\nexport const toExpanded = (size) => toQauds(size) * EXPANDED_BYTES_PER_QUAD\n\n/**\n * Calculates the padded size of the piece from the given tree height.\n *\n * @param {number} height\n * @returns {API.uint64}\n */\nexport const fromHeight = (height) => {\n  // We calculate number of quads tree by calculating number of nodes tree\n  // at second layer. This works because we deal with a binary tree so first\n  // layer nodes will contain 2 leaves and second layer nodes will contain 4\n  // leaves hence number of quads.\n  const quads = 2n ** BigInt(height - 2)\n  return quads * PADDED_BYTES_PER_QUAD\n}\n\n/**\n * Calculates the height of the piece tree from unpadded size.\n *\n * @param {API.PaddedSize} size\n */\nexport const toHeight = (size) => log2Ceil(toWidth(size))\n\n/**\n * Takes `{@link API.PaddedPieceSize}` and returns corresponding\n * piece tree width (leaf count).\n *\n * @param {API.PaddedSize} size\n */\nexport const toWidth = (size) => toQauds(size) * LEAFS_PER_QUAD\n\n/**\n *\n * @param {API.uint64} width\n * @returns {API.PaddedSize}\n */\nexport const fromWidth = (width) => fromQuads(width / LEAFS_PER_QUAD)\n\n/**\n * @param {API.PaddedSize} size\n */\nconst toQauds = (size) => size / PADDED_BYTES_PER_QUAD\n\n/**\n *\n * @param {API.uint64} count\n * @returns {API.PaddedSize}\n */\nconst fromQuads = (count) => count * PADDED_BYTES_PER_QUAD\n","/**\n * @internal\n *\n * Map with a LRU (Least recently used) policy.\n * @see https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU\n */\nexport class LruMap<value = unknown> extends Map<string, value> {\n  maxSize: number\n\n  constructor(size: number) {\n    super()\n    this.maxSize = size\n  }\n\n  override get(key: string) {\n    const value = super.get(key)\n\n    if (super.has(key) && value !== undefined) {\n      this.delete(key)\n      super.set(key, value)\n    }\n\n    return value\n  }\n\n  override set(key: string, value: value) {\n    super.set(key, value)\n    if (this.maxSize && this.size > this.maxSize) {\n      const firstKey = this.keys().next().value\n      if (firstKey) this.delete(firstKey)\n    }\n    return this\n  }\n}\n","/**\n * Bl is a list of byte chunks, similar to https://github.com/rvagg/bl but for\n * writing rather than reading.\n * A Bl object accepts set() operations for individual bytes and copyTo() for\n * inserting byte arrays. These write operations don't automatically increment\n * the internal cursor so its \"length\" won't be changed. Instead, increment()\n * must be called to extend its length to cover the inserted data.\n * The toBytes() call will convert all internal memory to a single Uint8Array of\n * the correct length, truncating any data that is stored but hasn't been\n * included by an increment().\n * get() can retrieve a single byte.\n * All operations (except toBytes()) take an \"offset\" argument that will perform\n * the write at the offset _from the current cursor_. For most operations this\n * will be `0` to write at the current cursor position but it can be ahead of\n * the current cursor. Negative offsets probably work but are untested.\n */\n\n// TODO: ipjs doesn't support this, only for test files: https://github.com/mikeal/ipjs/blob/master/src/package/testFile.js#L39\nimport { alloc, concat, slice } from './byte-utils.js'\n\n// the ts-ignores in this file are almost all for the `Uint8Array|number[]` duality that exists\n// for perf reasons. Consider better approaches to this or removing it entirely, it is quite\n// risky because of some assumptions about small chunks === number[] and everything else === Uint8Array.\n\nconst defaultChunkSize = 256\n\nexport class Bl {\n  /**\n   * @param {number} [chunkSize]\n   */\n  constructor (chunkSize = defaultChunkSize) {\n    this.chunkSize = chunkSize\n    /** @type {number} */\n    this.cursor = 0\n    /** @type {number} */\n    this.maxCursor = -1\n    /** @type {(Uint8Array|number[])[]} */\n    this.chunks = []\n    // keep the first chunk around if we can to save allocations for future encodes\n    /** @type {Uint8Array|number[]|null} */\n    this._initReuseChunk = null\n  }\n\n  reset () {\n    this.cursor = 0\n    this.maxCursor = -1\n    if (this.chunks.length) {\n      this.chunks = []\n    }\n    if (this._initReuseChunk !== null) {\n      this.chunks.push(this._initReuseChunk)\n      this.maxCursor = this._initReuseChunk.length - 1\n    }\n  }\n\n  /**\n   * @param {Uint8Array|number[]} bytes\n   */\n  push (bytes) {\n    let topChunk = this.chunks[this.chunks.length - 1]\n    const newMax = this.cursor + bytes.length\n    if (newMax <= this.maxCursor + 1) {\n      // we have at least one chunk and we can fit these bytes into that chunk\n      const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1\n      // @ts-ignore\n      topChunk.set(bytes, chunkPos)\n    } else {\n      // can't fit it in\n      if (topChunk) {\n        // trip the last chunk to `cursor` if we need to\n        const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1\n        if (chunkPos < topChunk.length) {\n          // @ts-ignore\n          this.chunks[this.chunks.length - 1] = topChunk.subarray(0, chunkPos)\n          this.maxCursor = this.cursor - 1\n        }\n      }\n      if (bytes.length < 64 && bytes.length < this.chunkSize) {\n        // make a new chunk and copy the new one into it\n        topChunk = alloc(this.chunkSize)\n        this.chunks.push(topChunk)\n        this.maxCursor += topChunk.length\n        if (this._initReuseChunk === null) {\n          this._initReuseChunk = topChunk\n        }\n        // @ts-ignore\n        topChunk.set(bytes, 0)\n      } else {\n        // push the new bytes in as its own chunk\n        this.chunks.push(bytes)\n        this.maxCursor += bytes.length\n      }\n    }\n    this.cursor += bytes.length\n  }\n\n  /**\n   * @param {boolean} [reset]\n   * @returns {Uint8Array}\n   */\n  toBytes (reset = false) {\n    let byts\n    if (this.chunks.length === 1) {\n      const chunk = this.chunks[0]\n      if (reset && this.cursor > chunk.length / 2) {\n        /* c8 ignore next 2 */\n        // @ts-ignore\n        byts = this.cursor === chunk.length ? chunk : chunk.subarray(0, this.cursor)\n        this._initReuseChunk = null\n        this.chunks = []\n      } else {\n        // @ts-ignore\n        byts = slice(chunk, 0, this.cursor)\n      }\n    } else {\n      // @ts-ignore\n      byts = concat(this.chunks, this.cursor)\n    }\n    if (reset) {\n      this.reset()\n    }\n    return byts\n  }\n}\n","import * as API from '../../api.js'\nimport {\n  EXPANDED_BYTES_PER_QUAD,\n  EXPANDED_BYTES_PER_NODE,\n} from '../../constant.js'\nimport { log2Ceil, onesCount64 } from '../../uint64.js'\n\nexport { toExpanded as fromPadded, fromExpanded as toPadded } from './padded.js'\nexport { toExpanded as fromUnpadded } from './unpadded.js'\n\n/**\n * Validates that given `size` is a valid {@link API.PieceSize} that is a\n * power of 2. Returns {@link API.Result} with `PaddedPieceSize` ok case and an\n * Error in the error case.\n *\n * @see https://github.com/filecoin-project/go-state-types/blob/ff2ed169ff566458f2acd8b135d62e8ca27e7d0c/abi/piece.go#L18-L29\n *\n * @param {number|API.uint64} input\n * @returns {API.Result<API.PieceSize, RangeError>}\n */\nexport const tryFrom = (input) => {\n  const size = BigInt(input)\n  if (size < EXPANDED_BYTES_PER_QUAD) {\n    return {\n      error: RangeError(\n        `Minimum piece size is ${EXPANDED_BYTES_PER_QUAD} bytes`\n      ),\n    }\n  }\n\n  if (onesCount64(size) !== 1) {\n    return { error: RangeError('Piece size must be a power of 2') }\n  }\n\n  return { ok: size }\n}\n\n/**\n * Validates that given `size` is a valid {@link API.PieceSize} and\n * returns {@link API.PieceSize} capturing the validation at the type\n * level. If given `size` is not a valid `PaddedPieceSize` throws an error.\n *\n * This function is a variation on {@link validate} that throws exceptions\n * instead of returning a {@link API.Result}.\n *\n * @param {number|API.uint64} size\n */\nexport const from = (size) => {\n  const result = tryFrom(size)\n  if (result.error) {\n    throw result.error\n  } else {\n    return result.ok\n  }\n}\n\n/**\n * Calculates the {@link API.PieceSize} for the given height of the piece tree.\n *\n * @param {number} height\n * @returns {API.PieceSize}\n */\nexport const fromHeight = (height) => fromWidth(2n ** BigInt(height))\n\n/**\n * Calculates the height of the piece tree from unpadded size.\n *\n * @param {API.PieceSize} size\n */\nexport const toHeight = (size) => log2Ceil(toWidth(size))\n\n/**\n * Takes piece tree width (leaf count) and returns corresponding\n * {@link API.PieceSize}.\n *\n * @param {API.uint64} width\n * @returns {API.PieceSize}\n */\nexport const fromWidth = (width) => width * EXPANDED_BYTES_PER_NODE\n\n/**\n * Takes `{@link API.PaddedPieceSize}` and returns corresponding\n * piece tree width (leaf count).\n *\n * @param {API.PieceSize} size\n */\nexport const toWidth = (size) => size / EXPANDED_BYTES_PER_NODE\n","import type * as Errors from './Errors.js'\n\nconst bigIntSuffix = '#__bigint'\n\n/**\n * Parses a JSON string, with support for `bigint`.\n *\n * @example\n * ```ts twoslash\n * import { Json } from 'ox'\n *\n * const json = Json.parse('{\"foo\":\"bar\",\"baz\":\"69420694206942069420694206942069420694206942069420#__bigint\"}')\n * // @log: {\n * // @log:   foo: 'bar',\n * // @log:   baz: 69420694206942069420694206942069420694206942069420n\n * // @log: }\n * ```\n *\n * @param string - The value to parse.\n * @param reviver - A function that transforms the results.\n * @returns The parsed value.\n */\nexport function parse(\n  string: string,\n  reviver?: ((this: any, key: string, value: any) => any) | undefined,\n) {\n  return JSON.parse(string, (key, value_) => {\n    const value = value_\n    if (typeof value === 'string' && value.endsWith(bigIntSuffix))\n      return BigInt(value.slice(0, -bigIntSuffix.length))\n    return typeof reviver === 'function' ? reviver(key, value) : value\n  })\n}\n\nexport declare namespace parse {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Stringifies a value to its JSON representation, with support for `bigint`.\n *\n * @example\n * ```ts twoslash\n * import { Json } from 'ox'\n *\n * const json = Json.stringify({\n *   foo: 'bar',\n *   baz: 69420694206942069420694206942069420694206942069420n,\n * })\n * // @log: '{\"foo\":\"bar\",\"baz\":\"69420694206942069420694206942069420694206942069420#__bigint\"}'\n * ```\n *\n * @param value - The value to stringify.\n * @param replacer - A function that transforms the results. It is passed the key and value of the property, and must return the value to be used in the JSON string. If this function returns `undefined`, the property is not included in the resulting JSON string.\n * @param space - A string or number that determines the indentation of the JSON string. If it is a number, it indicates the number of spaces to use as indentation; if it is a string (e.g. `'\\t'`), it uses the string as the indentation character.\n * @returns The JSON string.\n */\nexport function stringify(\n  value: any,\n  replacer?: ((this: any, key: string, value: any) => any) | null | undefined,\n  space?: string | number | undefined,\n) {\n  return JSON.stringify(\n    value,\n    (key, value) => {\n      if (typeof replacer === 'function') return replacer(key, value)\n      if (typeof value === 'bigint') return value.toString() + bigIntSuffix\n      return value\n    },\n    space,\n  )\n}\n\nexport declare namespace stringify {\n  type ErrorType = Errors.GlobalErrorType\n}\n","import * as Bytes from './Bytes.js'\nimport * as Errors from './Errors.js'\nimport * as Hex from './Hex.js'\nimport type { Compute, ExactPartial } from './internal/types.js'\nimport * as Json from './Json.js'\n\n/** Root type for an ECDSA Public Key. */\nexport type PublicKey<\n  compressed extends boolean = false,\n  bigintType = bigint,\n  numberType = number,\n> = Compute<\n  compressed extends true\n    ? {\n        prefix: numberType\n        x: bigintType\n        y?: undefined\n      }\n    : {\n        prefix: numberType\n        x: bigintType\n        y: bigintType\n      }\n>\n\n/**\n * Asserts that a {@link ox#PublicKey.PublicKey} is valid.\n *\n * @example\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * PublicKey.assert({\n *   prefix: 4,\n *   y: 49782753348462494199823712700004552394425719014458918871452329774910450607807n,\n * })\n * // @error: PublicKey.InvalidError: Value \\`{\"y\":\"1\"}\\` is not a valid public key.\n * // @error: Public key must contain:\n * // @error: - an `x` and `prefix` value (compressed)\n * // @error: - an `x`, `y`, and `prefix` value (uncompressed)\n * ```\n *\n * @param publicKey - The public key object to assert.\n */\nexport function assert(\n  publicKey: ExactPartial<PublicKey>,\n  options: assert.Options = {},\n): asserts publicKey is PublicKey {\n  const { compressed } = options\n  const { prefix, x, y } = publicKey\n\n  // Uncompressed\n  if (\n    compressed === false ||\n    (typeof x === 'bigint' && typeof y === 'bigint')\n  ) {\n    if (prefix !== 4)\n      throw new InvalidPrefixError({\n        prefix,\n        cause: new InvalidUncompressedPrefixError(),\n      })\n    return\n  }\n\n  // Compressed\n  if (\n    compressed === true ||\n    (typeof x === 'bigint' && typeof y === 'undefined')\n  ) {\n    if (prefix !== 3 && prefix !== 2)\n      throw new InvalidPrefixError({\n        prefix,\n        cause: new InvalidCompressedPrefixError(),\n      })\n    return\n  }\n\n  // Unknown/invalid\n  throw new InvalidError({ publicKey })\n}\n\nexport declare namespace assert {\n  type Options = {\n    /** Whether or not the public key should be compressed. */\n    compressed?: boolean\n  }\n\n  type ErrorType = InvalidError | InvalidPrefixError | Errors.GlobalErrorType\n}\n\n/**\n * Compresses a {@link ox#PublicKey.PublicKey}.\n *\n * @example\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * const publicKey = PublicKey.from({\n *   prefix: 4,\n *   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n *   y: 24099691209996290925259367678540227198235484593389470330605641003500238088869n,\n * })\n *\n * const compressed = PublicKey.compress(publicKey) // [!code focus]\n * // @log: {\n * // @log:   prefix: 3,\n * // @log:   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n * // @log: }\n * ```\n *\n * @param publicKey - The public key to compress.\n * @returns The compressed public key.\n */\nexport function compress(publicKey: PublicKey<false>): PublicKey<true> {\n  const { x, y } = publicKey\n  return {\n    prefix: y % 2n === 0n ? 2 : 3,\n    x,\n  }\n}\n\nexport declare namespace compress {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Instantiates a typed {@link ox#PublicKey.PublicKey} object from a {@link ox#PublicKey.PublicKey}, {@link ox#Bytes.Bytes}, or {@link ox#Hex.Hex}.\n *\n * @example\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * const publicKey = PublicKey.from({\n *   prefix: 4,\n *   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n *   y: 24099691209996290925259367678540227198235484593389470330605641003500238088869n,\n * })\n * // @log: {\n * // @log:   prefix: 4,\n * // @log:   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n * // @log:   y: 24099691209996290925259367678540227198235484593389470330605641003500238088869n,\n * // @log: }\n * ```\n *\n * @example\n * ### From Serialized\n *\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * const publicKey = PublicKey.from('0x048318535b54105d4a7aae60c08fc45f9687181b4fdfc625bd1a753fa7397fed753547f11ca8696646f2f3acb08e31016afac23e630c5d11f59f61fef57b0d2aa5')\n * // @log: {\n * // @log:   prefix: 4,\n * // @log:   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n * // @log:   y: 24099691209996290925259367678540227198235484593389470330605641003500238088869n,\n * // @log: }\n * ```\n *\n * @param value - The public key value to instantiate.\n * @returns The instantiated {@link ox#PublicKey.PublicKey}.\n */\nexport function from<\n  const publicKey extends\n    | CompressedPublicKey\n    | UncompressedPublicKey\n    | Hex.Hex\n    | Bytes.Bytes,\n>(value: from.Value<publicKey>): from.ReturnType<publicKey> {\n  const publicKey = (() => {\n    if (Hex.validate(value)) return fromHex(value)\n    if (Bytes.validate(value)) return fromBytes(value)\n\n    const { prefix, x, y } = value\n    if (typeof x === 'bigint' && typeof y === 'bigint')\n      return { prefix: prefix ?? 0x04, x, y }\n    return { prefix, x }\n  })()\n\n  assert(publicKey)\n\n  return publicKey as never\n}\n\n/** @internal */\ntype CompressedPublicKey = PublicKey<true>\n\n/** @internal */\ntype UncompressedPublicKey = Omit<PublicKey<false>, 'prefix'> & {\n  prefix?: PublicKey['prefix'] | undefined\n}\n\nexport declare namespace from {\n  type Value<\n    publicKey extends\n      | CompressedPublicKey\n      | UncompressedPublicKey\n      | Hex.Hex\n      | Bytes.Bytes = PublicKey,\n  > = publicKey | CompressedPublicKey | UncompressedPublicKey\n\n  type ReturnType<\n    publicKey extends\n      | CompressedPublicKey\n      | UncompressedPublicKey\n      | Hex.Hex\n      | Bytes.Bytes = PublicKey,\n  > = publicKey extends CompressedPublicKey | UncompressedPublicKey\n    ? publicKey extends UncompressedPublicKey\n      ? Compute<publicKey & { readonly prefix: 0x04 }>\n      : publicKey\n    : PublicKey\n\n  type ErrorType = assert.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Deserializes a {@link ox#PublicKey.PublicKey} from a {@link ox#Bytes.Bytes} value.\n *\n * @example\n * ```ts twoslash\n * // @noErrors\n * import { PublicKey } from 'ox'\n *\n * const publicKey = PublicKey.fromBytes(new Uint8Array([128, 3, 131, ...]))\n * // @log: {\n * // @log:   prefix: 4,\n * // @log:   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n * // @log:   y: 24099691209996290925259367678540227198235484593389470330605641003500238088869n,\n * // @log: }\n * ```\n *\n * @param publicKey - The serialized public key.\n * @returns The deserialized public key.\n */\nexport function fromBytes(publicKey: Bytes.Bytes): PublicKey {\n  return fromHex(Hex.fromBytes(publicKey))\n}\n\nexport declare namespace fromBytes {\n  type ErrorType =\n    | fromHex.ErrorType\n    | Hex.fromBytes.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Deserializes a {@link ox#PublicKey.PublicKey} from a {@link ox#Hex.Hex} value.\n *\n * @example\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * const publicKey = PublicKey.fromHex('0x8318535b54105d4a7aae60c08fc45f9687181b4fdfc625bd1a753fa7397fed753547f11ca8696646f2f3acb08e31016afac23e630c5d11f59f61fef57b0d2aa5')\n * // @log: {\n * // @log:   prefix: 4,\n * // @log:   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n * // @log:   y: 24099691209996290925259367678540227198235484593389470330605641003500238088869n,\n * // @log: }\n * ```\n *\n * @example\n * ### Deserializing a Compressed Public Key\n *\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * const publicKey = PublicKey.fromHex('0x038318535b54105d4a7aae60c08fc45f9687181b4fdfc625bd1a753fa7397fed75')\n * // @log: {\n * // @log:   prefix: 3,\n * // @log:   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n * // @log: }\n * ```\n *\n * @param publicKey - The serialized public key.\n * @returns The deserialized public key.\n */\nexport function fromHex(publicKey: Hex.Hex): PublicKey {\n  if (\n    publicKey.length !== 132 &&\n    publicKey.length !== 130 &&\n    publicKey.length !== 68\n  )\n    throw new InvalidSerializedSizeError({ publicKey })\n\n  if (publicKey.length === 130) {\n    const x = BigInt(Hex.slice(publicKey, 0, 32))\n    const y = BigInt(Hex.slice(publicKey, 32, 64))\n    return {\n      prefix: 4,\n      x,\n      y,\n    } as never\n  }\n\n  if (publicKey.length === 132) {\n    const prefix = Number(Hex.slice(publicKey, 0, 1))\n    const x = BigInt(Hex.slice(publicKey, 1, 33))\n    const y = BigInt(Hex.slice(publicKey, 33, 65))\n    return {\n      prefix,\n      x,\n      y,\n    } as never\n  }\n\n  const prefix = Number(Hex.slice(publicKey, 0, 1))\n  const x = BigInt(Hex.slice(publicKey, 1, 33))\n  return {\n    prefix,\n    x,\n  } as never\n}\n\nexport declare namespace fromHex {\n  type ErrorType = Hex.slice.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Serializes a {@link ox#PublicKey.PublicKey} to {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * const publicKey = PublicKey.from({\n *   prefix: 4,\n *   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n *   y: 24099691209996290925259367678540227198235484593389470330605641003500238088869n,\n * })\n *\n * const bytes = PublicKey.toBytes(publicKey) // [!code focus]\n * // @log: Uint8Array [128, 3, 131, ...]\n * ```\n *\n * @param publicKey - The public key to serialize.\n * @returns The serialized public key.\n */\nexport function toBytes(\n  publicKey: PublicKey<boolean>,\n  options: toBytes.Options = {},\n): Bytes.Bytes {\n  return Bytes.fromHex(toHex(publicKey, options))\n}\n\nexport declare namespace toBytes {\n  type Options = {\n    /**\n     * Whether to include the prefix in the serialized public key.\n     * @default true\n     */\n    includePrefix?: boolean | undefined\n  }\n\n  type ErrorType =\n    | Hex.fromNumber.ErrorType\n    | Bytes.fromHex.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Serializes a {@link ox#PublicKey.PublicKey} to {@link ox#Hex.Hex}.\n *\n * @example\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * const publicKey = PublicKey.from({\n *   prefix: 4,\n *   x: 59295962801117472859457908919941473389380284132224861839820747729565200149877n,\n *   y: 24099691209996290925259367678540227198235484593389470330605641003500238088869n,\n * })\n *\n * const hex = PublicKey.toHex(publicKey) // [!code focus]\n * // @log: '0x048318535b54105d4a7aae60c08fc45f9687181b4fdfc625bd1a753fa7397fed753547f11ca8696646f2f3acb08e31016afac23e630c5d11f59f61fef57b0d2aa5'\n * ```\n *\n * @param publicKey - The public key to serialize.\n * @returns The serialized public key.\n */\nexport function toHex(\n  publicKey: PublicKey<boolean>,\n  options: toHex.Options = {},\n): Hex.Hex {\n  assert(publicKey)\n\n  const { prefix, x, y } = publicKey\n  const { includePrefix = true } = options\n\n  const publicKey_ = Hex.concat(\n    includePrefix ? Hex.fromNumber(prefix, { size: 1 }) : '0x',\n    Hex.fromNumber(x, { size: 32 }),\n    // If the public key is not compressed, add the y coordinate.\n    typeof y === 'bigint' ? Hex.fromNumber(y, { size: 32 }) : '0x',\n  )\n\n  return publicKey_\n}\n\nexport declare namespace toHex {\n  type Options = {\n    /**\n     * Whether to include the prefix in the serialized public key.\n     * @default true\n     */\n    includePrefix?: boolean | undefined\n  }\n\n  type ErrorType = Hex.fromNumber.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Validates a {@link ox#PublicKey.PublicKey}. Returns `true` if valid, `false` otherwise.\n *\n * @example\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * const valid = PublicKey.validate({\n *   prefix: 4,\n *   y: 49782753348462494199823712700004552394425719014458918871452329774910450607807n,\n * })\n * // @log: false\n * ```\n *\n * @param publicKey - The public key object to assert.\n */\nexport function validate(\n  publicKey: ExactPartial<PublicKey>,\n  options: validate.Options = {},\n): boolean {\n  try {\n    assert(publicKey, options)\n    return true\n  } catch (_error) {\n    return false\n  }\n}\n\nexport declare namespace validate {\n  type Options = {\n    /** Whether or not the public key should be compressed. */\n    compressed?: boolean\n  }\n\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Thrown when a public key is invalid.\n *\n * @example\n * ```ts twoslash\n * import { PublicKey } from 'ox'\n *\n * PublicKey.assert({ y: 1n })\n * // @error: PublicKey.InvalidError: Value `{\"y\":1n}` is not a valid public key.\n * // @error: Public key must contain:\n * // @error: - an `x` and `prefix` value (compressed)\n * // @error: - an `x`, `y`, and `prefix` value (uncompressed)\n * ```\n */\nexport class InvalidError extends Errors.BaseError {\n  override readonly name = 'PublicKey.InvalidError'\n\n  constructor({ publicKey }: { publicKey: unknown }) {\n    super(`Value \\`${Json.stringify(publicKey)}\\` is not a valid public key.`, {\n      metaMessages: [\n        'Public key must contain:',\n        '- an `x` and `prefix` value (compressed)',\n        '- an `x`, `y`, and `prefix` value (uncompressed)',\n      ],\n    })\n  }\n}\n\n/** Thrown when a public key has an invalid prefix. */\nexport class InvalidPrefixError<\n  cause extends InvalidCompressedPrefixError | InvalidUncompressedPrefixError =\n    | InvalidCompressedPrefixError\n    | InvalidUncompressedPrefixError,\n> extends Errors.BaseError<cause> {\n  override readonly name = 'PublicKey.InvalidPrefixError'\n\n  constructor({ prefix, cause }: { prefix: number | undefined; cause: cause }) {\n    super(`Prefix \"${prefix}\" is invalid.`, {\n      cause,\n    })\n  }\n}\n\n/** Thrown when the public key has an invalid prefix for a compressed public key. */\nexport class InvalidCompressedPrefixError extends Errors.BaseError {\n  override readonly name = 'PublicKey.InvalidCompressedPrefixError'\n\n  constructor() {\n    super('Prefix must be 2 or 3 for compressed public keys.')\n  }\n}\n\n/** Thrown when the public key has an invalid prefix for an uncompressed public key. */\nexport class InvalidUncompressedPrefixError extends Errors.BaseError {\n  override readonly name = 'PublicKey.InvalidUncompressedPrefixError'\n\n  constructor() {\n    super('Prefix must be 4 for uncompressed public keys.')\n  }\n}\n\n/** Thrown when the public key has an invalid serialized size. */\nexport class InvalidSerializedSizeError extends Errors.BaseError {\n  override readonly name = 'PublicKey.InvalidSerializedSizeError'\n\n  constructor({ publicKey }: { publicKey: Hex.Hex | Bytes.Bytes }) {\n    super(`Value \\`${publicKey}\\` is an invalid public key size.`, {\n      metaMessages: [\n        'Expected: 33 bytes (compressed + prefix), 64 bytes (uncompressed) or 65 bytes (uncompressed + prefix).',\n        `Received ${Hex.size(Hex.from(publicKey))} bytes.`,\n      ],\n    })\n  }\n}\n","import { equalBytes } from '@noble/curves/abstract/utils'\nimport * as Errors from './Errors.js'\nimport * as Hex from './Hex.js'\nimport * as internal from './internal/bytes.js'\nimport * as internal_hex from './internal/hex.js'\nimport * as Json from './Json.js'\n\nconst decoder = /*#__PURE__*/ new TextDecoder()\nconst encoder = /*#__PURE__*/ new TextEncoder()\n\n/** Root type for a Bytes array. */\nexport type Bytes = Uint8Array\n\n/**\n * Asserts if the given value is {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.assert('abc')\n * // @error: Bytes.InvalidBytesTypeError:\n * // @error: Value `\"abc\"` of type `string` is an invalid Bytes value.\n * // @error: Bytes values must be of type `Uint8Array`.\n * ```\n *\n * @param value - Value to assert.\n */\nexport function assert(value: unknown): asserts value is Bytes {\n  if (value instanceof Uint8Array) return\n  if (!value) throw new InvalidBytesTypeError(value)\n  if (typeof value !== 'object') throw new InvalidBytesTypeError(value)\n  if (!('BYTES_PER_ELEMENT' in value)) throw new InvalidBytesTypeError(value)\n  if (value.BYTES_PER_ELEMENT !== 1 || value.constructor.name !== 'Uint8Array')\n    throw new InvalidBytesTypeError(value)\n}\n\nexport declare namespace assert {\n  type ErrorType = InvalidBytesTypeError | Errors.GlobalErrorType\n}\n\n/**\n * Concatenates two or more {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const bytes = Bytes.concat(\n *   Bytes.from([1]),\n *   Bytes.from([69]),\n *   Bytes.from([420, 69]),\n * )\n * // @log: Uint8Array [ 1, 69, 420, 69 ]\n * ```\n *\n * @param values - Values to concatenate.\n * @returns Concatenated {@link ox#Bytes.Bytes}.\n */\nexport function concat(...values: readonly Bytes[]): Bytes {\n  let length = 0\n  for (const arr of values) {\n    length += arr.length\n  }\n  const result = new Uint8Array(length)\n  for (let i = 0, index = 0; i < values.length; i++) {\n    const arr = values[i]\n    result.set(arr!, index)\n    index += arr!.length\n  }\n  return result\n}\n\nexport declare namespace concat {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Instantiates a {@link ox#Bytes.Bytes} value from a `Uint8Array`, a hex string, or an array of unsigned 8-bit integers.\n *\n * :::tip\n *\n * To instantiate from a **Boolean**, **String**, or **Number**, use one of the following:\n *\n * - `Bytes.fromBoolean`\n *\n * - `Bytes.fromString`\n *\n * - `Bytes.fromNumber`\n *\n * :::\n *\n * @example\n * ```ts twoslash\n * // @noErrors\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.from([255, 124, 5, 4])\n * // @log: Uint8Array([255, 124, 5, 4])\n *\n * const data = Bytes.from('0xdeadbeef')\n * // @log: Uint8Array([222, 173, 190, 239])\n * ```\n *\n * @param value - Value to convert.\n * @returns A {@link ox#Bytes.Bytes} instance.\n */\nexport function from(value: Hex.Hex | Bytes | readonly number[]): Bytes {\n  if (value instanceof Uint8Array) return value\n  if (typeof value === 'string') return fromHex(value)\n  return fromArray(value)\n}\n\nexport declare namespace from {\n  type ErrorType =\n    | fromHex.ErrorType\n    | fromArray.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Converts an array of unsigned 8-bit integers into {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.fromArray([255, 124, 5, 4])\n * // @log: Uint8Array([255, 124, 5, 4])\n * ```\n *\n * @param value - Value to convert.\n * @returns A {@link ox#Bytes.Bytes} instance.\n */\nexport function fromArray(value: readonly number[] | Uint8Array): Bytes {\n  return value instanceof Uint8Array ? value : new Uint8Array(value)\n}\n\nexport declare namespace fromArray {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Encodes a boolean value into {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.fromBoolean(true)\n * // @log: Uint8Array([1])\n * ```\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.fromBoolean(true, { size: 32 })\n * // @log: Uint8Array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n * ```\n *\n * @param value - Boolean value to encode.\n * @param options - Encoding options.\n * @returns Encoded {@link ox#Bytes.Bytes}.\n */\nexport function fromBoolean(value: boolean, options: fromBoolean.Options = {}) {\n  const { size } = options\n  const bytes = new Uint8Array(1)\n  bytes[0] = Number(value)\n  if (typeof size === 'number') {\n    internal.assertSize(bytes, size)\n    return padLeft(bytes, size)\n  }\n  return bytes\n}\n\nexport declare namespace fromBoolean {\n  type Options = {\n    /** Size of the output bytes. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | internal.assertSize.ErrorType\n    | padLeft.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Encodes a {@link ox#Hex.Hex} value into {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.fromHex('0x48656c6c6f20776f726c6421')\n * // @log: Uint8Array([72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33])\n * ```\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.fromHex('0x48656c6c6f20776f726c6421', { size: 32 })\n * // @log: Uint8Array([72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n * ```\n *\n * @param value - {@link ox#Hex.Hex} value to encode.\n * @param options - Encoding options.\n * @returns Encoded {@link ox#Bytes.Bytes}.\n */\nexport function fromHex(value: Hex.Hex, options: fromHex.Options = {}): Bytes {\n  const { size } = options\n\n  let hex = value\n  if (size) {\n    internal_hex.assertSize(value, size)\n    hex = Hex.padRight(value, size)\n  }\n\n  let hexString = hex.slice(2) as string\n  if (hexString.length % 2) hexString = `0${hexString}`\n\n  const length = hexString.length / 2\n  const bytes = new Uint8Array(length)\n  for (let index = 0, j = 0; index < length; index++) {\n    const nibbleLeft = internal.charCodeToBase16(hexString.charCodeAt(j++))\n    const nibbleRight = internal.charCodeToBase16(hexString.charCodeAt(j++))\n    if (nibbleLeft === undefined || nibbleRight === undefined) {\n      throw new Errors.BaseError(\n        `Invalid byte sequence (\"${hexString[j - 2]}${hexString[j - 1]}\" in \"${hexString}\").`,\n      )\n    }\n    bytes[index] = (nibbleLeft << 4) | nibbleRight\n  }\n  return bytes\n}\n\nexport declare namespace fromHex {\n  type Options = {\n    /** Size of the output bytes. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | internal_hex.assertSize.ErrorType\n    | Hex.padRight.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Encodes a number value into {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.fromNumber(420)\n * // @log: Uint8Array([1, 164])\n * ```\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.fromNumber(420, { size: 4 })\n * // @log: Uint8Array([0, 0, 1, 164])\n * ```\n *\n * @param value - Number value to encode.\n * @param options - Encoding options.\n * @returns Encoded {@link ox#Bytes.Bytes}.\n */\nexport function fromNumber(\n  value: bigint | number,\n  options?: fromNumber.Options | undefined,\n) {\n  const hex = Hex.fromNumber(value, options)\n  return fromHex(hex)\n}\n\nexport declare namespace fromNumber {\n  export type Options = Hex.fromNumber.Options\n\n  export type ErrorType =\n    | Hex.fromNumber.ErrorType\n    | fromHex.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Encodes a string into {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.fromString('Hello world!')\n * // @log: Uint8Array([72, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100, 33])\n * ```\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.fromString('Hello world!', { size: 32 })\n * // @log: Uint8Array([72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n * ```\n *\n * @param value - String to encode.\n * @param options - Encoding options.\n * @returns Encoded {@link ox#Bytes.Bytes}.\n */\nexport function fromString(\n  value: string,\n  options: fromString.Options = {},\n): Bytes {\n  const { size } = options\n\n  const bytes = encoder.encode(value)\n  if (typeof size === 'number') {\n    internal.assertSize(bytes, size)\n    return padRight(bytes, size)\n  }\n  return bytes\n}\n\nexport declare namespace fromString {\n  type Options = {\n    /** Size of the output bytes. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | internal.assertSize.ErrorType\n    | padRight.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Checks if two {@link ox#Bytes.Bytes} values are equal.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.isEqual(Bytes.from([1]), Bytes.from([1]))\n * // @log: true\n *\n * Bytes.isEqual(Bytes.from([1]), Bytes.from([2]))\n * // @log: false\n * ```\n *\n * @param bytesA - First {@link ox#Bytes.Bytes} value.\n * @param bytesB - Second {@link ox#Bytes.Bytes} value.\n * @returns `true` if the two values are equal, otherwise `false`.\n */\nexport function isEqual(bytesA: Bytes, bytesB: Bytes) {\n  return equalBytes(bytesA, bytesB)\n}\n\nexport declare namespace isEqual {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Pads a {@link ox#Bytes.Bytes} value to the left with zero bytes until it reaches the given `size` (default: 32 bytes).\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.padLeft(Bytes.from([1]), 4)\n * // @log: Uint8Array([0, 0, 0, 1])\n * ```\n *\n * @param value - {@link ox#Bytes.Bytes} value to pad.\n * @param size - Size to pad the {@link ox#Bytes.Bytes} value to.\n * @returns Padded {@link ox#Bytes.Bytes} value.\n */\nexport function padLeft(\n  value: Bytes,\n  size?: number | undefined,\n): padLeft.ReturnType {\n  return internal.pad(value, { dir: 'left', size })\n}\n\nexport declare namespace padLeft {\n  type ReturnType = internal.pad.ReturnType\n  type ErrorType = internal.pad.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Pads a {@link ox#Bytes.Bytes} value to the right with zero bytes until it reaches the given `size` (default: 32 bytes).\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.padRight(Bytes.from([1]), 4)\n * // @log: Uint8Array([1, 0, 0, 0])\n * ```\n *\n * @param value - {@link ox#Bytes.Bytes} value to pad.\n * @param size - Size to pad the {@link ox#Bytes.Bytes} value to.\n * @returns Padded {@link ox#Bytes.Bytes} value.\n */\nexport function padRight(\n  value: Bytes,\n  size?: number | undefined,\n): padRight.ReturnType {\n  return internal.pad(value, { dir: 'right', size })\n}\n\nexport declare namespace padRight {\n  type ReturnType = internal.pad.ReturnType\n  type ErrorType = internal.pad.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Generates random {@link ox#Bytes.Bytes} of the specified length.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const bytes = Bytes.random(32)\n * // @log: Uint8Array([... x32])\n * ```\n *\n * @param length - Length of the random {@link ox#Bytes.Bytes} to generate.\n * @returns Random {@link ox#Bytes.Bytes} of the specified length.\n */\nexport function random(length: number): Bytes {\n  return crypto.getRandomValues(new Uint8Array(length))\n}\n\nexport declare namespace random {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Retrieves the size of a {@link ox#Bytes.Bytes} value.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.size(Bytes.from([1, 2, 3, 4]))\n * // @log: 4\n * ```\n *\n * @param value - {@link ox#Bytes.Bytes} value.\n * @returns Size of the {@link ox#Bytes.Bytes} value.\n */\nexport function size(value: Bytes): number {\n  return value.length\n}\n\nexport declare namespace size {\n  export type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Returns a section of a {@link ox#Bytes.Bytes} value given a start/end bytes offset.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.slice(\n *   Bytes.from([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n *   1,\n *   4,\n * )\n * // @log: Uint8Array([2, 3, 4])\n * ```\n *\n * @param value - The {@link ox#Bytes.Bytes} value.\n * @param start - Start offset.\n * @param end - End offset.\n * @param options - Slice options.\n * @returns Sliced {@link ox#Bytes.Bytes} value.\n */\nexport function slice(\n  value: Bytes,\n  start?: number | undefined,\n  end?: number | undefined,\n  options: slice.Options = {},\n): Bytes {\n  const { strict } = options\n  internal.assertStartOffset(value, start)\n  const value_ = value.slice(start, end)\n  if (strict) internal.assertEndOffset(value_, start, end)\n  return value_\n}\n\nexport declare namespace slice {\n  type Options = {\n    /** Asserts that the sliced value is the same size as the given start/end offsets. */\n    strict?: boolean | undefined\n  }\n\n  export type ErrorType =\n    | internal.assertStartOffset.ErrorType\n    | internal.assertEndOffset.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Decodes a {@link ox#Bytes.Bytes} into a bigint.\n *\n * @example\n * ```ts\n * import { Bytes } from 'ox'\n *\n * Bytes.toBigInt(Bytes.from([1, 164]))\n * // @log: 420n\n * ```\n *\n * @param bytes - The {@link ox#Bytes.Bytes} to decode.\n * @param options - Decoding options.\n * @returns Decoded bigint.\n */\nexport function toBigInt(bytes: Bytes, options: toBigInt.Options = {}): bigint {\n  const { size } = options\n  if (typeof size !== 'undefined') internal.assertSize(bytes, size)\n  const hex = Hex.fromBytes(bytes, options)\n  return Hex.toBigInt(hex, options)\n}\n\nexport declare namespace toBigInt {\n  type Options = {\n    /** Whether or not the number of a signed representation. */\n    signed?: boolean | undefined\n    /** Size of the bytes. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | Hex.fromBytes.ErrorType\n    | Hex.toBigInt.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Decodes a {@link ox#Bytes.Bytes} into a boolean.\n *\n * @example\n * ```ts\n * import { Bytes } from 'ox'\n *\n * Bytes.toBoolean(Bytes.from([1]))\n * // @log: true\n * ```\n *\n * @param bytes - The {@link ox#Bytes.Bytes} to decode.\n * @param options - Decoding options.\n * @returns Decoded boolean.\n */\nexport function toBoolean(\n  bytes: Bytes,\n  options: toBoolean.Options = {},\n): boolean {\n  const { size } = options\n  let bytes_ = bytes\n  if (typeof size !== 'undefined') {\n    internal.assertSize(bytes_, size)\n    bytes_ = trimLeft(bytes_)\n  }\n  if (bytes_.length > 1 || bytes_[0]! > 1)\n    throw new InvalidBytesBooleanError(bytes_)\n  return Boolean(bytes_[0])\n}\n\nexport declare namespace toBoolean {\n  type Options = {\n    /** Size of the bytes. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | internal.assertSize.ErrorType\n    | trimLeft.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Encodes a {@link ox#Bytes.Bytes} value into a {@link ox#Hex.Hex} value.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.toHex(Bytes.from([72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33]))\n * // '0x48656c6c6f20576f726c6421'\n * ```\n *\n * @param value - The {@link ox#Bytes.Bytes} to decode.\n * @param options - Options.\n * @returns Decoded {@link ox#Hex.Hex} value.\n */\nexport function toHex(value: Bytes, options: toHex.Options = {}): Hex.Hex {\n  return Hex.fromBytes(value, options)\n}\n\nexport declare namespace toHex {\n  type Options = {\n    /** Size of the bytes. */\n    size?: number | undefined\n  }\n\n  type ErrorType = Hex.fromBytes.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Decodes a {@link ox#Bytes.Bytes} into a number.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.toNumber(Bytes.from([1, 164]))\n * // @log: 420\n * ```\n */\nexport function toNumber(bytes: Bytes, options: toNumber.Options = {}): number {\n  const { size } = options\n  if (typeof size !== 'undefined') internal.assertSize(bytes, size)\n  const hex = Hex.fromBytes(bytes, options)\n  return Hex.toNumber(hex, options)\n}\n\nexport declare namespace toNumber {\n  type Options = {\n    /** Whether or not the number of a signed representation. */\n    signed?: boolean | undefined\n    /** Size of the bytes. */\n    size?: number | undefined\n  }\n\n  type ErrorType =\n    | Hex.fromBytes.ErrorType\n    | Hex.toNumber.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Decodes a {@link ox#Bytes.Bytes} into a string.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * const data = Bytes.toString(Bytes.from([72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33]))\n * // @log: 'Hello world'\n * ```\n *\n * @param bytes - The {@link ox#Bytes.Bytes} to decode.\n * @param options - Options.\n * @returns Decoded string.\n */\nexport function toString(bytes: Bytes, options: toString.Options = {}): string {\n  const { size } = options\n\n  let bytes_ = bytes\n  if (typeof size !== 'undefined') {\n    internal.assertSize(bytes_, size)\n    bytes_ = trimRight(bytes_)\n  }\n  return decoder.decode(bytes_)\n}\n\nexport declare namespace toString {\n  export type Options = {\n    /** Size of the bytes. */\n    size?: number | undefined\n  }\n\n  export type ErrorType =\n    | internal.assertSize.ErrorType\n    | trimRight.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Trims leading zeros from a {@link ox#Bytes.Bytes} value.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.trimLeft(Bytes.from([0, 0, 0, 0, 1, 2, 3]))\n * // @log: Uint8Array([1, 2, 3])\n * ```\n *\n * @param value - {@link ox#Bytes.Bytes} value.\n * @returns Trimmed {@link ox#Bytes.Bytes} value.\n */\nexport function trimLeft(value: Bytes): Bytes {\n  return internal.trim(value, { dir: 'left' })\n}\n\nexport declare namespace trimLeft {\n  type ErrorType = internal.trim.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Trims trailing zeros from a {@link ox#Bytes.Bytes} value.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.trimRight(Bytes.from([1, 2, 3, 0, 0, 0, 0]))\n * // @log: Uint8Array([1, 2, 3])\n * ```\n *\n * @param value - {@link ox#Bytes.Bytes} value.\n * @returns Trimmed {@link ox#Bytes.Bytes} value.\n */\nexport function trimRight(value: Bytes): Bytes {\n  return internal.trim(value, { dir: 'right' })\n}\n\nexport declare namespace trimRight {\n  export type ErrorType = internal.trim.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Checks if the given value is {@link ox#Bytes.Bytes}.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.validate('0x')\n * // @log: false\n *\n * Bytes.validate(Bytes.from([1, 2, 3]))\n * // @log: true\n * ```\n *\n * @param value - Value to check.\n * @returns `true` if the value is {@link ox#Bytes.Bytes}, otherwise `false`.\n */\nexport function validate(value: unknown): value is Bytes {\n  try {\n    assert(value)\n    return true\n  } catch {\n    return false\n  }\n}\n\nexport declare namespace validate {\n  export type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Thrown when the bytes value cannot be represented as a boolean.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.toBoolean(Bytes.from([5]))\n * // @error: Bytes.InvalidBytesBooleanError: Bytes value `[5]` is not a valid boolean.\n * // @error: The bytes array must contain a single byte of either a `0` or `1` value.\n * ```\n */\nexport class InvalidBytesBooleanError extends Errors.BaseError {\n  override readonly name = 'Bytes.InvalidBytesBooleanError'\n\n  constructor(bytes: Bytes) {\n    super(`Bytes value \\`${bytes}\\` is not a valid boolean.`, {\n      metaMessages: [\n        'The bytes array must contain a single byte of either a `0` or `1` value.',\n      ],\n    })\n  }\n}\n\n/**\n * Thrown when a value cannot be converted to bytes.\n *\n * @example\n * ```ts twoslash\n * // @noErrors\n * import { Bytes } from 'ox'\n *\n * Bytes.from('foo')\n * // @error: Bytes.InvalidBytesTypeError: Value `foo` of type `string` is an invalid Bytes value.\n * ```\n */\nexport class InvalidBytesTypeError extends Errors.BaseError {\n  override readonly name = 'Bytes.InvalidBytesTypeError'\n\n  constructor(value: unknown) {\n    super(\n      `Value \\`${typeof value === 'object' ? Json.stringify(value) : value}\\` of type \\`${typeof value}\\` is an invalid Bytes value.`,\n      {\n        metaMessages: ['Bytes values must be of type `Bytes`.'],\n      },\n    )\n  }\n}\n\n/**\n * Thrown when a size exceeds the maximum allowed size.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.fromString('Hello World!', { size: 8 })\n * // @error: Bytes.SizeOverflowError: Size cannot exceed `8` bytes. Given size: `12` bytes.\n * ```\n */\nexport class SizeOverflowError extends Errors.BaseError {\n  override readonly name = 'Bytes.SizeOverflowError'\n\n  constructor({ givenSize, maxSize }: { givenSize: number; maxSize: number }) {\n    super(\n      `Size cannot exceed \\`${maxSize}\\` bytes. Given size: \\`${givenSize}\\` bytes.`,\n    )\n  }\n}\n\n/**\n * Thrown when a slice offset is out-of-bounds.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.slice(Bytes.from([1, 2, 3]), 4)\n * // @error: Bytes.SliceOffsetOutOfBoundsError: Slice starting at offset `4` is out-of-bounds (size: `3`).\n * ```\n */\nexport class SliceOffsetOutOfBoundsError extends Errors.BaseError {\n  override readonly name = 'Bytes.SliceOffsetOutOfBoundsError'\n\n  constructor({\n    offset,\n    position,\n    size,\n  }: { offset: number; position: 'start' | 'end'; size: number }) {\n    super(\n      `Slice ${\n        position === 'start' ? 'starting' : 'ending'\n      } at offset \\`${offset}\\` is out-of-bounds (size: \\`${size}\\`).`,\n    )\n  }\n}\n\n/**\n * Thrown when a the padding size exceeds the maximum allowed size.\n *\n * @example\n * ```ts twoslash\n * import { Bytes } from 'ox'\n *\n * Bytes.padLeft(Bytes.fromString('Hello World!'), 8)\n * // @error: [Bytes.SizeExceedsPaddingSizeError: Bytes size (`12`) exceeds padding size (`8`).\n * ```\n */\nexport class SizeExceedsPaddingSizeError extends Errors.BaseError {\n  override readonly name = 'Bytes.SizeExceedsPaddingSizeError'\n\n  constructor({\n    size,\n    targetSize,\n    type,\n  }: {\n    size: number\n    targetSize: number\n    type: 'Hex' | 'Bytes'\n  }) {\n    super(\n      `${type.charAt(0).toUpperCase()}${type\n        .slice(1)\n        .toLowerCase()} size (\\`${size}\\`) exceeds padding size (\\`${targetSize}\\`).`,\n    )\n  }\n}\n","/**\n * Constants for the Synapse SDK\n */\n\nimport * as Abis from '@filoz/synapse-core/abis'\nimport { MAX_UPLOAD_SIZE as CORE_MAX_UPLOAD_SIZE } from '@filoz/synapse-core/piece'\nimport { erc20Abi, multicall3Abi } from 'viem'\nimport type { FilecoinNetworkType } from '../types.ts'\n\n/**\n * Token identifiers\n */\nexport const TOKENS = {\n  USDFC: 'USDFC' as const,\n  FIL: 'FIL' as const,\n} as const\n\n/**\n * Network chain IDs\n */\nexport const CHAIN_IDS: Record<FilecoinNetworkType, number> = {\n  mainnet: 314,\n  calibration: 314159,\n} as const\n\n/**\n * Contract ABIs\n */\nexport const CONTRACT_ABIS = {\n  /**\n   * ERC20 ABI - minimal interface needed for balance and approval operations\n   */\n  ERC20: erc20Abi,\n\n  /**\n   * Minimal ERC20Permit ABI - for reading nonces() and version()\n   */\n  ERC20_PERMIT: Abis.erc20WithPermit,\n\n  /**\n   * Payments contract ABI - based on fws-payments contract\n   */\n  PAYMENTS: Abis.payments,\n\n  /**\n   * PDPVerifier contract ABI - core PDP verification functions\n   */\n  PDP_VERIFIER: Abis.pdp,\n\n  /**\n   * Warm Storage ABI - write functions and service provider management\n   * View methods are in the WARM_STORAGE_VIEW contract\n   */\n  WARM_STORAGE: Abis.storage,\n\n  /**\n   * Warm Storage View contract ABI - read-only view methods separated from main contract\n   * These methods were moved from the main Warm Storage contract to reduce contract size\n   */\n  WARM_STORAGE_VIEW: Abis.storageView,\n\n  /**\n   * Multicall3 ABI - for batching multiple contract calls into a single RPC request\n   */\n  MULTICALL3: multicall3Abi,\n\n  /**\n   * ServiceProviderRegistry ABI - for provider management\n   */\n  SERVICE_PROVIDER_REGISTRY: Abis.serviceProviderRegistry,\n\n  /**\n   * SessionKeyRegistry ABI - for session key management\n   */\n  SESSION_KEY_REGISTRY: Abis.sessionKeyRegistry,\n} as const\n\n/**\n * EIP-2612 typed data schema (Permit)\n */\nexport const EIP2612_PERMIT_TYPES: Record<string, { name: string; type: string }[]> = {\n  Permit: [\n    { name: 'owner', type: 'address' },\n    { name: 'spender', type: 'address' },\n    { name: 'value', type: 'uint256' },\n    { name: 'nonce', type: 'uint256' },\n    { name: 'deadline', type: 'uint256' },\n  ],\n}\n\n/**\n * Time and size constants\n */\nexport const TIME_CONSTANTS = {\n  /**\n   * Duration of each epoch in seconds on Filecoin\n   */\n  EPOCH_DURATION: 30,\n\n  /**\n   * Number of epochs in a day (24 hours * 60 minutes * 2 epochs per minute)\n   */\n  EPOCHS_PER_DAY: 2880n,\n\n  /**\n   * Number of epochs in a month (30 days)\n   */\n  EPOCHS_PER_MONTH: 86400n, // 30 * 2880\n\n  /**\n   * Number of days in a month (used for pricing calculations)\n   */\n  DAYS_PER_MONTH: 30n,\n\n  /**\n   * Default lockup period in days\n   */\n  DEFAULT_LOCKUP_DAYS: 30n,\n} as const\n\n/**\n * Genesis timestamps for Filecoin networks (Unix timestamp in seconds)\n */\nexport const GENESIS_TIMESTAMPS: Record<FilecoinNetworkType, number> = {\n  /**\n   * Mainnet genesis: August 24, 2020 22:00:00 UTC\n   */\n  mainnet: 1598306400,\n  /**\n   * Calibration testnet genesis: November 1, 2022 18:13:00 UTC\n   */\n  calibration: 1667326380,\n} as const\n\n/**\n * Data size constants\n */\nexport const SIZE_CONSTANTS = {\n  /**\n   * Bytes in 1 KiB\n   */\n  KiB: 1024n,\n\n  /**\n   * Bytes in 1 MiB\n   */\n  MiB: 1n << 20n,\n\n  /**\n   * Bytes in 1 GiB\n   */\n  GiB: 1n << 30n,\n\n  /**\n   * Bytes in 1 TiB\n   */\n  TiB: 1n << 40n,\n\n  /**\n   * Bytes in 1 PiB\n   */\n  PiB: 1n << 50n,\n\n  /**\n   * Maximum upload size supported by Curio PDP servers: 1 GiB adjusted for fr32 expansion.\n   *\n   * 1 GiB * (127/128) = 1,065,353,216 bytes\n   *\n   * Fr32 encoding adds 2 bits of padding per 254 bits of data, resulting in 128 bytes\n   * of padded data for every 127 bytes of raw data.\n   *\n   * Note: While it's technically possible to upload pieces this large as Uint8Array\n   * (even in browsers), streaming via AsyncIterable is strongly recommended for\n   * non-trivial sizes. In-memory operations with large byte arrays can:\n   * - Cause memory pressure and garbage collection issues\n   * - Block the JavaScript event loop during allocation/copying\n   * - Trigger browser tab slowdowns or \"unresponsive script\" warnings\n   *\n   * For optimal performance and resource utilization, prefer streaming for pieces\n   * larger than a few megabytes, especially in browser environments.\n   *\n   * Imported from @filoz/synapse-core/piece\n   */\n  MAX_UPLOAD_SIZE: CORE_MAX_UPLOAD_SIZE,\n\n  /**\n   * Minimum upload size (127 bytes)\n   * PieceCIDv2 calculation requires at least 127 bytes payload\n   */\n  MIN_UPLOAD_SIZE: 127,\n\n  /**\n   * Default number of uploads to batch together in a single addPieces transaction\n   * This balances gas efficiency with reasonable transaction sizes\n   */\n  DEFAULT_UPLOAD_BATCH_SIZE: 32,\n} as const\n\n/**\n * Common metadata keys\n */\nexport const METADATA_KEYS = {\n  /**\n   * Key used to request that CDN services should be enabled for a data set. The presence of this\n   * key does not strictly guarantee that CDN services will be provided, but the Warm Storage\n   * contract will attempt to enable payment for CDN services if this key is present.\n   *\n   * The value for this key is always an empty string.\n   *\n   * Only valid for *data set* metadata.\n   */\n  WITH_CDN: 'withCDN',\n\n  /**\n   * Key used to request that a PDP server perform IPFS indexing and announcing to IPNI should be\n   * enabled for all pieces in a data set. The contents of the associated data sets are assumed to\n   * be indexable (i.e. a CAR or a PoDSI container) and the PDP server will be requested to perform\n   * best-effort indexing. The presence of this key does not guarantee that indexing will be\n   * performed or succeed.\n   *\n   * The value for this key is always an empty string.\n   *\n   * Only valid for *data set* metadata.\n   */\n  WITH_IPFS_INDEXING: 'withIPFSIndexing',\n\n  /**\n   * Key used to indicate a root CID of an IPLD DAG contained within the associated piece.\n   * Advisory only: do not treat as proof that the CID is valid, that IPLD blocks are present, or\n   * that the referenced DAG is fully present or retrievable. Intended as a secondary identifier\n   * provided by the data producer; not interpreted by contracts.\n   *\n   * The value for this key should be a valid CID string.\n   *\n   * Only valid for *piece* metadata.\n   */\n  IPFS_ROOT_CID: 'ipfsRootCID',\n} as const\n\n/**\n * Timing constants for blockchain operations\n */\nexport const TIMING_CONSTANTS = {\n  /**\n   * How long to wait for a transaction to appear on the network\n   * This is used when we have a transaction hash but need to fetch the transaction object\n   * Filecoin has 30-second epochs, so this gives six full epochs for propagation\n   * Matches viem's standard timeout for transaction receipt (180s)\n   */\n  TRANSACTION_PROPAGATION_TIMEOUT_MS: 180000, // 180 seconds (3 minutes, 6 epochs)\n\n  /**\n   * How often to poll when waiting for a transaction to appear\n   */\n  TRANSACTION_PROPAGATION_POLL_INTERVAL_MS: 2000, // 2 seconds\n\n  /**\n   * Maximum time to wait for a data set creation to complete\n   * This includes transaction mining and the data set becoming live on-chain\n   */\n  DATA_SET_CREATION_TIMEOUT_MS: 7 * 60 * 1000, // 7 minutes\n\n  /**\n   * How often to poll for data set creation status\n   */\n  DATA_SET_CREATION_POLL_INTERVAL_MS: 2000, // 2 seconds\n\n  /**\n   * Maximum time to wait for a piece to be parked (uploaded) to storage\n   * This is typically slower than blockchain operations as it involves data transfer\n   */\n  PIECE_PARKING_TIMEOUT_MS: 7 * 60 * 1000, // 7 minutes\n\n  /**\n   * How often to poll for piece parking status\n   * Less frequent than blockchain polling as uploads take longer\n   */\n  PIECE_PARKING_POLL_INTERVAL_MS: 5000, // 5 seconds\n\n  /**\n   * Number of confirmations to wait for when calling transaction.wait()\n   * Set to 1 by default to ensure the transaction is mined, could be increased\n   * in the future, or aligned to F3 expectations\n   */\n  TRANSACTION_CONFIRMATIONS: 1,\n\n  /**\n   * Default expiry time for EIP-2612 permit signatures (in seconds)\n   * Permits are time-limited approvals that expire after this duration\n   */\n  PERMIT_DEADLINE_DURATION: 3600, // 1 hour\n\n  /**\n   * Maximum time to wait for a piece addition to be confirmed and acknowledged\n   * This includes transaction confirmation and server verification\n   */\n  PIECE_ADDITION_TIMEOUT_MS: 7 * 60 * 1000, // 7 minutes\n\n  /**\n   * How often to poll for piece addition status\n   */\n  PIECE_ADDITION_POLL_INTERVAL_MS: 1000, // 1 second\n} as const\n\n/**\n * Settlement fee required for rail settlement operations\n * This is the NETWORK_FEE constant in the Payments contract that gets burned to the Filecoin network\n * Value: 0.0013 FIL (1300000000000000 attoFIL)\n *\n * IMPORTANT: This value must be kept in sync with the Payments contract's NETWORK_FEE constant.\n * If the contract is upgraded with a different fee, this constant must be updated accordingly.\n */\nexport const SETTLEMENT_FEE = 1300000000000000n // 0.0013 FIL in attoFIL\n\n/**\n * Recommended RPC endpoints for Filecoin networks\n */\nexport const RPC_URLS: Record<FilecoinNetworkType, { http: string; websocket: string }> = {\n  mainnet: {\n    http: 'https://api.node.glif.io/rpc/v1',\n    websocket: 'wss://wss.node.glif.io/apigw/lotus/rpc/v1',\n  },\n  calibration: {\n    http: 'https://api.calibration.node.glif.io/rpc/v1',\n    websocket: 'wss://wss.calibration.node.glif.io/apigw/lotus/rpc/v1',\n  },\n} as const\n\n/**\n * Contract addresses\n */\nexport const CONTRACT_ADDRESSES = {\n  /**\n   * Warm Storage service contract addresses - the only address needed for SDK initialization\n   * All other contract addresses are discovered from this contract\n   */\n  WARM_STORAGE: {\n    mainnet: '0x8408502033C418E1bbC97cE9ac48E5528F371A9f',\n    calibration: '0x02925630df557F957f70E112bA06e50965417CA0',\n  } as const satisfies Record<FilecoinNetworkType, string>,\n\n  /**\n   * Multicall3 contract addresses - used for batching multiple contract calls\n   * Same address across most EVM chains including Filecoin\n   */\n  MULTICALL3: {\n    mainnet: '0xcA11bde05977b3631167028862bE2a173976CA11',\n    calibration: '0xcA11bde05977b3631167028862bE2a173976CA11',\n  } as const satisfies Record<FilecoinNetworkType, string>,\n\n  USDFC: {\n    mainnet: '0x80B98d3aa09ffff255c3ba4A241111Ff1262F045',\n    calibration: '0xb3042734b608a1B16e9e86B374A3f3e389B4cDf0',\n  } as const satisfies Record<FilecoinNetworkType, string>,\n} as const\n","import type { Address as abitype_Address } from 'abitype'\nimport * as Bytes from './Bytes.js'\nimport * as Caches from './Caches.js'\nimport * as Errors from './Errors.js'\nimport * as Hash from './Hash.js'\nimport * as PublicKey from './PublicKey.js'\n\nconst addressRegex = /^0x[a-fA-F0-9]{40}$/\n\n/** Root type for Address. */\nexport type Address = abitype_Address\n\n/**\n * Asserts that the given value is a valid {@link ox#Address.Address}.\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.assert('0xA0Cf798816D4b9b9866b5330EEa46a18382f251e')\n * ```\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.assert('0xdeadbeef')\n * // @error: InvalidAddressError: Address \"0xdeadbeef\" is invalid.\n * ```\n *\n * @param value - Value to assert if it is a valid address.\n * @param options - Assertion options.\n */\nexport function assert(\n  value: string,\n  options: assert.Options = {},\n): asserts value is Address {\n  const { strict = true } = options\n\n  if (!addressRegex.test(value))\n    throw new InvalidAddressError({\n      address: value,\n      cause: new InvalidInputError(),\n    })\n\n  if (strict) {\n    if (value.toLowerCase() === value) return\n    if (checksum(value as Address) !== value)\n      throw new InvalidAddressError({\n        address: value,\n        cause: new InvalidChecksumError(),\n      })\n  }\n}\n\nexport declare namespace assert {\n  type Options = {\n    /**\n     * Enables strict mode. Whether or not to compare the address against its checksum.\n     *\n     * @default true\n     */\n    strict?: boolean | undefined\n  }\n\n  type ErrorType = InvalidAddressError | Errors.GlobalErrorType\n}\n\n/**\n * Computes the checksum address for the given {@link ox#Address.Address}.\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.checksum('0xa0cf798816d4b9b9866b5330eea46a18382f251e')\n * // @log: '0xA0Cf798816D4b9b9866b5330EEa46a18382f251e'\n * ```\n *\n * @param address - The address to compute the checksum for.\n * @returns The checksummed address.\n */\nexport function checksum(address: string): Address {\n  if (Caches.checksum.has(address)) return Caches.checksum.get(address)!\n\n  assert(address, { strict: false })\n\n  const hexAddress = address.substring(2).toLowerCase()\n  const hash = Hash.keccak256(Bytes.fromString(hexAddress), { as: 'Bytes' })\n\n  const characters = hexAddress.split('')\n  for (let i = 0; i < 40; i += 2) {\n    if (hash[i >> 1]! >> 4 >= 8 && characters[i]) {\n      characters[i] = characters[i]!.toUpperCase()\n    }\n    if ((hash[i >> 1]! & 0x0f) >= 8 && characters[i + 1]) {\n      characters[i + 1] = characters[i + 1]!.toUpperCase()\n    }\n  }\n\n  const result = `0x${characters.join('')}` as const\n  Caches.checksum.set(address, result)\n  return result\n}\n\nexport declare namespace checksum {\n  type ErrorType =\n    | assert.ErrorType\n    | Hash.keccak256.ErrorType\n    | Bytes.fromString.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Converts a stringified address to a typed (optionally checksummed) {@link ox#Address.Address}.\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.from('0xa0cf798816d4b9b9866b5330eea46a18382f251e')\n * // @log: '0xa0cf798816d4b9b9866b5330eea46a18382f251e'\n * ```\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.from('0xa0cf798816d4b9b9866b5330eea46a18382f251e', {\n *   checksum: true\n * })\n * // @log: '0xA0Cf798816D4b9b9866b5330EEa46a18382f251e'\n * ```\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.from('hello')\n * // @error: InvalidAddressError: Address \"0xa\" is invalid.\n * ```\n *\n * @param address - An address string to convert to a typed Address.\n * @param options - Conversion options.\n * @returns The typed Address.\n */\nexport function from(address: string, options: from.Options = {}): Address {\n  const { checksum: checksumVal = false } = options\n  assert(address)\n  if (checksumVal) return checksum(address)\n  return address as Address\n}\n\nexport declare namespace from {\n  type Options = {\n    /**\n     * Whether to checksum the address.\n     *\n     * @default false\n     */\n    checksum?: boolean | undefined\n  }\n\n  type ErrorType =\n    | assert.ErrorType\n    | checksum.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Converts an ECDSA public key to an {@link ox#Address.Address}.\n *\n * @example\n * ```ts twoslash\n * import { Address, PublicKey } from 'ox'\n *\n * const publicKey = PublicKey.from(\n *   '0x048318535b54105d4a7aae60c08fc45f9687181b4fdfc625bd1a753fa7397fed753547f11ca8696646f2f3acb08e31016afac23e630c5d11f59f61fef57b0d2aa5',\n * )\n * const address = Address.fromPublicKey(publicKey)\n * // @log: '0xf39fd6e51aad88f6f4ce6ab8827279cfffb92266'\n * ```\n *\n * @param publicKey - The ECDSA public key to convert to an {@link ox#Address.Address}.\n * @param options - Conversion options.\n * @returns The {@link ox#Address.Address} corresponding to the public key.\n */\nexport function fromPublicKey(\n  publicKey: PublicKey.PublicKey,\n  options: fromPublicKey.Options = {},\n): Address {\n  const address = Hash.keccak256(\n    `0x${PublicKey.toHex(publicKey).slice(4)}`,\n  ).substring(26)\n  return from(`0x${address}`, options)\n}\n\nexport declare namespace fromPublicKey {\n  type Options = {\n    /**\n     * Whether to checksum the address.\n     *\n     * @default false\n     */\n    checksum?: boolean | undefined\n  }\n\n  type ErrorType =\n    | Hash.keccak256.ErrorType\n    | PublicKey.toHex.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Checks if two {@link ox#Address.Address} are equal.\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.isEqual(\n *   '0xa0cf798816d4b9b9866b5330eea46a18382f251e',\n *   '0xA0Cf798816D4b9b9866b5330EEa46a18382f251e'\n * )\n * // @log: true\n * ```\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.isEqual(\n *   '0xa0cf798816d4b9b9866b5330eea46a18382f251e',\n *   '0xA0Cf798816D4b9b9866b5330EEa46a18382f251f'\n * )\n * // @log: false\n * ```\n *\n * @param addressA - The first address to compare.\n * @param addressB - The second address to compare.\n * @returns Whether the addresses are equal.\n */\nexport function isEqual(addressA: Address, addressB: Address): boolean {\n  assert(addressA, { strict: false })\n  assert(addressB, { strict: false })\n  return addressA.toLowerCase() === addressB.toLowerCase()\n}\n\nexport declare namespace isEqual {\n  type ErrorType = assert.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Checks if the given address is a valid {@link ox#Address.Address}.\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.validate('0xA0Cf798816D4b9b9866b5330EEa46a18382f251e')\n * // @log: true\n * ```\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.validate('0xdeadbeef')\n * // @log: false\n * ```\n *\n * @param address - Value to check if it is a valid address.\n * @param options - Check options.\n * @returns Whether the address is a valid address.\n */\nexport function validate(\n  address: string,\n  options: validate.Options = {},\n): address is Address {\n  const { strict = true } = options ?? {}\n  try {\n    assert(address, { strict })\n    return true\n  } catch {\n    return false\n  }\n}\n\nexport declare namespace validate {\n  type Options = {\n    /**\n     * Enables strict mode. Whether or not to compare the address against its checksum.\n     *\n     * @default true\n     */\n    strict?: boolean | undefined\n  }\n}\n\n/**\n * Thrown when an address is invalid.\n *\n * @example\n * ```ts twoslash\n * import { Address } from 'ox'\n *\n * Address.from('0x123')\n * // @error: Address.InvalidAddressError: Address `0x123` is invalid.\n * ```\n */\nexport class InvalidAddressError<\n  cause extends InvalidInputError | InvalidChecksumError =\n    | InvalidInputError\n    | InvalidChecksumError,\n> extends Errors.BaseError<cause> {\n  override readonly name = 'Address.InvalidAddressError'\n\n  constructor({ address, cause }: { address: string; cause: cause }) {\n    super(`Address \"${address}\" is invalid.`, {\n      cause,\n    })\n  }\n}\n\n/** Thrown when an address is not a 20 byte (40 hexadecimal character) value. */\nexport class InvalidInputError extends Errors.BaseError {\n  override readonly name = 'Address.InvalidInputError'\n\n  constructor() {\n    super('Address is not a 20 byte (40 hexadecimal character) value.')\n  }\n}\n\n/** Thrown when an address does not match its checksum counterpart. */\nexport class InvalidChecksumError extends Errors.BaseError {\n  override readonly name = 'Address.InvalidChecksumError'\n\n  constructor() {\n    super('Address does not match its checksum counterpart.')\n  }\n}\n","import { Rounding } from \"./types\";\n\nfunction divideAndRoundUp(dividend: bigint, divisor: bigint) {\n  const num = divisor > 0n ? dividend : -dividend;\n  const den = divisor > 0n ? divisor : -divisor;\n  const remainder = num % den;\n  const roundUp = remainder > 0n ? 1n : 0n;\n  return num / den + roundUp;\n}\n\nfunction divideAndRoundDown(dividend: bigint, divisor: bigint) {\n  const num = divisor > 0n ? dividend : -dividend;\n  const den = divisor > 0n ? divisor : -divisor;\n  const remainder = num % den;\n  const roundDown = remainder < 0n ? -1n : 0n;\n  return num / den + roundDown;\n}\n\nfunction divideAndRoundHalf(dividend: bigint, divisor: bigint) {\n  const num = divisor > 0n ? dividend : -dividend;\n  const den = divisor > 0n ? divisor : -divisor;\n  const invertSign = num < 0n ? -1n : 1n;\n  return (num * invertSign + den / 2n) / den * invertSign;\n}\n\nexport function divideAndRound(\n  dividend: bigint,\n  divisor: bigint,\n  rounding: Rounding = \"ROUND_HALF\",\n) {\n  return rounding === \"ROUND_UP\"\n    ? divideAndRoundUp(dividend, divisor)\n    : rounding === \"ROUND_DOWN\"\n    ? divideAndRoundDown(dividend, divisor)\n    : divideAndRoundHalf(dividend, divisor);\n}\n\nexport function splitNumber(number: string) {\n  let [whole, fraction = \"0\"] = number.split(\".\");\n  if (whole === \"\") {\n    whole = \"0\";\n  }\n\n  // trim trailing zeros\n  fraction = fraction.replace(/(?!^)0*$/, \"\");\n\n  return [whole, fraction];\n}\n\nexport function powerOfTen(zeroes: number) {\n  // This is to avoid using the ** operator which\n  // doesn’t seem to work for BigInt values on CodeSandbox.\n  // See https://github.com/codesandbox/codesandbox-client/issues/6706\n  return BigInt(\"1\" + \"0\".repeat(zeroes));\n}\n\nexport function roundToPower(value: bigint, power: bigint) {\n  const a = (value / power) * power;\n  const b = a + power;\n  return (value - a >= b - value) ? b : a;\n}\n\nexport function ceilToPower(value: bigint, power: bigint) {\n  const remainder = value % power;\n  return remainder === 0n ? value : ((value / power) * power) + power;\n}\n\nexport function floorToPower(value: bigint, power: bigint) {\n  return (value / power) * power;\n}\n\nexport function abs(value: bigint) {\n  return value < 0n ? -value : value;\n}\n","import type * as abitype from 'abitype'\nimport * as AbiParameters from './AbiParameters.js'\nimport * as Address from './Address.js'\nimport * as Bytes from './Bytes.js'\nimport * as Errors from './Errors.js'\nimport * as Hash from './Hash.js'\nimport * as Hex from './Hex.js'\nimport type { Compute } from './internal/types.js'\nimport * as Json from './Json.js'\nimport * as Solidity from './Solidity.js'\n\nexport type TypedData = abitype.TypedData\nexport type Domain = abitype.TypedDataDomain\nexport type Parameter = abitype.TypedDataParameter\n\n// TODO: Make reusable for Viem?\nexport type Definition<\n  typedData extends TypedData | Record<string, unknown> = TypedData,\n  primaryType extends keyof typedData | 'EIP712Domain' = keyof typedData,\n  ///\n  primaryTypes = typedData extends TypedData ? keyof typedData : string,\n> = primaryType extends 'EIP712Domain'\n  ? EIP712DomainDefinition<typedData, primaryType>\n  : MessageDefinition<typedData, primaryType, primaryTypes>\n\nexport type EIP712DomainDefinition<\n  typedData extends TypedData | Record<string, unknown> = TypedData,\n  primaryType extends 'EIP712Domain' = 'EIP712Domain',\n  ///\n  schema extends Record<string, unknown> = typedData extends TypedData\n    ? abitype.TypedDataToPrimitiveTypes<typedData>\n    : Record<string, unknown>,\n> = {\n  types?: typedData | undefined\n} & {\n  primaryType:\n    | 'EIP712Domain'\n    | (primaryType extends 'EIP712Domain' ? primaryType : never)\n  domain: schema extends { EIP712Domain: infer domain }\n    ? domain\n    : Compute<Domain>\n  message?: undefined\n}\n\nexport type MessageDefinition<\n  typedData extends TypedData | Record<string, unknown> = TypedData,\n  primaryType extends keyof typedData = keyof typedData,\n  ///\n  primaryTypes = typedData extends TypedData ? keyof typedData : string,\n  schema extends Record<string, unknown> = typedData extends TypedData\n    ? abitype.TypedDataToPrimitiveTypes<typedData>\n    : Record<string, unknown>,\n  message = schema[primaryType extends keyof schema\n    ? primaryType\n    : keyof schema],\n> = {\n  types: typedData\n} & {\n  primaryType:\n    | primaryTypes // show all values\n    | (primaryType extends primaryTypes ? primaryType : never) // infer value\n  domain?:\n    | (schema extends { EIP712Domain: infer domain } ? domain : Compute<Domain>)\n    | undefined\n  message: { [_: string]: any } extends message // Check if message was inferred\n    ? Record<string, unknown>\n    : message\n}\n\n/**\n * Asserts that [EIP-712 Typed Data](https://eips.ethereum.org/EIPS/eip-712) is valid.\n *\n * @example\n * ```ts twoslash\n * import { TypedData } from 'ox'\n *\n * TypedData.assert({\n *   domain: {\n *     name: 'Ether!',\n *     version: '1',\n *     chainId: 1,\n *     verifyingContract: '0xCcCCccccCCCCcCCCCCCcCcCccCcCCCcCcccccccC',\n *   },\n *   primaryType: 'Foo',\n *   types: {\n *     Foo: [\n *       { name: 'address', type: 'address' },\n *       { name: 'name', type: 'string' },\n *       { name: 'foo', type: 'string' },\n *     ],\n *   },\n *   message: {\n *     address: '0xb9CAB4F0E46F7F6b1024b5A7463734fa68E633f9',\n *     name: 'jxom',\n *     foo: '0xb9CAB4F0E46F7F6b1024b5A7463734fa68E633f9',\n *   },\n * })\n * ```\n *\n * @param value - The Typed Data to validate.\n */\nexport function assert<\n  const typedData extends TypedData | Record<string, unknown>,\n  primaryType extends keyof typedData | 'EIP712Domain',\n>(value: assert.Value<typedData, primaryType>): void {\n  const { domain, message, primaryType, types } =\n    value as unknown as assert.Value\n\n  const validateData = (\n    struct: readonly Parameter[],\n    data: Record<string, unknown>,\n  ) => {\n    for (const param of struct) {\n      const { name, type } = param\n      const value = data[name]\n\n      const integerMatch = type.match(Solidity.integerRegex)\n      if (\n        integerMatch &&\n        (typeof value === 'number' || typeof value === 'bigint')\n      ) {\n        const [, base, size_] = integerMatch\n        // If number cannot be cast to a sized hex value, it is out of range\n        // and will throw.\n        Hex.fromNumber(value, {\n          signed: base === 'int',\n          size: Number.parseInt(size_ ?? '', 10) / 8,\n        })\n      }\n\n      if (\n        type === 'address' &&\n        typeof value === 'string' &&\n        !Address.validate(value)\n      )\n        throw new Address.InvalidAddressError({\n          address: value,\n          cause: new Address.InvalidInputError(),\n        })\n\n      const bytesMatch = type.match(Solidity.bytesRegex)\n      if (bytesMatch) {\n        const [, size] = bytesMatch\n        if (size && Hex.size(value as Hex.Hex) !== Number.parseInt(size, 10))\n          throw new BytesSizeMismatchError({\n            expectedSize: Number.parseInt(size, 10),\n            givenSize: Hex.size(value as Hex.Hex),\n          })\n      }\n\n      const struct = types[type]\n      if (struct) {\n        validateReference(type)\n        validateData(struct, value as Record<string, unknown>)\n      }\n    }\n  }\n\n  // Validate domain types.\n  if (types.EIP712Domain && domain) {\n    if (typeof domain !== 'object') throw new InvalidDomainError({ domain })\n    validateData(types.EIP712Domain, domain)\n  }\n\n  // Validate message types.\n  if (primaryType !== 'EIP712Domain') {\n    if (types[primaryType]) validateData(types[primaryType], message)\n    else throw new InvalidPrimaryTypeError({ primaryType, types })\n  }\n}\n\nexport declare namespace assert {\n  type Value<\n    typedData extends TypedData | Record<string, unknown> = TypedData,\n    primaryType extends keyof typedData | 'EIP712Domain' = keyof typedData,\n  > = Definition<typedData, primaryType>\n\n  type ErrorType =\n    | Address.InvalidAddressError\n    | BytesSizeMismatchError\n    | InvalidPrimaryTypeError\n    | Hex.fromNumber.ErrorType\n    | Hex.size.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Creates [EIP-712 Typed Data](https://eips.ethereum.org/EIPS/eip-712) [`domainSeparator`](https://eips.ethereum.org/EIPS/eip-712#definition-of-domainseparator) for the provided domain.\n *\n * @example\n * ```ts twoslash\n * import { TypedData } from 'ox'\n *\n * TypedData.domainSeparator({\n *   name: 'Ether!',\n *   version: '1',\n *   chainId: 1,\n *   verifyingContract: '0xCcCCccccCCCCcCCCCCCcCcCccCcCCCcCcccccccC',\n * })\n * // @log: '0x9911ee4f58a7059a8f5385248040e6984d80e2c849500fe6a4d11c4fa98c2af3'\n * ```\n *\n * @param domain - The domain for which to create the domain separator.\n * @returns The domain separator.\n */\nexport function domainSeparator(domain: Domain): Hex.Hex {\n  return hashDomain({\n    domain,\n  })\n}\n\nexport declare namespace domainSeparator {\n  type ErrorType = hashDomain.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Encodes typed data in [EIP-712 format](https://eips.ethereum.org/EIPS/eip-712): `0x19 ‖ 0x01 ‖ domainSeparator ‖ hashStruct(message)`.\n *\n * @example\n * ```ts twoslash\n * import { TypedData, Hash } from 'ox'\n *\n * const data = TypedData.encode({ // [!code focus:33]\n *   domain: {\n *     name: 'Ether Mail',\n *     version: '1',\n *     chainId: 1,\n *     verifyingContract: '0x0000000000000000000000000000000000000000',\n *   },\n *   types: {\n *     Person: [\n *       { name: 'name', type: 'string' },\n *       { name: 'wallet', type: 'address' },\n *     ],\n *     Mail: [\n *       { name: 'from', type: 'Person' },\n *       { name: 'to', type: 'Person' },\n *       { name: 'contents', type: 'string' },\n *     ],\n *   },\n *   primaryType: 'Mail',\n *   message: {\n *     from: {\n *       name: 'Cow',\n *       wallet: '0xCD2a3d9F938E13CD947Ec05AbC7FE734Df8DD826',\n *     },\n *     to: {\n *       name: 'Bob',\n *       wallet: '0xbBbBBBBbbBBBbbbBbbBbbbbBBbBbbbbBbBbbBBbB',\n *     },\n *     contents: 'Hello, Bob!',\n *   },\n * })\n * // @log: '0x19012fdf3441fcaf4f30c7e16292b258a5d7054a4e2e00dbd7b7d2f467f2b8fb9413c52c0ee5d84264471806290a3f2c4cecfc5490626bf912d01f240d7a274b371e'\n * // @log: (0x19 ‖ 0x01 ‖ domainSeparator ‖ hashStruct(message))\n *\n * const hash = Hash.keccak256(data)\n * ```\n *\n * @param value - The Typed Data to encode.\n * @returns The encoded Typed Data.\n */\nexport function encode<\n  const typedData extends TypedData | Record<string, unknown>,\n  primaryType extends keyof typedData | 'EIP712Domain',\n>(value: encode.Value<typedData, primaryType>): Hex.Hex {\n  const { domain = {}, message, primaryType } = value as encode.Value\n\n  const types = {\n    EIP712Domain: extractEip712DomainTypes(domain),\n    ...value.types,\n  } as TypedData\n\n  // Need to do a runtime validation check on addresses, byte ranges, integer ranges, etc\n  // as we can't statically check this with TypeScript.\n  assert({\n    domain,\n    message,\n    primaryType,\n    types,\n  })\n\n  // Typed Data Format: `0x19 ‖ 0x01 ‖ domainSeparator ‖ hashStruct(message)`\n  const parts: Hex.Hex[] = ['0x19', '0x01']\n  if (domain)\n    parts.push(\n      hashDomain({\n        domain,\n        types,\n      }),\n    )\n  if (primaryType !== 'EIP712Domain')\n    parts.push(\n      hashStruct({\n        data: message,\n        primaryType,\n        types,\n      }),\n    )\n\n  return Hex.concat(...parts)\n}\n\nexport declare namespace encode {\n  type Value<\n    typedData extends TypedData | Record<string, unknown> = TypedData,\n    primaryType extends keyof typedData | 'EIP712Domain' = keyof typedData,\n  > = Definition<typedData, primaryType>\n\n  type ErrorType =\n    | extractEip712DomainTypes.ErrorType\n    | hashDomain.ErrorType\n    | hashStruct.ErrorType\n    | assert.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Encodes [EIP-712 Typed Data](https://eips.ethereum.org/EIPS/eip-712) schema for the provided primaryType.\n *\n * @example\n * ```ts twoslash\n * import { TypedData } from 'ox'\n *\n * TypedData.encodeType({\n *   types: {\n *     Foo: [\n *       { name: 'address', type: 'address' },\n *       { name: 'name', type: 'string' },\n *       { name: 'foo', type: 'string' },\n *     ],\n *   },\n *   primaryType: 'Foo',\n * })\n * // @log: 'Foo(address address,string name,string foo)'\n * ```\n *\n * @param value - The Typed Data schema.\n * @returns The encoded type.\n */\nexport function encodeType(value: encodeType.Value): string {\n  const { primaryType, types } = value\n\n  let result = ''\n  const unsortedDeps = findTypeDependencies({ primaryType, types })\n  unsortedDeps.delete(primaryType)\n\n  const deps = [primaryType, ...Array.from(unsortedDeps).sort()]\n  for (const type of deps) {\n    result += `${type}(${(types[type] ?? [])\n      .map(({ name, type: t }) => `${t} ${name}`)\n      .join(',')})`\n  }\n\n  return result\n}\n\nexport declare namespace encodeType {\n  type Value = {\n    primaryType: string\n    types: TypedData\n  }\n\n  type ErrorType = findTypeDependencies.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Gets [EIP-712 Typed Data](https://eips.ethereum.org/EIPS/eip-712) schema for EIP-721 domain.\n *\n * @example\n * ```ts twoslash\n * import { TypedData } from 'ox'\n *\n * TypedData.extractEip712DomainTypes({\n *   name: 'Ether!',\n *   version: '1',\n *   chainId: 1,\n *   verifyingContract: '0xCcCCccccCCCCcCCCCCCcCcCccCcCCCcCcccccccC',\n * })\n * // @log: [\n * // @log:   { 'name': 'name', 'type': 'string' },\n * // @log:   { 'name': 'version', 'type': 'string' },\n * // @log:   { 'name': 'chainId', 'type': 'uint256' },\n * // @log:   { 'name': 'verifyingContract', 'type': 'address' },\n * // @log: ]\n * ```\n *\n * @param domain - The EIP-712 domain.\n * @returns The EIP-712 domain schema.\n */\nexport function extractEip712DomainTypes(\n  domain: Domain | undefined,\n): Parameter[] {\n  return [\n    typeof domain?.name === 'string' && { name: 'name', type: 'string' },\n    domain?.version && { name: 'version', type: 'string' },\n    (typeof domain?.chainId === 'number' ||\n      typeof domain?.chainId === 'bigint') && {\n      name: 'chainId',\n      type: 'uint256',\n    },\n    domain?.verifyingContract && {\n      name: 'verifyingContract',\n      type: 'address',\n    },\n    domain?.salt && { name: 'salt', type: 'bytes32' },\n  ].filter(Boolean) as Parameter[]\n}\n\nexport declare namespace extractEip712DomainTypes {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/**\n * Gets the payload to use for signing typed data in [EIP-712 format](https://eips.ethereum.org/EIPS/eip-712).\n *\n * @example\n * ```ts twoslash\n * import { Secp256k1, TypedData, Hash } from 'ox'\n *\n * const payload = TypedData.getSignPayload({ // [!code focus:99]\n *   domain: {\n *     name: 'Ether Mail',\n *     version: '1',\n *     chainId: 1,\n *     verifyingContract: '0x0000000000000000000000000000000000000000',\n *   },\n *   types: {\n *     Person: [\n *       { name: 'name', type: 'string' },\n *       { name: 'wallet', type: 'address' },\n *     ],\n *     Mail: [\n *       { name: 'from', type: 'Person' },\n *       { name: 'to', type: 'Person' },\n *       { name: 'contents', type: 'string' },\n *     ],\n *   },\n *   primaryType: 'Mail',\n *   message: {\n *     from: {\n *       name: 'Cow',\n *       wallet: '0xCD2a3d9F938E13CD947Ec05AbC7FE734Df8DD826',\n *     },\n *     to: {\n *       name: 'Bob',\n *       wallet: '0xbBbBBBBbbBBBbbbBbbBbbbbBBbBbbbbBbBbbBBbB',\n *     },\n *     contents: 'Hello, Bob!',\n *   },\n * })\n *\n * const signature = Secp256k1.sign({ payload, privateKey: '0x...' })\n * ```\n *\n * @param value - The typed data to get the sign payload for.\n * @returns The payload to use for signing.\n */\nexport function getSignPayload<\n  const typedData extends TypedData | Record<string, unknown>,\n  primaryType extends keyof typedData | 'EIP712Domain',\n>(value: encode.Value<typedData, primaryType>): Hex.Hex {\n  return Hash.keccak256(encode(value))\n}\n\nexport declare namespace getSignPayload {\n  type ErrorType =\n    | Hash.keccak256.ErrorType\n    | encode.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Hashes [EIP-712 Typed Data](https://eips.ethereum.org/EIPS/eip-712) domain.\n *\n * @example\n * ```ts twoslash\n * import { TypedData } from 'ox'\n *\n * TypedData.hashDomain({\n *   domain: {\n *     name: 'Ether Mail',\n *     version: '1',\n *     chainId: 1,\n *     verifyingContract: '0x0000000000000000000000000000000000000000',\n *   },\n * })\n * // @log: '0x6192106f129ce05c9075d319c1fa6ea9b3ae37cbd0c1ef92e2be7137bb07baa1'\n * ```\n *\n * @param value - The Typed Data domain and types.\n * @returns The hashed domain.\n */\nexport function hashDomain(value: hashDomain.Value): Hex.Hex {\n  const { domain, types } = value\n  return hashStruct({\n    data: domain,\n    primaryType: 'EIP712Domain',\n    types: {\n      ...types,\n      EIP712Domain: types?.EIP712Domain || extractEip712DomainTypes(domain),\n    },\n  })\n}\n\nexport declare namespace hashDomain {\n  type Value = {\n    /** The Typed Data domain. */\n    domain: Domain\n    /** The Typed Data types. */\n    types?:\n      | {\n          EIP712Domain?: readonly Parameter[] | undefined\n          [key: string]: readonly Parameter[] | undefined\n        }\n      | undefined\n  }\n\n  type ErrorType = hashStruct.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Hashes [EIP-712 Typed Data](https://eips.ethereum.org/EIPS/eip-712) struct.\n *\n * @example\n * ```ts twoslash\n * import { TypedData } from 'ox'\n *\n * TypedData.hashStruct({\n *   types: {\n *     Foo: [\n *       { name: 'address', type: 'address' },\n *       { name: 'name', type: 'string' },\n *       { name: 'foo', type: 'string' },\n *     ],\n *   },\n *   primaryType: 'Foo',\n *   data: {\n *     address: '0xb9CAB4F0E46F7F6b1024b5A7463734fa68E633f9',\n *     name: 'jxom',\n *     foo: '0xb9CAB4F0E46F7F6b1024b5A7463734fa68E633f9',\n *   },\n * })\n * // @log: '0x996fb3b6d48c50312d69abdd4c1b6fb02057c85aa86bb8d04c6f023326a168ce'\n * ```\n *\n * @param value - The Typed Data struct to hash.\n * @returns The hashed Typed Data struct.\n */\nexport function hashStruct(value: hashStruct.Value): Hex.Hex {\n  const { data, primaryType, types } = value\n  const encoded = encodeData({\n    data,\n    primaryType,\n    types,\n  })\n  return Hash.keccak256(encoded)\n}\n\nexport declare namespace hashStruct {\n  type Value = {\n    /** The Typed Data struct to hash. */\n    data: Record<string, unknown>\n    /** The primary type of the Typed Data struct. */\n    primaryType: string\n    /** The types of the Typed Data struct. */\n    types: TypedData\n  }\n\n  type ErrorType =\n    | encodeData.ErrorType\n    | Hash.keccak256.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/**\n * Serializes [EIP-712 Typed Data](https://eips.ethereum.org/EIPS/eip-712) schema into string.\n *\n * @example\n * ```ts twoslash\n * import { TypedData } from 'ox'\n *\n * TypedData.serialize({\n *   domain: {\n *     name: 'Ether!',\n *     version: '1',\n *     chainId: 1,\n *     verifyingContract: '0xCcCCccccCCCCcCCCCCCcCcCccCcCCCcCcccccccC',\n *   },\n *   primaryType: 'Foo',\n *   types: {\n *     Foo: [\n *       { name: 'address', type: 'address' },\n *       { name: 'name', type: 'string' },\n *       { name: 'foo', type: 'string' },\n *     ],\n *   },\n *   message: {\n *     address: '0xb9CAB4F0E46F7F6b1024b5A7463734fa68E633f9',\n *     name: 'jxom',\n *     foo: '0xb9CAB4F0E46F7F6b1024b5A7463734fa68E633f9',\n *   },\n * })\n * // @log: \"{\"domain\":{},\"message\":{\"address\":\"0xb9cab4f0e46f7f6b1024b5a7463734fa68e633f9\",\"name\":\"jxom\",\"foo\":\"0xb9CAB4F0E46F7F6b1024b5A7463734fa68E633f9\"},\"primaryType\":\"Foo\",\"types\":{\"Foo\":[{\"name\":\"address\",\"type\":\"address\"},{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"foo\",\"type\":\"string\"}]}}\"\n * ```\n *\n * @param value - The Typed Data schema to serialize.\n * @returns The serialized Typed Data schema. w\n */\nexport function serialize<\n  const typedData extends TypedData | Record<string, unknown>,\n  primaryType extends keyof typedData | 'EIP712Domain',\n>(value: serialize.Value<typedData, primaryType>): string {\n  const {\n    domain: domain_,\n    message: message_,\n    primaryType,\n    types,\n  } = value as unknown as serialize.Value\n\n  const normalizeData = (\n    struct: readonly Parameter[],\n    value: Record<string, unknown>,\n  ) => {\n    const data = { ...value }\n    for (const param of struct) {\n      const { name, type } = param\n      if (type === 'address') data[name] = (data[name] as string).toLowerCase()\n    }\n    return data\n  }\n\n  const domain = (() => {\n    if (!domain_) return {}\n    const type = types.EIP712Domain ?? extractEip712DomainTypes(domain_)\n    return normalizeData(type, domain_)\n  })()\n\n  const message = (() => {\n    if (primaryType === 'EIP712Domain') return undefined\n    if (!types[primaryType]) return {}\n    return normalizeData(types[primaryType], message_)\n  })()\n\n  return Json.stringify({ domain, message, primaryType, types }, (_, value) => {\n    if (typeof value === 'bigint') return value.toString()\n    return value\n  })\n}\n\nexport declare namespace serialize {\n  type Value<\n    typedData extends TypedData | Record<string, unknown> = TypedData,\n    primaryType extends keyof typedData | 'EIP712Domain' = keyof typedData,\n  > = Definition<typedData, primaryType>\n\n  type ErrorType = Json.stringify.ErrorType | Errors.GlobalErrorType\n}\n\n/**\n * Checks if [EIP-712 Typed Data](https://eips.ethereum.org/EIPS/eip-712) is valid.\n *\n * @example\n * ```ts twoslash\n * import { TypedData } from 'ox'\n *\n * const valid = TypedData.validate({\n *   domain: {\n *     name: 'Ether!',\n *     version: '1',\n *     chainId: 1,\n *     verifyingContract: '0xCcCCccccCCCCcCCCCCCcCcCccCcCCCcCcccccccC',\n *   },\n *   primaryType: 'Foo',\n *   types: {\n *     Foo: [\n *       { name: 'address', type: 'address' },\n *       { name: 'name', type: 'string' },\n *       { name: 'foo', type: 'string' },\n *     ],\n *   },\n *   message: {\n *     address: '0xb9CAB4F0E46F7F6b1024b5A7463734fa68E633f9',\n *     name: 'jxom',\n *     foo: '0xb9CAB4F0E46F7F6b1024b5A7463734fa68E633f9',\n *   },\n * })\n * // @log: true\n * ```\n *\n * @param value - The Typed Data to validate.\n */\nexport function validate<\n  const typedData extends TypedData | Record<string, unknown>,\n  primaryType extends keyof typedData | 'EIP712Domain',\n>(value: assert.Value<typedData, primaryType>): boolean {\n  try {\n    assert(value)\n    return true\n  } catch {\n    return false\n  }\n}\n\nexport declare namespace validate {\n  type ErrorType = assert.ErrorType | Errors.GlobalErrorType\n}\n\n/** Thrown when the bytes size of a typed data value does not match the expected size. */\nexport class BytesSizeMismatchError extends Errors.BaseError {\n  override readonly name = 'TypedData.BytesSizeMismatchError'\n\n  constructor({\n    expectedSize,\n    givenSize,\n  }: { expectedSize: number; givenSize: number }) {\n    super(`Expected bytes${expectedSize}, got bytes${givenSize}.`)\n  }\n}\n\n/** Thrown when the domain is invalid. */\nexport class InvalidDomainError extends Errors.BaseError {\n  override readonly name = 'TypedData.InvalidDomainError'\n\n  constructor({ domain }: { domain: unknown }) {\n    super(`Invalid domain \"${Json.stringify(domain)}\".`, {\n      metaMessages: ['Must be a valid EIP-712 domain.'],\n    })\n  }\n}\n\n/** Thrown when the primary type of a typed data value is invalid. */\nexport class InvalidPrimaryTypeError extends Errors.BaseError {\n  override readonly name = 'TypedData.InvalidPrimaryTypeError'\n\n  constructor({\n    primaryType,\n    types,\n  }: { primaryType: string; types: TypedData | Record<string, unknown> }) {\n    super(\n      `Invalid primary type \\`${primaryType}\\` must be one of \\`${JSON.stringify(Object.keys(types))}\\`.`,\n      {\n        metaMessages: ['Check that the primary type is a key in `types`.'],\n      },\n    )\n  }\n}\n\n/** Thrown when the struct type is not a valid type. */\nexport class InvalidStructTypeError extends Errors.BaseError {\n  override readonly name = 'TypedData.InvalidStructTypeError'\n\n  constructor({ type }: { type: string }) {\n    super(`Struct type \"${type}\" is invalid.`, {\n      metaMessages: ['Struct type must not be a Solidity type.'],\n    })\n  }\n}\n\n/** @internal */\nexport function encodeData(value: {\n  data: Record<string, unknown>\n  primaryType: string\n  types: TypedData\n}): Hex.Hex {\n  const { data, primaryType, types } = value\n  const encodedTypes: AbiParameters.Parameter[] = [{ type: 'bytes32' }]\n  const encodedValues: unknown[] = [hashType({ primaryType, types })]\n\n  for (const field of types[primaryType] ?? []) {\n    const [type, value] = encodeField({\n      types,\n      name: field.name,\n      type: field.type,\n      value: data[field.name],\n    })\n    encodedTypes.push(type)\n    encodedValues.push(value)\n  }\n\n  return AbiParameters.encode(encodedTypes, encodedValues)\n}\n\n/** @internal */\nexport declare namespace encodeData {\n  type ErrorType =\n    | AbiParameters.encode.ErrorType\n    | encodeField.ErrorType\n    | hashType.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function hashType(value: {\n  primaryType: string\n  types: TypedData\n}): Hex.Hex {\n  const { primaryType, types } = value\n  const encodedHashType = Hex.fromString(encodeType({ primaryType, types }))\n  return Hash.keccak256(encodedHashType)\n}\n\n/** @internal */\nexport declare namespace hashType {\n  type ErrorType =\n    | Hex.fromString.ErrorType\n    | encodeType.ErrorType\n    | Hash.keccak256.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function encodeField(properties: {\n  types: TypedData\n  name: string\n  type: string\n  value: any\n}): [type: AbiParameters.Parameter, value: Hex.Hex] {\n  let { types, name, type, value } = properties\n\n  if (types[type] !== undefined)\n    return [\n      { type: 'bytes32' },\n      Hash.keccak256(encodeData({ data: value, primaryType: type, types })),\n    ]\n\n  if (type === 'bytes') {\n    const prepend = value.length % 2 ? '0' : ''\n    value = `0x${prepend + value.slice(2)}`\n    return [{ type: 'bytes32' }, Hash.keccak256(value, { as: 'Hex' })]\n  }\n\n  if (type === 'string')\n    return [\n      { type: 'bytes32' },\n      Hash.keccak256(Bytes.fromString(value), { as: 'Hex' }),\n    ]\n\n  if (type.lastIndexOf(']') === type.length - 1) {\n    const parsedType = type.slice(0, type.lastIndexOf('['))\n    const typeValuePairs = (value as [AbiParameters.Parameter, any][]).map(\n      (item) =>\n        encodeField({\n          name,\n          type: parsedType,\n          types,\n          value: item,\n        }),\n    )\n    return [\n      { type: 'bytes32' },\n      Hash.keccak256(\n        AbiParameters.encode(\n          typeValuePairs.map(([t]) => t),\n          typeValuePairs.map(([, v]) => v),\n        ),\n      ),\n    ]\n  }\n\n  return [{ type }, value]\n}\n\n/** @internal */\nexport declare namespace encodeField {\n  type ErrorType =\n    | AbiParameters.encode.ErrorType\n    | Hash.keccak256.ErrorType\n    | Bytes.fromString.ErrorType\n    | Errors.GlobalErrorType\n}\n\n/** @internal */\nexport function findTypeDependencies(\n  value: {\n    primaryType: string\n    types: TypedData\n  },\n  results: Set<string> = new Set(),\n): Set<string> {\n  const { primaryType: primaryType_, types } = value\n  const match = primaryType_.match(/^\\w*/u)\n  const primaryType = match?.[0]!\n  if (results.has(primaryType) || types[primaryType] === undefined)\n    return results\n\n  results.add(primaryType)\n\n  for (const field of types[primaryType])\n    findTypeDependencies({ primaryType: field.type, types }, results)\n  return results\n}\n\n/** @internal */\nexport declare namespace findTypeDependencies {\n  type ErrorType = Errors.GlobalErrorType\n}\n\n/** @internal */\nfunction validateReference(type: string) {\n  // Struct type must not be a Solidity type.\n  if (\n    type === 'address' ||\n    type === 'bool' ||\n    type === 'string' ||\n    type.startsWith('bytes') ||\n    type.startsWith('uint') ||\n    type.startsWith('int')\n  )\n    throw new InvalidStructTypeError({ type })\n}\n","import type {\n  AliasedOptions,\n  Decimals,\n  Dnum,\n  Numberish,\n  Rounding,\n  Value,\n} from \"./types\";\n\nimport fromExponential from \"from-exponential\";\nimport {\n  abs,\n  ceilToPower,\n  divideAndRound,\n  floorToPower,\n  powerOfTen,\n  roundToPower,\n  splitNumber,\n} from \"./utils\";\n\nexport function isDnum(value: unknown): value is Dnum {\n  return (\n    Array.isArray(value)\n    && typeof value[0] === \"bigint\"\n    && typeof value[1] === \"number\"\n  );\n}\n\n// Matches:\n//  - whole numbers (123)\n//  - decimal numbers (1.23, .23)\n//  - negative numbers (-123, -1.23, -.23)\nconst NUM_RE = /^-?(?:[0-9]+|(?:[0-9]*(?:\\.[0-9]+)))$/;\n\n// Based on ethers parseFixed():\n// https://github.com/ethers-io/ethers.js/blob/8b62aeff9cce44cbd16ff41f8fc01ebb101f8265/packages/bignumber/src.ts/fixednumber.ts#L70\nexport function from(\n  value: Numberish,\n  decimals: number | true = true,\n): Dnum {\n  if (isDnum(value)) {\n    return setDecimals(value, decimals === true ? value[1] : decimals);\n  }\n\n  value = String(value);\n\n  if (value.includes(\"e\")) {\n    value = fromExponential(value);\n  }\n\n  if (!value.match(NUM_RE)) {\n    throw new Error(`dnum: incorrect number (${value})`);\n  }\n\n  const negative = value.startsWith(\"-\");\n  if (negative) {\n    value = value.slice(1);\n  }\n\n  const parts = splitNumber(value);\n  const whole = parts[0];\n  let fraction = parts[1];\n\n  if (decimals === true) {\n    decimals = fraction === \"0\" ? 0 : fraction.length;\n  }\n\n  // truncate according to decimals\n  fraction = fraction.slice(0, decimals);\n\n  // pad fraction with trailing zeros\n  fraction = fraction + \"0\".repeat(decimals - fraction.length);\n\n  const result = (\n    BigInt(whole) * powerOfTen(decimals) + BigInt(fraction)\n  ) * (\n    negative ? -1n : 1n\n  );\n\n  return [result, decimals];\n}\n\nexport function setValueDecimals(\n  value: Value,\n  decimalsDiff: Decimals,\n  options: { rounding?: Rounding } = {},\n): Value {\n  options.rounding ??= \"ROUND_HALF\";\n\n  if (decimalsDiff > 0) {\n    return value * powerOfTen(decimalsDiff);\n  }\n\n  if (decimalsDiff < 0) {\n    return divideAndRound(value, powerOfTen(-decimalsDiff), options.rounding);\n  }\n\n  return value;\n}\n\nexport function setDecimals(\n  value: Dnum,\n  decimals: Decimals,\n  options: { rounding?: Rounding } = {},\n): Dnum {\n  options.rounding ??= \"ROUND_HALF\";\n\n  if (value[1] === decimals) {\n    return value;\n  }\n\n  if (value[1] < 0 || decimals < 0) {\n    throw new Error(\"dnum: decimals cannot be negative\");\n  }\n\n  const decimalsDiff = decimals - value[1];\n  return [\n    setValueDecimals(value[0], decimalsDiff, options),\n    decimals,\n  ];\n}\n\nexport function equalizeDecimals(nums: Dnum[], decimals?: number): Dnum[] {\n  const decimals_ = decimals\n    ?? Math.max(...nums.map(([, decimals]) => decimals), 0);\n  return nums.map((num) => setDecimals(num, decimals_));\n}\n\nexport function toJSON([value, decimals]: Dnum) {\n  return JSON.stringify([String(value), decimals]);\n}\n\nexport function fromJSON(jsonValue: string): Dnum {\n  const [value, decimals] = JSON.parse(jsonValue);\n  return [BigInt(value), decimals];\n}\n\nexport function toParts(\n  dnum: Dnum,\n  optionsOrDigits: AliasedOptions<{\n    digits?: number; // defaults to decimals\n    trailingZeros?: boolean;\n    decimalsRounding?: Rounding;\n  }, \"digits\"> = {},\n): [\n  whole: bigint, // always positive\n  fraction: string | null,\n] {\n  const [value, decimals] = dnum;\n\n  // options.digits can also be passed directly as the second argument\n  const options = typeof optionsOrDigits === \"number\"\n    ? { digits: optionsOrDigits }\n    : optionsOrDigits;\n\n  const {\n    digits = decimals,\n    trailingZeros,\n    decimalsRounding,\n  } = options;\n\n  const decimalsDivisor = powerOfTen(decimals);\n\n  let whole = value / decimalsDivisor;\n  const fractionValue = abs(value % decimalsDivisor);\n\n  const roundFn = decimalsRounding === \"ROUND_UP\"\n    ? ceilToPower\n    : decimalsRounding === \"ROUND_DOWN\"\n    ? floorToPower\n    : roundToPower;\n\n  let fraction = String(\n    roundFn(\n      BigInt(\n        // prefix with 1 to keep the leading zeros\n        \"1\"\n          // leading zeros\n          + \"0\".repeat(\n            Math.max(\n              0,\n              String(decimalsDivisor).length - String(fractionValue).length - 1,\n            ),\n          )\n          // non zero numbers\n          + String(fractionValue),\n      ),\n      powerOfTen(Math.max(0, decimals - digits)),\n    ),\n  );\n\n  // if the 1 prefix has changed to 2, it means that the\n  // rounding caused the whole part to be incremented\n  if (fraction.startsWith(\"2\")) {\n    whole += 1n;\n  }\n\n  // remove the leading 1 and extra decimal places (see above)\n  fraction = fraction.slice(1, digits + 1);\n\n  // trim or pad with trailing zeros\n  fraction = trailingZeros\n    ? fraction.padEnd(digits, \"0\")\n    : fraction.replace(/0+$/, \"\");\n\n  return [\n    abs(whole),\n    fraction === \"\" || (BigInt(fraction) === 0n && !trailingZeros)\n      ? null\n      : fraction,\n  ];\n}\n\nexport function toNumber(\n  value: Dnum,\n  optionsOrDigits?: Parameters<typeof toParts>[1],\n) {\n  return Number(toString(value, optionsOrDigits));\n}\n\nexport function toString(\n  value: Dnum,\n  optionsOrDigits?: Parameters<typeof toParts>[1],\n) {\n  const [whole, fraction] = toParts(value, optionsOrDigits);\n  return (value[0] >= 0n ? \"\" : \"-\")\n    + whole\n    + (fraction ? `.${fraction}` : \"\");\n}\n","/**\n * Subgraph queries\n */\n\nexport const QUERIES = {\n  // queries for subgraphRetriever\n  GET_APPROVED_PROVIDERS_FOR_PIECE_LINK: `\n    query GetApprovedProvidersForCommP($cid: Bytes!) {\n      pieces(where: { cid: $cid }) {\n        id\n        dataSet {\n          setId\n          serviceProvider {\n            id\n            providerId\n            serviceProvider\n            payee\n            name\n            description\n            registeredAt\n            status\n            approvedAt\n            products {\n              decodedProductData\n              productType\n              isActive\n              capabilityValues\n              capabilityKeys\n            }\n          }\n        }\n      }\n    }\n  `,\n  GET_PROVIDER_BY_ADDRESS: `\n    query Provider($serviceProvider: ID!) {\n      provider (id: $serviceProvider) {\n        id\n        providerId\n        serviceProvider\n        payee\n        name\n        description\n        registeredAt\n        status\n        approvedAt\n        products {\n          decodedProductData\n          productType\n          isActive\n          capabilityValues\n          capabilityKeys\n        }\n      }\n    }\n  `,\n  // flexible query templates\n  GET_PROVIDERS_FLEXIBLE: `\n    query ProvidersFlexible($where: Provider_filter, $first: Int, $skip: Int, $orderBy: Provider_orderBy, $orderDirection: OrderDirection) {\n      providers(\n        where: $where\n        first: $first\n        skip: $skip\n        orderBy: $orderBy\n        orderDirection: $orderDirection\n      ) {\n        id\n        providerId\n        serviceProvider\n        payee\n        registeredAt\n        approvedAt\n        status\n        totalFaultedPeriods\n        totalFaultedPieces\n        totalDataSets\n        totalPieces\n        totalDataSize\n        createdAt\n        updatedAt\n        products {\n          decodedProductData\n          productType\n          isActive\n          capabilityValues\n          capabilityKeys\n        }\n      }\n    }\n  `,\n  GET_DATA_SETS_FLEXIBLE: `\n    query DataSetsFlexible($where: DataSet_filter, $first: Int, $skip: Int, $orderBy: DataSet_orderBy, $orderDirection: OrderDirection) {\n      dataSets(\n        where: $where\n        first: $first\n        skip: $skip\n        orderBy: $orderBy\n        orderDirection: $orderDirection\n      ) {\n        id\n        setId\n        listener\n        payer\n        withCDN\n        isActive\n        leafCount\n        challengeRange\n        lastProvenEpoch\n        nextChallengeEpoch\n        totalPieces\n        totalDataSize\n        totalProofs\n        totalProvedPieces\n        totalFaultedPeriods\n        totalFaultedPieces\n        metadataKeys\n        metadataValues\n        createdAt\n        updatedAt\n        serviceProvider {\n          id\n          providerId\n          serviceProvider\n          payee\n          name\n          description\n          registeredAt\n          status\n          approvedAt\n          products {\n            decodedProductData\n            productType\n            isActive\n            capabilityValues\n            capabilityKeys\n          }\n        }\n        rails {\n          id\n          type\n          railId\n          token\n          paymentRate\n          settledUpto\n          endEpoch\n        }\n      }\n    }\n  `,\n  GET_PIECES_FLEXIBLE: `\n    query PiecesFlexible($where: Piece_filter, $first: Int, $skip: Int, $orderBy: Piece_orderBy, $orderDirection: OrderDirection) {\n      pieces(\n        where: $where\n        first: $first\n        skip: $skip\n        orderBy: $orderBy\n        orderDirection: $orderDirection\n      ) {\n        id\n        setId\n        pieceId\n        rawSize\n        leafCount\n        cid\n        removed\n        totalProofsSubmitted\n        totalPeriodsFaulted\n        lastProvenEpoch\n        lastProvenAt\n        lastFaultedEpoch\n        lastFaultedAt\n        createdAt\n        metadataKeys\n        metadataValues\n        dataSet {\n          id\n          setId\n          isActive\n          serviceProvider {\n            id\n            providerId\n            serviceProvider\n            payee\n            name\n            description\n            registeredAt\n            status\n            approvedAt\n            products {\n              decodedProductData\n              productType\n              isActive\n              capabilityValues\n              capabilityKeys\n            }\n          }\n        }\n      }\n    }\n  `,\n  GET_FAULT_RECORDS_FLEXIBLE: `\n    query FaultRecordsFlexible($where: FaultRecord_filter, $first: Int, $skip: Int, $orderBy: FaultRecord_orderBy, $orderDirection: OrderDirection) {\n      faultRecords(\n        where: $where\n        first: $first\n        skip: $skip\n        orderBy: $orderBy\n        orderDirection: $orderDirection\n      ) {\n        id\n        dataSetId\n        pieceIds\n        currentChallengeEpoch\n        nextChallengeEpoch\n        periodsFaulted\n        deadline\n        createdAt\n        dataSet {\n          id\n          setId\n          serviceProvider {\n            id\n            providerId\n            serviceProvider\n            payee\n            name\n            description\n            registeredAt\n            status\n            approvedAt\n            products {\n              decodedProductData\n              productType\n              isActive\n              capabilityValues\n              capabilityKeys\n            }\n          }\n        }\n      }\n    }\n  `,\n} as const\n","import type { Dnum } from \"./types\";\n\nimport { toParts } from \"./dnum\";\n\ntype SignDisplay = \"auto\" | \"always\" | \"exceptZero\" | \"negative\" | \"never\";\n\nexport function format(\n  dnum: Dnum,\n  // see toParts() in src/dnum.ts\n  optionsOrDigits: Parameters<typeof toParts>[1] & {\n    compact?: boolean;\n    locale?: ConstructorParameters<typeof Intl.NumberFormat>[0];\n    signDisplay?: SignDisplay;\n  } = {},\n): string {\n  const options = typeof optionsOrDigits === \"number\"\n    ? { digits: optionsOrDigits }\n    : optionsOrDigits;\n\n  const {\n    compact,\n    locale = Intl.NumberFormat().resolvedOptions().locale,\n    signDisplay = \"auto\",\n    ...toPartsOptions\n  } = options;\n\n  const [whole, fraction] = toParts(dnum, toPartsOptions);\n\n  const decimalsSeparator = new Intl.NumberFormat(locale)\n    .formatToParts(.1)\n    .find((v) => v.type === \"decimal\")?.value ?? \".\";\n\n  const roundsToZero = whole === 0n && (\n    fraction === null || /^0+$/.test(fraction)\n  );\n\n  const wholeString = formatSign(\n    dnum,\n    roundsToZero,\n    signDisplay,\n  ) + BigInt(whole).toLocaleString(locale, {\n    notation: compact ? \"compact\" : \"standard\",\n  });\n\n  return fraction === null\n      // check if a compact notation has been applied\n      || !/\\d/.test(wholeString.at(-1) as string) // “as string” is safe because whole.toLocaleString() always returns a non-empty string\n    ? wholeString\n    : `${wholeString}${decimalsSeparator}${fraction}`;\n}\n\nexport function formatSign(\n  dnum: Dnum,\n  roundsToZero: boolean,\n  signDisplay: SignDisplay,\n): \"-\" | \"+\" | \"\" {\n  if (signDisplay === \"auto\") {\n    return dnum[0] >= 0n ? \"\" : \"-\";\n  }\n  if (signDisplay === \"always\") {\n    return dnum[0] >= 0n ? \"+\" : \"-\";\n  }\n  if (signDisplay === \"exceptZero\") {\n    return roundsToZero ? \"\" : (dnum[0] >= 0n ? \"+\" : \"-\");\n  }\n  if (signDisplay === \"negative\") {\n    return dnum[0] >= 0n || roundsToZero ? \"\" : \"-\";\n  }\n  return \"\";\n}\n","import type {\n  AliasedOptions,\n  Decimals,\n  Dnum,\n  Numberish,\n  Rounding,\n} from \"./types\";\n\nimport {\n  equalizeDecimals,\n  from,\n  isDnum,\n  setDecimals,\n  setValueDecimals,\n} from \"./dnum\";\nimport { divideAndRound } from \"./utils\";\n\nexport function add(\n  num1: Numberish,\n  num2: Numberish,\n  decimals?: Decimals,\n): Dnum {\n  const [num1_, num2_] = normalizePairAndDecimals(num1, num2, decimals);\n  return setDecimals(\n    [num1_[0] + num2_[0], num1_[1]],\n    decimals ?? (isDnum(num1) ? num1[1] : num1_[1]),\n  );\n}\n\nexport function subtract(\n  num1: Numberish,\n  num2: Numberish,\n  decimals?: Decimals,\n): Dnum {\n  const [num1_, num2_] = normalizePairAndDecimals(num1, num2, decimals);\n  return setDecimals(\n    [num1_[0] - num2_[0], num1_[1]],\n    decimals ?? (isDnum(num1) ? num1[1] : num1_[1]),\n  );\n}\n\nexport function multiply(\n  num1: Numberish,\n  num2: Numberish,\n  optionsOrDecimals: AliasedOptions<{\n    decimals?: Decimals;\n    rounding?: Rounding;\n  }, \"decimals\"> = {},\n): Dnum {\n  const options = typeof optionsOrDecimals === \"number\"\n    ? { decimals: optionsOrDecimals }\n    : optionsOrDecimals;\n  options.rounding ??= \"ROUND_HALF\";\n\n  const [num1_, num2_] = normalizePairAndDecimals(num1, num2, options.decimals);\n  return setDecimals(\n    [num1_[0] * num2_[0], num1_[1] * 2],\n    options.decimals ?? (isDnum(num1) ? num1[1] : num1_[1]),\n    { rounding: options.rounding },\n  );\n}\n\nexport function divide(\n  num1: Numberish,\n  num2: Numberish,\n  optionsOrDecimals: AliasedOptions<{\n    decimals?: Decimals;\n    rounding?: Rounding;\n  }, \"decimals\"> = {},\n): Dnum {\n  const options = typeof optionsOrDecimals === \"number\"\n    ? { decimals: optionsOrDecimals }\n    : optionsOrDecimals;\n  options.rounding ??= \"ROUND_HALF\";\n\n  const [num1_, num2_] = normalizePairAndDecimals(num1, num2, options.decimals);\n  if (num2_[0] === 0n) {\n    throw new Error(\"dnum: division by zero\");\n  }\n  const value1 = setValueDecimals(\n    num1_[0],\n    Math.max(num1_[1], options.decimals ?? 0),\n  );\n  const value2 = setValueDecimals(num2_[0], 0);\n  return setDecimals(\n    [divideAndRound(value1, value2, options.rounding), num1_[1]],\n    options.decimals ?? (isDnum(num1) ? num1[1] : num1_[1]),\n    { rounding: options.rounding },\n  );\n}\n\nexport function remainder(\n  num1: Numberish,\n  num2: Numberish,\n  decimals?: Decimals,\n): Dnum {\n  const [num1_, num2_] = normalizePairAndDecimals(num1, num2);\n  return setDecimals(\n    [num1_[0] % num2_[0], num1_[1]],\n    decimals ?? (isDnum(num1) ? num1[1] : num1_[1]),\n  );\n}\n\nexport function compare(num1: Numberish, num2: Numberish): 1 | -1 | 0 {\n  const [num1_, num2_] = normalizePairAndDecimals(num1, num2);\n  return num1_[0] > num2_[0] ? 1 : num1_[0] < num2_[0] ? -1 : 0;\n}\n\nexport function equal(num1: Numberish, num2: Numberish): boolean {\n  const [num1_, num2_] = normalizePairAndDecimals(num1, num2);\n  return num1_[0] === num2_[0];\n}\n\nexport function greaterThan(num1: Numberish, num2: Numberish): boolean {\n  const [num1_, num2_] = normalizePairAndDecimals(num1, num2);\n  return num1_[0] > num2_[0];\n}\n\nexport function greaterThanOrEqual(num1: Numberish, num2: Numberish): boolean {\n  return !lessThan(num1, num2);\n}\n\nexport function lessThan(num1: Numberish, num2: Numberish): boolean {\n  const [num1_, num2_] = normalizePairAndDecimals(num1, num2);\n  return num1_[0] < num2_[0];\n}\n\nexport function lessThanOrEqual(num1: Numberish, num2: Numberish): boolean {\n  return !greaterThan(num1, num2);\n}\n\nexport function abs(num: Numberish, decimals?: Decimals): Dnum {\n  const [valueIn, decimalsIn] = from(num);\n  if (decimals === undefined) decimals = decimalsIn;\n\n  let valueAbs = valueIn;\n  if (valueAbs < 0n) {\n    valueAbs = -valueAbs;\n  }\n\n  return setDecimals([valueAbs, decimalsIn], decimals);\n}\n\nexport function floor(num: Numberish, decimals?: Decimals): Dnum {\n  return round(num, { decimals, rounding: \"ROUND_DOWN\" });\n}\n\nexport function ceil(num: Numberish, decimals?: Decimals): Dnum {\n  return round(num, { decimals, rounding: \"ROUND_UP\" });\n}\n\nexport function round(\n  num: Numberish,\n  optionsOrDecimals: AliasedOptions<{\n    decimals?: Decimals;\n    rounding?: Rounding;\n  }, \"decimals\"> = {},\n): Dnum {\n  const options = typeof optionsOrDecimals === \"number\"\n    ? { decimals: optionsOrDecimals }\n    : optionsOrDecimals;\n  options.rounding ??= \"ROUND_HALF\";\n\n  const numIn = from(num);\n  return setDecimals(\n    setDecimals(numIn, 0, { rounding: options.rounding }), // setDecimals() uses divideAndRound() internally\n    options.decimals === undefined ? numIn[1] : options.decimals,\n  );\n}\n\n// Converts a pair of Numberish into Dnum and equalize\n// their decimals based on the highest precision found.\nfunction normalizePairAndDecimals(\n  num1: Numberish,\n  num2: Numberish,\n  decimals?: number,\n) {\n  const num1_ = from(num1);\n  const num2_ = from(num2);\n\n  if (num1_[1] < 0 || num2_[1] < 0) {\n    throw new Error(\"dnum: decimals cannot be negative\");\n  }\n\n  return equalizeDecimals(\n    [num1_, num2_],\n    Math.max(num1_[1], num2_[1], decimals ?? 0),\n  );\n}\n","/**\n * @packageDocumentation\n *\n * This library defines common interfaces and low level building blocks for various interrelated multiformat technologies (multicodec, multihash, multibase, and CID). They can be used to implement custom base encoders / decoders / codecs, codec encoders /decoders and multihash hashers that comply to the interface that layers above assume.\n *\n * This library provides implementations for most basics and many others can be found in linked repositories.\n *\n * ```TypeScript\n * import { CID } from 'multiformats/cid'\n * import * as json from 'multiformats/codecs/json'\n * import { sha256 } from 'multiformats/hashes/sha2'\n *\n * const bytes = json.encode({ hello: 'world' })\n *\n * const hash = await sha256.digest(bytes)\n * const cid = CID.create(1, json.code, hash)\n * //> CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)\n * ```\n *\n * ## Creating Blocks\n *\n * ```TypeScript\n * import * as Block from 'multiformats/block'\n * import * as codec from '@ipld/dag-cbor'\n * import { sha256 as hasher } from 'multiformats/hashes/sha2'\n *\n * const value = { hello: 'world' }\n *\n * // encode a block\n * let block = await Block.encode({ value, codec, hasher })\n *\n * block.value // { hello: 'world' }\n * block.bytes // Uint8Array\n * block.cid   // CID() w/ sha2-256 hash address and dag-cbor codec\n *\n * // you can also decode blocks from their binary state\n * block = await Block.decode({ bytes: block.bytes, codec, hasher })\n *\n * // if you have the cid you can also verify the hash on decode\n * block = await Block.create({ bytes: block.bytes, cid: block.cid, codec, hasher })\n * ```\n *\n * ## Multibase Encoders / Decoders / Codecs\n *\n * CIDs can be serialized to string representation using multibase encoders that implement [`MultibaseEncoder`](https://github.com/multiformats/js-multiformats/blob/master/src/bases/interface.ts) interface. This library provides quite a few implementations that can be imported:\n *\n * ```TypeScript\n * import { base64 } from \"multiformats/bases/base64\"\n * cid.toString(base64.encoder)\n * //> 'mAYAEEiCTojlxqRTl6svwqNJRVM2jCcPBxy+7mRTUfGDzy2gViA'\n * ```\n *\n * Parsing CID string serialized CIDs requires multibase decoder that implements [`MultibaseDecoder`](https://github.com/multiformats/js-multiformats/blob/master/src/bases/interface.ts) interface. This library provides a decoder for every encoder it provides:\n *\n * ```TypeScript\n * CID.parse('mAYAEEiCTojlxqRTl6svwqNJRVM2jCcPBxy+7mRTUfGDzy2gViA', base64.decoder)\n * //> CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)\n * ```\n *\n * Dual of multibase encoder & decoder is defined as multibase codec and it exposes\n * them as `encoder` and `decoder` properties. For added convenience codecs also\n * implement `MultibaseEncoder` and `MultibaseDecoder` interfaces so they could be\n * used as either or both:\n *\n * ```TypeScript\n * cid.toString(base64)\n * CID.parse(cid.toString(base64), base64)\n * ```\n *\n * **Note:** CID implementation comes bundled with `base32` and `base58btc`\n * multibase codecs so that CIDs can be base serialized to (version specific)\n * default base encoding and parsed without having to supply base encoders/decoders:\n *\n * ```TypeScript\n * const v1 = CID.parse('bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea')\n * v1.toString()\n * //> 'bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea'\n *\n * const v0 = CID.parse('QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n')\n * v0.toString()\n * //> 'QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n'\n * v0.toV1().toString()\n * //> 'bafybeihdwdcefgh4dqkjv67uzcmw7ojee6xedzdetojuzjevtenxquvyku'\n * ```\n *\n * ## Multicodec Encoders / Decoders / Codecs\n *\n * This library defines [`BlockEncoder`, `BlockDecoder` and `BlockCodec` interfaces](https://github.com/multiformats/js-multiformats/blob/master/src/codecs/interface.ts).\n * Codec implementations should conform to the `BlockCodec` interface which implements both `BlockEncoder` and `BlockDecoder`.\n * Here is an example implementation of JSON `BlockCodec`.\n *\n * ```TypeScript\n * export const { name, code, encode, decode } = {\n *   name: 'json',\n *   code: 0x0200,\n *   encode: json => new TextEncoder().encode(JSON.stringify(json)),\n *   decode: bytes => JSON.parse(new TextDecoder().decode(bytes))\n * }\n * ```\n *\n * ## Multihash Hashers\n *\n * This library defines [`MultihashHasher` and `MultihashDigest` interfaces](https://github.com/multiformats/js-multiformats/blob/master/src/hashes/interface.ts) and convinient function for implementing them:\n *\n * ```TypeScript\n * import * as hasher from 'multiformats/hashes/hasher'\n *\n * const sha256 = hasher.from({\n *   // As per multiformats table\n *   // https://github.com/multiformats/multicodec/blob/master/table.csv#L9\n *   name: 'sha2-256',\n *   code: 0x12,\n *\n *   encode: (input) => new Uint8Array(crypto.createHash('sha256').update(input).digest())\n * })\n *\n * const hash = await sha256.digest(json.encode({ hello: 'world' }))\n * CID.create(1, json.code, hash)\n *\n * //> CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)\n * ```\n *\n * ## Traversal\n *\n * This library contains higher-order functions for traversing graphs of data easily.\n *\n * `walk()` walks through the links in each block of a DAG calling a user-supplied loader function for each one, in depth-first order with no duplicate block visits. The loader should return a `Block` object and can be used to inspect and collect block ordering for a full DAG walk. The loader should `throw` on error, and return `null` if a block should be skipped by `walk()`.\n *\n * ```TypeScript\n * import { walk } from 'multiformats/traversal'\n * import * as Block from 'multiformats/block'\n * import * as codec from 'multiformats/codecs/json'\n * import { sha256 as hasher } from 'multiformats/hashes/sha2'\n *\n * // build a DAG (a single block for this simple example)\n * const value = { hello: 'world' }\n * const block = await Block.encode({ value, codec, hasher })\n * const { cid } = block\n * console.log(cid)\n * //> CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)\n *\n * // create a loader function that also collects CIDs of blocks in\n * // their traversal order\n * const load = (cid, blocks) => async (cid) => {\n *   // fetch a block using its cid\n *   // e.g.: const block = await fetchBlockByCID(cid)\n *   blocks.push(cid)\n *   return block\n * }\n *\n * // collect blocks in this DAG starting from the root `cid`\n * const blocks = []\n * await walk({ cid, load: load(cid, blocks) })\n *\n * console.log(blocks)\n * //> [CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)]\n * ```\n *\n * ## Legacy interface\n *\n * [`blockcodec-to-ipld-format`](https://github.com/ipld/js-blockcodec-to-ipld-format) converts a multiformats [`BlockCodec`](https://github.com/multiformats/js-multiformats/blob/master/src/codecs/interface.ts#L21) into an\n * [`interface-ipld-format`](https://github.com/ipld/interface-ipld-format) for use with the [`ipld`](https://github.com/ipld/ipld) package. This can help bridge IPLD codecs implemented using the structure and interfaces defined here to existing code that assumes, or requires `interface-ipld-format`. This bridge also includes the relevant TypeScript definitions.\n *\n * ## Implementations\n *\n * By default, no base encodings (other than base32 & base58btc), hash functions,\n * or codec implementations are exposed by `multiformats`, you need to\n * import the ones you need yourself.\n *\n * ### Multibase codecs\n *\n * | bases                                                         | import                      | repo                                                                                              |\n * | ------------------------------------------------------------- | --------------------------- | ------------------------------------------------------------------------------------------------- |\n * | `base16`                                                      | `multiformats/bases/base16` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) |\n * | `base32`, `base32pad`, `base32hex`, `base32hexpad`, `base32z` | `multiformats/bases/base32` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) |\n * | `base64`, `base64pad`, `base64url`, `base64urlpad`            | `multiformats/bases/base64` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) |\n * | `base58btc`, `base58flick4`                                   | `multiformats/bases/base58` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) |\n *\n * Other (less useful) bases implemented in [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) include: `base2`, `base8`, `base10`, `base36` and `base256emoji`.\n *\n * ### Multihash hashers\n *\n * | hashes                                                                                                                          | import                         | repo                                                                                                               |\n * | ------------------------------------------------------------------------------------------------------------------------------- | ------------------------------ | ------------------------------------------------------------------------------------------------------------------ |\n * | `sha2-256`, `sha2-512`                                                                                                          | `multiformats/hashes/sha2`     | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/src/hashes)             |\n * | `sha3-224`, `sha3-256`, `sha3-384`,`sha3-512`, `shake-128`, `shake-256`, `keccak-224`, `keccak-256`, `keccak-384`, `keccak-512` | `@multiformats/sha3`           | [multiformats/js-sha3](https://github.com/multiformats/js-sha3)                                                    |\n * | `identity`                                                                                                                      | `multiformats/hashes/identity` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/src/hashes/identity.js) |\n * | `murmur3-128`, `murmur3-32`                                                                                                     | `@multiformats/murmur3`        | [multiformats/js-murmur3](https://github.com/multiformats/js-murmur3)                                              |\n * | `blake2b-*`, `blake2s-*`                                                                                                        | `@multiformats/blake2`         | [multiformats/js-blake2](https://github.com/multiformats/js-blake2)                                                |\n *\n * ### IPLD codecs (multicodec)\n *\n * | codec      | import                     | repo                                                                                                   |\n * | ---------- | -------------------------- | ------------------------------------------------------------------------------------------------------ |\n * | `raw`      | `multiformats/codecs/raw`  | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/src/codecs) |\n * | `json`     | `multiformats/codecs/json` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/src/codecs) |\n * | `dag-cbor` | `@ipld/dag-cbor`           | [ipld/js-dag-cbor](https://github.com/ipld/js-dag-cbor)                                                |\n * | `dag-json` | `@ipld/dag-json`           | [ipld/js-dag-json](https://github.com/ipld/js-dag-json)                                                |\n * | `dag-pb`   | `@ipld/dag-pb`             | [ipld/js-dag-pb](https://github.com/ipld/js-dag-pb)                                                    |\n * | `dag-jose` | `dag-jose`                 | [ceramicnetwork/js-dag-jose](https://github.com/ceramicnetwork/js-dag-jose)                            |\n */\n\nimport * as bytes from './bytes.js'\nimport { CID } from './cid.js'\nimport * as digest from './hashes/digest.js'\nimport * as hasher from './hashes/hasher.js'\nimport * as varint from './varint.js'\n\n// This way TS will also expose all the types from module\nexport * from './interface.js'\n\nexport { CID, hasher, digest, varint, bytes }\n"],"names":["num","digitsParts","fractionDigits","e","dividend","den","invertSign","divideAndRound","divisor","ceilToPower","value","fromExponential","parts","fraction","decimals","whole","powerOfTen","negative","decimalsDiff","options","nums","fractionValue","trailingZeros","optionsOrDigits","v","roundsToZero","wholeString","formatSign","locale","decimalsSeparator","dnum","signDisplay","num1_","num2","multiply","num1","value2","setDecimals","isDnum","compare","equal","greaterThan","lessThan","normalizePairAndDecimals","num2_","valueIn","valueAbs","decimalsIn","floor","optionsOrDecimals","equalizeDecimals"],"mappings":"8C4FqVQ,QARF,QACmB,CjFwRO,gMqFtlBc,ClBgCC,AmBnCvC,ACCyC,yFFSf,iDa+b3B,IAAA,EAAyB,qBACP,OAAA,EAAA,CAAY,CnGmeH,CAAA,cmGneoB,EpE4cvB,UoE5cmC,CAAE,OAE1D,oBACI,MACJ,8BACI,CAAE,KAAA,GAAU,aAAc,UAAW,CnGqeP,CAAC,CAAA,CmGreU,CAAE,SAAS,CAAE,CAAC,iBAChD,CU2dC,OVzdpB,0BAEY,CACV,CtB2TyC,IsB3TnC,kCACG,CAAC,CkBiJG,KlBjJK,gBAAkB,UAAW,IAAI,CAAE,SAAS,CAAE,CAAC,+BAI3D,kBACE,EAAA,CACR,KAAM,gCACG,EAAG,ChCiLqB,IgCjLf,ChCiLoB,AnEyTrB,emG1emB,CnG0eW,cmG1eM,4BACpC,ChCiLG,QgC9KpB,CpEqeG,IAAA,kBoEpeK,eACW,GpEqeK,UAAA,kBoEre4B,IAAI,CAAE,SAAS,CAAE,EACjE,KAAM,QAAS,aAAc,UAAW,KAAA,WAC3C,CACD,KAAM,mBACG,CACP,CAAE,KAAA,QAAe,GpE4eK,UoE5eS,UAAW,IpE4eM,AoE5eF,CpE4esB,AoE5epB,SAAS,CAAE,CAC3D,MAAQ,gBAAiB,aAAc,SAAS,CAAE,CpE8eG,CAAA,EoE9eC,CAAE,KnGmfG,ImGnfM,CAAE,OAC3D,GnGkfmE,CAAC,CAAA,QmGlftD,aAAc,UAAW,CnGqfD,ImGrfO,iBAC7C,mCAAqC,CpE8eW,SoE9eA,IAAI,CAAE,GpE8ea,CAAC,CAAA,IoE9eL,CAAE,kBAE1D,EpE+eA,A8EQF,MVrfjB,CACE,IAAI,CAAE,WACN,CpEqfG,MAAA,CoEpfD,CUufC,KVvfO,qBAAuB,kBAAmB,CpEqfG,CAAA,EoErfC,CAAE,SAAS,CAAE,OAE/D,sBACG,EACL,KAAM,ChCyLK,YgCzLS,ChCyLI,YgCzLU,SAAU,KAAA,QAAc,CAAE,OACtD,GUsf8D,sBVtfnC,UAAW,KAAA,SAAe,CAAE,CAChE,iBACgB,MAAM,AhCyLA,QgCtLjB,WACN,OAAA,8CACoD,IAAI,AsBiME,CtBjMA,SAAS,CAAE,OAC3D,YAAa,aAAc,CnGkgBD,CAAC,QmGlgBW,IAAI,CUkhBC,AVlhBC,CUkhBA,M7GhBK,EmGlgBI,CAAE,mBAC1C,aAAc,UAAW,IAAI,CAAE,SnGmgBZ,AmGngBqB,EAC9D,MACK,sBACG,EAAA,4BAGX,MACQ,GnGygBC,QmGxgBP,CpEkhBG,A8EUF,MAAA,CV3hBC,MAAQ,qBAAuB,kBAAmB,CpEkhBG,CAAA,EoElhBC,CAAE,SAAS,CAAE,CACnE,aAAgB,aAAA,UAAyB,CsB8LG,AzH2UN,CyH3UO,GAAA,YtB7L3C,KAAM,CpEkhBG,iBoElhBiB,SAAS,CAAE,IAAI,CAAE,GsB8LG,MtB9LM,CAAE,EACtD,KAAA,YAAmB,aAAc,GU8hBG,OV9hBQ,IAAI,CAAE,SAAS,GAC3D,KAAM,IU+hBI,gBV/hBiB,aAAc,eAAiB,SAAS,CAAE,EACrE,KAAM,EU+hBA,oBV/hBuB,aAAc,UAAW,IAAI,CAAE,SAAS,CAAE,CAC1E,MACK,qBACG,CAAC,CAAE,IAAI,CAAA,GAAM,aAAc,KsBoLiB,ItBpLR,CAAE,EpEkiBE,EoEliBE,CAAE,SAAS,CAAE,CAAC,+BAGnE,ChC0MC,yBgCvMK,KAAA,qBAA6B,kBAAmB,IAAI,CAAE,SAAS,CAAE,EACjE,KAAM,KAAM,EUoiBI,A5BhYA,WAAA,UkBpKqB,KAAA,SAAe,CAAE,EACtD,KAAA,sBAA8B,GUqiBb,OVriBwB,IAAI,CAAE,KUsiB9B,IVtiBuC,CAAE,GnGwgBD,sBmGrgBpD,EAAE,iBACM,iBAGX,WACN,OAAA,EACI,KAAM,QAAS,aAAc,oBAAqB,IAAI,CAAE,SAAS,CAAE,OAC7D,IAAI,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,AsB4LM,CtB5LJ,SAAS,CAAE,CACxD,CAAE,IAAI,CAAE,QAAQ,CAAE,KhCmNY,AsDvBA,OtB5LA,CAAA,UAAa,IAAI,ChCmNO,AsDvBA,AtB5LL,SAAS,CAAE,CAC5D,CAAE,KAAA,aAAoB,aAAc,UAAW,IAAI,CAAE,SAAS,CAAE,OACxD,qCAAwC,KAAA,YAC9C,KAAM,qBAAuB,eAAiB,YAC9C,KAAM,CkBuLG,CAAA,ClBvLA,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,EACjD,KAAM,GAAG,CAAE,aAAc,UAAW,IAAI,CAAE,SAAS,CAAE,EACrD,KAAM,IAAK,aAAc,SAAS,CAAE,KAAM,SAAS,CAAE,CACxD,MACK,sDAEW,YAAY,EAE/B,CACE,InGkiBI,AmGliBA,CAAE,EsByLM,CzHyWH,QmGjiBT,OAAA,EACI,KAAM,qBAAuB,oBAAqB,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,KAAM,CnGkiBG,CAAA,AyHrWG,EtB7LF,cAAgB,GsB6LkC,OtB7LvB,IAAI,CAAE,SAAS,CAAE,CACxD,CAAE,IAAI,CAAE,GsB6LO,MtB7LG,KsB6LoB,QtB7LN,KsB6LoB,KtB7LT,CsB6LgB,IAAA,StB7LD,CAAE,CAC5D,CAAE,KAAA,aAAoB,OsB8LW,MAAA,UtB9Lc,IAAI,CAAE,SAAS,CAAE,EAC9D,KAAM,cAAe,aAAc,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,EAC/D,GsB8LG,CtB9LC,CnG8iBA,AmG9iBE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,EsB8LE,GtB9LI,GAAG,AsB8LA,CtB9LE,aAAc,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,OAC3C,GAAG,AsB8LA,CtB9LE,aAAA,UAAyB,IAAI,CAAE,SAAS,CAAE,EACrD,GsB8LG,CtB9LC,CAAE,IAAK,aAAc,InG8iBM,WmG9iBW,SAAS,CAAE,CACvD,MAAQ,WAAY,CnG+iBG,YmG/iBW,UAAW,IAAI,CAAE,SAAS,CAAE,CAC9D,sBAAyB,CnG+iBG,CAAA,UmG/iBS,CAAE,SAAS,MAAQ,SAAS,CAAE,EACjE,IAAI,AnG+iBE,CmG/iBA,kBAAmB,aAAc,eAAiB,SAAS,CAAE,EACnE,KAAM,kBAAmB,aAAc,eAAiB,IhCkOE,KgClOO,CAAE,CACtE,MACK,EkB2LwE,mDlB1LrE,EAAE,CACX,gBAAA,eAGA,KAAM,CsB4MG,iBtB3MD,CACN,CAAE,KAAM,OAAO,CAAE,YAAY,CAAE,mBAAmB,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,KAAM,KAAM,CsBsNO,YtBtNO,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxD,CAAE,KAAM,qCAAyC,SAAS,CAAE,CAC5D,gCAAoC,UAAW,KAAM,SAAS,CAAE,CAChE,CAAE,KAAM,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,4BAClC,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,EACzD,EsB4NE,CAAC,CtB5NC,CnGqjBC,AmGrjBC,IAAK,CsB4NC,YtB5Na,QAAS,GsB4NG,CtB5NC,CAAE,OAAO,CAAE,CsB4NC,CtB3NlD,IAAI,AnGqjBA,CmGrjBE,IAAK,MnGqjBM,CAAA,KmGrjBM,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvD,CAAE,KAAM,GAAG,CsB6NK,AtB7NH,aAAc,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvD,MAAQ,CsB6NG,UtB7NS,aAAA,UAAyB,IAAI,CAAE,SAAS,CAAE,CAC9D,CsB6NG,6BtB3ND,aAAA,UACA,KAAM,GsB8NS,MtB9NA,ChC6NU,OgC1NnB,0BACN,QkB4LY,KlB5LE,SAAS,CACvB,IAAI,CAAE,WAET,CACD,KAAM,EsBiOI,EJzCgD,0DlBvLjD,EAAA,qCAIH,WACN,OAAQ,EACJ,EsBkOE,CAAC,CtBlOC,CAAE,MsBkOM,EtBlOG,WsBmOF,CtBnOc,AsBmOb,CtBnOe,IsBmOT,8BtBlOtB,MAAQ,CnG4jBG,ImG5jBG,aAAc,UAAW,KAAM,CnG4jBG,CAAC,SmG3jBjD,CAAE,IAAI,CAAE,KnG4jBO,ImG5jBG,aAAc,SAAS,CAAE,KAAM,SAAS,CAAE,kBACxC,aAAc,UAAW,KAAM,OnG6jBS,EmG7jBA,CAAE,CAC9D,CAAE,IAAI,CAAE,GAAG,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CACnD,CAAE,EsBkPQ,EzHiVA,AmGnkBJ,CAAE,GAAG,CAAE,aAAc,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvD,MAAQ,GAAG,CAAE,GnGmkBK,UmGnkBS,EnGmkBI,QmGnkBO,CnGmkBG,CAAA,GmGnkBG,SAAS,CAAE,CACxD,CACD,KAAM,CsBwPG,2BtBvPA,EAAE,EsBwPI,etBvPE,KkBwLU,CIgEF,CAAC,CtD3BI,YgC1NxB,mBAEJ,CAAE,IsB0PQ,AtB1PJ,CAAE,InGmkBI,CAAA,GmGnkBK,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,EACjE,IAAI,CAAE,KAAM,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,EACtD,KAAM,QAAQ,wBAA2B,IAAI,CAAE,SAAS,CAAE,EAC1D,IAAI,CAAE,CnGglBK,uBmGhlBqB,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,EAC5D,KAAM,GAAG,CAAE,aAAc,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,EACjD,KAAM,IAAK,CsBiQG,GzH+UC,SmGhlBU,OnGglBO,GmGhlBI,IAAI,CAAE,KnGglBK,ImGhlBI,CAAE,EACrD,KAAM,GsBiQK,AtBjQF,CAAE,KnG+kB0D,CAAC,CAAA,KmG/kB/C,CAAE,MhCmNoB,GgCnNX,CAAE,IAAI,CAAE,SAAS,CAAE,OAC/C,KsBiQO,GzH+UG,EmGhlBA,CAAE,SnGglBW,ImGhlBG,InGglBM,CAAC,CAAA,GmGhlBE,CAAE,IAAI,CAAE,SAAS,CAAE,EAC5D,IAAI,CAAE,6BAA+B,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,EACjE,KAAM,kBAAmB,OnGglBO,MmGhlBO,QnGglBQ,CmGhlBC,CAAE,IAAI,CAAE,SAAS,CAAE,EACnE,IAAI,CAAE,EnG+kBsE,CAAC,CAAA,cmG/kBpD,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,KAAM,sCACN,QAAA,EAAW,CACX,gBAAiB,aAClB,CACD,CACE,IAAI,CAAE,WACN,OAAQ,CACN,CAAE,KAAM,QAAS,EkB+LP,WlB/LqB,CkB+LR,CAAC,gBlB/L0B,IAAI,CAAE,AkBgMxD,SlBhMiE,CAAE,CACnE,CAAE,KAAM,IAAI,CAAE,aAAc,UAAW,IAAI,CAAE,SAAS,CAAE,CACxD,CAAE,IAAI,CAAE,CnGqlBG,QmGrlBO,ChC0NQ,YgC1NM,EhC0NQ,CAAC,OgC1NE,ChC0NO,GgC1NH,CAAE,SAAS,CAAE,CAC5D,CAAE,KAAM,WAAY,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,WACjD,aAAc,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,EACjD,AhC4NiD,IgC5N7C,CAAE,EnGulBI,CmGvlBD,ChC8NG,agC9Na,SAAS,CAAE,IAAI,AkBiLc,ClD6CX,SgC9NQ,CAAE,CACvD,CAAE,IAAI,CAAE,GAAG,CnGulBG,AmGvlBD,aAAc,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,EACrD,KAAM,wBAA0B,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACE,IAAI,CAAE,wBACN,EnGylBM,WmGzlBQ,SAAS,CACvB,KAAM,SAAS,AnGylBE,EmGvlBnB,CACE,InG2lBE,AmG3lBE,CnG2lBD,0BmG1lBH,aAAA,UACA,IAAI,CAAE,UACP,CACF,CACD,IAAI,CAAE,+CACN,QAAS,EAAE,CnG2lBL,AmG1lBN,CnG0lBO,emG1lBU,aAClB,CACD,CACE,IAAI,CAAE,kBACE,CnG8lBH,AmG7lBH,CAAE,KAAM,QAAS,ChC0NQ,YgC1NM,EhC0NQ,CAAC,AnEoYR,emG9lBkB,KAAM,SAAS,CAAE,CACnE,CAAE,AnGimBD,KmGjmBO,QAAS,aAAc,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,MACK,kCACG,CACP,CAAE,IAAI,CAAA,mBAAsB,aAAc,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CAAE,IAAI,CAAA,eAAkB,YAAY,CAAE,eAAiB,SAAS,CAAE,EAChE,IAAI,CAAE,iBAAkB,IhCoNkB,QgCpNN,AnGymBN,CmGzmBQ,UAAW,CnGymBL,ImGzmBW,SAAS,CAAE,CACpE,CAAE,IAAI,CAAE,oBAAqB,InGymBF,SmGzmBgB,SAAS,CAAE,EnGymBJ,EmGzmBQ,CAAE,SAAS,CAAE,CnGymBL,AmGxmBnE,CACD,eAAe,CAAE,QAEnB,CACE,IAAI,CAAE,WACN,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,MnGmnBF,OmGnnBgB,CnGmnBP,SmGnnBkB,GnGmnBL,CAAC,AmGnnBQ,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,InGknBkE,KmGlnBzD,CACf,OAAO,CAAE,CACP,CACE,IAAI,CAAE,EAAE,CACR,aAAc,+BAA+B,CAC7C,KAAM,OAAO,CACb,WAAY,CACV,CAAE,KAAM,GnG2nBC,kBmG3nBsB,IhCyNc,CAAC,SAAS,GgCzNP,CAAE,IAAI,CAAE,SAAS,CAAE,EACjE,KAAM,MnG0nBsE,CAAC,AmG1nB/D,CnG0nB+D,YmG1nBjD,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,KAAM,GhCiOF,CgCjOM,CAAE,aAAc,QhCiOG,CAAC,AgCjOK,CAAE,AhCiON,IgCjOU,CAAE,EhCkOjD,OgClO0D,CAAE,CACxD,CAAE,IAAI,CAAE,WAAY,aAAc,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,KAAM,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,KAAM,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CAAE,IAAI,CAAE,CnG4nBK,amG5nBU,ShCmN2B,GgCnNf,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,GnG4nBO,WmG5nBQ,EnG4nBM,UmG5nBM,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,EnG4nBM,EmG5nBF,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACE,IAAI,CnG4nBO,AmG5nBL,mBAAmB,CACzB,YAAY,CAAE,AnG4nBK,SmG5nBI,CACvB,EnG4nBQ,EmG5nBJ,CAAE,SAAS,EAEjB,CACE,IAAI,CAAE,qBAAqB,CAC3B,aAAc,SAAS,CACvB,IAAI,CnGkoBO,WmGhoBd,EAEJ,CACD,gBAAiB,MAAM,CACxB,CACD,CACE,IAAI,CAAE,kBACE,EACJ,IAAI,CAAE,QAAS,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,EACzD,IAAI,CAAE,QAAS,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,EACjE,IAAI,CAAE,SAAU,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,EAC1D,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,ShCsNuB,AgCtNd,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,ChCoNwD,GgCpNpD,CAAE,0BAA0B,CAChC,OAAO,CAAE,CACP,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,iCAAiC,CAC/C,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAC5D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACF,CACD,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,IAAI,CAAE,0BAA0B,CAChC,OAAO,CAAE,CACP,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,iCAAiC,CAC/C,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAC5D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACF,CACD,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACE,IAAI,CAAE,uBAAuB,CAC7B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CACE,IAAI,CAAE,yBAAyB,CAC/B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACD,IAAI,CAAE,0BAA0B,CAChC,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CACD,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAC1D,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACxD,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CACD,IAAI,CAAE,YAAY,CAClB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,oBAAoB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxE,CAAE,IAAI,CAAE,qBAAqB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACzE,CACE,IAAI,CAAE,yBAAyB,CAC/B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACzD,CACD,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,uCAAuC,CAC7C,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,oBAAoB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxE,CAAE,IAAI,CAAE,qBAAqB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACzE,CACE,IAAI,CAAE,yBAAyB,CAC/B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACzD,CACD,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,UAAU,CAChB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,IAAI,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxD,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,YAAY,CAClB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,iBAAiB,CAC/B,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,eAAe,CACrB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,qBAAqB,CAC3B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACF,CAFiB,AAGlB,IAAI,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,iBAAiB,CAC/B,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAEb,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,OAAO,EAAE,CAAI,CAAE,CACzE,CADuE,AACrE,IAAI,CAAE,IAAI,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,OAAO,EAAE,CAAI,CAAE,CACvE,CADqE,AAEnE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACF,CAFiB,AAGlB,IAAI,CAAE,iBAAiB,CACxB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,iBAAiB,CAC/B,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CADc,AAEf,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAEb,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,OAAO,EAAE,CAAK,CAAE,CACxE,CACE,CAFoE,GAEhE,CAAE,eAAe,CACrB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACD,CAFgB,AAGd,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,yBAAyB,CAChC,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CADc,AAEf,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,AAHa,IAGT,CAAE,OAAO,CACb,YAAY,CAAE,iBAAiB,CAC/B,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACD,CAFgB,AAGd,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,qBAAqB,CAC3B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,mBAAmB,CACzB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,aAAa,CACpB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,eAAe,CACtB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,oBAAoB,CAC3B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACD,CAFgB,AAGd,IAAI,CAAE,oBAAoB,CAC1B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,6BAA6B,CACpC,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,SAAS,CACf,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,CAAE,GACX,EADgB,IACV,CAAE,CACN,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,oBAAoB,CAC1B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,qBAAqB,CAC3B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,oBAAoB,CAC1B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACD,CAFgB,AAGd,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,aAAa,CACpB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAEb,IAAI,CAAE,IAAI,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,OAAO,EAAE,CAAI,CAAE,CACvE,CACE,AAFmE,IAE/D,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,gBAAgB,CACvB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,iBAAiB,CAC/B,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAAE,AAFa,IAET,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,OAAO,EAAE,CAAI,CAAE,CACzE,CADuE,AACrE,IAAI,CAAE,IAAI,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,OAAO,EAAE,CAAI,CAAE,CACvE,CADqE,AAEnE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,oBAAoB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxE,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CACD,IAAI,CAAE,0CAA0C,CACjD,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,0BAA0B,CACjC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CACD,IAAI,CAAE,0CAA0C,CACjD,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CACD,IAAI,CAAE,gCAAgC,CACvC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,IAAI,CAAE,2BAA2B,CAClC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,oCAAoC,CAC3C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,gCAAgC,CACvC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,iCAAiC,CACxC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CACD,IAAI,CAAE,gCAAgC,CACvC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACD,IAAI,CAAE,2BAA2B,CAClC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CACE,IAAI,CAAE,0BAA0B,CAChC,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,6BAA6B,CACpC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACE,IAAI,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACD,IAAI,CAAE,mCAAmC,CAC1C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CACD,IAAI,CAAE,6BAA6B,CACpC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CACE,IAAI,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACD,IAAI,CAAE,qDAAqD,CAC5D,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CACD,IAAI,CAAE,2CAA2C,CAClD,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CACD,IAAI,CAAE,sCAAsC,CAC7C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,oBAAoB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxE,CACE,IAAI,CAAE,uBAAuB,CAC7B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACD,IAAI,CAAE,oDAAoD,CAC3D,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,kBAAkB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,IAAI,CAAE,oCAAoC,CAC3C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CACD,IAAI,CAAE,wBAAwB,CAC/B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACD,IAAI,CAAE,2BAA2B,CAClC,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,4BAA4B,CAAE,CACjE,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CACD,IAAI,CAAE,2BAA2B,CAClC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACpE,IAAI,CAAE,wBAAwB,CAC/B,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,yBAAyB,CAAE,CAC9D,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,IAAI,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxD,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,qBAAqB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACzE,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxE,CACD,IAAI,CAAE,wBAAwB,CAC/B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,8BAA8B,CACrC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,6BAA6B,CACpC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,yBAAyB,CAChC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,iCAAiC,CACxC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,qBAAqB,CAC5B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,+BAA+B,CACtC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,GAAG,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvD,CAAE,IAAI,CAAE,GAAG,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvD,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CACD,IAAI,CAAE,yBAAyB,CAChC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,GAAG,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,IAAI,CAAE,kCAAkC,CACzC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,mBAAmB,CAC1B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,sCAAsC,CAC7C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,yBAAyB,CAChC,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,8BAA8B,CAAE,CACnE,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,0BAA0B,CACjC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACD,IAAI,CAAE,uCAAuC,CAC9C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,oCAAoC,CAC3C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CACD,IAAI,CAAE,kCAAkC,CACzC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACD,IAAI,CAAE,sCAAsC,CAC7C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CACrE,IAAI,CAAE,uBAAuB,CAC9B,CACO,CAAA,AAm+CG,EAAyC,CACpD,CACE,IAAI,CAAE,aAAa,CACnB,MAAM,CAAE,CACN,CACE,IAAI,CAAE,CALqC,SAK3B,CAChB,YAAY,CAAE,qCAAqC,CACnD,IAAI,CAAE,SAAS,CAChB,CACF,CACD,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,iBAAiB,CACvB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,gBAAgB,CACtB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACrE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,IAAI,CAAE,cAAc,CACpB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,0BAA0B,CAChC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,uBAAuB,CAC7B,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,UAAU,CAAE,IAAI,CAAE,UAAU,CAAE,CAC5D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,UAAU,CAAE,IAAI,CAAE,UAAU,CAAE,CAC/D,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACD,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,UAAU,CAAE,IAAI,CAAE,UAAU,CAAE,CAC5D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,UAAU,CAAE,IAAI,CAAE,UAAU,CAAE,CAC/D,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,IAAI,CAAE,sBAAsB,CAC5B,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACtE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,4BAA4B,CAClC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,uBAAuB,CAC7B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,qDAAqD,CACnE,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACF,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,YAAY,CAClB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,MAAM,CACZ,YAAY,CAAE,mDAAmD,CACjE,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACF,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,KAAK,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CACD,IAAI,CAAE,oBAAoB,CAC1B,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACtD,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC1D,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,uBAAuB,CAC7B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,+CAA+C,CAC7D,IAAI,CAAE,OAAO,CACd,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,cAAc,CACpB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,kBAAkB,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACpE,CAAE,IAAI,CAAE,qBAAqB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACzE,CAAE,IAAI,CAAE,oBAAoB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxE,CACE,IAAI,CAAE,0BAA0B,CAChC,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,KAAK,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CACD,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACtD,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC1D,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC1E,IAAI,CAAE,oBAAoB,CAC1B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAAC,CAC3D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,6BAA6B,CACnC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,aAAa,CACnB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,oBAAoB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxE,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC/D,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAAC,CAC3D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAAC,CAC3D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,iBAAiB,CACvB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,CACP,CACE,IAAI,CAAE,EAAE,CACR,YAAY,CAAE,qCAAqC,CACnD,IAAI,CAAE,SAAS,CAChB,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,sBAAsB,CAC5B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,6BAA6B,CACpC,CACO,CAAA,AA4BG,EAAiB,CAC5B,CAAE,IAAI,CAAE,KADiB,QACJ,CAAE,MAAM,CAAE,EAAE,CAAE,eAAe,CAAE,YAAY,CAAE,CAClE,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,uBAAuB,CAC7B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,iBAAiB,CACvB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,mBAAmB,CACjC,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAAC,CACrE,CACD,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAC5D,CACD,IAAI,CAAE,WAAW,CACjB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,SAAS,CAC3B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,0BAA0B,CAChC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAC5D,CACD,IAAI,CAAE,6BAA6B,CACnC,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAC5D,CACD,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,SAAS,CAC3B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,aAAa,CACnB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAAC,CAC3D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAC5D,CACD,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,WAAW,CACjB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACrE,CACD,IAAI,CAAE,cAAc,CACpB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,EAAE,CACR,YAAY,CAAE,qCAAqC,CACnD,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACF,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,IAAI,CAAE,iBAAiB,CACvB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,mBAAmB,CACjC,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAAC,CACrE,CACD,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CAClE,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACxD,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,sBAAsB,CAC5B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,oBAAoB,CAC1B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtD,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvD,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,uBAAuB,CAC7B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,gBAAgB,CACtB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACD,IAAI,CAAE,aAAa,CACnB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,EAAE,CACR,YAAY,CAAE,iBAAiB,CAC/B,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAAC,CACrE,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACD,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,sBAAsB,CAC5B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CAAC,CACrE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,oBAAoB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACzE,CACD,IAAI,CAAE,YAAY,CAClB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAC5D,CACD,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,OAAO,CACb,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACD,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAAC,CAC3D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACD,IAAI,CAAE,WAAW,CACjB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAAC,CAC3D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,oBAAoB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACzE,CACD,IAAI,CAAE,+BAA+B,CACrC,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,0BAA0B,CACxC,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CAChE,CACF,CACF,CACD,IAAI,CAAE,iBAAiB,CACvB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,SAAS,CAC3B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CAClE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAC5D,CACD,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACxE,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CACD,IAAI,CAAE,gBAAgB,CACtB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CACvD,CACD,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,SAAS,CAC3B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,QAAQ,CACtB,IAAI,CAAE,QAAQ,CACd,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,gBAAgB,CACvB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,CAAE,GACX,EADgB,IACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,AAHa,IAGT,CAAE,kBAAkB,CACxB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,gBAAgB,CACvB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,cAAc,CACrB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,eAAe,CACrB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,mBAAmB,CAC1B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,QAAQ,CACtB,IAAI,CAAE,QAAQ,CACd,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,aAAa,CACpB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,AAHa,IAGT,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,mBAAmB,CAC1B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,eAAe,CACrB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,WAAW,CACzB,IAAI,CAAE,WAAW,CACjB,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,WAAW,CACjB,YAAY,CAAE,mBAAmB,CACjC,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAAC,CACpE,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,aAAa,CACpB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,WAAW,CACzB,IAAI,CAAE,WAAW,CACjB,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,eAAe,CACtB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,qCAAqC,CACnD,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAEb,IAAI,CAAE,KAAK,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,OAAO,EAAE,CAAK,CAAE,CAC1E,CACD,CAFyE,GAErE,CAAE,cAAc,CACrB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,oBAAoB,CAC1B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,AAHa,IAGT,CAAE,oBAAoB,CAC1B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,wBAAwB,CAC/B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,UAAU,CACjB,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,8BAA8B,CACrC,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,mBAAmB,CAAE,CACxD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,YAAY,CAAE,CACjD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,KAAK,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACzD,CAAE,IAAI,CAAE,KAAK,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CACD,IAAI,CAAE,cAAc,CACrB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,uBAAuB,CAAE,CAC5D,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,iBAAiB,CAAE,CACtD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,qBAAqB,CAC5B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACvE,IAAI,CAAE,4BAA4B,CACnC,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,6BAA6B,CAAE,CAClE,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACpE,IAAI,CAAE,8BAA8B,CACrC,CACO,CAAA,AA4BG,EAA6B,CACxC,CAAE,IAAI,CAAE,aAAa,CAAE,GADc,GACR,CAAE,EAAE,CAAE,eAAe,CAAE,YAAY,CAAE,CAClE,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,6BAA6B,CACnC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACF,CACD,IAAI,CAAE,gCAAgC,CACtC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACD,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,UAAU,CAAE,IAAI,CAAE,UAAU,CAAE,CACtE,CAAE,IAAI,CAAE,kBAAkB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CACD,IAAI,CAAE,YAAY,CAClB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC3E,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,cAAc,CACpB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC1D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC3D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACrE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,IAAI,CAAE,uBAAuB,CAC7B,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACrE,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACxD,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACF,CACD,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACxD,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,UAAU,CAAE,IAAI,CAAE,UAAU,CAAE,CAC5D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACD,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,UAAU,CAAE,IAAI,CAAE,UAAU,CAAE,CAC7D,CACD,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACvE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC1E,IAAI,CAAE,aAAa,CACnB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,MAAM,CACZ,YAAY,CAAE,wDAAwD,CACtE,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,MAAM,CACZ,YAAY,CACV,2DAA2D,CAC7D,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CACF,CACF,CACF,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,IAAI,CAAE,sBAAsB,CAC5B,OAAO,CAAE,CACP,CACE,IAAI,CAAE,MAAM,CACZ,YAAY,CAAE,wDAAwD,CACtE,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,MAAM,CACZ,YAAY,CACV,2DAA2D,CAC7D,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CACF,CACF,CACF,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC1E,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACF,CACD,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,CACP,CACE,IAAI,CAAE,EAAE,CACR,YAAY,CACV,2DAA2D,CAC7D,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,cAAc,CACpB,YAAY,CACV,2DAA2D,CAC7D,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CACF,CACD,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CACV,sDAAsD,CACxD,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACD,CACE,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,UAAU,CACxB,IAAI,CAAE,UAAU,CACjB,CACD,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CACF,CACD,CACE,IAAI,CAAE,yBAAyB,CAC/B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACF,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACtE,CACD,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,eAAe,CACrB,YAAY,CACV,0DAA0D,CAC5D,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,MAAM,CACZ,YAAY,CACV,2DAA2D,CAC7D,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CACF,CACF,CACF,CACD,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC7D,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACD,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAC1D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,CACP,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CACV,0DAA0D,CAC5D,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CACV,6DAA6D,CAC/D,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,cAAc,CACpB,YAAY,CACV,2DAA2D,CAC7D,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,QAAQ,CACtB,IAAI,CAAE,QAAQ,CACf,CACD,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CACF,CACD,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CACV,sDAAsD,CACxD,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CACV,iDAAiD,CACnD,IAAI,CAAE,OAAO,CACd,CACD,CACE,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,UAAU,CACxB,IAAI,CAAE,UAAU,CACjB,CACD,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CACF,CACD,CACE,IAAI,CAAE,yBAAyB,CAC/B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACF,CACD,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACxD,CACF,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,YAAY,CAClB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC1E,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAAC,CAC3D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACxE,IAAI,CAAE,sBAAsB,CAC5B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAAC,CAC3D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CACxE,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,OAAO,CACb,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACD,CAAE,IAAI,CAAE,KAAK,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CACD,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAAC,CAClE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACF,CACD,IAAI,CAAE,0BAA0B,CAChC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACF,CACD,IAAI,CAAE,oBAAoB,CAC1B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CAAC,CAC3D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACF,CACD,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACD,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC1E,IAAI,CAAE,WAAW,CACjB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,MAAM,CAAE,IAAI,CAAE,MAAM,CAAE,CACzD,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC/D,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACD,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,UAAU,CAAE,IAAI,CAAE,UAAU,CAAE,CACtE,CAAE,IAAI,CAAE,kBAAkB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CACD,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC3E,eAAe,CAAE,SAAS,CAC3B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACF,CACD,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,gBAAgB,CACtB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACxE,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACD,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,UAAU,CAAE,IAAI,CAAE,UAAU,CAAE,CACtE,CAAE,IAAI,CAAE,kBAAkB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CACD,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAChE,CACD,IAAI,CAAE,oBAAoB,CAC1B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CACvD,CACD,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,SAAS,CAC3B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,QAAQ,CACtB,IAAI,CAAE,QAAQ,CACd,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,kBAAkB,CACzB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,SAAS,EAAE,EAAO,GAAF,GAAQ,CAAE,EAAE,CAAE,IAAI,CAAE,qBAAqB,CAAE,CAC5E,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,QAAQ,CACtB,IAAI,CAAE,QAAQ,CACd,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,aAAa,CACpB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,eAAe,CACrB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CADc,AAEf,CACE,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACb,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACD,CAFgB,AAGd,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,UAAU,CACxB,IAAI,CAAE,UAAU,CAChB,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,kBAAkB,CACxB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,cAAc,CACrB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACb,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,gBAAgB,CACvB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACb,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,gBAAgB,CACtB,YAAY,CAAE,UAAU,CACxB,IAAI,CAAE,UAAU,CAChB,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,kBAAkB,CACxB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACF,CAFiB,AAGlB,IAAI,CAAE,gBAAgB,CACvB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACF,AAFgB,CAGjB,IAAI,CAAE,qBAAqB,CAC5B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,AAHa,IAGT,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,oBAAoB,CAC3B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,CAAE,GACX,EADgB,IACV,CAAE,CACN,CACE,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,iBAAiB,CACxB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,CAAE,GACX,EADgB,IACV,CAAE,CACN,CACE,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,UAAU,CACjB,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,8BAA8B,CACrC,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,mBAAmB,CAAE,CACxD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,YAAY,CAAE,CACjD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CACE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,iDAAiD,CAC/D,IAAI,CAAE,OAAO,CACd,CACF,CACD,IAAI,CAAE,oCAAoC,CAC3C,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,uBAAuB,CAAE,CAC5D,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,iBAAiB,CAAE,CACtD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,qBAAqB,CAC5B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACvE,IAAI,CAAE,4BAA4B,CACnC,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,6BAA6B,CAAE,CAClE,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACpE,IAAI,CAAE,8BAA8B,CACrC,CACO,CAAA,GA54GR,CACE,IAAI,CAAE,aAAa,CACnB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,qBAAqB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACzE,CACE,IAAI,CAAE,0BAA0B,CAChC,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,yBAAyB,CACvC,IAAI,CAAE,SAAS,CAChB,CACD,CACE,IAAI,CAAE,4BAA4B,CAClC,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CACE,IAAI,CAAE,0BAA0B,CAChC,YAAY,CAAE,kCAAkC,CAChD,IAAI,CAAE,SAAS,CAChB,CACD,CACE,IAAI,CAAE,qBAAqB,CAC3B,YAAY,CAAE,6BAA6B,CAC3C,IAAI,CAAE,SAAS,CAChB,CACF,CACD,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAAC,CAC/D,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC1E,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CACE,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,kDAAkD,CAChE,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,oBAAoB,CAC1B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC/D,CACF,CACF,CACD,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC1E,IAAI,CAAE,uBAAuB,CAC7B,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACrE,CACE,IAAI,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACD,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAC5D,CACD,IAAI,CAAE,gBAAgB,CACtB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtD,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CACnD,CACD,IAAI,CAAE,gBAAgB,CACtB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,cAAc,CACpB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC1D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC3D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACrE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACpE,IAAI,CAAE,UAAU,CAChB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CACD,IAAI,CAAE,gBAAgB,CACtB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CAAC,CACrE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,IAAI,CAAE,0BAA0B,CAChC,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,iBAAiB,CACvB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,kDAAkD,CAChE,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,0BAA0B,CAChC,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CACE,IAAI,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CACE,IAAI,CAAE,4BAA4B,CAClC,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CACE,IAAI,CAAE,cAAc,CACpB,YAAY,CAAE,iBAAiB,CAC/B,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CACE,IAAI,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACF,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACrE,CACE,IAAI,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CACE,IAAI,CAAE,2BAA2B,CACjC,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACzD,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACjE,CACD,IAAI,CAAE,YAAY,CAClB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CACD,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CACnD,CACD,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,OAAO,CACb,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,yBAAyB,CAC/B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,oBAAoB,CAC1B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,mBAAmB,CACjC,IAAI,CAAE,SAAS,CACf,UAAU,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAAC,CACrE,CACD,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAC5D,CACD,IAAI,CAAE,aAAa,CACnB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CAClE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAC5D,CACD,IAAI,CAAE,uBAAuB,CAC7B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtD,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtD,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,gBAAgB,CACtB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CACD,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,yBAAyB,CAC/B,OAAO,CAAE,CACP,CACE,IAAI,CAAE,EAAE,CACR,YAAY,CAAE,kCAAkC,CAChD,IAAI,CAAE,SAAS,CAChB,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,oBAAoB,CAC1B,OAAO,CAAE,CACP,CACE,IAAI,CAAE,EAAE,CACR,YAAY,CAAE,6BAA6B,CAC3C,IAAI,CAAE,SAAS,CAChB,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CACD,IAAI,CAAE,iBAAiB,CACvB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtD,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtD,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtD,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CACnD,CACD,IAAI,CAAE,wBAAwB,CAC9B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CACE,IAAI,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACD,IAAI,CAAE,sBAAsB,CAC5B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CACD,IAAI,CAAE,2BAA2B,CACjC,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACxE,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,eAAe,CACrB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,kBAAkB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CACD,IAAI,CAAE,yBAAyB,CAC/B,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,mBAAmB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CACvD,CACD,IAAI,CAAE,kBAAkB,CACxB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,SAAS,CAC3B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,mBAAmB,CACzB,OAAO,CAAE,CACP,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,yBAAyB,CAAE,IAAI,CAAE,SAAS,CAAE,CACvE,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACvD,CACD,IAAI,CAAE,iBAAiB,CACvB,OAAO,CAAE,CACP,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,oCAAoC,CAClD,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACzD,CACF,CACF,CACD,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,EAAE,CACV,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,CAAE,GACX,EADgB,IACV,CAAE,CACN,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,yBAAyB,CAChC,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACD,CAFgB,AAGd,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,QAAQ,CACtB,IAAI,CAAE,QAAQ,CACd,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,OAAO,CACb,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,cAAc,CACpB,YAAY,CAAE,UAAU,CACxB,IAAI,CAAE,UAAU,CAChB,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,gBAAgB,CACtB,YAAY,CAAE,UAAU,CACxB,IAAI,CAAE,UAAU,CAChB,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,gBAAgB,CACvB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,AAHa,IAGT,CAAE,oBAAoB,CAC1B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,oBAAoB,CAC1B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,+BAA+B,CACtC,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,SAAS,EAAE,EAAO,GAAF,GAAQ,CAAE,EAAE,CAAE,IAAI,CAAE,qBAAqB,CAAE,CAC5E,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,aAAa,CACpB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,eAAe,CACrB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,eAAe,CACrB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,0BAA0B,CACjC,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,OAAO,CAAE,EAAK,CAAE,CACxE,CADsE,AAEpE,IAAI,CAAE,aAAa,CACnB,YAAY,CAAE,QAAQ,CACtB,IAAI,CAAE,QAAQ,CACd,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,yBAAyB,CAChC,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,QAAQ,CACtB,IAAI,CAAE,QAAQ,CACd,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,aAAa,CACpB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,eAAe,CACrB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACF,AAFgB,CAGjB,IAAI,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CACD,CAFgB,AAGd,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,SAAS,CACf,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CADc,AAEf,CACE,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,iBAAiB,CAC/B,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,OAAO,CAAE,IAAI,CAAE,OAAO,CAAE,CAAC,CACpE,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,MAAM,CACZ,YAAY,CAAE,UAAU,CACxB,IAAI,CAAE,UAAU,CAChB,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,QAAQ,CACd,YAAY,CAAE,UAAU,CACxB,IAAI,CAAE,UAAU,CAChB,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,YAAY,CACnB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,cAAc,CACpB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,aAAa,CACnB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,gBAAgB,CACvB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,AAHiB,IAGb,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,YAAY,CAClB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,oBAAoB,CAC3B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,SAAS,CACf,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,iBAAiB,CACxB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,CAAE,GACV,CADc,AAEf,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,iBAAiB,CACvB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,WAAW,CACjB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,mBAAmB,CAC1B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,CAAE,GACX,EADgB,IACV,CAAE,CACN,CACE,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,kDAAkD,CAChE,IAAI,CAAE,OAAO,CACb,UAAU,CAAE,CACV,CACE,IAAI,CAAE,oBAAoB,CAC1B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACD,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC/D,CACD,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CACD,AAHiB,IAGb,CAAE,UAAU,CACjB,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,cAAc,CACpB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACF,CAFgB,AAGjB,IAAI,CAAE,iBAAiB,CACxB,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,kBAAkB,CACzB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,8BAA8B,CAAE,CACnE,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,6BAA6B,CACpC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,mCAAmC,CAC1C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,gBAAgB,CACvB,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,mBAAmB,CAC1B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,yBAAyB,CAChC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CACD,IAAI,CAAE,gCAAgC,CACvC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CACE,IAAI,CAAE,gBAAgB,CACtB,YAAY,CAAE,4BAA4B,CAC1C,IAAI,CAAE,OAAO,CACd,CACD,CAAE,IAAI,CAAE,KAAK,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACzD,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,0BAA0B,CACjC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,wBAAwB,CAC/B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,iCAAiC,CACxC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CACD,IAAI,CAAE,8BAA8B,CACrC,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,gBAAgB,CAAE,CACrD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,KAAK,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CACxD,CACD,IAAI,CAAE,sBAAsB,CAC7B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,8BAA8B,CACrC,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,mBAAmB,CAAE,CACxD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,mBAAmB,CAAE,CACxD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACD,IAAI,CAAE,mBAAmB,CAC1B,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,YAAY,CAAE,CACjD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,6BAA6B,CACpC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CACD,IAAI,CAAE,iCAAiC,CACxC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CACE,IAAI,CAAE,uBAAuB,CAC7B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACD,IAAI,CAAE,6BAA6B,CACpC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,iBAAiB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACrE,CACE,IAAI,CAAE,sBAAsB,CAC5B,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CAChB,CACF,CACD,IAAI,CAAE,6BAA6B,CACpC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,eAAe,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,qBAAqB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1E,CACD,IAAI,CAAE,2BAA2B,CAClC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,kBAAkB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACtE,CAAE,IAAI,CAAE,qBAAqB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1E,CACD,IAAI,CAAE,4BAA4B,CACnC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,kBAAkB,CACzB,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CACD,IAAI,CAAE,mBAAmB,CAC1B,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,uBAAuB,CAAE,CAC5D,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,iCAAiC,CACxC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,0BAA0B,CACjC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,oBAAoB,CAC3B,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,sBAAsB,CAAE,CAC3D,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,oBAAoB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACxE,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CACD,IAAI,CAAE,4BAA4B,CACnC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,cAAc,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACnE,CACD,IAAI,CAAE,mCAAmC,CAC1C,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,6BAA6B,CACpC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,+BAA+B,CACtC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,gBAAgB,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,gCAAgC,CACvC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,kBAAkB,CACzB,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,iBAAiB,CAAE,CACtD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,8BAA8B,CACrC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,wBAAwB,CAC/B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC3D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,qBAAqB,CAC5B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,OAAO,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACrE,IAAI,CAAE,qBAAqB,CAC5B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,SAAS,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACvE,IAAI,CAAE,4BAA4B,CACnC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAClE,CACD,IAAI,CAAE,0BAA0B,CACjC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CACE,IAAI,CAAE,WAAW,CACjB,YAAY,CAAE,uBAAuB,CACrC,IAAI,CAAE,OAAO,CACd,CACD,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC7D,CACD,IAAI,CAAE,qBAAqB,CAC5B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC1E,IAAI,CAAE,yBAAyB,CAChC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CAC1E,IAAI,CAAE,2BAA2B,CAClC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACxE,IAAI,CAAE,uBAAuB,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACzE,IAAI,CAAE,mBAAmB,CAC1B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,WAAW,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC9D,CAAE,IAAI,CAAE,UAAU,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC/D,CACD,IAAI,CAAE,qBAAqB,CAC5B,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACtE,IAAI,CAAE,mBAAmB,CAC1B,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,kCAAkC,CAAE,CACvE,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAChE,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CACD,IAAI,CAAE,qBAAqB,CAC5B,CACD,CAAE,IAAI,CAAE,OAAO,CAAE,MAAM,CAAE,EAAE,CAAE,IAAI,CAAE,6BAA6B,CAAE,CAClE,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CAAC,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACpE,IAAI,CAAE,8BAA8B,CACrC,CACD,CACE,IAAI,CAAE,OAAO,CACb,MAAM,CAAE,CACN,CACE,IAAI,CAAE,OAAO,CACb,YAAY,CAAE,0BAA0B,CACxC,IAAI,CAAE,OAAO,CACd,CACF,CACD,IAAI,CAAE,aAAa,CACpB,gQAhkGuE,CAAE,CAAC,CCiBH,mHDZG,C3EPG,CAAA,E+CuLC,CFvLG,wN8BenC,KAAA,SAAe,CAAE,6FAOR,6DACI,CFSC,AlBqBA,CAAC,AkBrBA,AtF0DI,ATZJ,OiGvDO,oDACT,+DACE,CAAE,E5B4MI,0D4BrMxD,sOASe,aAAA,UAAyB,KAAA,SAAe,CAAE,EpB2CI,CAAC,CAAA,ARgLC,iJ4BnN9B,eAAiB,SAAS,wKAYtC,gEACc,KAAA,yEAM5B,SAAU,aAAA,UAAyB,KAAM,SAAS,CAAE,CAAC,E7F6IA,CAAC,CAAA,mD6FxI5D,KAAA,mCAA4C,IAAI,CAAE,SAAS,CAAE,CAAC,6FAKlB,KAAM,CsBoEC,UtBpEW,MACnE,wFAK+B,UAAW,EDwBA,CAAC,CCxBG,ADwBH,CCxBG,SAAW,CAAE,iDACT,4DACC,wEAIhC,6EAIY,UAAW,KAAM,SAAS,CAAE,0BAClC,cAAgB,QAAQ,6DAItB,iDAIvB,0BAA4B,CD+BC,cC/BgB,QhGsBU,CgGtBD,AhGsBC,QgGrBvD,8BAAgC,CjGkHE,AI2DA,AFpFG,CsCtHH,CAAC,OyD6BQ,ClGkOD,IkGlOO,CnG2JG,QmG3JM,CAAE,ElGkOA,CAAC,IDvEQ,oGmGrJN,MACnE,sDAMF,KAAA,iGAKE,sGAK4C,SAAS,CAAE,yBAChC,aAAA,eAA+B,SAAS,CAAE,G3CoMC,4C2CnMlB,C3CqMD,U2CpMpD,kHAM0D,wDACG,uCACnB,eAAiB,+BACnC,aAAA,0IAUnB,0DAE4C,mDACH,KAAM,gDACV,EjGgKA,AuHpEsB,C1FiGrC,A0FjGqC,CvHoEpB,EAAE,IiGhKO,EjBeQ,EiBfJ,AnG2PlC,CAAA,SmG3P6C,4CAGnD,eACR,4IASY,aAAc,UAAW,KAAA,wDACK,KAAM,C7F0QE,Q6F1QO,CAAE,CnG2QnC,yCmG1Qc,KAAA,oDACD,UAAW,KAAM,I7F0QM,AuGnGrD,KVvKwD,CAAE,mGAO3B,KAAM,4CACf,CpEkNG,CAAA,QoElNQ,KAAM,uCACtB,UAAW,KAAA,+FAOR,kFAC2B,CAAE,iCAC5B,CD8CD,CAAC,CAAA,qBC9C0B,CAAE,C3C2NL,M2C1NnD,qCAAyC,CPHK,CkB+BH,CAAC,MX5BM,CAAE,CAC7D,AxFyPkD,gCwFrPnD,KAAM,sBAEI,C9BQC,8C8BRkD,8DACH,E9BQE,G8BRI,C9BQC,Q8BRQ,CAAE,E9BQE,yC8BHvE,yDACiD,KAAM,WAAY,kEAMlD,aAAc,UAAW,KAAM,kDACR,CNSO,A4B4GF,CAAC,GtBrHA,SAAS,CAAE,kCAKzD,iBACK,KAAA,gCAAyC,KAAA,WAAkB,+CAIhE,gBACG,CAAE,KAAA,gCAAyC,KAAM,QjBiCU,AqCuDF,GpBxFI,yEAMhD,aAAc,sDACF,ElG4WE,QkG5WS,KAAA,kFAOjB,aAAc,UAAW,KAAM,SAAS,CAAE,mCAC9B,eAAiB,M5BqXtB,G4BrX+B,yDAMvD,C5B+XC,IAAA,mC4B/X2C,C9BQC,AuBVJ,CrBiYK,G4B/XI,WAAY,C5B+XC,CAAA,2B4B5X1E,KAAA,uBAAiC,oDAIvB,kCAAoC,eAAiB,E9BQI,O8BRK,CAAE,2CACzB,CiB0HO,IAAA,SjB1HQ,CAAE,4DAO9D,KAAA,0BAAkC,UAAW,KAAM,SAAS,CAAE,IpEgQhB,yCoE/PC,KAAA,4DAK7C,eACE,4BACyB,KlG4YO,KkG5YI,ElG4YI,EkG5YA,CAAE,SAAS,CAAE,SpEyQW,CAAC,CAAA,sBoExQnC,SAAS,CAAE,CjB2GK,AnD8JF,CmD9JG,AnD8JF,CmD9JG,AnD8JH,CoEzQA,CAAE,SAAS,CAAE,EAC9D,GlG2YmE,CAAC,CAAA,AkG3YpE,gCAAyC,KAAM,SAAS,CAAE,CPKc,AOJ3E,MACK,qCAGA,8BAEa,aAAA,eAA+B,qDACD,IAAI,CpEiRG,uCoEhRtB,C3C2QH,AzBQqB,SoEnRP,KAAM,SAAS,CAAE,CtBiOnB,AsBhO1C,4DAKO,C1CkBG,C0CjBP,C1CkBU,EAAW,EAAA,yB0ClBY,C3C2QH,AvDkII,ckG7YgB,SAAS,CAAE,CUyTC,CAAC,AVxT/D,CUwT+D,IVxT/D,8BAAsC,UAAW,KAAM,SAAS,CAAE,CACpE,iBAAoB,ClG6YC,AuDlIJ,YAAA,U2C3Q4B,KAAA,WAC9C,CACD,KAAA,wDAIS,MAAQ,C3C2QH,W2C3QgB,aAAc,UAAW,IAAI,CAAE,CvFkSG,QuFlSM,CAAE,CAAC,+EAMpC,eAAiB,KnG4XK,ImG5XI,CAAE,8CACZ,uCACnB,eAAiB,SAAS,CAAE,OnG8XS,CAAC,CAAA,0CmGxXxE,CnG+XC,CAAA,KAAA,EmG9XG,KAAM,kCAAqC,IAAI,CAAE,YACjD,KAAM,CU6UC,qBV7UuB,UAAW,KAAM,SAAS,GAE5D,KAAA,8CAIA,OAAQ,CiBwJD,APuME,CV9VL,KAAA,wBAAgC,CvFwTK,AiGuCJ,SV/VU,EnG2YA,GAAA,SmG3Ye,CvFwTM,AuFxTJ,CAC9D,CAAE,KAAA,SAAgB,CnG2YF,YmG3YgB,UAAW,IAAI,CAAE,SAAS,EAC3D,uDAMG,KAAM,kCAAqC,IAAI,CAAE,SAAS,CAAE,gBAC5C,aAAc,UAAW,IAAI,CtBiQC,AsBjQC,6BAIrD,EsBkJI,ItBjJI,sBAEI,qBAAuB,eAAiB,iBACxC,wBAA0B,GpEwUK,OoExUM,EiB6IgB,EjB7IZ,CAAE,SAAS,CAAE,CAC/D,IpEuUsE,EoEtUjE,6CAKJ,MAAQ,OtB4Qa,4BsB5QyB,KAAA,SAAe,EAC7D,MAAQ,EvF0TW,GZoGJ,gCmG9ZiC,KAAM,EnGga9B,OmGhauC,EAChE,MACK,iDAIE,gCAGU,EpEyVI,0CoEtVZ,aAAc,aAAA,UAAyB,KAAM,E9BmBe,EAAE,K8BnBR,CAAE,EAC9D,KAAM,SAAU,aAAc,eAAiB,SAAS,CAAE,8BAIhE,kBiB2I8G,GjBzIpG,CAAC,CAAE,KAAM,YAAa,ID2EM,CAAC,InEiSlB,IoE5WyB,eAAiB,SAAS,CAAE,CAAC,WUwZzD,A9E5CgD,CAAC,wCoEvWzD,CAAC,CAAE,KAAA,0BAAkC,CtB+RG,A9C8EJ,SoE7WY,CtB+RG,IsB/RG,CtB+RG,CAAC,CAAC,MsB/RI,CAAE,CAAC,MACpE,EnGgdsB,CAAA,wBmG9c9B,MACQ,eACE,OAAS,0BAA4B,eAAiB,SAAS,CAAE,CAAC,mCAG5E,CACE,AU6aD,CAEI,IV/aG,ChCmKG,6CgClKkC,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACxE,KAAM,ChCmKG,wBgCjKX,MACQ,CtB2SF,csB1SI,CAAC,CAAE,KAAA,YAAmB,ChCoKG,ApC8OF,YoElZa,EpEkZE,QoElZS,IAAI,CAAE,QUkbM,CVlbG,AUkbF,EVlbK,uDAKxD,wCAA4C,SAAS,CAAE,CAAC,MACnE,+BAER,MACQ,QACN,OAAA,OACU,yBAA2B,SAAS,AnG8dA,CmG9dE,IAAI,CAAE,SAAS,CAAE,EAC7D,IAAI,CAAE,CtBiTK,E7E6KF,QmG9dS,aAAc,KtBiTS,C7E6KH,A6E7KI,C7E6KH,CAAA,OmG9dU,SAAS,CAAE,+BAC5B,UAAW,IAAI,CAAE,SAAS,CAAE,CAC/D,GnG6dmE,iDmGxdzD,CtBiTC,CAAC,EsBjTE,CAAA,sBAA0B,UAAW,ItBkTd,AsBlTkB,CAAE,MvF4YQ,WuF3Y5D,0CAEiB,CU0cD,CV1cG,CAAE,KAAM,kCAAkC,CU0cY,AV1cV,CACvE,uBAGM,EhC+KoB,GgC/Kd,0BAA4B,UAAW,IAAI,CAAE,SAAS,CAAE,2CACjB,IAAI,CAAA,WACpD,8BAID,KAAA,QACA,CpE4bG,MAAA,gCoE5b0C,KAAM,OAAO,CAAE,CAAC,+BAG/D,CACE,KAAM,gBAEJ,CACE,KAAM,CnG6eC,OmG5eP,aAAc,gCACR,CpE4dK,A0F5RE,QtB9LhB,qB1Dza+F,CAAA,EViBN,CAAA,SzCxBvF,IAAM,EAAoC,OAFrB,AAE4B,GAmB3C,EACX,OAPE,AAOK,KAGI,EACX,OAPE,AAOK,CAXU,IAkBN,EAAW,OAlBS,CAId,AAmBN,KALwB,AASxB,EAA8C,OAFxD,AArB+B,AAuBgC,IAOrD,EAAmB,EAAI,EAAY,EkF1B1C,EAAQ,CAjBM,AAAC,IAEnB,ElFgCsB,CkFhClB,aAAiB,YAAY,AAC/B,GAAI,EAAM,MAAM,CAAG,EACjB,OAAO,EADgB,AACV,QAAQ,CAAC,EAAG,QACpB,GAAI,EAAM,MAAM,EAAI,EACzB,OAAO,CACT,CAGF,AALmC,IAK7B,EAAO,IAAI,WAAW,GAE5B,OADA,EAAK,GAAG,CAAC,IAAI,EAAM,EACZ,CACT,GAImB,IAAI,WAAW,GAAM,IAAI,CAAC,IAC7C,OAAO,MAAM,CAAC,EAAM,MAAM,2F1C7B2C,KAAA,+FAKM,KAAK,CAAA,M9B8CjE,EACb,cAAc,EACd,cAAc,GACf,MAAM,mBAAmB,CAAA,MwChDwG,CAAA,4BVQrF,WACvB,EAAA,6DASkC,cAAc,+EACd,0EAEJ,UAAU,6IAUrD,IAAA,cAAA,MAAA,CAAA,+LvCxCT,IAAA,EAAA,EAAA,CAAA,CAAA,QKAO,IAAM,EAAO,WAIP,EAAS,IAAI,WAAW,CAAC,GAAI,GAAG,CAEtC,OAAM,EAIX,YAAY,CAAK,CAAE,CAEjB,IAAI,CAAC,IAAI,CAXO,EAWJ,CAEZ,IAAI,CAAC,IAAI,CAAG,EACZ,IAAI,CAAC,KAAK,CAAG,EAEb,IAAI,CAAC,IAAI,GAAG,CACZ,IAAI,CAAC,MAAM,CAAG,EAAM,QAAQ,CAAC,EAC/B,CACF,CLXO,IAAM,EAAS,AAAC,IACrB,IAAM,EAAS,IAAI,WAAW,EAAO,MAAM,CKRzB,ELQ4B,EAO9C,OANA,EAAO,GAAG,CAAC,EAAQ,GACnB,EAAO,GAAG,CACR,EAAA,OAAM,CAAC,UAAU,CAAC,UAAU,MAAM,CAAC,GAAS,MAAM,GAClD,EAAO,MAAM,EAGR,IAAI,EAAO,EACpB,uDCbA,IAAM,EAAU,CACd,SACA,SACA,SACA,SACD,CAEK,EAAkB,CACtB,WACA,YACA,iBACA,oBACA,yBACA,gBACA,aACA,QACA,SACA,SACA,SACA,OACA,QACA,MACA,MACA,UACA,UACA,cACA,oBACA,WACA,UACA,MACA,cACA,YACA,aACA,oBACA,aACA,cACA,aACA,cACA,eACA,eACA,gBACA,iBACD,AC/CD,OAAM,EAMJ,YAAa,CAAK,CAAE,CAAI,CAAE,CAAQ,CAAE,CAClC,IAAI,CAAC,KAAK,CAAG,EACb,IAAI,CAAC,YAAY,CAAG,GAAS,EAC7B,IAAI,CAAC,IAAI,CAAG,EACZ,IAAI,CAAC,QAAQ,CAAG,CAClB,CAGA,UAAY,CACV,MAAO,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,CAAC,EAAE,EAAE,IAAI,CAAC,IAAI,CAAA,CAAE,AAC3C,CAMA,QAAS,CAAG,CAAE,CAEZ,OAAO,IAAI,CAAC,KAAK,CAAG,EAAI,KAAK,CAAG,CAAC,IAAI,IAAI,CAAC,KAAK,CAAG,EAAI,KAAA,AAAK,CAC7D,CACF,CAFkE,AAKlE,EAAK,EALiE,EAK7D,CAAG,IAAI,EAAK,EAAG,QAAQ,GAChC,EAAK,MAAM,CAAG,IAAI,EAAK,EAAG,UAAU,GACpC,EAAK,KAAK,CAAG,IAAI,EAAK,EAAG,SAAS,GAClC,EAAK,MAAM,CAAG,IAAI,EAAK,EAAG,UAAU,GACpC,EAAK,KAAK,CAAG,IAAI,EAAK,EAAG,SAAS,GAClC,EAAK,GAAG,CAAG,IAAI,EAAK,EAAG,OAAO,GAC9B,EAAK,GAAG,CAAG,IAAI,EAAK,EAAG,OAAO,GAC9B,EAAK,GADgC,EAC3B,CAAG,IAAI,EAAK,EAAG,CADwB,OACf,IAClC,EAAK,KAAK,CAAG,IAAI,EAAK,EAAG,SAAS,GAClC,EAAK,IAAI,CAAG,IAAI,EAAK,EAAG,QAAQ,GAChC,EAAK,IAAI,CAAG,IAAI,EAAK,EAAG,QAAQ,GAChC,EAAK,SAAS,CAAG,IAAI,EAAK,EAAG,YAAa,IAC1C,EAAK,KAAK,CAAG,IAAI,EAAK,EAAG,SAAS,EAGlC,OAAM,EAMJ,YAAa,CAAI,CAAE,CAAK,CAAE,CAAa,CAAE,CACvC,IAAI,CAAC,IAAI,CAAG,EACZ,IAAI,CAAC,KAAK,CAAG,EACb,IAAI,CAAC,aAAa,CAAG,EAErB,IAAI,CAAC,YAAY,MAAG,EAEpB,IAAI,CAAC,SAAS,MAAG,CACnB,CAGA,UAAY,CACV,MAAO,CAAC,MAAM,EAAE,IAAI,CAAC,IAAI,CAAC,EAAE,EAAE,IAAI,CAAC,KAAK,CAAA,CAAE,AAC5C,CACF,CuD5DO,IAAM,EAAY,WAAW,OAAO,EAEzC,CAAC,CADD,UACY,GADC,IACM,CAAC,OAAO,EAE3B,EADA,SACW,IADE,EACI,EAEqB,EADtC,UACA,GADa,IACN,WAAW,MAAM,CAAC,QAAQ,CAE7B,EAAc,IAAI,YAClB,EAAc,IAAI,YAMxB,SAAS,EAAU,CAAG,EAEpB,OAAO,GAAa,WAAW,MAAM,CAAC,QAAQ,CAAC,EACjD,CAMO,SAAS,EAAO,CAAG,SAElB,AAAN,IAAI,CAAC,QAAgB,UAAU,CAGxB,EAH2B,AAGlB,GAAO,IAAI,WAAW,EAAI,MAAM,CAAE,EAAI,UAAU,CAAE,EAAI,UAAU,EAAI,EAF3E,WAAW,IAAI,CAAC,EAG3B,CAEO,IAAM,EAAW,EAOpB,CAAC,EAAO,EAAO,IACN,CANT,CAMe,EAAQ,GAGnB,EADF,SACa,IADA,EACM,CAAC,IAAI,CAAC,EAAM,QAAQ,CAAC,EAAO,IAAM,QAAQ,CAAC,QAC1D,EAAU,EAAO,EAAO,GAS9B,CAAC,EAAO,EAAO,IACN,EAAM,EAAQ,GACjB,EAAY,MAAM,CAAC,EAAM,QAAQ,CAAC,EAAO,IACzC,EAAU,EAAO,EAAO,GAGrB,EAAa,EAKtB,AAAC,GACQ,EAAO,KAJhB,CAIsB,CAAG,GAGrB,EADF,SACa,IADA,EACM,CAAC,IAAI,CAAC,GACrB,EAAY,GAOlB,AAAC,GACQ,EAAO,MAAM,CAAG,GAAK,EAAY,MAAM,CAAC,GAAU,EAAY,GAY9D,EAAQ,EAOjB,CAAC,EAAO,EAAO,IACb,AAAI,CANN,CAMe,GACJ,IAAI,CADQ,UACG,EAAM,QAAQ,CAAC,EAAO,IAEvC,EAAM,KAAK,CAAC,EAAO,GAS5B,CAAC,EAAO,EAAO,IACN,EAAM,KAAK,CAAC,EAAO,GAGnB,EAAS,EAOlB,CAAC,EAAQ,KAGP,EAAS,AARX,EAQkB,GAAG,CAAC,AAAC,GAAM,aAAa,WACpC,EAKF,EADA,SACW,IADE,EACI,CAAC,IAAI,CAAC,IAElB,EAAM,WAAW,MAAM,CAAC,MAAM,CAAC,EAAQ,KAShD,CAAC,EAAQ,KACP,IAAM,EAAM,IAAI,WAAW,GACvB,EAAM,EACV,IAAK,IAAI,KAAK,EACR,EAAM,EAAE,CADQ,KACF,CAAG,EAAI,MAAM,EAAE,CAE/B,EAAI,EAAE,QAAQ,CAAC,EAAG,EAAI,MAAM,CAAG,EAAA,EAEjC,EAAI,GAAG,CAAC,EAAG,GACX,GAAO,EAAE,MAAM,CAEjB,OAAO,CACT,EAES,EAAQ,EAMjB,AAAC,GAGQ,OAPT,IAOoB,MAAM,CAAC,WAAW,CAAC,GAQtC,AAAD,GACS,IAAI,WAAW,GAqFrB,SAAS,EAAS,CAAE,CAAE,CAAE,EAE7B,GAAI,EAAS,IAAO,EAAS,GAG3B,EAHgC,KAGzB,EAAG,OAAO,CAAC,GAEpB,IAAK,IAAI,EAAI,EAAG,EAAI,EAAG,MAAM,CAAE,IAAK,AAClC,GAAI,CAAE,CAAC,EAAE,GAAK,CAAE,CAAC,EAAE,CAGnB,CAHqB,MAGd,CAAE,CAAC,EAAE,CAAG,CAAE,CAAC,EAAE,CAAG,CAAC,EAAI,EAE9B,OAAO,CACT,CASA,SAAS,EAAa,CAAG,EACvB,IAAM,EAAM,EAAE,CACV,EAAI,EACR,IAAK,IAAI,EAAI,EAAG,EAAI,EAAI,MAAM,CAAE,IAAK,CACnC,IAAI,EAAI,EAAI,UAAU,CAAC,GACnB,EAAI,IACN,CADW,AACR,CAAC,IAAI,CAAG,GACF,EAAI,KACb,CADmB,AAChB,CAAC,IAAI,CAAI,GAAK,EAAK,KAGtB,CAAM,MAAJ,CAAI,CAAM,EAAM,OAAY,EAAI,EAAK,EAAI,MAAM,EAChD,CAAyB,MAAxB,EAAI,UAAU,CAAC,EAAI,EAAK,CAAM,EAAM,OAEtC,CAF+C,CAE3C,OAAW,CAAK,EAAN,GAAE,CAAI,CAAM,EAAK,EAAA,CAAE,EAA2B,EAAvB,GAAC,EAAI,UAAU,CAAC,EAAE,EAAK,CAAM,CAClE,CAAG,CAAC,IAAI,CAAI,GAAK,GAAM,IACvB,CAAG,CAAC,IAAI,CAAG,GAAO,GAAM,GAAM,KAI9B,CAAG,CAAC,IAAI,CAAI,GAAK,GAAM,IACvB,CAAG,CAAC,IAAI,CAAG,GAAO,EAAK,GAAM,KAC7B,CAAG,CAAC,IAAI,CAAQ,GAAJ,EAAU,IAE1B,CACA,OAAO,CACT,CAWA,SAAS,EAAW,CAAG,CAAE,CAAM,CAAE,CAAG,EAClC,IAAM,EAAM,EAAE,CAEd,KAAO,EAAS,GAAK,CACnB,IAAM,EAAY,CAAG,CAAC,EAAO,CACzB,EAAY,KACZ,EAAoB,EAAY,IAAQ,EAAK,EAAY,IAAQ,EAAK,EAAY,IAAQ,EAAI,EAElG,GAAI,EAAS,GAAoB,EAAK,CACpC,IAAI,EAAY,EAAW,EAAY,EAEvC,OAAQ,GACN,KAAK,EACC,EAAY,MAAM,AACpB,EAAY,CAAA,EAEd,KACF,MAAK,EAEE,CAAa,KADlB,EAAa,CAAG,CAAC,EAAS,EAAA,AAAE,CACV,CAAI,EAAM,KAEtB,CAF4B,AAChC,EAAgB,CAAa,GAAZ,CAAY,CAAI,EAAK,EAAoB,GAAb,CAAa,EACtC,MAAM,AACxB,EAAY,CAAA,EAGhB,KACF,MAAK,EACH,EAAa,CAAG,CAAC,EAAS,EAAE,CAC5B,EAAY,CAAG,CAAC,EAAS,EAAE,EACT,IAAb,CAAa,CAAI,EAAM,KAAQ,CAAC,AAAY,KAAA,CAAI,EAAM,KAGrD,CAH2D,AAC/D,EAAgB,CAAa,GAAZ,CAAY,CAAG,EAAK,GAAM,CAAc,GAAb,CAAa,CAAI,EAAK,EAAmB,GAAZ,CAAY,EAEjE,OAAU,EAAgB,AAAjB,OAA2B,EAAgB,KAAA,CAAM,GAAG,AAC/E,EAAY,CAAA,EAGhB,KACF,MAAK,EACH,EAAa,CAAG,CAAC,EAAS,EAAE,CAC5B,EAAY,CAAG,CAAC,EAAS,EAAE,CAC3B,EAAa,CAAG,CAAC,EAAS,EAAE,EACV,IAAb,CAAa,CAAI,EAAM,KAAQ,CAAa,IAAZ,CAAY,CAAI,EAAM,KAAQ,CAAc,IAAb,CAAa,CAAI,EAAM,KAErF,CADJ,AAD+F,EAC/E,CAAa,GAAZ,CAAY,CAAG,EAAK,GAAO,CAAc,GAAb,CAAa,CAAI,EAAK,GAAM,CAAa,GAAZ,CAAY,CAAI,EAAK,EAAoB,GAAb,CAAa,EAC/F,OAAU,EAAgB,UAAU,AACtD,EAAY,CAAA,CAGpB,CACF,CAGkB,MAAM,CAApB,GAGF,EAAY,MACZ,EAAmB,GACV,EAAY,QAAQ,AAE7B,GAAa,MACb,EAAI,IAAI,CAAC,IAAc,GAAK,KAAQ,OACpC,EAAY,MAAqB,KAAZ,GAGvB,EAAI,IAAI,CAAC,GACT,GAAU,CACZ,KAcqC,EAZR,EAa7B,IAAM,EADyC,AACnC,EAAW,MAAM,CAC7B,GAAI,GARuB,IAQhB,CACT,OAAO,OAAO,OADiB,KACL,CAAC,KAAK,CAAC,OAAQ,GAI3C,IAAI,EAAM,GAJ6C,AAKnD,EAAI,EACR,KAAO,EAAI,GACT,CADc,EACP,KAPoE,EAO7D,YAAY,CAAC,KAAK,CAC9B,OACA,EAAW,KAAK,CAAC,EAAG,KAAK,KAG7B,OAAO,CA1BT,CiE3WO,MAAM,EAIX,YAAa,EANU,GAMkB,CAAE,CACzC,IAAI,CAAC,AADkB,SACT,CAAG,EAEjB,IAAI,CAAC,MAAM,CAAG,EAEd,IAAI,CAAC,SAAS,CAAG,CAAC,EAElB,IAAI,CAAC,MAAM,CAAG,EAAE,CAGhB,IAAI,CAAC,eAAe,CAAG,IACzB,CAEA,OAAS,CACP,IAAI,CAAC,MAAM,CAAG,EACd,IAAI,CAAC,SAAS,CAAG,CAAC,EACd,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,CACtB,IAAI,CAAC,MAAM,CAAG,EAAA,AAAE,EAEW,MAAM,CAA/B,IAAI,CAAC,eAAe,GACtB,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,eAAe,EACrC,IAAI,CAAC,SAAS,CAAG,IAAI,CAAC,eAAe,CAAC,MAAM,CAAG,EAEnD,CAKA,KAAM,CAAK,CAAE,CACX,IAAI,EAAW,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAG,EAAE,CAElD,GAAI,AADW,IAAI,CAAC,MAAM,CAAG,EAAM,MAAM,EAC3B,IAAI,CAAC,SAAS,CAAG,EAAG,CAEhC,IAAM,EAAW,EAAS,MAAM,EAAI,CAAD,GAAK,CAAC,SAAS,CAAG,IAAI,CAAC,MAAA,AAAM,EAAI,EAEpE,EAAS,GAAG,CAAC,EAAO,EACtB,KAAO,CAEL,GAAI,EAAU,CAEZ,IAAM,EAAW,EAAS,MAAM,CAAI,EAAD,GAAK,CAAC,SAAS,CAAG,IAAI,CAAC,MAAM,AAAN,EAAU,EAChE,EAAW,EAAS,MAAM,EAAE,CAE9B,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAG,EAAE,CAAG,EAAS,QAAQ,CAAC,EAAG,GAC3D,IAAI,CAAC,SAAS,CAAG,IAAI,CAAC,MAAM,CAAG,EAEnC,CACI,EAAM,MAAM,CAAG,IAAM,EAAM,MAAM,CAAG,IAAI,CAAC,SAAS,EAAE,AAEtD,EAAW,EAAM,IAAI,CAAC,SAAS,EAC/B,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,GACjB,IAAI,CAAC,SAAS,EAAI,EAAS,MAAM,CACJ,MAAM,CAA/B,IAAI,CAAC,eAAe,GACtB,IAAI,CAAC,eAAe,CAAG,CAAA,EAGzB,EAAS,GAAG,CAAC,EAAO,KAGpB,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,GACjB,IAAI,CAAC,SAAS,EAAI,EAAM,MAAM,CAElC,CACA,IAAI,CAAC,MAAM,EAAI,EAAM,MAAM,AAC7B,CAMA,QAAS,GAAQ,CAAK,CAAE,CACtB,IAAI,EACJ,GAA2B,IAAvB,IAAI,CAAC,MAAM,CAAC,MAAM,CAAQ,CAC5B,IAAM,EAAQ,IAAI,CAAC,MAAM,CAAC,EAAE,CACxB,GAAS,IAAI,CAAC,MAAM,CAAG,EAAM,MAAM,CAAG,GAAG,AAG3C,EAAO,IAAI,CAAC,MAAM,GAAK,EAAM,MAAM,CAAG,EAAQ,EAAM,QAAQ,CAAC,EAAG,IAAI,CAAC,MAAM,EAC3E,IAAI,CAAC,eAAe,CAAG,KACvB,IAAI,CAAC,MAAM,CAAG,EAAE,EAGhB,EAAO,EAAM,EAAO,EAAG,IAAI,CAAC,MAAM,CAEtC,MAEE,CAFK,CAEE,EAAO,IAAI,CAAC,MAAM,CAAE,IAAI,CAAC,MAAM,EAKxC,OAHI,GACF,IADS,AACL,CAAC,KAAK,GAEL,CACT,CACF,CvH3HA,IAAM,EAAkB,qBAClB,EAAkB,qBAElB,GAAuB,EAAE,CAY/B,SAAS,GAAkB,CAAI,CAAE,CAAG,CAAE,CAAI,EACxC,GAAI,EAAK,MAAM,CAAG,EAAM,EACtB,IAD4B,EACtB,AAAI,MAAM,CAAA,EAAG,EAAgB,yBAAyB,CAAC,CAEjE,CAfA,EAAoB,CAAC,GAAG,CAAG,EAC3B,EAAoB,CAAC,GAAG,CAAG,EAC3B,EAAoB,CAAC,GAAG,CAAG,EAC3B,EAAoB,CAAC,GAAG,CAAG,EAC3B,EAAoB,CAAC,GAAG,CAAG,EyDHpB,IAAM,GAAiB,CAAC,GAAI,IAAK,MAAO,YAAY,OAAO,wBAAwB,CAanF,SAAS,GAAW,CAAI,CAAE,CAAM,CAAE,CAAO,EAC9C,GAAiB,EAAM,EAAQ,GAC/B,IAAM,EAAQ,CAAI,CAAC,EAAO,CAC1B,GAAuB,KAAnB,EAAQ,MAAM,EAAa,EAAQ,EAAc,CAAC,EAAE,CACtD,CADwD,KAClD,AAAI,MAAM,CAAA,EAAG,EAAgB,6DAA6D,CAAC,EAEnG,OAAO,CACT,CAQO,SAAS,GAAY,CAAI,CAAE,CAAM,CAAE,CAAO,EAC/C,GAAiB,EAAM,EAAQ,GAC/B,IAAM,EAAS,CAAI,CAAC,EAAO,EAAI,EAAK,CAAI,CAAC,EAAS,EAAE,CACpD,IAAuB,IAAnB,EAAQ,MAAM,EAAa,EAAQ,EAAc,CAAC,EAAE,CACtD,CADwD,KAClD,AAAI,MAAM,CAAA,EAAG,EAAgB,6DAA6D,CAAC,EAEnG,OAAO,CACT,CAQO,SAAS,GAAY,CAAI,CAAE,CAAM,CAAE,CAAO,EAC/C,GAAiB,EAAM,EAAQ,GAC/B,IAAM,EAAwB,SAAS,CAAxB,CAAI,CAAC,EAAO,EAA8B,CAAI,CAAC,EAAZ,AAAqB,EAAE,EAAI,EAArB,AAAqB,CAAE,EAAK,CAAI,CAAC,AAAN,EAAe,EAAE,EAAI,CAAC,EAAI,CAAI,CAAC,EAAS,EAAE,CAC7H,GAAI,CAAmB,MAAX,MAAM,EAAa,EAAQ,EAAc,CAAC,EAAE,CACtD,CADwD,KAClD,AAAI,MAAM,CAAA,EAAG,EAAgB,6DAA6D,CAAC,EAEnG,OAAO,CACT,CAQO,SAAS,GAAY,CAAI,CAAE,CAAM,CAAE,CAAO,EAE/C,GAAiB,EAAM,EAAQ,GAC/B,IAAM,EAAM,AAAe,SAAS,EAApB,CAAC,EAAO,CAA8B,EAAI,CAAC,EAAS,AAArB,EAAuB,EAAI,EAArB,AAAqB,CAAE,EAAK,CAAI,CAAL,AAAM,EAAS,EAAE,GAAI,CAAC,CAAI,CAAI,CAAC,EAAS,EAAE,CACpH,EAAyB,SAAS,CAA5B,CAAI,CAAC,EAAS,EAAE,EAA8B,CAAI,CAAC,AAAZ,EAAqB,EAAE,EAAjB,AAAqB,EAAA,CAAE,EAAK,CAAI,CAAL,AAAM,EAAS,EAAE,GAAI,CAAC,CAAI,CAAI,CAAC,EAAS,EAAE,CACxH,EAAQ,AAAC,QAAO,IAAO,OAAO,GAAA,CAAG,CAAI,OAAO,GAClD,IAAuB,IAAnB,EAAQ,MAAM,EAAa,EAAQ,EAAc,CAAC,EAAE,CACtD,CADwD,KAClD,AAAI,MAAM,CAAA,EAAG,EAAgB,6DAA6D,CAAC,EAEnG,GAAI,GAAS,OAAO,gBAAgB,CAClC,CADoC,MAC7B,OAAO,GAEhB,IAA4B,IAAxB,EAA8B,AAAtB,WAAW,CACrB,OAAO,CAET,OAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,6DAA6D,CAAC,CACnG,CAyDO,SAAS,GAAY,CAAG,CAAE,CAAK,EACpC,OAAO,GAAgB,EAAK,EAAG,EAAM,KAAK,CAC5C,CAOO,SAAS,GAAiB,CAAG,CAAE,CAAK,CAAE,CAAI,EAC/C,GAAI,EAAO,EAAc,CAAC,EAAE,CAAE,CAC5B,IAAM,EAAQ,OAAO,GAErB,EAAI,IAAI,CAAC,CAAC,EAAQ,EAAM,CAC1B,MAAO,GAAI,EAAO,EAAc,CAAC,EAAE,CAAE,CACnC,IAAM,EAAQ,OAAO,GAErB,EAAI,IAAI,CAAC,CAAS,GAAR,EAAY,EAAM,CAC9B,MAAO,GAAI,EAAO,EAAc,CAAC,EAAE,CAAE,CACnC,IAAM,EAAQ,OAAO,GAErB,EAAI,IAAI,CAAC,CAAS,GAAR,EAAY,IAAU,EAAW,IAAR,EAAa,CAClD,MAAO,GAAI,EAAO,EAAc,CAAC,EAAE,CAAE,CACnC,IAAM,EAAQ,OAAO,GAErB,EAAI,IAAI,CAAC,CAAS,GAAR,EAAa,IAAU,GAAM,IAAO,IAAU,GAAM,IAAO,IAAU,EAAK,IAAc,IAAR,EAAa,CACzG,KAAO,CACL,IAAM,EAAQ,OAAO,GACrB,GAAI,EAAQ,EAAc,CAAC,EAAE,CAAE,CAE7B,IAAM,EAAM,CAAS,GAAR,EAAY,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAE,CAEzC,EAAK,OAAO,EAAQ,OAAO,aAC3B,EAAK,OAAO,GAAS,OAAO,IAAM,OAAO,aAC7C,CAAG,CAAC,EAAE,CAAQ,IAAL,EACT,IAAW,CAAN,CACL,CAAG,CAAC,EAAE,CAAQ,IAAL,EACT,IAAW,CAAN,CACL,CAAG,CAAC,EAAE,CAAQ,IAAL,EACT,IAAW,CAAN,CACL,CAAG,CAAC,EAAE,CAAQ,IAAL,EACT,CAAG,CAAC,EAAE,CAAQ,IAAL,EACT,IAAW,CAAN,CACL,CAAG,CAAC,EAAE,CAAQ,IAAL,EACT,IAAW,CAAN,CACL,CAAG,CAAC,EAAE,CAAQ,IAAL,EACT,IAAW,CAAN,CACL,CAAG,CAAC,EAAE,CAAQ,IAAL,EACT,EAAI,IAAI,CAAC,EACX,MACE,CADK,KACC,AAAI,MAAM,CAAA,EAAG,EAAgB,+CAA+C,CAAC,CAEvF,CACF,CAMA,GAAW,WAAW,CAAG,SAAS,AAAa,CAAK,EAClD,OAAO,GAAgB,WAAW,CAAC,EAAM,KAAK,CAChD,EAMA,GAAgB,WAAW,CAAG,SAAS,AAAa,CAAI,SAClD,AAAJ,EAAW,EAAc,CAAC,EAAE,CACnB,CADqB,CAG1B,EAAO,EAAc,CAAC,EAAE,CACnB,CADqB,CAG1B,EAAO,EAAc,CAAC,EAAE,CACnB,CADqB,CAG1B,EAAO,EAAc,CAAC,EAAE,CACnB,CADqB,CAGvB,CACT,EAOA,GAAW,aAAa,CAAG,SAAS,AAAe,CAAI,CAAE,CAAI,EAC3D,OAAO,EAAK,KAAK,CAAG,EAAK,KAAK,CAAG,CAAC,IAAI,EAAK,KAAK,CAAG,EAAK,KAAA,AAAK,CAC/D,EADkE,AyDrLlE,IzDqLsE,AyDrLhE,GAAQ,OAAO,CAAC,GAChB,GAAQ,CzDoL0E,GAAG,GyDpLtE,GA2Bd,SAAS,GAAc,CAAG,CAAE,CAAK,EACtC,IAAM,EAAS,EAAM,KAAK,CAE1B,GAAqB,EAAK,EAAM,IAAI,CAAC,YAAY,CADb,CACe,SADjC,OAAO,EAAuB,EAAS,GAAQ,GAAmB,CAAC,EAAV,EAAc,EAE3F,C1D3DA,SAAS,GAAS,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAM,EACzC,GAAiB,EAAM,EAAK,EAAS,GACrC,IAAM,EAAM,EAAM,EAAM,EAAM,EAAQ,EAAM,EAAS,GACrD,OAAO,IAAI,EAAM,EAAK,KAAK,CAAE,EAAK,EAAS,EAC7C,CASO,SAAS,GAAoB,CAAI,CAAE,CAAG,CAAE,CAAK,CAAE,CAAQ,EAC5D,OAAO,GAAQ,EAAM,EAAK,EAAG,EAC/B,CAyDA,SAAS,GAAY,CAAK,EAKxB,YAJ2B,IAAvB,EAAM,KAA4B,OAAhB,GACpB,EAAM,YAAY,CAAG,EAAM,IAAI,GAAK,EAAK,MAAM,CAAG,EAAW,EAAM,KAAK,EAAI,EAAM,KAAA,AAAK,EAGlF,EAAM,YAAY,AAC3B,CAMO,SAAS,GAAa,CAAG,CAAE,CAAK,EACrC,IAAM,EAAQ,GAAW,GACzB,GAAqB,EAAK,EAAM,IAAI,CAAC,YAAY,CAAE,EAAM,MAAM,EAC/D,EAAI,IAAI,CAAC,EACX,CQtFA,SAAS,GAAS,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAM,CAAE,CAAO,EAClD,IAAM,EAAY,EAAS,EAC3B,GAAiB,EAAM,EAAK,GAC5B,IAAM,EAAM,IAAI,EAAM,EAAK,MAAM,CAAE,EAAS,EAAM,EAAM,EAAQ,EAAM,GAAY,GAIlF,OAHkC,IAA9B,EAAQ,AAA4B,iBAAX,GAC3B,EAAI,SAAS,CAAG,EAAM,EAAM,EAAM,EAAQ,EAAM,EAAA,EAE3C,CACT,CASO,SAAS,GAAqB,CAAI,CAAE,CAAG,CAAE,CAAK,CAAE,CAAO,EAC5D,OAAO,GAAQ,EAAM,EAAK,EAAG,EAAO,EACtC,CbtBA,SAAS,GAAS,CAAK,CAAE,CAAI,CAAE,CAAM,CAAE,CAAM,EAC3C,OAAO,IAAI,EAAM,EAAK,KAAK,CAAE,EAAQ,EACvC,CASO,SAAS,GAAoB,CAAI,CAAE,CAAG,CAAE,CAAK,CAAE,CAAQ,EAC5D,OAAO,GAAQ,EAAM,EAAK,EAAG,EAC/B,CAqEO,SAAS,GAAa,CAAG,CAAE,CAAK,EACrC,GAAqB,EAAK,EAAK,KAAK,CAAC,YAAY,CAAE,EAAM,KAAK,CAChE,CCpFA,SAAS,GAAS,CAAK,CAAE,CAAI,CAAE,CAAM,CAAE,CAAM,EAC3C,OAAO,IAAI,EAAM,EAAK,GAAG,CAAE,EAAQ,EACrC,CASO,SAAS,GAAkB,CAAI,CAAE,CAAG,CAAE,CAAK,CAAE,CAAQ,EAC1D,OAAO,GAAQ,EAAM,EAAK,EAAG,EAC/B,CAqEO,SAAS,GAAW,CAAG,CAAE,CAAK,EACnC,GAAqB,EAAK,EAAK,GAAG,CAAC,YAAY,CAAE,EAAM,KAAK,CAC9D,CyDrFO,SAAS,GAAkB,CAAK,CAAE,CAAI,CAAE,CAAK,CAAE,CAAQ,EAC5D,OAAO,IAAI,EAAM,EAAK,GAAG,CAAE,EAAO,EACpC,CAkDO,SAAS,GAAW,CAAG,CAAE,CAAK,EACnC,GAAqB,EAAK,EAAK,GAAG,CAAC,YAAY,CAAE,EAAM,KAAK,CAC9D,CvCfA,SAAS,GAAa,CAAK,CAAE,CAAK,CAAE,CAAO,EACzC,GAAI,EAAS,CACX,IAAyB,IAArB,EAAQ,QAAQ,EAAc,OAAO,KAAK,CAAC,GAC7C,KADqD,CAC/C,AAAI,MAAM,CAAA,EAAG,EAAgB,6BAA6B,CAAC,EAEnE,IAA8B,IAA1B,EAAQ,GAA2B,UAAd,GAAe,IAAU,KAAY,IAAU,CAAC,GAAA,CAAQ,CAC/E,EADkF,IAC5E,AAAI,MAAM,CAAA,EAAG,EAAgB,kCAAkC,CAAC,CAE1E,CACA,OAAO,IAAI,EAAM,EAAK,KAAK,CAAE,EAAO,EACtC,CAwCO,SAAS,GAAa,CAAG,CAAE,CAAK,CAAE,CAAO,EAC9C,IAAM,EAAQ,EAAM,KAAK,CAEzB,IAAc,IAAV,EACF,CADmB,CACf,IAAI,CAAC,CA/FO,GA+FN,EAAK,KAAK,CAAC,YAAY,CAAe,EAAZ,KAC/B,IAAc,IAAV,EAAgB,AACzB,EAAI,IAAI,CAAC,CAhGM,GAgGL,EAAK,KAAK,CAAC,YAAY,CAAc,EAAX,KAC/B,GAAc,MAAM,CAAhB,EACT,EAAI,IAAI,CAAC,CAjGM,GAiGL,EAAK,KAAK,CAAC,YAAY,CAAc,EAAX,KAC/B,QAAc,IAAV,EACT,EAAI,GAD0B,CACtB,CAAC,CAlGW,GAkGV,EAAK,KAAK,CAAC,YAAY,CAAmB,EAAhB,IAC/B,KAoKe,EAlKpB,CAkKuB,GAlKnB,GAAU,EACT,IAA+B,IAApB,EAAQ,AAAkB,OAAX,GAC7B,GAAc,GAEV,IADM,GAAY,GAAM,AACd,IAAW,OAAO,KAAK,CAAC,IACpC,EAAI,CAAC,CADuC,CACrC,CAAG,IACV,EAAI,IAAI,CAAC,GAAK,KAAK,CAAC,EAAG,IACvB,GAAU,IAEV,GAAc,GAEV,IADM,GAAY,GAAM,AACd,KACZ,EAAI,CAAC,CADgB,CACd,CAAG,IACV,EAAI,IAAI,CAAC,GAAK,KAAK,CAAC,EAAG,IACvB,GAAU,KAIX,MACW,EAgJlB,CAjJgB,EAiJP,UAAU,CAAC,EAAG,GAAK,GA/Id,GAAY,GAAM,GAC5B,EAAI,CAAC,EAAE,CAAG,IACV,EAAI,IAAI,CAAC,GAAK,KAAK,CAAC,EAAG,IAE3B,CACF,C4C5DA,GAAa,WAAW,CAAG,SAAS,AAAa,CAAK,EACpD,IAAM,EAAS,EAAM,KAAK,CACpB,EAA8B,UAAlB,OAAO,EAAuB,EAAS,GAAQ,GAAmB,CAAC,EAAV,EAAc,SAGzF,AAAI,EAAW,EAAmB,CAAC,EAAE,CAC5B,CAD8B,CAGnC,EAAW,EAAmB,CAAC,EAAE,CAC5B,CAD8B,CAGnC,EAAW,EAAmB,CAAC,EAAE,CAC5B,CAD8B,CAGnC,EAAW,EAAmB,CAAC,EAAE,CAC5B,CAD8B,CAGhC,CACT,EAOA,GAAa,aAAa,CAAG,SAAS,AAAe,CAAI,CAAE,CAAI,EAE7D,OAAO,EAAK,KAAK,CAAG,EAAK,KAAK,CAAG,EAAI,EAAK,KAAK,CAAG,EAAK,KAAK,CAAG,CAAC,EAAyB,CAC3F,CADsE,C1DEtE,GAAY,WAAW,CAAG,E0DF8D,O1DExC,AAAb,CAAkB,EACnD,IAAM,EAAQ,GAAW,GACzB,OAAO,GAAqB,WAAW,CAAC,EAAM,MAAM,EAAI,EAAM,MAChE,AADsE,EAQtE,GAAY,aAAa,CAAG,SAAS,AAAe,CAAI,CAAE,CAAI,UAC5D,OAQ4B,AARrB,EAQuB,AARV,GAAW,GAQC,EARM,AAQJ,GARe,GAS1C,EAAG,MAAM,CAAG,EAAG,MAAM,CAAG,CAAC,EAAI,EAAG,MAAM,CAAG,EAAG,MAAM,CAAG,EAAI,EAAQ,EAAI,EAR9E,ELnBA,GAAY,aAAa,CAAG,GAAgB,aAAa,CAMzD,GAAY,WAAW,CAAG,SAAS,AAAa,CAAK,EACnD,OAAO,GAAqB,WAAW,CAAC,EAAM,KAAK,CACrD,ECRA,GAAU,aAAa,CAAG,GAAgB,aAAa,CAMvD,GAAU,WAAW,CAAG,SAAS,AAAa,CAAK,EACjD,OAAO,GAAqB,WAAW,CAAC,EAAM,KAAK,CACrD,EyDzCA,GAAU,aAAa,CAAG,GAAgB,aAAa,CAMvD,GAAU,WAAW,CAAG,SAAsB,AAAb,CAAkB,EACjD,OAAO,GAAqB,WAAW,CAAC,EAAM,KAAK,CACrD,EvCsEA,GAAY,WAAW,CAAG,SAAS,AAAa,CAAK,CAAE,CAAO,EAC5D,IAAM,EAAQ,EAAM,KAAK,CAEzB,GAAI,AAAU,SAAmB,IAAV,GAAoC,MAAlB,EACvC,EADmE,KAC5D,CAD0C,CAInD,GAAI,CAJ4E,AAI3E,IAA+B,IAApB,EAAQ,OAAO,CAAW,CACxC,GAAc,GACd,IAAI,EAAU,GAAY,GAAM,GAChC,GAAI,IAAU,GAAW,OAAO,KAAK,CAAC,GACpC,KAD4C,EACrC,EAIT,GAFA,GAAc,GAEV,KADJ,EAAU,GAAY,AACR,GADc,EAAA,EAE1B,EADqB,KACd,CAEX,CACA,OAAO,CACT,EAEA,IAAM,GAAS,IAAI,YAAY,GACzB,GAAW,IAAI,SAAS,GAAQ,GAChC,GAAO,IAAI,WAAW,GAAQ,GAKpC,SAAS,GAAe,CAAG,EACzB,GAAI,IAAQ,IACV,GAAS,GADW,MACF,CAAC,EAAG,OAAQ,QACzB,GAAI,IAAQ,CAAC,IAClB,GAAS,GADmB,MACV,CAAC,EAAG,OAAQ,QACzB,GAAI,OAAO,KAAK,CAAC,GACtB,GAD4B,AACnB,SAAS,CAAC,EAAG,OAAQ,OACzB,CACL,GAAS,UAAU,CAAC,EAAG,GACvB,IAAM,EAAS,GAAS,SAAS,CAAC,GAC5B,EAAW,CAAU,WAAT,CAAS,CAAU,EAAK,GACpC,EAAoB,QAAT,EAGjB,GAAI,AAAa,MAAM,EAErB,GAAS,SAAS,CAAC,EAAG,OAAQ,QACzB,GAAiB,IAAb,EAET,AAF4B,GAEnB,SAAS,CAAC,EAAG,CAAE,AAAM,YAAA,CAAU,EAAK,GAAO,GAAY,IAAK,OAChE,CAEL,IAAM,EAAkB,EAAW,IAG/B,EAAkB,CAAC,GAKrB,CALyB,EAKhB,SAAS,CAAC,EAAG,GACb,EAAkB,CAAC,GAI5B,CAJgC,EAIvB,SAAS,CAAC,EAAI,CAAU,WAAT,CAAS,CAAU,EAAK,GAAsB,GAAM,GAAK,GAAmB,GAEpG,GAAS,SAAS,CAAC,EAAI,CAAU,WAAT,CAAS,CAAU,EAAK,GAAQ,EAAkB,IAAO,GAAO,GAAY,IAAK,EAE7G,CACF,CACF,CAOA,SAAS,GAAa,CAAI,CAAE,CAAG,MAiBzB,EAhBJ,GAAI,EAAK,MAAM,CAAG,EAAM,EACtB,CADyB,KACnB,AAAI,MAAM,CAAA,EAAG,EAAgB,4BAA4B,CAAC,EAGlE,IAAM,EAAO,CAAC,CAAI,CAAC,EAAI,GAAI,CAAC,CAAI,CAAI,CAAC,EAAM,EAAE,CAC7C,GAAa,QAAT,AAAiB,EACnB,OAAO,IAET,GAAa,QAAT,AAAiB,EACnB,MAAO,CAAC,IAEV,GAAa,QAAT,AAAiB,EACnB,OAAO,IAET,IAAM,EAAO,GAAQ,GAAM,GACrB,EAAO,AAAO,OAWpB,OARE,EADU,GAAG,CAAX,EACY,KAAK,CAAC,eAAd,EACW,IAAI,CAAZ,EACH,AAAC,GAAO,IAAA,CAAI,CAAK,IAAM,CAAD,CAAO,EAAA,CAAE,CAItB,IAAT,EAAa,IAAW,IAEjB,MAAR,EAAkB,CAAC,EAAM,CAClC,CAKA,SAAS,GAAe,CAAG,EACzB,GAAS,UAAU,CAAC,EAAG,EAAK,GAC9B,CAOA,SAAS,GAAa,CAAI,CAAE,CAAG,EAC7B,GAAI,EAAK,MAAM,CAAG,EAAM,EACtB,CADyB,KACf,AAAJ,MAAU,CAAA,EAAG,EAAgB,4BAA4B,CAAC,EAElE,IAAM,EAAS,CAAC,EAAK,UAAU,EAAI,CAAC,EAAI,EACxC,OAAO,IAAI,SAAS,EAAK,MAAM,CAAE,EAAQ,GAAG,UAAU,CAAC,GAAG,EAC5D,CAcA,SAAS,GAAa,CAAI,CAAE,CAAG,EAC7B,GAAI,EAAK,MAAM,CAAG,EAAM,EACtB,CADyB,KACf,AAAJ,MAAU,CAAA,EAAG,EAAgB,4BAA4B,CAAC,EAElE,IAAM,EAAS,CAAC,EAAK,UAAU,GAAI,CAAC,CAAI,EACxC,OAAO,IAAI,SAAS,EAAK,MAAM,CAAE,EAAQ,GAAG,UAAU,CAAC,EAAG,GAC5D,C+BjRA,SAAS,GAAc,CAAI,CAAE,CAAG,CAAE,CAAK,EACrC,MAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,4BAA4B,EAAE,EAAM,YAAY,EAAE,CAAI,CAAC,EAAI,GAAK,EAAA,CAAG,CACxG,CAMA,SAAS,GAAS,CAAG,EACnB,MAAO,KAAQ,MAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,CAAC,EAAE,EAAA,CAAK,CAAE,CAC9D,C/B8QA,GAAY,aAAa,CAAG,GAAW,aAAa,C+B3Q7C,C/B4QP,G+B5Qa,GAAO,EAAE,CAGtB,IAAK,IAAI,EAAI,EAAG,GAAK,GAAM,IAAK,AAC9B,EAAI,CAAC,EAAE,CAAG,GAEZ,EAAI,CAAC,GAAK,C5CuDH,E4CvDM,EAFY,K5CyDT,AAAa,CAAI,CAAE,CAAG,CAAE,CAAM,C4CvDhB,A5CuDkB,CAAO,EACrD,OAAO,IAAI,EAAM,EAAK,IAAI,CAAE,GAAU,EAAM,EAAM,EAAG,E4C1De,C5C0DL,EACjE,E4CxDA,EAAI,CAAC,GADsE,AACjE,C5CiEH,E4CjEM,O5CiEG,AAAc,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,A4CjEzB,E5CkE7B,OAAO,IAAI,EAAM,EAAK,IAAI,CAAE,GAAW,EAAM,EAAM,EAAG,GAAU,EAClE,E4ClEA,EAAI,CAAC,GAAK,C5C2EH,C4C5EsE,CAChE,O5C2EiB,AAAd,CAAkB,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,A4C3EzB,E5C4E7B,OAAO,IAAI,EAAM,EAAK,IAAI,CAAE,GAAW,EAAM,EAAM,EAAG,GAAU,EAClE,E4C5EA,EAAI,CAAC,GAAK,C5CqFH,E4CtFuE,AACjE,O5CqFG,AAAc,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,A4CrFzB,E5CsF7B,OAAO,IAAI,EAAM,EAAK,IAAI,CAAE,GAAW,EAAM,EAAM,EAAG,GAAU,EAClE,E4CtFA,EAAI,CAAC,GAAK,CAAG,GADkE,AAE/E,EAAI,CAAC,GAAK,CAAG,GACb,EAAI,CAAC,GAAK,CAAG,GACb,EAAI,CAAC,GAAK,CAAG,GAEb,IAAK,IAAI,EAAI,GAAM,GAAK,GAAM,IAAK,AACjC,EAAI,CAAC,EAAE,CAAG,GAEZ,EAAI,CAAC,GAAK,CalCH,EbkCM,EAFY,KahCT,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,CbkCvB,CajChC,OAAO,IAAI,EAAM,EAAK,MAAM,Ab+B8B,Ca/B5B,CAAC,EAAI,GAAe,EAAM,EAAM,EAAG,GAAU,EAC7E,EbiCA,EAAI,CAAC,GAAK,CaxBH,EbwBM,KAD6E,EavB1D,AAAhB,CAAoB,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACxD,AbuBiC,OavB1B,IAAI,EAAM,EAAK,MAAM,CAAE,CAAC,EAAI,GAAgB,EAAM,EAAM,EAAG,GAAU,EAC9E,EbuBA,EAAI,CAAC,GAAK,CadH,EbcM,OadG,AAAgB,Aba4D,CabxD,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACxD,AbaiC,Oab1B,IAAI,EAAM,EAAK,MAAM,CAAE,CAAC,EAAI,GAAgB,EAAM,EAAM,EAAG,GAAU,EAC9E,EbaA,EAAI,CAAC,GAAK,CaDH,EbCM,MAD8E,CaA3E,AAAgB,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACxD,AbAiC,IaA3B,EAAM,GAAgB,EAAM,EAAM,EAAG,GAC3C,GAAmB,UAAf,OAAO,EAAkB,CAC3B,IAAM,EAAQ,CAAC,EAAI,EACnB,GAAI,EbHoF,CaG3E,OAAO,gBAAgB,CAClC,CADoC,MAC7B,IAAI,EAAM,EAAK,MAAM,CAAE,EAAO,EAEzC,CACA,IAA4B,IAAxB,EAAQ,AAAsB,WAAX,CACrB,MAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,6DAA6D,CAAC,EAEnG,OAAO,IAAI,EAAM,EAAK,MAAM,CAAE,GAAQ,OAAO,GAAM,EACrD,EbVA,EAAI,CAAC,GAAK,CAAG,GACb,EAAI,CAAC,GAAK,CAAG,GACb,EAAI,CAAC,GAAK,CAAG,GACb,EAAI,CAAC,GAAK,CAAG,GAEb,IAAK,IAAI,EAAI,GAAM,GAAK,GAAM,IAAK,AACjC,EAAI,CAAC,EAAE,CAAG,GAEZ,EAAI,CAAC,GAAK,C7CvBH,E6CuBM,O7CvBG,AAAc,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,A6CuBxB,E7CtB9B,OAAO,GAAQ,EAAM,EAAK,EAAG,GAAe,EAAM,EAAM,EAAG,GAC7D,E6CsBA,EAAI,CAAC,GAAK,C7CbH,E6CaM,O7CbG,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,C6CaxB,C7CZ/B,M6CW6F,C7CXtF,GAAQ,EAAM,EAAK,EAAG,GAAgB,EAAM,EAAM,EAAG,GAC9D,E6CYA,EAAI,CAAC,GAAK,C7CHH,E6CGM,O7CHG,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,C6CGxB,C7CF/B,OAAO,C6CCwF,E7CDhF,EAAM,EAAK,EAAG,GAAgB,EAAM,EAAM,EAAG,GAC9D,E6CEA,EAAI,CAAC,GAAK,C7CQH,E6CRM,O7CQG,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,C6CRxB,C7CS/B,IAAM,EAAI,G6CVsF,A7CUtE,EAAM,EAAM,EAAG,GACzC,GAAiB,UAAb,AAAuB,OAAhB,EACT,MAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,Q6CX4D,mC7CWjB,CAAC,EAEjF,OAAO,GAAQ,EAAM,EAAK,EAAG,EAC/B,E6CbA,EAAI,CAAC,GAAK,CAAG,GACb,EAAI,CAAC,GAAK,CAAG,GACb,EAAI,CAAC,GAAK,CAAG,GACb,EAAI,CAAC,GAAK,CAAG,GAAQ,qDAErB,CAF0E,GAErE,IAAI,EAAI,GAAM,GAAK,IAAM,IAAK,AACjC,EAAI,CAAC,EAAE,CAAG,GAEZ,EAAI,CAAC,IAAK,CrC7BH,EqC6BM,OrC7BG,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,CqC6BvB,CrC5BhC,AqCuBkI,OrCvB3H,GAAQ,EAAM,EAAK,EAAG,GAAe,EAAM,EAAM,EAAG,GAAU,EACvE,EqC4BA,EAAI,CAAC,IAAK,CrCnBH,EqCmBM,OrCnBG,AAAgB,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACxD,AqCkBiC,KAD+D,ErCjBzF,GAAQ,EAAM,EAAK,EAAG,GAAgB,EAAM,EAAM,EAAG,GAAU,EACxE,EqCkBA,EAAI,CAAC,IAAK,CrCTH,EqCSM,OrCTmB,AAAhB,CAAoB,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACxD,AqCQiC,OrCR1B,AqCO2F,GrCPnF,EAAM,EAAK,EAAG,GAAgB,EAAM,EAAM,EAAG,GAAU,EACxE,EqCQA,EAAI,CAAC,IAAK,CrCEH,EqCFM,OrCEG,AAAgB,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACxD,AqCHiC,IrCG3B,EAAI,EqCJyF,CrCIzE,EAAM,EAAM,EAAG,GACzC,GAAiB,UAAb,AAAuB,OAAhB,EACT,MAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,UqCL+D,kCrCKnB,CAAC,EAElF,OAAO,GAAQ,EAAM,EAAK,EAAG,EAAG,EAClC,EqCPA,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GAAQ,qDAErB,CAF0E,GAErE,IAAI,EAAI,IAAM,GAAK,IAAM,IAAK,AACjC,EAAI,CAAC,EAAE,CAAG,GAEZ,EAAI,CAAC,IAAK,ClDlDH,EkDkDM,GAL2G,IlD7C1F,AAAd,CAAkB,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,AkDkDxB,ElDjD9B,OAAO,GAAQ,EAAM,EAAK,EAAG,GAAe,EAAM,EAAM,EAAG,GAC7D,EkDiDA,EAAI,CAAC,IAAK,ClDxCH,EkDwCM,OlDxCG,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,CkDwCxB,ClDvC/B,IkDsC4F,GlDtCrF,GAAQ,EAAM,EAAK,EAAG,GAAgB,EAAM,EAAM,EAAG,GAC9D,EkDuCA,EAAI,CAAC,IAAK,ClD9BH,EkD8BM,OlD9BG,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,CkD8BxB,ClD7B/B,MkD4B8F,ClD5BvF,GAAQ,EAAM,EAAK,EAAG,GAAgB,EAAM,EAAM,EAAG,GAC9D,EkD6BA,EAAI,CAAC,IAAK,ClDnBH,EkDmBM,OlDnBG,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,CkDmBxB,ClDlB/B,IAAM,EAAI,CkDiBqF,ElDjBrE,EAAM,EAAM,EAAG,GACzC,GAAI,AAAa,UAAU,OAAhB,EACT,MAAU,AAAJ,MAAU,CAAA,EAAG,EAAgB,OkDgB2D,oClDhBhB,CAAC,EAEjF,OAAO,GAAQ,EAAM,EAAK,EAAG,EAC/B,EkDcA,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,ClDRH,EkDQM,OlDRG,AAAuB,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EAC/D,IAAgC,GkDOO,ClDPnC,EAAQ,CAA2B,cAAZ,CACzB,MAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,ckDMoD,sBlDNhB,CAAC,EAE1E,OAAO,GAAQ,EAAM,EAAK,EAAG,IAC/B,EkDKA,IAAK,IAAI,EAAI,IAAM,GAAK,IAAM,IAAK,AACjC,EAAI,CAAC,EAAE,CAAG,GAEZ,EAAI,CAAC,IAAK,CjD9DH,EiD8DM,OjD9DG,AAAY,CAAI,CAAE,CAAG,CAAE,CAAM,AiD8DjB,CjD9DmB,CAAO,EACpD,OAAO,GAAQ,EAAM,EAAK,EAAG,GAAe,EAAM,EAAM,EAAG,GAC7D,EiD6DA,EAAI,CAAC,IAAK,CjDpDH,EiDoDM,OjDpDG,AAAa,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,AiDoDnB,CjDpD0B,EACrD,OAAO,EiDkDwF,CjDlDhF,EAAM,EAAK,EAAG,GAAgB,EAAM,EAAM,EAAG,GAC9D,EiDmDA,EAAI,CAAC,IAAK,CjD1CH,EiD0CM,OjD1CG,AAAa,CAAI,CAAE,CAAG,CAAE,CAAM,CiD0CjB,AjD1CmB,CAAO,EACrD,OAAO,GAAQ,CiDwCkF,CjDxC5E,EAAK,EAAG,GAAgB,EAAM,EAAM,EAAG,GAC9D,EiDyCA,EAAI,CAAC,IAAK,CjD/BH,EiD+BM,OjD/BG,AAAa,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,AiD+BnB,CjD/B0B,EACrD,IAAM,EAAI,GAAgB,EAAM,CiD6BkE,CjD7B5D,EAAG,GACzC,GAAiB,UAAb,AAAuB,OAAhB,EACT,MAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,YiD4B8D,6BjD5BrB,CAAC,EAE/E,OAAO,GAAQ,EAAM,EAAK,EAAG,EAC/B,EiD0BA,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CjDpBH,EiDoBM,OjDpBG,AAAqB,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EAC7D,IAAgC,CiDmBG,GjDnB/B,EAAQ,CAA2B,cAAZ,CACzB,MAAU,AAAJ,MAAU,CAAA,EAAG,EAAgB,mBiDkBuD,iBjDlBnB,CAAC,EAE1E,OAAO,GAAQ,EAAM,EAAK,EAAG,IAC/B,EiDiBA,IAAK,IAAI,EAAI,IAAM,GAAK,IAAM,IAAK,AACjC,EAAI,CAAC,EAAE,CAAG,GAEZ,EAAI,CAAC,IAAK,CQtFH,ERsFM,OQtFG,AAAY,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACpD,OAAO,IAAI,EAAM,EAAK,GAAG,CAAE,GAAe,EAAM,EAAM,EAAG,GAAU,EACrE,ERqFA,EAAI,CAAC,IAAK,CQ5EH,ER4EM,OQ5EG,AAAa,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACrD,OAAO,IAAI,EAAM,EAAK,GAAG,CAAE,GAAgB,EAAM,EAAM,EAAG,GAAU,EACtE,ER2EA,EAAI,CAAC,IAAK,CQlEH,ERkEM,OQlEgB,AAAb,CAAiB,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACrD,OAAO,IAAI,EAAM,EAAK,GAAG,CAAE,GAAgB,EAAM,EAAM,EAAG,GAAU,EACtE,ERiEA,EAAI,CAAC,IAAK,CQxDH,ERwDM,OQxDG,AAAa,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,EACrD,OAAO,IAAI,EAAM,EAAK,GAAG,CAAE,GAAgB,EAAM,EAAM,EAAG,GAAU,EACtE,ERuDA,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GAEb,IAAK,IAAI,EAAI,IAAM,GAAK,IAAM,IAAK,AACjC,EAAI,CAAC,EAAE,CAAG,GAAQ,mCAEpB,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,GACb,AAF0B,EAEtB,CAAC,IAAK,CAAG,GADa,AAE1B,EAAI,CAAC,IAAK,C/BtGH,E+BsGM,CADa,M/BrGO,A+BmGqB,A/BnGtC,CAAsB,CAAE,CAAI,CAAE,CAAM,CAAE,CAAO,EAC3D,C+BmGmD,AAElB,G/BrGF,IAA3B,EAAQ,CAA0B,C+BoGa,CACN,W/BrGnB,CACxB,MAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,mCAAmC,CAAC,QAClE,CAAsC,IAAlC,EAAQ,AAAgC,qBAAX,CAC/B,IAAI,EAAM,EAAK,IAAI,CAAE,KAAM,GAE7B,IAAI,EAAM,EAAK,SAAS,MAAE,EAAW,EAC9C,E+BgGA,EAAI,CAAC,IAAK,CAAG,GAAQ,mCACrB,CADwD,CACpD,CAAC,IAAK,C/BxDH,E+BwDM,O/BxDG,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,C+BwDxB,C/BvD/B,OAAO,GAAY,GAAY,EAAM,EAAM,GAAI,C+BsDqD,C/BtDlD,EACpD,E+BuDA,EAAI,CAAC,IAAK,C/B9CH,E+B8CM,MAD+D,C/B7C5D,AAAe,CAAI,CAAE,CAAG,CAAE,CAAM,CAAE,CAAO,C+B8CxB,C/B7C/B,OAAO,GAAY,GAAY,EAAM,EAAM,GAAI,EAAG,EACpD,E+B6CA,EAAI,CAAC,IAAK,C/BpCH,E+BoCM,O/BpCG,AAAe,CAAI,C+BmC4C,A/BnC1C,CAAG,CAAE,CAAM,CAAE,CAAO,C+BoCxB,C/BnC/B,OAAO,GAAY,GAAY,EAAM,EAAM,GAAI,EAAG,EACpD,E+BmCA,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,CAAG,CAFmE,EAGhF,EAAI,CAAC,IAAK,CAAG,GACb,EAAI,CAAC,IAAK,C/B9FH,E+B8FM,O/B9FG,AAAa,CAAK,CAAE,CAAI,CAAE,CAAM,CAAE,A+B8FnB,C/B9F0B,EACvD,IAAgC,IAA5B,EAAQ,CAA2B,M+B6FU,Q/B7FtB,CACzB,MAAM,AAAI,MAAM,CAAA,EAAG,EAAgB,oCAAoC,CAAC,EAE1E,OAAO,IAAI,EAAM,EAAK,KAAK,MAAE,EAAW,EAC1C,E+B4FO,IAAM,GAAQ,EAAE,CAEvB,IAAK,IAAI,EAAI,EAAG,EAAI,GAAI,IAAK,AAC3B,EAAK,CAAC,EAAE,CAAG,IAAI,EAAM,EAAK,IAAI,CAAE,EAAG,GAGrC,IAAK,IAAI,EAAI,CAAC,EAAG,GAAK,CAAC,GAAI,IAAK,AAC9B,EAAK,CAAC,GAAK,EAAE,CAAG,IAAI,EAAM,EAAK,MAAM,CAAE,EAAG,GAG5C,EAAK,CAAC,GAAK,CAAG,IAAI,EAAM,EAAK,KAAK,CAAE,IAAI,WAAW,GAAI,GAEvD,EAAK,CAAC,GAAK,CAAG,IAAI,EAAM,EAAK,MAAM,CAAE,GAAI,GAEzC,EAAK,CAAC,IAAK,CAAG,IAAI,EAAM,EAAK,KAAK,CAAE,EAAG,GAEvC,EAAK,CAAC,IAAK,CAAG,IAAI,EAAM,EAAK,GAAG,CAAE,EAAG,GAErC,EAAK,CAAC,IAAK,CAAG,IAAI,EAAM,EAAK,KAAK,EAAE,EAAO,GAE3C,EAAK,CAAC,IAAK,CAAG,IAAI,EAAM,EAAK,IAAI,EAAE,EAAM,GAEzC,EAAK,CAAC,IAAK,CAAG,IAAI,EAAM,EAAK,IAAI,CAAE,KAAM,GS/HlC,IAAM,GAAuB,OAAO,MAAM,CAAC,CAChD,SAAS,EACT,UAoXF,CApXa,QAoXJ,AAAkB,CAAE,CAAE,CAAE,EAC/B,GAAI,CAAE,CAAC,EAAE,WAAY,GAAS,CAAE,CAAC,EAAE,WAAY,EAAO,CACpD,IAAM,EAA6B,CAAE,CAAC,EAAE,CAClC,EAA6B,CAAE,CAAC,EAAE,CAUxC,OARI,AAAC,EAAG,SAAS,EAAE,CACjB,EAAG,SAAS,CAAG,wBAkBO,GAAc,KAlBP,EAAG,MAAK,EAGnC,AAAC,EAAG,SAAS,EAAE,CACjB,EAAG,SAAS,CAAG,AAarB,SAAS,AAAe,CAAI,EAC1B,OAAO,GAAa,QACtB,EAfmC,EAAG,MAAK,EAGhC,EAAQ,EAAG,SAAS,CAAE,EAAG,SAAS,CAC3C,CAEA,MAAM,AAAI,MAAM,4DAClB,EApYE,iBTkIK,CSlIL,QTkIc,AAAkB,CAAK,EACrC,OAAQ,EAAM,IAAI,EAChB,KAAK,EAAK,KAAK,OACb,OAAO,EAAU,CAAC,IAAK,gB/C/EL,G+CgFpB,MAAK,EAAK,IAAI,OACZ,OAAO,EAAU,CAAC,IAAK,mBACzB,MAAK,EAAK,IAAI,OACZ,OAAO,EAAU,CAAC,IAAK,mBACzB,MAAK,EAAK,KAAK,CACb,GAAI,CAAC,EAAM,KAAK,CAAC,MAAM,EAAE,MACvB,OAAO,EAAU,CAAC,GAAK,mBAAA,CAEzB,MACF,MAAK,EAAK,MAAM,CACd,GAAI,AAAgB,IAAI,GAAd,KAAK,CACb,K/C5FkB,E+C4FX,SAAU,CAAC,GAAK,mBAAA,CAEzB,MACF,MAAK,EAAK,KAAK,CACb,GAAoB,GAAG,CAAnB,EAAM,KAAK,QACb,OAAO,EAAU,CAAC,IAAK,mBAAA,CAIzB,MACF,MAAK,EAAK,GAAG,CACX,GAAoB,GAAG,CAAnB,EAAM,KAAK,QACb,OAAO,EAAU,CAAC,IAAK,mBAAA,CAIzB,MACF,MAAK,EAAK,IAAI,CACZ,GAAI,EAAM,KAAK,CAAG,IAAI,MACpB,OAAO,EAAU,CAAC,OAAO,EAAM,KAAK,EAAE,mBAAA,CAExC,MACF,MAAK,EAAK,MAAM,CACd,GAAI,EAAM,KAAK,EAAI,CAAC,IAAI,MACtB,OAAO,EAAU,CAAC,GAAK,OAAO,EAAM,KAAK,EAAE,C/CnH1C,WAAW,KAAK,E+CmH0B,CAEjD,CACF,CS3KA,GAgBM,IAXJ,CADM,EAAW,EAAE,CACX,CAAC,EAAK,EAWK,EAXD,CAAC,KAAK,CAAC,CAAG,GAC5B,CAAQ,CAAC,EAAK,MAAM,CAAC,KAAK,CAAC,CAAG,GAC9B,CAAQ,CAAC,EAAK,KAAK,CAAC,KAAK,CAAC,CAAG,GAC7B,CAAQ,CAAC,EAAK,MAAM,CAAC,KAAK,CAAC,C9C4CD,E8C5CI,CAC9B,CAAQ,CAAC,EAAK,KAAK,CAAC,KAAK,CAAC,CAAG,GAC7B,CAAQ,CAAC,EAAK,GAAG,CAAC,KAAK,CAAC,CAAG,GAC3B,CAAQ,CAAC,EAAK,GAAG,CAAC,KAAK,CAAC,CAAG,GAC3B,CAAQ,CAAC,EAAK,KAAK,CAAC,KAAK,CAAC,CAAG,GACtB,GAKH,GAAM,IAAI,CAGhB,OAAM,GAKJ,YAAa,CAAG,CAAE,CAAM,CAAE,CACxB,IAAI,CAAC,GAAG,CAAG,EACX,IAAI,CAAC,MAAM,CAAG,CAChB,CAMA,SAAU,CAAG,CAAE,CAEb,IAAI,EAAI,IAAI,CACZ,GAAG,AACD,GAAI,EAAE,GAAG,GAAK,EACZ,GADiB,IACV,QAEF,EAAI,EAAE,MAAM,CAAC,AACtB,CADuB,MAChB,CACT,CAOA,OAAO,OATwC,KAS3B,CAAK,CAAE,CAAG,CAAE,CAC9B,GAAI,GAAS,EAAM,QAAQ,CAAC,GAC1B,GADgC,GAC1B,AAAI,MAAM,CAAA,EAAG,EAAgB,oCAAoC,CAAC,EAE1E,OAAO,IAAI,GAAI,EAAK,EACtB,CACF,CAEA,IAAM,GAAe,CACnB,KAAM,IAAI,EAAM,EAAK,IAAI,CAAE,MAC3B,UAAW,IAAI,EAAM,EAAK,SAAS,MAAE,GACrC,KAAM,IAAI,EAAM,EAAK,IAAI,EAAE,GAC3B,MAAO,IAAI,EAAM,EAAK,KAAK,EAAE,GAC7B,WAAY,IAAI,EAAM,EAAK,KAAK,CAAE,GAClC,SAAU,IAAI,EAAM,EAAK,GAAG,CAAE,EAChC,EAGM,GAAe,QAQnB,CAAQ,EAAK,CAAF,CAAQ,EAAU,AAAZ,IACf,AAAI,AAAC,EADoB,GAAW,EACxB,SAAS,CAAC,IAAS,IAAD,GAAQ,aAAa,CAAC,GAEzC,GAF+C,AAExC,EACT,CADY,GACR,EAAM,EAAK,IAAI,CAAE,GAErB,IAAI,EAAM,EAAK,MAAM,CAAE,GAJvB,IAAI,EAAM,EAAK,KAAK,CAAE,UAejC,CAAQ,EAAK,CAAF,CAAQ,EAAF,AAAY,IAC3B,AAAI,EADqB,CACd,EADyB,KAClB,GACT,CADa,GACT,EAAM,EAAK,IAAI,CAAE,GAErB,IAAI,EAAM,EAAK,MAAM,CAAE,cAWlC,CAAY,EAAK,CAAF,CAAQ,EAAF,AAAY,IACxB,EADsB,EAClB,CAD6B,CACvB,EAAK,KAAK,CAAE,UAU/B,CAAQ,EAAK,CAAF,CAAQ,EAAU,AAAZ,IACR,EADkB,EACd,CADyB,CACnB,EAAK,MAAM,CAAE,WAUhC,CAAS,EAAK,CAAF,CAAQ,EAAF,AAAY,IACrB,EADmB,AACb,GADwB,AACX,IAAI,CAAG,GAAa,KAAK,MAUrD,CAAM,EAAM,EAAF,AAAQ,EAAU,AAAZ,IACP,EADiB,CACJ,EADe,EACX,WAU1B,CAAW,EAAM,EAAM,AAAR,EAAkB,AAAZ,IACZ,EADsB,CACT,EADoB,OACX,aAU/B,CAAa,EAAK,CAAF,CAAQ,EAAF,AAAY,IACzB,EADuB,EACnB,CAD8B,CACxB,EAAK,KAAK,CAAE,IAAI,WAAW,aAU9C,CAAU,EAAK,CAAF,CAAQ,EAAF,AAAY,IACtB,EADoB,EAChB,CAD2B,CACrB,EAAK,KAAK,CAAE,IAAI,WAAW,EAAI,MAAM,CAAE,EAAI,UAAU,CAAE,EAAI,UAAU,GAUxF,MAAO,CAAG,CAAE,CAAI,CAAE,CAAO,CAAE,CAAQ,EACjC,GAAI,CAAC,EAAI,MAAM,EAAE,KACf,CAA+B,IAA3B,EAAQ,AAAyB,cAAX,CACjB,CAAC,GAAa,UAAU,CAAE,IAAI,EAAM,EAAK,KAAK,EAAE,CAElD,GAAa,UAAU,CAEhC,EAAW,GAAI,WAAW,CAAC,EAAU,GACrC,IAAM,EAAU,EAAE,CACd,EAAI,EACR,IAAK,IAAM,KAAK,EACd,CAAO,CADY,AACX,IAAI,CAAG,GAAe,EAAG,EAAS,UAE5C,AAAI,EAAQ,cAAc,CACjB,CADmB,AAClB,IAAI,EAAM,EAAK,KAAK,CAAE,EAAI,MAAM,EAAG,EAAS,IAAI,EAAM,EAAK,KAAK,EAAE,CAErE,CAAC,IAAI,EAAM,EAAK,KAAK,CAAE,EAAI,MAAM,EAAG,EAAQ,AACrD,EASA,OAAQ,CAAG,CAAE,CAAG,CAAE,CAAO,CAAE,CAAQ,UAEjC,IAAM,EAAgB,WAAR,EAER,EAAO,EAAQ,EAAI,IAAI,GAAK,OAAO,IAAI,CAAC,GACxC,EAAS,EAAQ,EAAI,IAAI,CAAG,EAAK,MAAM,CAC7C,GAAI,CAAC,QAAQ,AACX,CAA+B,IAA3B,EAAQ,AAAyB,cAAX,CACjB,CAAC,GAAa,QAAQ,CAAE,IAAI,EAAM,EAAK,KAAK,EAAE,CAEhD,GAAa,QAAQ,CAE9B,EAAW,GAAI,WAAW,CAAC,EAAU,GAErC,IAAM,EAAU,EAAE,CACd,EAAI,EACR,IAAK,IAAM,KAAO,EAChB,CAAO,CAAC,CADc,GACV,CAAG,CACb,GAAe,EAAK,EAAS,GAC7B,GAAe,EAAQ,EAAI,GAAG,CAAC,GAAO,CAAG,CAAC,EAAI,CAAE,EAAS,GAC1D,OAGH,CA6FqB,EA9FN,EA+Fb,CAD4B,EA9FN,AA8FI,GAClB,EAD2B,OAClB,EAAE,AACrB,EAAQ,IAAI,CAAC,EAAQ,SAAS,EA/F1B,EAAQ,cAAc,EAAE,AACnB,CAAC,IAAI,EAAM,EAAK,GAAG,CAAE,GAAS,EAAS,IAAI,EAAM,EAAK,KAAK,EAAE,CAE/D,CAAC,IAAI,EAAM,EAAK,GAAG,CAAE,GAAS,EAAQ,AAC/C,CACF,EAIA,IAAK,IAAM,KAFX,GAAa,GAAG,CAAG,GAAa,MAAM,CACtC,GAAa,MAAM,CAAG,GAAa,UAAU,CAC3B,iFAAiF,KAAK,CAAC,KAAM,CAC7G,EAAY,CAAC,CAAA,EAAG,EAAI,KAAK,CAAC,CAAC,CAAG,GAAa,QAAQ,CASrD,SAAS,GAAgB,CAAG,CAAE,EAAU,CAAC,CAAC,CAAE,CAAQ,EAClD,IAAM,EAAM,AhH/OP,SAAS,AAAI,CAAK,QACvB,GAAc,MAAM,CAAhB,EACF,MAAO,OAET,QAAc,IAAV,EACF,KADuB,CAChB,YAET,IAAc,IAAV,IAA4B,IAAV,EACpB,CADqC,KAC9B,UAET,IAAM,EAAS,OAAO,EACtB,GAAI,EAAQ,QAAQ,CAAC,GACnB,MAD4B,CACrB,EAIT,GAAe,YAAY,CAAvB,EACF,MAAO,WAET,GAAI,MAAM,OAAO,CAAC,GAChB,KADwB,CACjB,QAET,GAgBO,CAhBH,AAea,EAfJ,GAeS,CACN,EAAM,EAhBD,SAgBY,EAAI,EAAM,WAAW,CAAC,QAAQ,EAAI,EAAM,WAAW,CAAC,QAAQ,CAAC,IAAI,CAAC,KAAM,GAfvG,MAAO,SAET,IAAM,EAAa,AAoBrB,SAAS,AAAe,CAAK,EAC3B,IAAM,EAAiB,OAAO,SAAS,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAO,KAAK,CAAC,EAAG,CAAC,GACvE,GAAI,EAAgB,QAAQ,CAAC,GAC3B,OAAO,CAIX,EA3BmC,IAsBa,MArB9C,AAAI,GAIG,QACT,CALkB,CgHqND,GACT,EAAoB,GAAY,EAAQ,YAAY,EAAuC,EAAQ,AAA3C,YAAuD,CAAC,EAAI,EAAK,EAAY,CAAC,EAAI,CAChJ,GAAiC,MAD6D,MAC1F,OAAO,EAAkC,CAC3C,IAAM,EAAS,EAAkB,EAAK,EAAK,EAAS,GACpD,GAAc,MAAV,AAAgB,EAClB,OAAO,CAEX,CACA,IAAM,EAAc,EAAY,CAAC,EAAI,CACrC,GAAI,CAAC,EACH,MAAM,AAAI,KADM,CACA,CAAA,EAAG,EAAgB,mBAAmB,EAAE,EAAA,CAAK,EAE/D,OAAO,EAAY,EAAK,EAAK,EAAS,EACxC,CAuJA,SAAS,GAAc,CAAI,CAAE,CAAQ,CAAE,CAAO,EAC5C,IAAM,EAAS,GAAe,EAAM,GACpC,GAAI,CAAC,MAAM,OAAO,CAAC,IAAW,EAAQ,gBAAgB,CAAE,CACtD,IAAM,EAAa,EAAQ,gBAAgB,CAAC,GAC5C,GAAI,EACF,OAAO,EAET,CAHgB,GAGV,EAAU,CAAQ,CAAC,EAAO,IAAI,CAAC,KAAK,CAAC,CAC3C,GAAI,EAAQ,WAAW,CAAE,CAEvB,IAAM,EAAM,IAAI,EADH,CACM,CADE,WAAW,CAAC,EAAQ,IAKzC,GAHA,EAAQ,EAAK,EAAQ,GAGK,GAAG,CAAzB,EAAI,MAAM,CAAC,MAAM,CACnB,MAAM,AAAI,MAAM,CAAC,4CAA4C,EAAE,EAAO,UAAU,CAAC,EAEnF,OAAO,EAAM,EAAI,MAAM,CAAC,EAAE,CAC5B,CACF,CAGA,OAFA,GAAI,KAAK,IApCX,AAqCE,SArCO,EAAiB,CAAG,CAAE,CAAM,CAAE,CAAQ,CAAE,CAAO,EACtD,GAAI,MAAM,OAAO,CAAC,GAChB,IAAK,EADoB,EACd,KAAS,EAClB,EAAgB,EAAK,CADK,CACE,EAAU,QAGxC,CAAQ,CAAC,EAAO,IAAI,CAAC,KAAK,CAAC,CAAC,EAAK,EAAQ,EAE7C,EA6BkB,GAAK,EAAQ,EAAU,GAChC,GAAI,OAAO,EAAC,EACrB,C5Draa,OAAO,GAAG,CAAC,QACV,OAAO,GAAG,CAAC,8CFkFV,mKA1HU,iBAAa,UAAA,EAAA,iDAIR,CAAA,mEACoD,+BACC,GoCuCf,ApCcxB,UAAA,sBAC7B,MAAA,MAAA,wDAKE,8CAOoB,CAAI,EAAU,IAAO,CqB0JC,ArB1JA,CAAC,iBAC9B,IAEb,CAAA,EAAA,EAAA,SAH8E,CqB0JC,EAAE,mDrBjJlE,IAAA,GAAA,EAAA,CAAA,GAAA,AAAuC,CAAC,IAAxC,EAA4C,GAAG,CAAI,IAAK,CAAC,G6B8SX,E7B7SjD,CAAC,EAAI,GAAA,sCAIT,MAAA,AAAU,CwCgDwB,AWJpC,KAAA,6BnDvCR,OAAD,CAAC,EAAA,yBAG6B,0CAGE,CAAA,CAAG,yJApFa,CAAA,EAAS,UAAU,CAAC,CAAC,uEAI1C,CAAC,AoEeA,AzGME,CAAC,AyGNH,A1G+BG,kGsCvCI,CAAC,GAApB,CAAA,CAAA,EAAc,uFAYb,CAAA,IAAA,GAAgB,EAAA,CAAA,CAAU,CqBoGC,A7DVJ,AwC1FI,CAAa,AAAb,CAAc,CAAC,GAAf,EAAe,IAAA,WACjD,CAAG,CAAA,EAAK,GAAA,wCAIG,MAAA,+CAMJ,MAAA,EAAA,wGA6Dd,EAAA,uBAEP,MAAA,CAAA,IAAA,EAAA,EAAA,UAAA,CAAiC,gKoExGb,IAAA,CAAA,UAAA,CAAA,GAAA,CAAwB,C7GiKA,A6GjKA,oYAiCG,CzDSxB,IAAA,SyDTsC,CAAC,GAAK,CAAD,CAAC,EAAK,IAAI,CAAC,IAAI,CAAA,4CAAA,EAA+C,IAAI,CAAC,MAAM,CAAA,CAAE,CAAC,CAAA,sBAE5H,CAAA,EAAA,KAAA,CAAA,IAAA,CAAA,MAAA,CAAA,MAAA,6JAwBlB,CAAA,CAAA,WAC2B,CAC3B,EAAA,IAAA,CAAA,QAAA,CAAA,EAAA,gDAIa,CAAA,kCAAA,EAAqC,IAAI,CAAC,SAAA,CAAA,GAAA,4BAAA,EAA+C,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAA,cAAA,CAAgB,CAAC,CAAA,cAKrD,CAAA,CAAA,SAC7F,IAAA,GAAA,0BACqD,CAAC,CAAA,EAAQ,kBACzC,EAAA,MAAA,CAAmC,C9GiHtB,A6G/BlB,0RCpDnB,SAAA,GAAA,CAAA,KAAA,CAAA,CAAqE,QAAA,CAAA,OAAA,CAAA,CAAA,OAAA,CAAA,CAAA,sBAClC,yCAG2C,CAAA,CAAA,8BACvC,UACpC,GAAA,gEA8F+D,CAAA,QAAM,CAAA,CAAA,YAAA,CAAmB,CAAA,SAAA,CAAU,CAAyE,iBAZ3K,AAAmB,CAAA,mBAGjB,EAAA,EAAA,EAAA,EAAA,MAAA,CAAA,EAAA,GACI,CAAA,CAAA,CAAU,EAAE,CAAC,CAAA,SAEnB,CACT,YAOS,GAAA,4BAhDT,SAAA,CAAiC,C9GqNhB,A4F/OA,A5F+OA,CAAA,CAAA,CAAA,Q8GpN0B,QAApB,EAAS,MAAA,CAAS,EAAE,CACzC,EAAA,CAAA,GAAmB,CAAA,EAAe,IACxB,eAIL,IAAA,EAAA,EAAA,EAAA,EAAA,MAAA,CAA4B,EAAE,ClGsLD,AkGtLE,YAFkB,EZiBD,CAAA,CYbnB,GAHyB,+CAetB,EAAc,EAAA,AAAO,OAIjD,EACA,CAAA,EAAA,MAAA,CAAA,EAAA,CAAA,GAAA,qBA0BS,EAAA,EAAA,UAER,kBA9F6E,CAAE,CjCoG5C,AiCpGwD,CjCoGxD,gEiC5FG,CAAC,CAAC,AAAG,CAAC,AxGwKF,CAAA,AwGxKG,CAAA,MAI1C,EzCpBmD,EyCqBlD,wBAAuB,GAG7B,EAAA,CAAA,CAAA,CAAA,CAA2B,EAAA,CALmB,AAKnB,E7B+HtB,mD6B7HoC,OAI3B,EAAA,qDAWyB,EAAA,CAAA,GAAgB,CAAC,AvC8QJ,AxCpHA,CwCoHA,CuC9QM,iBAC1C,2CA6D2B,wG5CpOlB,0jBA0CM,kGAOlC,GAAA,6KLlDM,GAAA,0VlCFH,+HAyCM,mBAAA,EAEV,CAAC,CAAG,EAAI,C0FhBgE,K1FgB1D,CtBH+D,AsBG9D,E1BwK+D,A0BtK/E,0BAIO,WAAA,4HAyBZ,SAAA,CAAA,mBATS,iEAIY,YAaT,UAAA,EAAA,oBAAA,EAAA,EAVH,mBAUG,EAAA,yCWpFW,KAAA,wBAAA,2CASd,iBgBNiD,CAAA,MAClD,EAAA,EAAA,UAAA,ahBKC,GgBHiD,C1BIC,oH0BYnD,CAAA,EAAA,EAAA,CAAA,GAAA,EAA2C,QAAQ,CAAC,CCeH,gBDdzB,EAAA,GAE9B,CwByBC,A1EJA,AL8BA,A+GnDA,EAAA,ExDAU,UAAA,GAAA,yCAIJ,IAAA,GAAA,EAAA,EAAA,EAA+B,8OA+BD,CAAA,CAAA,CAAA,CAAA,wJ4CoW9B,CAA6B,CAAA,CAAA,CAA8B,CAA+B,gBAC9E,YACM,MAAM,6CACkB,GCzEC,CDyEG,CAAA,SAAA,CAAA,MAG/C,EAAA,EAAA,GAAA,CAAA,4BAEE,EAAA,EAAA,MAAA,CAAA,GAAA,KAA8B,CAAA,YAC9B,GAAA,CAAI,EWuSI,KXlSlB,CAAC,YAha4C,CjDcY,EAAA,OiDdK,CrBwD/B,AqBvDxB,CAAA,AAiaP,CtFgPC,QsFhP4C,CAAiB,CAAA,CAA4B,CAAE,CAAA,cAC5E,CAAE,CAAG,EnE+QE,EmE/QE,AACX,EtF4RE,AsF5RI,GAAA,CAAI,MACX,eAKF,CALQ,MACT,EAAM,EAAA,MAAW,CAAC,CrBqMD,EqBnMvB,OADA,EAAM,GAAG,CAAA,EAAA,GACF,QACF,OAnaQ,GAAA,OAAA,+OA+BW,AACjB,IAAA,+QA4CK,CAAA,CAAA,UAAA,CAAA,CAAA,CAAA,IAAA,4EAOU,GAAA,8IAYe,IAAI,CAAC,OAAO,CAAA,CtF4Ec,yCAAA,CsF5E8B,CACxF,CAAA,uDAQa,CAAA,CAAA,CAAA,IAAA,CAAA,SAAyB,MACP,EAAA,2BAEZ,ClG2GS,AGlHE,G+FOP,CAAE,0CAQxB,CAAA,4BAAA,EAA+B,IAAI,CAAC,OAAO,CAAA,0CAAA,CAA4C,GAM/F,OAAA,CAAA,CAAA,WACa,MAAM,CAAA,IAAK,CAAA,mEAQH,EAAA,OAAe,EtFyFE,AiEPI,GAAA,EAAA,SAAA,CqBjFR,EAAA,SAAA,uDASX,IAAA,wHAYM,GAAA,CAAA,CAAA,wDAmBN,UADP,KAIG,OAAA,CAAA,IAAA,EAAA,CAAA,CAAA,IAAA,GAAA,EAAA,KAAA,EAAgD,EAAA,KAAW,IvBzBI,CuByBC,yCAMxC,CAAA,uBAKrC,GAAS,GAAU,ClGsM0C,CkGtMjC,EAAM,EAAF,AAAY,KAAK,CAAC,CACnD,CAAA,0DAK2B,CC3CC,CD2CK,sDAeuF,CAAA,CAAA,gFAKtH,CAAA,EAAQ,KAAA,YAAiB,UAAA,2DAWxB,OAAA,IAAW,GAAA,EAAa,EAAA,EAAA,EAAA,KAA0B,CAAC,C1C2KG,A0C3KH,oDAHT,ClGwO3C,AqHzPgE,ARuJlD,EXtIwC,gBAAA,CAAkB,CACtE,CAAA,uBAM2C,KAAA,kBACtB,EAAA,EAAc,CrBqHO,AR3JJ,A+CkFE,CAAC,A/ClFF,AQ2JG,CR3JF,A+CkFE,2ElBhChC,CAAA,EAAA,GAAA,UASZ,SAAA,CAAA,CAAA,CAAqG,CAAA,kBACxF,EAAA,EAAA,UAUb,OAAA,CAAA,CAAA,UACoB,C3BuSL,AFhVI,E6ByCK,WAAW,CAAC,yBAEjC,AAAI,MAAM,CtFuMG,AXoFF,mCiG7Qd,YAAA,CAAA,CAAA,KACC,EAAQ,GAAA,YAAA,CAAiB,GACzB,EAAA,EAAmB,IAAI,CAAG,EAAM,C1CmMD,Y0CnMc,GAC5B,C5FoQH,CAAA,E4FnQZ,E3BiU8B,EAAE,IAAA,C2BjUvB,EAAY,EAAa,EAAM,GAAD,UAAc,CAAC,CAC7D,CAAA,GACG,EAAA,UAAA,GAA8B,EAAA,aAAmB,C3BgUC,gC2B7TtD,IAAA,EAAA,EAAmC,QAAQ,CACzC,EAAA,aAAmB,CAAG,EAAM,UAAU,CACvC,CAAA,wBAEoB,CACnB,EAAA,UAAgB,CAChB,EACA,SADW,AAON,KANS,CACf,CAAA,+DAKwD,UAYpD,aAAA,CAA4H,CAAA,WAEpH,iBACuB,EAAA,QAAqB,CAAC,gBAEjD,GAGT,EAAc,sBAIF,CAAM,GACP,CrBkKY,AqBlKX,CAAA,A1C4MD,G0C1MD,uBAIF,WAAA,CAAA,oBAAA,EAAsC,ElG+SG,CkG/SM,CAAC,ClG+SP,AkG/SO,gBAKrC,IACb,EAAA,EAAA,mBADuC,GC/DE,kCDmEK,uBAAe,UAS9D,MAA0G,CAAgE,CAAE,CAAmC,CAAA,KAC7M,EAAA,EAAc,CAAA,SAeqG,CnEiO1G,AmEjO0K,CzC9CzK,AoBgOM,AqBlLmK,CAAA,WAC7K,EAAA,eAGL,EAAA,GAAA,SACC,WAEL,EAAQ,MAAM,CAAA,CAAA,EAAI,GAAU,MAAM,CAAA,EAAG,EAAA,CAAA,WAG1B,MAAM,CAAE,CAAC,A7B1DW,CAAC,CYiLV,gBiBrHjB,CAAC,GAAA,MAAA,aAAmD,SAEjD,CjGoWH,KAAA,CiGpWW,uBAEH,CWyRG,AxCnVW,ArE8Xb,KAAA,GkGpUyB,MAAM,CAAC,GAAQ,MAErD,GAAO,MAAM,MACV,EAAA,GAAkB,UAChB,GAAA,MAAuB,GAAU,KmB2BD,CnB3BO,CAAA,GAAS,CAAA,yBAIhD,MAAA,iGAID,KAAoB,GAAO,MAAA,CAAO,GAAQ,CAGvD,AAHuD,CAGtD,CA9CwB,CuBwHtB,CvBxHiD,IAAI,CAAC,CAAA,EAErC,E7BtDI,I6BsDE,CAAC,CzC/C6C,EyCiDpE,GAAA,IAAA,EAAA,OAAA,EAAA,AAAuC,MAAvC,CAAA,CAAA,EAAkC,aACpB,oEAIJ,GAAA,GAAA,CAAA,EAAA,MAmEd,IAAM,GAAc,IACd,GAAe,EtF6RJ,UsF3RR,CrBuMH,A7EmKD,C6EnKC,CAAA,CAAA,CqBvMoC,CAAY,CAAA,CAAuB,MACrE,KAAmC,KrBuMK,GqBvM3B,EACmC,GC3EC,AD4EjD,CADoD,CAC5C,GADkB,CACd,CWiVD,UXjVY,EAAa,EAAU,EnEiSV,QmEjSoB,CAAC,AnEiSL,CmEjSK,OAC/D,CC3EC,CtB6RG,CqBlNY,CtF4RD,CAAA,EsF5RiB,eAE1B,GAAG,CAAA,EAAA,SAIL,GAAA,OAAA,GAAsB,CAAA,oB9D5WtB,GAAiB,CACrB,SAAS,EACT,aAAc,CACZ,IAZJ,CAYS,QAZA,AAAY,CAAG,EACtB,IAAK,IAAM,KAAO,EAAI,IAAI,GAAI,AAC5B,GAAmB,UAAf,OAAO,GAAoB,AAAe,GAAG,GAAd,MAAM,CACvC,MAAM,AAAI,MAAM,sFAGpB,OAAO,IACT,EAMI,OAhEJ,CAgEY,QAhEH,AAAY,CAAG,EACtB,GAAI,EAAI,KAAK,GAAK,GAAO,CAAG,CAAC,IAAI,GAAK,EAAI,KAAK,CAC7C,CAD+C,MACxC,KAAK,AAEd,IAAM,EAAM,GAAI,KAAK,CAAC,GAGtB,GAAI,CAAC,EACH,GANuC,AAK/B,IACD,KAET,IAAM,EAAQ,IAAI,WAAW,EAAI,KAAK,CAAC,UAAU,CAAG,GAEpD,OADA,EAAM,GAAG,CAAC,EAAI,KAAK,CAAE,GACd,CADiB,AAEtB,IAAI,EAAY,EAAW,GAAG,CA9Cb,CA8Ce,GAChC,IAAI,EAAY,EAAW,KAAK,CAAE,GACnC,AACH,EAiDI,MAtD+D,IAcnE,CAwCe,QAxCN,EACP,MAAM,AAAI,MAAM,4EAClB,EAuCI,OA7BJ,CA6BY,QA7BH,AAAe,CAAG,EACzB,GAAI,OAAO,KAAK,CAAC,GACf,GADqB,GACf,AAAI,MAAM,uEAElB,GAAI,IAAQ,KAAY,IAAQ,CAAC,IAC/B,MADyC,AACnC,AAAI,MAAM,4FAElB,OAAO,IACT,CAsBE,CACF,GAE6B,CAC3B,GAAG,EAAc,CACjB,aAAc,CACZ,GAAG,GAAe,YAAY,AAChC,EACF,EAaA,IAAM,GAAiB,CACrB,iBAAiB,EACjB,uBAAuB,EACvB,UAAU,EACV,eAAe,EACf,aAAa,EAEb,QAAQ,EACR,SAAS,EACT,wBAAwB,EAExB,KAAM,EAAE,AACV,2CACA,GAAe,IAAI,CAAC,GAAa,CApBjC,EAoBoC,OApB3B,AAAY,CAAK,EACxB,GAAiB,GAAG,CAAhB,CAAK,CAAC,EAAE,CACV,MAAM,AAAI,MAAM,sDAElB,OAAO,GAAI,MAAM,CAAC,EAAM,QAAQ,CAAC,GACnC,CADuC,CAoB/B,GAAe,IAAI,CAAC,KAAK,QApB4B,oLiDhBtD,IAAM,GAAc,CAAC,EAAM,EAAO,KACvC,IAAM,EAAU,IAAI,WAAW,EAAK,MAAM,CAAG,EAAM,MAAM,EAGzD,OAFA,EAAQ,GAAG,CAAC,EAAM,GAClB,EAAQ,GAAG,CAAC,EAAO,EAAK,MAAM,EAhBzB,AAiBE,SAjBO,AAAc,CAAO,CAAE,EAAU,CAAC,CAAC,MAwB1B,EAtBvB,EAsB2B,CAtBrB,QAAE,CAAM,CAAE,CAAG,CADJ,EAAQ,MAAM,EAAI,EAAA,EACP,MAAM,CAAC,GACjC,OAAO,EAAS,EAsBhB,CAAI,CAAC,EAAW,EAAE,EAAI,GACf,CAtBT,EAauB,EAAS,EAChC,EtC/EM,GAAY,IAAI,AAvBtB,MAAM,AACJ,aAAc,CACZ,IAAI,CAAC,KAAK,CAAG,IAAI,WAAW,GAAY,GACxC,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,EAAc,GAE7B,IAAI,CAAC,IAAI,CyBec,EzBfX,AAEZ,IAAI,CAAC,MAAM,CAAG,CAChB,CAKA,MAAM,CAAK,CAAE,CAAG,CAAE,CAChB,KAAO,IAAI,CAAC,MAAM,CAAG,GACnB,CADwB,GACpB,CAAC,IAAI,CAAG,GAAkB,IAAI,CAAC,IAAI,CAAE,IAAI,CAAC,IAAI,EAClD,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAE,IAAI,CAAC,MAAM,EACrC,IAAI,CAAC,MAAM,EAAI,EAGjB,OAAO,IAAI,CAAC,KAAK,CAAC,QAAQ,CAAC,EAAO,EACpC,CACF,EAUa,GAAY,AAAC,IACxB,GAAI,EAAQ,GAAK,GAtCD,GAuCd,GADwB,GAClB,AAAI,MACR,CAAC,CAFgC,yBAEN,EAAE,YAAY,EAAE,aAI/C,OAAO,GAAU,CAJsD,CAAC,GAIlD,CAAC,EAAY,EAAO,GAAa,GAAQ,CAAC,CAClE,E2BSa,E3BV2C,C2BUnC,AAAC,IACpB,IAAM,EAAQ,EAAO,MAAM,CAAG,EACxB,EAAS,AAAI,MAAM,GACzB,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,IAAK,CAC9B,IAAM,EAAS,EAAI,EACb,EAAQ,EAAO,QAAQ,CAAC,EAAQ,EAAS,EAC/C,EAAM,CAAC,EAAE,CAAG,CACd,CACA,OAAO,CACT,E+BnDO,SAAS,GAAiB,CAAW,EAC1C,IAAM,EAAO,KAAK,GAAG,CAAC,EAAa,GAC7B,EAAa,KAAK,KAAK,CAAC,KAAK,IAAI,CAAC,IAElC,EAAQ,KAAK,IAAI,CAAC,EAAW,IAAM,CAAD,EAAc,CAAC,EAGvD,OAAO,GAAQ,EAAQ,EAAQ,KAAK,IAAI,CAAC,EAAW,IAAM,CAAD,EAAc,CAAC,CAC1E,CAQO,IAAM,GAAc,AAAC,GAAS,GAAiB,GAAQ,EAgBjD,GAAM,CACjB,EACA,EAAS,IAAI,WAAW,GAAY,EAAO,MAAM,EAAE,IAInD,IAAM,EAFO,AAEK,GAFY,EAAO,EAEZ,QAFsB,MAM/C,IAAK,IAAI,EAAI,EAAG,EAAI,EAAW,IAAK,CAClC,IAAM,EAAa,IAAI,EACjB,MAAc,EAGpB,EAHwB,AAGjB,GAAG,CAAC,EAAO,QAAQ,CAAC,EAAY,EAAa,IAAK,GAGzD,CAAM,CAAC,EAAc,GAAG,EAAI,GAG5B,IAAK,IAAI,EAAI,GAAI,EAAI,GAAI,IAAK,AAC5B,CAAM,CAAC,EAAc,EAAE,CACpB,CAAM,CAAC,EAAa,EAAE,EAAI,EAAM,CAAM,CAAC,EAAa,EAAI,EAAE,EAAI,EAInE,CAAM,CAAC,EAAc,GAAG,EAAI,GAE5B,IAAK,IAAI,EAAI,GAAI,EAAI,GAAI,IAAK,AAC5B,CAAM,CAAC,EAAc,EAAE,CACpB,CAAM,CAAC,EAAa,EAAE,EAAI,EAAM,CAAM,CAAC,EAAa,EAAI,EAAE,EAAI,CAInE,EAAM,CAAC,EAAc,GAAG,EAAI,GAE5B,IAAK,IAAI,EAAI,GAAI,EAAI,IAAK,IAAK,AAC7B,CAAM,CAAC,EAAc,EAAE,CACpB,CAAM,CAAC,EAAa,EAAE,EAAI,EAAM,CAAM,CAAC,EAAa,EAAI,EAAE,EAAI,EAInE,CAAM,CAAC,EAAc,IAAI,CAAG,CAAM,CAAC,EAAa,IAAI,EAAI,CAC1D,CAEA,OAAO,CACT,EhC5Ea,GAAW,AAAC,GAAO,IAAK,CAAE,CAAG,EAAI,CAXrB,AAAC,IACxB,IAAI,GAAS,CAAE,CACf,KAAQ,KAAM,CAAE,EAAG,IACnB,OAAO,OAAO,EAChB,GAOwD,OAAO,IAAK,CAAE,EAAI,EkCe7D,GAAW,AAAC,GAAS,GAAQ,GAAQ,EAiBrC,GAAU,AAAC,GAAS,GAAQ,GAAQ,EAe3C,GAAU,AAAC,IAOR,CAAE,EAAI,OAAO,GAHF,CAAC,EAAO,GAAwB,AAAE,AAGvB,CAHqB,EAAM,uBArDjC,CAAC,QAAE,CAAM,SAAE,CAAO,CAAE,GAC3C,CIwEc,CAAE,EAAI,OAAO,AJxET,EIwEkB,GACrB,EJzEa,iBAyBJ,AAAC,GAAS,GAAQ,GAAQ,eAe3B,AAAD,GAAU,GAAS,GAAQ,kCAhC1B,AAAC,GAAS,GAAS,GAAQ,0BOoC7C,IAAM,GAAa,AAAC,GAAW,GAAU,CAAE,GAAI,OAAO,IAgBhD,GAAY,AAAC,GAAU,EAAQ,2H3EnDa,EROI,ErBzBA,C8BLG,8BD6CrD,CpCpCR,AJgBA,AoFlBE,ArBWF,G3DTA,+DoC0CsF,CAAA,CAAA,CAAkD,CAAA,2OAWlD,CAAC,eAAe,CAAA,CAAE,mCAGzD,QAAA,CAAA,IAAe,CAAA,eAAgB,EAAE,CAAC,oEACF,IAAI,CAAC,eAAe,CAAA,CAAE,CAAC,CAAA,ArB4CG,IqChEI,CAAC,CAAA,uCOeX,CAC/F,CAAA,gFvBeqD,CAAA,IAAA,CAAA,GAAA,4GAaJ,CAAA,kBACpB,yEACmD,UAAA,CAAA,CAAY,CAAC,CAAA,EuBUG,CAAC,qHwC5FjG,IAAM,GACX,4CAuBW,GAAY,GAAO,IAAI,CAKvB,GAAkB,GAAiC,GAAO,IAAI,CAE9D,GAAW,GAAO,EAFmB,YAEL,CAAC,MAKjC,GACX,GAAW,GAAO,cAAc,CAAC,IAAmB,GAczC,GACV,GARuB,KAQU,IAAd,GAAqB,KAAe,OAAO,KAoCpD,GAAY,AAAC,GAAU,IAAI,GAAO,GAyClC,GAAS,CAAC,QAAE,CAAM,CAAE,IAC/B,GAAM,EAAG,EAAO,CAAG,GAAO,MAAM,CAAC,GACjC,OAAO,CAAM,CAAC,EAAO,AACvB,EAMa,GAAU,CAAC,QAAE,CAAM,CAAE,IAChC,GAAM,CAAC,EAAQ,CAAG,GAAO,MAAM,CAAC,GAChC,OAAO,OAAO,EAChB,EAMa,GAAO,CAAC,QAAE,CAAM,CAAE,IAC7B,GAAM,EAAG,EAAO,CAAG,GAAO,MAAM,CAAC,GACjC,OAAO,EAAO,QAAQ,CACpB,IACA,IAAuB,CADd,EACqB,EAArB,EAAyB,CAEtC,CAKA,OAAM,GAIJ,YAAY,CAAK,CAAE,CACjB,IAAI,CAAC,KAAK,CAAG,EACb,KAAM,CAAC,EAAI,CAAG,GAAO,MAAM,CAAC,GAC5B,UAAI,EACF,MADU,AACJ,AAAI,OADM,IACK,CAAC,6BAA6B,EAAE,KAGvD,EAH6D,EAGzD,EAAS,GACb,KAAM,CAAC,EAAM,EAAO,CAAG,GAAO,MAAM,CAAC,EAAO,GAC5C,GAAU,EACV,MAAM,EAAS,EAAM,QAAQ,CAAC,GAE9B,GAAI,EAAO,MAAM,GAAK,EACpB,IAD0B,EACpB,AAAI,WACR,CAAC,gCAAgC,EAAE,EAAS,EAAK,YAAY,EAC3D,EAAM,MAAM,CACb,MAAM,CAAC,EAIZ,IAAI,CAAC,MAAM,CAAG,CAChB,CACA,IAAI,MAAO,CACT,OAAO,EACT,CACA,IAAI,MAAO,CACT,OAAO,IACT,CACA,IAAI,MAAO,CACT,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,AAC3B,CACA,IAAI,SAAU,CACZ,OAAO,GAAQ,IAAI,CACrB,CACA,IAAI,QAAS,CACX,OAAO,GAAO,IAAI,CACpB,CACA,IAAI,MAAO,CACT,OAAO,GAAK,IAAI,CAClB,CACF,wLAhJyB,CAAC,SAAE,CAAO,QAAE,CAAM,MAAE,CAAI,CAAE,IACjD,IAAM,EAAgB,GAAO,cAAc,CAAC,OAAO,IAC7C,EAAO,IAA8B,GACrC,EAAa,GAAO,IADG,UACW,CAAC,GAIrC,EAAS,EACP,EAAQ,IAAI,WAAW,AAHL,GAAW,EAAa,GAkBhD,OAdA,GAAO,QAAQ,CAAC,KAAM,EAAO,GAC7B,GAAU,GAEV,GAAO,QAAQ,CAAC,EAAM,EAAO,GAC7B,GAAU,EAEV,GAAO,QAAQ,CAAC,OAAO,GAAU,EAAO,GAGxC,CAAK,CAFL,AAEM,GAFI,EAEG,CAAG,EAChB,GA1DyB,EA4DzB,EAAM,GAFI,AAED,CAAC,EAAM,GAET,IAAI,GAAO,EACpB,mEAYuB,CAAC,QAAE,CAAM,CAAE,IAIhC,IAAM,EAAmB,AAHA,GAAO,cAAc,CAAC,EAAO,MAAM,EAGhB,GAK5C,GAAI,EAAO,UAAU,EAAI,EAAkB,CACzC,IAAM,EAAQ,IAAI,WAChB,EAAO,MAAM,CACb,EAAO,UAAU,CAAG,EACpB,EAAO,UAAU,CAAG,EAAO,MAAM,EAI7B,CAAC,EAAK,EAAO,CAAG,GAAO,MAAM,CAAC,GACpC,GAxGgB,OAwGZ,GAAgB,GAAO,EAAf,IAAqB,CAAC,EAAO,EAAO,CAAC,EAAE,GAAK,EAAO,MAAM,CACnE,CADqE,MAC9D,CAEX,CAEA,IAAM,EAAQ,IAAI,WAAW,EAAO,MAAM,CAAG,GAK7C,OAJA,GAAO,QAAQ,CAAC,KAAM,GACtB,GAAO,QAAQ,CAAC,EAAO,MAAM,CAAE,EAAO,IACtC,EAAM,GAAG,CAAC,EAAQ,GAEX,CACT,WD5HA,EAAA,CAAA,CAAA,kBA8BO,IAAM,GACX,GARwB,KAQU,IAAd,G/G7BI,A+G6BiB,KAAe,O/GzB/B,A+GyBsC,KAoBpD,GAAS,IAAM,IAAI,EAOhC,OAAM,GACJ,aAAc,CAMZ,IAAI,CAAC,YAAY,EAAG,CAAE,CAWtB,IAAI,CAAC,MAAM,CAAG,IAAI,WAAW,KAS7B,IAAI,CAAC,MAAM,CAAG,EAYd,IAAI,CAAC,MAAM,CAAG,CAAC,EAAE,CAAC,AACpB,CAQA,OAAQ,CACN,OAAO,IAAI,CAAC,YACd,AAD0B,CAS1B,QAAS,CACP,IAAM,EAAQ,IAAI,WAAW,IACvB,EAAQ,IAAI,CAAC,UAAU,CAAC,EAAO,GAAG,GACxC,OAAO,GAAiB,EAAM,QAAQ,CAAC,EAAG,GAC5C,CAYA,WAAW,CAAM,CAAE,EAAa,CAAC,CAAE,GAAc,CAAI,CAAE,CACrD,GAAM,QAAE,CAAM,QAAE,CAAM,QAAE,CAAM,cAAE,CAAY,CAAE,CAAG,IAAI,CAIjD,CAAC,EAAQ,GAAG,EAAM,CAAG,GAKrB,EAAS,IAAsB,CAAE,EAAE,CAArB,CAAiB,IACjC,EAAS,IAAI,KAAW,GAAM,GAAI,EAAO,IAAI,CAAC,EAAG,KAAU,EAG7D,IAAM,EAAO,GAAM,CAAC,KAAW,EAAM,EAC/B,EAAS,EAAK,MAAM,CAAG,EACvB,CAAC,EAAK,CAAG,CAAI,CAAC,EAAO,CACrB,EAAU,OAAO,GAAS,SAAS,CAAC,IAAI,CAAC,YAAY,GAErD,EAAgB,GAAO,cAAc,CACT,GAG9B,EAAY,EAEhB,GAAI,EAAa,CACf,GAAO,QAAQ,CAAC,AA9IF,KA8IQ,EAAQ,GAC9B,GAAa,GAEb,IAAM,EAAO,IAAqC,GAC5C,EAAa,GAAO,IADG,UACW,CAAC,GACzC,GAAO,QAAQ,CAAC,EAAM,EAAQ,GAC9B,GAAa,CACf,CAcA,OAZA,GAAO,QAAQ,CAAC,EAAS,EAAQ,GAIjC,CAAM,CAHN,AAGO,GAHM,EAGI,CAAG,EACpB,GAAa,EAGb,EAAO,GAAG,CAAC,EAAM,GAIV,CAHP,GAAa,EAAK,MAAA,AAAM,EAGL,CACrB,CAIA,MAAM,CAAK,CAAE,CACX,GAAM,QAAE,CAAM,QAAE,CAAM,QAAE,CAAM,CAAE,CAAG,IAAI,CACjC,EAAS,CAAM,CAAC,EAAE,CAClB,QAAE,CAAM,CAAE,CAAG,EAEnB,GAAe,GAAG,CAAd,EACF,OAAO,IAAI,CAEN,GAAI,IAAI,CAAC,YAAY,CAAG,OAAO,GAAU,GAC9C,MAAM,AAAI,UADsD,CAE9D,CAAC,QAAQ,EAAE,EAAO,mCAAmC,EAAE,GAAA,CAAkB,EAKxE,GAAI,EAAS,EAAS,EAAO,MAAM,CAItC,CAJwC,MACxC,EAAO,GAAG,CAAC,EAAO,GAClB,IAAI,CAAC,MAAM,EAAI,EACf,IAAI,CAAC,YAAY,EAAI,OAAO,GACrB,IAAI,AAMR,EAEH,IAAM,EAAgB,EAAO,MAAM,CAAG,EAGtC,EAAO,GAAG,CAAC,EAAM,QAAQ,CAAC,EAAG,GAAgB,GAC7C,EAAO,IAAI,IAAI,GAAM,GAAI,KAIzB,IAAI,EAAa,EACjB,KAAO,MAAiC,GAAQ,CAC9C,GADkB,CACZ,EAAO,EAAM,QAAQ,CAAC,EAAY,OACxC,EAAO,IAD8C,AAC1C,IAAI,GAAM,GAAI,KACzB,MACF,CAaA,OATA,AALgB,IAKZ,CAAC,MAAM,CAAC,GAAG,CAAC,EAAM,QAAQ,CAAC,GAAa,GAC5C,IAAI,CAAC,MAAM,CAAG,EAAS,EAGvB,IAAI,CAAC,YAAY,EAAI,OAAO,GAG5B,GAAM,IAAI,CAAC,MAAM,EAEV,IAAI,AACb,CACF,CAMA,OAAQ,CAKN,OAJA,IAAI,CAAC,MAAM,CAAG,EACd,IAAI,CAAC,YAAY,EAAG,CAAE,CACtB,IAAI,CAAC,MAAM,CAAC,MAAM,CAAG,EACrB,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,MAAM,CAAG,EACjB,IAAI,AACb,CAGA,SAAU,CACR,IAAI,CAAC,KAAK,EACZ,CACA,IAAI,MAAO,CACT,OAAO,IACT,CACA,IAAI,MAAO,CACT,MA5PF,CA4PS,0CACT,CACF,CAUA,IAAM,GAAQ,AAAC,GAAW,GAAM,EAAQ,IAUlC,GAAQ,AAAC,GAAW,GAAM,IAAI,EAAO,EAAE,GAOvC,GAAQ,CAAC,EAAQ,KAIrB,IAAI,EAAQ,EAGZ,KAAO,EAAQ,EAAO,MAAM,EAAE,CAC5B,IAAI,EAAO,CAAM,CAAC,EAAQ,EAAE,CACtB,EAAQ,CAAM,CAAC,EAAM,AAIvB,IAAS,EAAM,MAAM,CAAG,EAAI,GAAK,GACnC,EAAM,CADmC,GAC/B,CAAC,GAAkB,IAG/B,GAAS,EAKT,EAAO,EAAQ,EAAQ,IAAI,EAAK,CAAG,EAAQ,EAAE,CAC7C,IAAI,EAAQ,EAGZ,KAAO,EAAQ,EAAI,EAAM,MAAM,EAAE,CAC/B,IAAM,EAAO,GAAY,CAAK,CAAC,EAAM,CAAE,CAAK,CAAC,EAAQ,EAAE,CAGvD,QAAO,CAAK,CAAC,EAAM,CACnB,OAAO,CAAK,CAAC,EAAQ,EAAE,CAEvB,EAAK,IAAI,CAAC,GACV,GAAS,CACX,CAEI,EAAK,MAAM,EAAE,CACf,CAAM,CAAC,EAAM,CAAG,CAAA,EAKlB,EAAM,MAAM,CAAC,EAAG,EAClB,CAEA,OAAO,CACT,oD1F/OS,EAAA,IAAA,EAAA,OAAA,EAAA,SAAA,CAAuC,IAAA,KAAS,qCAuB1B,iEA7DrB,CAAA,iDA6B0E,UAAxB,KAAA,2EAiJjD,iBAAA,GAAA,AAAsC,MAAtC,GAAA,KAAA,CAA8B,SAAgB,EAAG,CuEzHU,AvEyHV,GAAK,CVmFI,AuDxED,C7CXc,GAAZ,MAAgB,CuEzHW,I1BoIJ,I7CXE,CAAC,IAAA,KAAS,qEAb9F,2CAEgC,EAAA,CAAU,GAqE/C,SAAA,8DAQuD,mDAW5C,MADI,EAAA,MAAA,sCASA,mBAqBH,CAAA,EAAA,IAAA,wEAgDhB,CAAkB,CAAA,CACiB,0DAKI,OAAA,GAAA,CAA0B,CyDvM1D,AzDuM2D,AwF1OF,kDxF+OX,CAAA,CAAA,EAAI,EAAA,UAAmB,CAAA,CAAE,CAAC,CAAA,wDAQzE,CAAA,OAAA,CAAwB,CAAA,YAAA,CAAa,CAAE,CAAG,KAG1C,EAAA,EAAA,oDkG7FqJ,sBlGsGtH,CThFH,UAAA,CSgFe,GAAA,WAA2B,CAAC,CThFH,CAAC,C8B0FD,ArBP5C,ATnF6C,C8B0FA,AuCoEhD,CvCpEgD,A1Bc7C,AiEsDF,OAAA,C5D9E8D,CAAC,CAAA,oCAMrD,CiFzP4C,ApC0N7C,C7C+BG,CAAA,AkE1FG,iClE8FvB,6DAQd,EAAA,mGAOuD,EAAE,EAAE,CAAC,IwFzPA,AxF0P1D,MAAA,CAAA,wCAAA,EACuC,CVkCuB,CAAA,CkG5RR,IxF0PR,GAAe,OAAA,EAAU,EAAX,CAAC,GAAgB,CAAC,GAAmB,CAAE,CACxG,CAAA,MAKY,IAAI,EANqF,CAAC,oBAKjE,IAAA,EAAA,EAAsB,C0DrPH,K1DqPS,C0DrPH,A1DqPK,gBAG3D,KAAA,IACF,GAAG,CAAA,EAAA,cACY,CCbG,ADaH,QAI1B,CAAC,CkHtXgD,iP1Bm/JZ,CACnC,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,MAAM,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC1D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,YAAY,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CACjE,CACD,IAAI,CAAE,qBAAqB,CAC3B,OAAO,CAAE,CAAC,CAAE,IAAI,CAAE,EAAE,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAAC,CACjE,eAAe,CAAE,MAAM,CACxB,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACrE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC3D,CACD,IAAI,CAAE,OAAO,CACb,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,iBAAiB,CAAE,IAAI,CAAE,SAAS,CAAE,CACpE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACrE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC3D,CACD,IAAI,CAAE,cAAc,CACpB,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,SAAS,CAC3B,CACD,CACE,IAAI,CAAE,UAAU,CAChB,MAAM,CAAE,CACN,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,SAAS,CAAE,IAAI,CAAE,SAAS,CAAE,CAC5D,CAAE,IAAI,CAAE,aAAa,CAAE,YAAY,CAAE,WAAW,CAAE,IAAI,CAAE,WAAW,CAAE,CACrE,CAAE,IAAI,CAAE,QAAQ,CAAE,YAAY,CAAE,QAAQ,CAAE,IAAI,CAAE,QAAQ,CAAE,CAC3D,CACD,IAAI,CAAE,QAAQ,CACd,OAAO,CAAE,EAAE,CACX,eAAe,CAAE,YAAY,CAC9B,CACD,CACE,IAAI,CAAE,OAAO,CACb,SAAS,EAAE,EACX,GADgB,GACV,CAAE,CACN,CACE,IAAI,CAAE,UAAU,CAChB,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CAFe,AAGb,IAAI,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,QAAQ,CACd,YAAY,CAAE,SAAS,CACvB,IAAI,CAAE,SAAS,CACf,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,aAAa,CACnB,YAAY,CAAE,WAAW,CACzB,IAAI,CAAE,WAAW,CACjB,OAAO,EAAE,EACV,CACD,CACE,CAHc,GAGV,CAAE,QAAQ,CACd,YAAY,CAAE,QAAQ,CACtB,IAAI,CAAE,QAAQ,CACd,OAAO,EAAE,EACV,CACF,CACD,CAHkB,GAGd,CAAE,uBAAuB,CAC9B,CACO,CAAA,yRmB/iKH,GAAA,wDAkBA,CAAA,4gD7D7FgE,OAAO,KAAK,IKoCN,CAAC,CAAA,ILpCe,CAAC,qCwCpBzE,4HAGoD,CAAA,AzCmFxB,CyBzBA,ApDhCA,oCoErBb,gCAAA,CAAA,EAAA,KAAA,CAAA,OAAA,oDAOlB,KAAA,YAAA,IACH,EAAA,KAAA,CAAA,QAAA,EAAA,EAAA,QAAA,eAI2B,EAAA,+BACI,GAAA,CAAA,2EAIqB,OAC9C,GAAA,EAAA,OAAA,CAAA,+BAIE,CAAA,KAAA,EAAA,EAAA,CAAA,CAAA,KAAA,iCACkC,CAAA,CAAA,CAAA,KAAA,wDAOtB,OAAS,EAAA,KAAA,ssBAGzB,gFAIyB,WAK7B,CAAA,sCAqBS,yBACgB,UAAA,GAAA,EAAA,KAA2B,CAAA,EAAA,EAAA,KAAA,CAAA,GAE1D,EAAK,KAAA,+CxEvB4B,EAAA,gBAEU,EAAA,aAAA,uTqEJkC,iHqBXvB,oDhDzDxB,aAAiB,CAAC,CnEiDC,AqEnDA,ChEIC,A8DFA,AGFA,AHEE,CnEiDD,AK/CD,AHoC8B,AmExC7B,GFEC,EACzD,EEHmE,MFG3D,CAAA,IAAA,QAAa,CAAC,CAAC,CAAE,GAAG,CAAC,CAChC,CAAA,WnE+C8G,CAAA,AuEjBlF,GAC5B,MAAM,iBAAiB,CAAA,iCJsGlB,SAAA,GAAA,CACU,CAAA,EAAA,CAAA,CAAA,yCAIwB,CAAC,CnEiHxB,wBmEhHwB,KACtB,EAAA,EAAA,IAAA,KAgCb,SAAA,GACJ,CxD4ImB,AwD5ID,CxD4IE,AwD5IF,EACW,CAAA,CAAA,gDAGmC,CAAA,sDAI7B,CjE6GC,GAAA,kBiEzEhC,SAAA,GAAA,CAAA,CAAA,EAE0B,CAAA,CAAE,CC3BkB,wBD6B5B,CAAA,uBAMM,EAAA,CAAoB,AU4FT,CAAA,CV5FX,OAAA,GU4FW,CAAA,CAAA,GV5FuB,AAAF,CAAE,GAC1C,EAAA,CAAA,CAAoB,CAAA,CAApB,OAAA,EAAoB,EAAA,CAAA,CAAA,CACZ,qDACe,OAGrC,EAAA,UAAA,OAAA,GAA2C,EAAS,CAAC,GAAW,CAAE,CAAG,CAAC,CAAA,ElEsMH,2DkElMtC,cACD,EAAA,CAAA,CAAA,KAAA,MACzB,CAAA,EAAA,EAAA,EAAA,EAAA,CAAA,8BAGa,EAAA,CAAQ,aAKlB,EAAA,EAAa,OAAO,EpCwIkD,KoCxI3C,CAAQ,CAAC,CAAR,AnEkNsB,EAAA,OmElNL,IAAW,CAAA,CAAM,CACxE,AAAD,QAAS,CAAC,EAAE,CAAC,CAAA,6BAKhB,CAAC,AAuCK,SAAA,GAAA,CAAA,CAAA,EAAA,CAAA,CAAA,SAIG,GAAA,GAAA,MAAA,CAAA,GAAiC,GAqDpC,SAAA,GAAA,CAAA,CAAA,CAAA,SAIG,GAAA,EAAA,oBACT,CAAC,SAsBe,CV/FH,EAAA,CUgGD,CAAA,CAAA,gCAGiC,CE3GD,EF4G5C,CAsFM,AAtFL,AUgGA,A4CjFA,StDuEe,GAAK,CAAA,EACnB,EkD9CI,KlD8CG,KAAK,IAAI,CAAC,CAAC,EAAM,MAAA,EAAS,CAAC,CAAC,yCAyS9B,KACH,CAAA,QACA,CgCxNsB,GAAA,GhCyNtB,CAAI,OACJ,CAAK,CAON,CAAA,KgCjOgD,ChCkO1C,CAAA,CAAA,SAAA,EACS,EAAK,CgClOI,CsB8LG,eAAA,EAAA,EAAA,CAAA,CAAA,EtDqCJ,CAAC,CAAR,EgCnOuC,AhCmO/B,IAAA,CAAA,CAAS,CnEmTwC,CmElTtE,AnEkTuE,CAAA,EmElTpE,EAAS,IAAH,CAAC,CAAC,GAAU,CAAG,AAAF,CAAC,K0CsU4E,M1CtUhE,C0CsUuE,CAAC,CAAA,YAAA,E1CtUtD,EAAM,CAAH,AAAG,CAAF,CAAC,CAAC,EAAM,EAAG,CAAA,OAAA,EAAW,EAAG,CAAA,EAAA,CAAK,CAAG,AAAF,CAAC,AAAC,SAAA,EAAY,EAAG,CAAA,EAAA,CAAK,CAAA,CAAE,CACjH,CAAA,mFAnBsB,gCAkIrB,MAAO,WAA0B,EgC1NJ,ChC6NjC,YAAY,WAAE,CAAS,CAAA,QAAA,CAAS,CAA0C,CAAA,CgC5NzC,AhC6N/B,KAAK,CACH,CAAA,qBAAA,EAAwB,EAAO,MnEsYS,kBAAA,EmEtYkB,EAAS,OAAA,EAAA,CAAW,CAC/E,CAAA,mFALsB,yBAMzB,CANgD,AAM/C,CACF,AAaK,MAAO,WAAoC,GAG/C,YAAY,QACV,CAAM,CAAA,SAAA,CACE,CAAA,KAAA,CACJ,CACwD,CAAA,CAC5D,EgChOkC,GhCgO7B,CACH,CAAA,MAAA,EACe,OAAO,CAAC,CAAC,CAAtB,EAAsB,CgCjOd,UhCiOc,SACxB,MgClO0D,OAAA,EhCkO1C,EAAM,IAAA,yBAAA,EAAgC,EAAI,EAAA,EAAA,CAAM,CACjE,CAAA,AAXe,OAAA,cAAA,CAAA,IAAA,CAAA,OAAA,iDAAO,mCAYzB,CAZ0D,AAYzD,CACF,AAaK,MAAO,WAAoC,GAG/C,GAHqD,CAAC,QAG1C,CAH2B,AAIrC,AAJ6D,MAIzD,CgCjOW,WhCkOf,CAAU,MACV,CAAI,CAKL,CAAA,CACC,KAAK,CACH,CAAA,EAAG,EAAK,EAAD,IAAO,CAAC,CAAC,CAAC,CAAC,WAAW,EAAE,CAAA,EAAG,EAC/B,EADmC,GAC9B,CAAC,CAAC,CAAC,CACR,WAAW,EAAE,CAAA,SAAA,EAAY,EAAI,EAAA,0BAAA,EAA+B,EAAU,IAAA,CAAM,CAChF,CAAA,CAD0E,kFAdpD,mCAgBzB,CAAC,CACF,uBkDhpBK,SAAA,GAAA,CAAA,CAEJ,EAA8B,CAAA,CAAA,gBAIxB,EAAA,GAAA,MAAA,CAAA,8BxCgQO,KwCvHN,EAAA,MAAA,6BAAA,MAAA,oBAtIE,AxC6PI,EwC7PJ,EAyFF,S5FlUO,CAAA,CAAA,EAAA,CAAA,CAAiD,oFAKzC,+GAQC,EAAA,MAAA,CAAA,EAAA,EAAsB,CAE7C,OAAA,G4FmTO,EAAA,CAAsB,IAAA,aAzFpB,8BAif4B,2BAGd,SAAE,CAAO,CAA0C,CAAA,MACnE,CACH,CAAA,qBAAA,EAAwB,EAAO,KAAA,mBAAA,EAA2B,EAAS,OAAA,EAAA,CAAW,CAC/E,CAAA,mFALsB,6BAO1B,AAwCK,MAAO,ElB5LF,SkB4LsC,GAG/C,GAHqD,CAAC,QAG1C,CAHmD,AAI7D,MAAI,ClB/LW,WkBgMf,CAAU,MACV,ClBjM6B,AkBiMzB,CAKL,CAAA,CACC,KAAK,CACH,CAAA,EAAG,EAAK,EAAD,IAAC,CAAO,CAAC,CAAC,CAAA,WAAY,EAAE,CAAA,EAAG,EAC/B,EADmC,GAC9B,CAAC,GACN,WAAW,GAAA,SAAA,EAAc,EAAI,EAAA,0BAAA,EAA+B,EAAU,IAAA,CAAM,CAChF,CAAA,CAD0E,kFAdpD,qCAgBzB,CAAC,CACF,yNLp2B8C,0W9BDQ,KAA8B,eAAvB,CAAC,CAAA,WAAA,CAAA,IAAA,AAAsB,CAAY,CAAC,CAAC,+DAWnD,MAAM,EAAA,MAAA,MAAA,iCAAA,EACW,CpB+BuB,eoB/BL,CAAC,CAAC,MAAM,CAAC,sRAsBb,iDAsBrE,CAAA,EAAA,CAAA,IAAA,CAAA,yCC9DuC,EAAE,A9BK8B,EAAA,C+BJT,EjFCA,CAAA,CkDGQ,CAAC,G8BJtD,QDkFmC,IAAI,CAAC,EAAE,CAAC,CAAhE,WAAA,IAAe,WAAW,CAAA,CAAE,WAAW,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CA2BpD,GAAA,IACD,8DAvBgB,WAAA,GAAA,EAAA,SAAA,IAAA,EAAA,MAAA,IAAA,GAAA,kIAsHX,IAAA,WAAe,IAAA,cAAA,MAAwB,CAAC,iBAyE3C,MAAA,WPrIgD,YAAY,IAAI,CAAA,uBAC5C,sBAAwB,WAAY,WAAY,GrEqNpD,CACjB,CAAA,CmD7NyE,gBkBQ7E,EAGY,GAAyB,SAAA,GAA4B,IAAI,CAAC,uBAC7C,sBAAwB,EzE6IF,CAAC,AI+EE,CLSD,ACxFA,AI+EE,A6FxOF,6BxBYoC,GkC+HD,CAAC,CAAA,KlC/HU,CAC/F,qBAGqE,CAAA,wDACR,UAAU,CAAE,UAAU,CAAE,UAAU,6CAC9C,sBAAwB,wBAInE,GAA+B,SAAA,GAAA,IAAA,CAAiC,CkCqIhB,4ClCpIL,iCAAoC,uDACpC,iCAAoC,I3E4NE,CAAC,CAAA,I2E5NO,8CiB/JtE,sDAIqB,KA0EM,EAAA,IAAA,KAC9C,KAAK,CAAA,KAFqB,C5F0IT,M4FxIZ,KAAA,GAAe,CAAA,KAAM,GAAG,CAAA,EAAK,CAAC,CAAC,CAAC,CAAC,QAsFd,CzB6DH,UAAA,IyB7DkB,CAAC,GAC1C,oBAA4B,cAAoB,EACpD,KAC6B,WAAkB,IAAA,CAAA,AAAS,CnCWS,ImCXpC,CAAiC,EAAE,CAAC,CAAC,IAAI,CAAA,GAAI,GAAG,CAAC,CAAC,CAAC,CAAA,IAAQ,CAAC,CAAC,CAAC,CAAC,cACtC,CzB+DH,AyB/DI,CAAG,GAAI,CAAC,CAAC,AAAG,GAAG,CAAC,AAClE,EADoE,CAAC,AACrE,CAAyB,Q5D6P+C,CAAC,CAAA,C4D1PjE,WAAM,yDAC0D,CAAA,EAAA,wBAGlC,MACH,CAAA,EAAA,CAGnC,GAA4B,4BACK,cAAmB,EACvD,6BAAwC,EAAE,C3FwRD,E2FxRM,CAAC,GAAK,8BACjB,QAAW,IAAM,CAAC,CAAC,KACnD,aAAkB,gBAAsB,MAAS,EAAE,EACvD,MAAQ,cAAoB,GAAI,MAAQ,KAAO,EAAG,C5FqSH,A4FrSI,CAAE,CAAC,CAAC,CMiDL,ANhDpD,CAAA,GAAA,CAAA,GAAA,WAAA,IAAA,CAAA,IACD,GAAA,GAAwC,CkB+BL,EAAA,CAAA,CAAA,ElB/Be,IAAM,EAAA,GAAA,CAAA,GAAe,EOGJ,CPHc,CAAC,AhFsNN,AoB2CA,CAAA,CAAA,E4DjQU,CAAC,CAAC,CAAC,AACnF,C5DgQ8E,E4DhQ9E,GAAA,GAAqC,CAAA,CAAA,EAAA,IAAa,COGL,AlG4RoB,C2F/RX,GAAA,CAAI,GAAA,EAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAC3E,KAAA,OAAA,IAAA,CAAiC,oCACG,gCAEJ,CAAA,oDvC3M3B,OAAA,GAAA,SAAA,sLAU2C,CrBUF,EqBVU,GAAW,CAAE,CAAC,0CASpD,CAAA,EAAA,CAAA,qCwCA1B,GAAA,OAAA,exCyCyD,0KwC3BpB,CAAK,CAAC,CAAI,CgBkED,AxDjEoC,sFwCIrB,EAAA,UAEjD,UAEJ,GAAA,GAAA,CAAA,sCxCA8C,GAAA,EAAA,GAAA,IAAA,QwCKgC,CAAC,CAAC,AvFyH9B,qBuFxHZ,EAAA,GAAA,GAAA,KAAA,AAA2B,OAA3B,EAA2B,GAAA,EAAA,OAAA,ExCRK,CGoGE,AHpGD,mCwCyEjF,CAAA,CAAA,GACY,CAAA,CAAA,EACK,EAAE,CAAA,kLAYT,GAAA,EAAA,GAAA,EAAA,MAAA,MAAA,+IXlEqC,CAAA,KAAO,KAAK,CAAC,EAAI,UAAA,CAAA,iMWLK,EAAA,GAAO,CAAA,CAAI,CAAC,EAAI,EAAE,CAAA,kBAC/D,GAAK,EAAA,4EAMY,CAAC,A7DmCA,CAAA,wB6DlCP,gBAErB,EAAA,EAAA,mDAOY,EAAA,2CAKhB,CAAC,EAAA,EAAA,mHAOgD,CAAG,CAAA,CAAA,CAAG,EAAA,CAAA,CAAK,CAAC,A7DsDtB,A6C8CH,A5EmHA,C+BjKG,EAAA,S6DnD9B,CAAA,EAAO,iCAiDJ,IAAI,CAAA,MAAA,uEAOX,4BAEa,IAAA,GAChB,EAAA,MAAA,wCAE2B,CAAA,GAAI,CAAE,EAAM,CAAH,EAAM,CAAC,CAAC,CpCRG,CAAC,AYLE,CZKD,qBoCSlB,CAAC,GAAA,GAAM,EAAI,CAAA,CAAK,IAAA,uFAO9C,EAAG,qBACD,CAAA,CAAA,IAAA,CAAA,CAAA,SAAA,CAAA,CAAA,CAA0B,IAAI,gBAG3B,EAAA,GAAA,IAAmB,EAAA,GAAA,IAAA,CAAA,MAAA,OACpB,EAAA,EAAA,4BAGC,CAAA,CAAA,6DAKF,CAAE,CAAA,IAAA,wBACkB,EAAA,GAAA,4BACM,wBACH,CAAC,MAAA,CAAQ,CjFsMG,CiFtMG,GAAG,QACrC,QAAA,CAAS,IAAA,CAAA,MAAA,CAAA,IAAiB,CAAA,MAAA,CAAA,GAAA,4IAWhD,IAAA,CAAA,CAAA,4TAmBoB,CAAA,CAAA,UAAA,CAAA,CAAA,OAAA,CAAyB,CAAA,UAAA,CAAA,CAAa,CAAA,IAAO,CAAC,sBACpC,EAAA,EAAA,EAA8B,EAAA,CAAO,EAAC,6BAE/D,GAAA,CAAA,IAAA,CAAA,GAAA,SACM,CAAA,IAAA,CAAA,MAAA,GACN,QAAA,CAAA,IAAA,CAAA,QAAA,gDAKS,C3F6LD,AiGlME,A9BQF,IwBFR,SAAS,CAAA,IAAO,CAAA,SAAA,IAoBhB,IAAM,IX6FP,EW3GS,IAAA,IAAA,GAcmD,C7FqSZ,G6FrSK,EAAY,GAAG,GAAzB,AAA4B,CXqGrE,CWnHkC,AAcqC,EXqGnC,CX4QV,AtEMZ,A4FvXkC,AgBmQlC,GhBjR0B,A5F4UnC,A4F9T8C,AtBiXzB,MAAA,CAAA,GW5QoC,IAAM,MAAM,EAAE,CAAC,ClF0OlE,SkFxOF,CAAA,QAAA,SAAA,GACT,QAAA,CAAW,EAAA,QAAA,UACF,IAAA,IACR,0FbzUiE,WAAY,UAAU,EnD4EK,iEmD3E3B,WAAY,K/D8CjE,oJ+D5CyC,CpC4BoB,CAAA,qFoC3BpB,sBAAwB,6EACZ,WAAY,wFACA,6EACZ,WAAY,UAAU,sBAI/C,OAkGb,GAAU,gEACsB,kBwC4Gc,6CxC3GpC,oFACA,qBAAsB,IbqKE,gFapKF,oFACA,0CAC5C,qBAAsB,qBAAsB,UZOM,qDYN5B,qBAAsB,ErEsKF,wCqErK1C,qBAAsB,CyCgBC,oBzChBqB,oBAAoB,gEACpB,+DACtB,qBAAsB,CYsJ1C,mFZrJ0C,oFACA,CpE2OD,mFoE1OC,oFACA,+DACtB,yGACsB,GrE2KpD,iFqE1KoD,0CAC5C,8HAC4C,IMYI,qGNVvE,CAAC,GAAA,CAAI,GAAK,OAAA,QF8CqB,EAAA,CE7Cc,CAAC,CAAC,CAC1C,GAA4B,EAAW,CAAA,EAAA,CAGvC,GAAA,IAAA,IAJ6B,CF6CH,OE5CE,AAG5B,6CvDrG+B,MuGmF/B,WvGjF0B,mBAAA,MAAA,OAAA,CAA4B,CAAA,oDuGwDpB,UAsGF,CAAA,EAAA,CAAA,CAA+B,MlDiCtB,EvDkJF,YiFrM1C,OwBuByB,EAAA,0GASF,EAAG,EAAA,EAAA,IAAyB,CAAC,WACI,UAAA,CAAA,uBACW,CAAC,0BACnB,WAAW,CAAC,AACpD,ElB9BoD,EkB8BhD,GACR,CAAA,wBAAA,EAA2B,CAAS,CAAC,CAAC,CAAG,EAAE,CAAA,EAAA,CAAA,CAAA,EAAiB,CAAC,CAAC,CAAA,MAAA,EAAS,EAAS,GAAA,CAAK,CACtF,CAAA,CADiF,AAG/E,CAAA,EAAA,CAAU,GAAe,CzBlCG,AyBkCF,CAAC,SAE3B,MApGA,CADH,eACG,WAAA,EAAsC,IAAA,WAAe,C7D8ID,yS+D7LC,GAAA,oHAON,gBACZ,CAAA,WAAY,EAAA,iCAKtD,GAAA,GAAA,CAAA,EAAA,+CAnDiB,sCA2QL,CAAA,QAAA,CAAA,CAAA,MAAA,CAAA,CAAqD,CAAA,yKAQtD,WAA0B,sBAI9B,CAAA,gLAKH,MAAA,WAAoC,sBAIjC,CAAA,uIAHkB,yP1CyKmC,CrBkC1B,yBqB/BK,CrBuCH,KqBvCS,CAAA,IAAO,CAAC,CrBuCW,qBqBtC7C,CAAA,CAAA,CAAY,CAAkB,CAAC,CAAC,CAAA,SAE5C,GAAc,GAAA,EACrB,CAAC,AAGD,CsBhOC,GtBgOK,EAAA,EAAgC,CAChC,EAA+B,EAAE,SAElC,IAAA,EAAQ,EAAA,EAAA,EAAA,MAAgC,CAAE,CAAC,GAAI,aAC1C,CuCrFK,AvCqFE,CAAA,QAAA,CAAA,CAAA,CAAA,CAAA,CAAiC,EAAA,MAE7B,IAAI,CAAA,GACJ,EAAa,EAAa,CAAE,IAAI,CsBjOS,AtBiOP,EAAE,CAAE,CAAC,CACvD,CAAA,aAEc,CgCsFG,EhCtFM,cAO5B,OAAO,MAAc,KAAA,mJAnIjB,SAAA,CAAA,gBAAA,CAAA,CAIJ,YAAU,QACV,CAAA,CAOD,EACC,IAAM,ArB2B0D,EqB3B1D,EAAA,KACD,CqB9IC,GAAA,EAAA,EAAA,EAAA,ErB8IyB,MAAM,CAAE,0CAqBrB,CAAK,CACvB,UAAW,CAAU,CgC+BA,MhC9BrB,CAAK,CAON,MsBOK,ItB6UG,CsB7UH,EtBNE,AsBMF,EtBJiD,CsBnND,GAAA,CtBmiB/B,CsB5UG,AsB2LF,IAAA,C5CiJK,qBACpB,GAEM,CAAC,CAAE,CAAA,OAAU,C7EgKC,CAAA,EAAA,E6EhKc,KAAM,CAAO,CAAC,CAAC,CAAE,CAAC,MACvD,QAlVF,GAAA,CAAA,EAAe,EAAK,C9C4BD,E8C3BnB,CNqIC,ArEhHA,MAAA,A2E8FC,SACJ,CAA0C,C9C8ChB,A8C7C1B,CAIC,KAEK,CAAA,gBAAA,CAAiB,QAAE,CAAM,CAAE,WAAA,CAAA,CAAA,EAE3B,EAAqB,AAArB,OAAA,mBAEY,CAAC,GAAA,MAAc,IAAA,GAAA,6BAEzB,IAAI,GAAuC,8BAElC,EAAA,MAAA,SACJ,EAAA,IAAc,CAAA,CAAA,EAAA,EAAA,CAAA,CAAa,YAIlC,EAAA,EAAA,aACU,CAAC,CjEmCC,EiEnCQ,CIpEL,AmCvCrB,KAAA,CAAA,IvC2GuC,CAAC,EuC3G1B,CAAC,CvC4GP,EAAgB,EAAA,qCAGb,CAAA,CAAA,EAAA,uBAGU,IAAA,CAAA,SAGN,EAAc,CAAC,MACf,GAAA,QACA,CAAC,C9CyDC,CAAA,e8CxD0C,CAAE,MAAQ,EAAE,CAAE,CAAC,CAAA,CuC9GQ,KvC+GvE,UACI,EACT,QAAA,EACqB,MAAA,CAAS,CAAC,CAAC,AAAC,CAAA,EAAY,EAAQ,G9C+Dc,A8C/DN,CAAJ,A9C+DgB,CAAA,I8C/DN,QAG9C,UAAW,CpBtOb,AzD6XJ,S6EvJgC,SAE9C,4BAEqC,GAAG,CAAC,CAAC,SAAE,CAAO,CAAE,EAAE,CAAG,CAAD,C4C/GC,IvH7B9D,EAAA,uC2E1BG,GAAA,aASY,EAKK,C7E0GD,AmG7TF,QtBmNY,CAAC,AAd3B,EAcQ,IAAA,QAyRV,SAAU,AAKd,CAA0C,CAAA,CAIzC,EAED,EwC/LI,AlDsCA,CUyJE,CAAA,gBAAA,CAAA,CAAA,UAAA,CAA4B,CAAE,CAAA,gBAI/B,IAAI,EAAA,EAAA,EAAA,EAAA,UAA+B,CAAC,CsB1UH,CnGweH,I6E9JY,CAAE,CAAC,EAAE,CAAE,KAC9C,EAAS,EAAA,UAAA,CAAA,EAAwB,CAAA,QACnB,OAAA,CAAQ,GAAS,CAAC,CAAC,AAAC,CAAA,CAAA,IAAY,CAAA,AAC9C,EAAA,EAAiC,sCAGhB,CAAA,EAAA,KAEJ,IAAI,CAAC,E4C1IE,C5C2I1B,EAAA,OAAyB,EAAA,CAAA,GAAY,CAAA,CACvC,CgCyIC,AhCzIA,MACM,mBAEI,EACL,GAAO,GAAA,MACO,EAAmB,E9CmJE,C8CnJC,CAAC,CAAA,SAAG,CAAA,CAAA,GAAc,IAC3D,AACH,CADG,AACF,EAFoE,CAAC,CAAC,4BArU/D,IAoBN,C3E+BC,AUeA,EAAA,WiE9CiC,CApB5B,AjEkEL,AiE9CkC,EjE8ClC,IAAA,QiE7CQ,AA8EL,SAAA,CAAA,CAAA,CAE0B,I5E+JQ,W4E7J9B,C9CqCH,A/BiGA,CAAA,CAAA,CAAA,C6EtIqB,C5E8JL,AW3GQ,YiElDd,EAAO,QAAU,IACzB,yBAEsB,C9CqDC,AoCjKE,AV1GqB,UoBsNb,MAtF/B,EAAA,iBAIS,SAzBZ,MAyBY,MAmMd,KAAsC,EACrB,kBAAV,EAAU,MAAA,IAAA,GAAA,CAAA,wBAAA,EAEU,EAAK,GAAA,MAAA,EAAY,OAAO,EAAK,GAAA,gCAAA,CAAqC,CAC9F,CAAA,OACM,CsB/RD,OAAA,CAAA,atB+RsC,CsB/RD,EtB+RiB,EsB/RA,CtB+RO,CAAE,CAAA,GAjOjE,AsB9DmE,MtB0FvD,CAAA,UAAW,CAAA,SA5BvB,AA4BuB,EAAA,IAA0B,CAAA,UAAA,CAAA,OAAA,OA5BjD,MA6ByB,CAAC,UAAA,CAAA,UACnB,EAAA,KAAA,CAAA,CAAA,GAA6B,IAAI,CAAA,AA9BxC,EA8BmD,CN+K7B,AF1X8B,AoD0HA,GpD1HA,GAAA,EQ2MU,QA+MhE,SACJ,CAAa,CACb,CAAE,QAAM,CAAA,KAAE,CAAI,CAAqC,KAExC,iBAAA,EAAmB,CAAC,QACf,CgC8HG,AVzaF,CAAA,CAAA,OAAA,GtB2SmB,CAAA,GAAU,CAAA,CAAV,CAAe,AAAE,C7EqKH,A6ErKI,CAAC,CsB3SC,EtB2SE,CAAE,CAAA,AACpD,CsB5SsD,CtB4SnD,CAAA,CAAY,CAAC,GAAM,CAAE,CAAA,CAAA,CAAA,IAC1B,EAAQ,GAAO,EAAA,EACjB,MAAM,IAAI,GAA2B,eAClB,CjE6EO,MiE5EnB,EAAA,QAAA,iBAEC,EAAO,QACN,EAAM,QAAA,KAGnB,MAAO,CsB3SD,StB4SK,UACA,GAAe,EAAO,CAC7B,C7E8KC,I6E9KK,UACN,IAGN,CwChLC,AxCgLA,iCApQO,kCAqLF,SACJ,AADc,CsB5QS,CAAb,AtB8QV,C9CoE2B,AoElVJ,KtB8QrB,CAAA,CAAA,OAEO,EAAc,CAAA,EAAA,KAAa,CAAA,SAC9B,EAAA,GAAqB,GAC3B,CjE2CC,CAAA,CAAA,CiE3CI,C7E4JC,CAAC,K6E3JD,EAAS,eAGU,CAAC,EAAA,CAAA,EACb,GqBrMK,AtF4RF,AZ+EF,A6EtKE,AAAU,EAAA,AAAiD,GAAjD,KAAA,IAAA,CAAkB,CAAC,EAAM,MAAM,EAAG,CAAC,CAAC,AAAG,CAAC,CAAG,EAAE,CAAC,CAAK,CAAC,CAAA,AACrE,UACI,UACA,GACP,GAAA,GAA2B,CgCgIqB,ChChIV,CR7PgC,AQ6P9B,CgCgIqB,IhChIf,EAAE,CAAE,CAAC,CAAC,CACpD,GAGN,CAAC,CgC4HoF,AxC3XjF,CQ4PQ,AgC+H0E,ChC9HjF,AgC8HkF,IhC3HrE,C7EmKL,M6EnKY,QAAQ,CAAC,EAAA,IAAA,MAAA,IACtB,GAAqC,CuCnIH,CAAC,YvCoI7B,E7EmKE,KAAA,Q6EnKa,CAAC,EAAe,WAAF,SAGxC,oBAA2B,GAAA,EAAmB,CAAE,AACzD,CAAC,AADwD,CAzKlC,EAA6B,MArC5C,AAqCoD,EAAU,IAAI,iBArClE,YA4QF,IACJ,CADwC,GAClC,EAAA,GAA0B,GAC1B,EAD+B,AAC/B,CgC0I4B,AhC3II,IAChC,IAAuB,CAAC,GAAS,CsBjTH,EtBiTe,IAC7C,EAAA,EAAA,SACG,CAAC,CAAA,EAAM,CAAC,CAAG,AjEoFJ,CmBsBH,C8C1GoB,IAAK,CAAC,CAC/B,G7E8K+B,CAAC,A6E9K5B,C7E8K4B,A6E9K3B,GVzRT,AUyRY,AAAU,GsBjTG,AtBiTA,A9CyGgB,C8CzGf,A9CyGe,KoCjY7C,CAAU,CACV,CAA0B,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,eAIV,CAAA,gF2BjaZ,KAAA,mB3BmagB,EACjB,OAAO,CAAC,KAAM,CiDoBD,ArF8IA,CoClKG,EAChB,KAAK,CAAC,CAAA,IAAU,CAAC,CAAA,EAAA,CAAA,GAAA,EAAqB,MAAA,EAAU,CAAC,CAAC,ClEsSC,CkEtSU,QAC5D,GAAA,2HAAiC,EAAQ,EAAA,GACtC,GU6Q6B,EAAD,A7EiLF,A6EjLiB,EAAE,C7EiLnB,E6EjLqB,CAAC,CAAC,CAAG,CAAC,CAAC,CAAG,EAAE,CAAC,CAAC,CAAC,CAAA,AAErE,MAAO,gCAGkC,GAAW,CjE0FqB,AuF5YF,AtBkTjB,CjE0FoB,GiE1FhB,CAAE,EAAE,CAAE,CAAC,CAAC,EAC9D,EAAG,KAAK,CACT,WAxRG,sCA3BW,CAAU,CAAA,EAAI,uBAMjC,CAAC,AwCjJA,CpClFuD,CrEXL,+DqEiBnB,4IAiDmB,CAAC,GAAA,mCAGnB,CAAC,EAAM,oEAwEvC,CAAA,IAAA,CAAA,GAAA,CAAA,CAAA,CAAA,wBAjDG,CNxI6C,AjCxCvB,AkD6BA,A7DwKE,CAAA,CAAA,CAAA,gBkDnBA,mCAKV,KAAV,AAAe,wFAM+C,GAAA,mCAIxC,EAAA,KAAA,CAAA,CAAA,IACX,OAAA,QAAA,CAAA,EAAsB,IAAM,SAClC,GAAA,EAAA,oBAEgB,wCAMhB,EAAA,EAAA,CAAA,6BAC4B,AAAE,GAAA,MAAwB,EAAG,CAAC,CAAI,AAAH,CAAI,CjFkEzD,AmGvN4C,MAAA,IAAA,GAAA,qBlBuJhC,QAAA,CAAA,EAAA,0BAGuB,gBAGd,KAAK,CAAC,gBAClB,OAAA,CAAA,GAAA,OACR,EAAA,CAAA,eAEL,EAAA,EAAA,EAAA,EAAA,MAAA,CAAA,IACP,EAAA,IAAA,CAAA,EAAA,EAAA,CAAA,CAAA,EAAA,CAAA,CAAA,4CAME,IAAA,GAAA,UAkQG,WAAiC,IkBpLA,2BlBuL1C,CoC3Da,AtFiSkB,CsFjSjB,AtFiSiB,YAAA,CAAA,CAAA,KAAA,CkDpO3B,CAC0D,CAAA,OAE5D,CAAA,iCAAA,EAAoC,EAAI,EAAA,cAAA,EAAmB,EAAc,YAAA,CAAA,EAAgB,EAAW,CjFgS3D,EiFhS2D,CAAK,CAC1G,CAAA,sBjFgSwC,CACpC,CAAA,2DiFzSkB,0CASzB,CAAC,CACF,AA4BK,MAAO,WAA+B,GAE1C,YAAA,CAAA,aAAA,CAAA,OAEE,CAAA,CACyC,CAAA,IJ+IL,GI7IlC,CAAA,eAAA,EAAkB,EAAK,GAAA,KAAA,EAAW,CjFiTE,EiFjTC,AACnC,CADoC,CAAI,CAEzC,EADM,CACN,kCAAA,EAAwC,EAAY,EAAA,CAAI,CAC1D,CAAA,KADsD,8EARhC,IdWJ,AsDKJ,sCxCoBb,E4BmUC,I5BnUM,WAA4B,MAAM,CAAC,SAAS,eAGrD,CAAc,CACd,aAAW,CAAA,CAAA;gCAK0B,E4B4UA,c5B5UgB,O4B4UK,CVvfC,AUufA;yB5B3U7B,SACrB,IADkC,2EATpB,uCA+BrB,MAAO,WAA0B,GAErC,YAAY,CAAc,CkBxKhB,AlBwKgB,MACnB,CAAC,CAAA,QAAA,EAAW,EAAA,wBAAA,CAA+B,CAAC,CAAA,ClD8VE,kFkDhW5B,ElD4WV,mCkDxWhB,mFAemB,OAAA,cAAA,CAAA,IAAA,CAAA,OAAA,iDAAO,IkB7JR,gClBiKlB,4DwClmB8C,CAAA,qHAevC,4DAMiC,GAAA,IAAA,wDFuJX,CAAA,CAAE,CrB3BO,ANjDM,iB2B8EpB,CAAA,GAAA,CAAA,0BAEH,CxF8ID,wH0FxRqC,QAAQ,CAAA,EAAA,IAAA,MAAA,IAAA,GAAA,gCAElB,qCAkvBhD,SAAS,AAAkB,CAAY,EAErC,GACW,YAAT,GACA,AAAS,CzH+UR,AmGhlBO,WAAA,AsBkQC,CtBjQD,UADA,GACA,EsBkQH,UAAU,CAAC,EzH+UE,QyH9UlB,EAAK,UAAU,CAAC,KzH+UG,IAAA,EyH9Ud,UAAU,CAAC,KAAK,CAAC,CAAA,KtBjQK,CAAA,IsBmQjB,GzHgVG,AyHhVoB,MAAE,GACvC,CAAC,AAD0C,cA9uBzC,GAAA,EAAA,YAAA,EAAA,EAAA,IACwB,mBAAA,MAAA,IAAA,GAAA,2DAMZ,EAAY,CAAA,EAAA,CAAoB,CAAA,EAAA,CAAA,qBACH,qBAAe,IAsCpD,SAAA,GAAA,CAAA,+DA6DiB,CAAA,CAAA,YAAA,CAAA,CAAA,CAAA,6HAoBN,uIAuDgB,OAGzB,EAAA,GAAA,aAAsC,CpD5GH,CAAC,MoD4Ge,EpD5GF,uCoD+GnB,E1FwHN,CoE7OK,CAAA,CAAA,GAAA,IsBqHwB,EAAE,CAAC,CAAA,ItBrHC,SsBuHvC,CAAA,CAAA,EAAA,EAAA,EAAA,EAAA,GAAA,CAAA,CACd,CAAA,KAAA,CAAA,CAAA,KAAA,CAAA,CAAA,GAAA,CAAA,EAAA,EAAA,CAAA,EAAA,EAAA,CAAA,EACL,IAAI,CAAA,KAAA,CAAA,CAAA,uEA2C6C,KAAM,sCACpB,KAAM,4HAMf,MACrB,6CAGQ,aAAgB,KAAA,SAAe,CAAE,CAClD,CAAA,ElD0QoD,IkD1QpD,CAAA,SAoDG,SAAA,GAGJ,CAA2C,EAC3C,OAAO,GAAA,GAAsB,IA+BzB,SAAA,GAAqB,CAAA,uBACF,CAAG,0DAKd,iBACa,CpDpIc,AzD2ST,aAAA,G6GvKoC,I5C+GM,C4C5G1E,A5C4G2E,CAAC,AR7O3E,AoDiIA,AAHyE,CAAC,WAiDhD,CAAuB,EAChD,C7GoMC,E6GpMK,CAAA,KAAA,CAAM,aAAE,CAAW,CAAA,MAAA,CAAO,CAAE,CAAG,KAAK,CAAA,MACpC,GAAqB,4BAGzB,IAGJ,CAAC,AAoDK,SAAU,GtDPiB,AsDU/B,CtDV+B,AU6JZ,A4CnJ2B,KACxC,CAAA,OAAA,CACW,CAAA,QACN,CtDZ0B,CAAD,CAAC,CkDhCD,AlDgCC,UsDanC,CJ7CyC,AI6C9B,CJ7C+B,AI8C1C,CJ9C0C,MI8CrC,CACN,CAAG,IAEkB,CAFiB,AAGrC,CAHqC,CAIrC,QZ8Q6E,GY5QhE,CAAE,GAAG,CAAK,CAAE,CAAA,E1FkRG,E0FjRvB,IAAM,CZ6QG,IAAA,EY7Qc,IACpB,MAAE,CzH6SG,EAAA,IyH7SG,CZ6QG,CAAA,CY7QM,AZ6QN,CY5QJ,C5CyI0B,CAAA,E4C1IX,KACN,IAAlB,IAAoB,CAAI,CAAC,EAAI,CzH8SvB,AyH9S4B,CAAL,AAAS,CAAC,EAAI,CAAa,CAAb,A1FqRnB,A/ByBJ,UyH9S+C,EAAA,CAAE,CAAA,C1FqR5B,CAAC,CAAC,CAAC,G0FnR3C,CACT,CAAC,CAAA,AAcD,E5CmJI,K4CnJG,GAAe,CAAE,EzHuTF,C6EpKO,I4C9J3B,AAAK,EAEE,EADM,EAAM,YAAY,EAAI,GAAyB,GACjC,GAFN,CAAA,EAWS,QANhB,CAAC,QACK,uBAAuB,EJrC1B,EIsCP,CAAC,EAAY,CAChB,CADkB,CAClB,CAAmB,CAAC,EAAY,CAAE,GADT,CAAA,GAEjC,CADkD,CAAC,CAAA,YAGX,QAAa,CAAK,CAAE,CAAT,AAAW,CAAC,CAAL,AAAM,CAAE,IAC5C,CADiD,EAAE,EAAE,KAC3C,EtB3KzB,OsB2KgC,EAAA,QAAc,EzH0T7B,AyH1T+B,CAAA,GA+CpD,SAAA,GAGJ,C1F6ToB,A0F7TuB,CtBxLxB,CsByLnB,GAAA,eAES,OACD,CAAC,QAET,C1FoUC,A0FpUA,AACH,CAOM,AAPL,MAOY,WAA+B,6BAIxC,CAAY,WACZ,CzHiU0B,CyHhUkB,CAAA,CAC5C,C1FqUG,C/BNuB,GyH/TrB,CAAC,CAAA,cAAA,EAAA,EAA6B,MzHgUG,KAAA,EyHhUW,EAAS,CAAA,CAAG,CAAC,CAAA,MtBjMK,6EsB2L5C,oCAOzB,CtB3LC,AsB2LA,CACF,AAGK,MAAO,CtB5LH,UsB4L8B,GAGtC,GAH4C,CAAC,QAG7C,QAAc,CAAM,CAAuB,CZ+VtB,MY9Vd,CAAA,CAAA,gBAAA,EAAoB,GAAe,GtB9LC,EAAA,CAAA,CsB8LY,MzH2UA,CmGzgBK,OsB+L1C,CAAC,C1FoVG,CAAC,CAAA,QoElhBO,uBsB8LuB,GAJnC,C1FqWb,CoE/hBqD,KpE+hBrD,cAAA,CAAA,IAAA,CAAA,OAAA,iD0FrWoB,kCAUrB,MAAA,WAAA,4BAIF,CAAW,OACX,CAAA,CACoE,CZsWjB,MYrW9C,CAAA,CAAA,uBAAA,EAAA,EAAA,oBAAA,EACyD,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,IAAI,CAAC,IAAO,CAAF,CAAC,CAAC,CAAK,CACnG,cACgB,CAAC,8KAGrB,CAAC,CAIG,AAHL,MAGK,WAAA,sBAGc,CAAoB,CAAA,yCAElC,aAAA,CAAe,iIAJM,oCAMzB,CtBxLC,AsBwLA,CACF,AAGK,SAAU,GAAW,CAI1B,CzHqW0B,CyHpWzB,GAAM,CAAA,KAAA,CAAM,aAAE,CAAW,CAAE,OAAK,CAAE,CAAG,EAC/B,EAA0C,CAAC,CAAE,IAAI,CAAE,ItB7L3B,KsB6LoC,CAAE,CAAC,CAAA,AAC/D,EtB9LmC,AsB8LR,CAAC,CtB7Ld,EsB6LuB,aAAE,ItB7LX,IsB6LwB,CAAK,CtB7LlB,AsB6LoB,CtB7Ld,AsB6Le,CAAC,KAE9D,CzH6WC,GyH7WK,GtB9LD,EsB8LU,CAAK,CAAC,EtB9LF,AsB8Lc,EAAI,EAAE,CAAE,CAAC,IACtC,EtB/LwC,AsB+LlC,EAAK,CAAI,EAAJ,CAAgB,KtB9LG,SsBgM7B,EAAM,IAAI,MACV,EAAM,CtB/La,GsB+LT,IzHgXM,GyH/Wf,CAAI,CAAC,EAAM,IAAI,CAAC,EJHS,AlB3LP,GsBgMd,IAAI,CAAC,UACC,EACrB,CAAC,AAED,OAAO,GAAqB,EAAc,EAC5C,CAAC,AAYK,OAboC,EAa1B,CAbyC,CAAC,CtB5LvC,AsB4LuC,CAgBzD,EACC,CtB7MiB,AAChB,EsB4MK,CAAA,CtB7MyB,WsB6MzB,CAAa,CzHqWH,MyHrWK,CAAK,CAAE,CAAG,EAE/B,GAFoC,CAAA,GzHqWA,AyHnW7B,GADD,GAAiC,GAAW,CzHuWH,AyHvWK,AAC9B,CzHsW2B,ayHvWgB,KAAK,EAAA,CAAE,CAAC,CAAC,CAAA,AAE5E,CAAC,AAYK,SAAA,GAAsB,CAK3B,EACC,GAAI,OAAE,CAAK,MAAE,CAAI,MAAE,CAAI,CzHyVP,AmGpjBI,MsB2NK,CAAK,CAAE,CAAG,EAEnC,CtB7NkC,OsB6Nd,GzHwVL,CyHxVX,CAAK,CAAA,EAAM,CACb,MAAO,CACL,CzHwVC,AyHxVC,IAAI,AtB5NA,CsB4NE,OtB5NO,EsB4NE,CAAE,CACnB,GAAe,CzHyVC,EyHzVU,CAAE,EtB7NC,EsB6NG,CAAE,EAAO,YAAa,IAAI,IAAE,CAAK,CAAE,CAAC,CAAC,CACtE,AADkE,CAClE,AAEH,GAAa,CtB7NH,SsB6NN,CzHwVD,CyHxVmB,CACpB,AADqB,IACf,EAAU,EtB7NR,AsB6Nc,EtB9NK,CsB8NN,GAAO,CAAG,CAAC,CAAC,AAAE,CAAD,AtB7NA,GsB6NO,EAAE,CAAA,AAE3C,GtB/N6C,GsB+NtC,CAAC,CAAE,EtB7NF,GsB6NQ,WAAa,GAD7B,CzHwVW,AyHvVsB,CADzB,AAC0B,CAD1B,EAAA,AtB5NyB,EsB4NpB,AAC+B,EADrB,EAAM,AACc,CzHuVf,AyHvVqB,IADf,CAAC,CAAC,CAAC,CAAA,CAAE,CAAA,AACY,CAAE,EAAE,CAAE,KAAK,CAAE,CAAC,CACnE,AADoE,CACnE,AAED,AAHoE,EtDEhE,CsDCS,GtB9NH,QsB8NN,CzHuVD,CmGrjBO,EsB8NF,IACC,CACL,CAAE,KAAM,WACR,GAAA,GAAgC,EzHuVE,CmGrjBD,CsB8NS,EAAE,CJnCD,AImCG,GzHuVG,EyHvVE,CAAE,CAAC,CJnCD,AIoCtD,CAAA,AtDIA,AsDFH,CtDEG,EsDFC,CJnCC,CACF,AIkCM,CJlCN,CIkCK,SAAY,CAAC,OAAS,EAAA,MAAW,CAAG,EAAG,CAAC,IACxC,EAAa,EAAK,KAAK,CAAA,EAAI,EAAK,WAAW,CAAC,EzHuVE,IyHtV9C,EAAkB,CzHuVA,CyHvV2C,GzHuVtD,AyHvVqD,AAAI,CACpE,AAAC,GACC,CADG,AAAI,EAAF,AACO,QAAD,AAET,GtBjOC,CsBiOG,CAAE,QACN,EACA,KAAK,CAAE,IAAI,CAGjB,MAAO,CACL,CAAE,KAAM,SzH0VS,AyH1VA,KAEf,GACE,EAAe,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,EtBpOqB,AsBoOnB,CAAG,CAAD,AtBpOkC,AsBoOhC,EAC7B,EAAe,GAAG,CAAC,CAAC,CAAC,CAAE,CAAC,CAAC,EAAE,CAAb,AAAgB,CAAD,AAAE,CAAC,CACjC,CACF,CACF,AACH,CADG,AACF,AAED,MAAO,OAAG,GAAQ,EAAM,AAC1B,CAD0B,AACzB,AAYK,EAbmB,OAaT,EtBlPJ,CsBmPV,CAGC,CACD,EAAuB,EtBvPiB,EsBuPb,GAAG,AAAE,EtBvPyB,AsByPzD,GAAM,CAAE,WAAW,CAAE,CzH2UD,AyH3Ua,OAAE,CAAK,CAAE,CAAG,EACvC,EAAQ,CADoC,CAAA,AACvB,EtBxPA,GsBwPK,CAAC,OAAO,CAAC,CACnC,AADmC,EACrB,GtBxPX,AsBwPkB,CAAC,CAAH,AAAI,CAAE,CAAA,AAC/B,EJhEI,AlDqCA,CsD2BA,EAAQ,GAAG,CAAC,GtBxPC,CsBwPsC,SAAvB,AAAgC,CtBxPjC,AsBwPM,CAAC,EAAY,CJhEG,AAAV,AIiEzC,CJjE0C,ElDqCY,AAAV,CAAC,GsD4BtC,CADwC,CAKjD,IAAK,IAAM,KAAK,EAFR,GAAG,CAAC,GAEI,CAAA,CAAU,EAAY,EAAA,GACf,CAAE,WAAW,CAAE,EAAM,GAAD,CAAK,OAAE,CAAK,CAAE,CAAE,EAAJ,CACvD,IADkE,CAAC,CAAA,CAC5D,CACT,CAAC,+BtD7BmG,+rBqB90B5D,6UAahB,KAAA,aACrB,wDAC4D,2UjFzBjB,IRI5C,KAAsC,CCcc,AIjBA,AHoBA,ACvBe,ACJf,CGwBE,ACxBA,ACAA,AHCA,ENStD,WAAA,MAAA,EAA6F,AAAxC,CeVe,CAAA,CEAE,ADEA,CAAA,KhBQT,EMTe,ANS4B,CAAA,AOc3B,EAAmC,AAAjC,CAAiC,EDvB9B,ENSH,CAAA,QAAS,6GA4BvF,gKAYA,iCAyBa,GAAA,CAAA,mDAGkD,4MmBeH,CAAA,CAAG,QAAA,CAAA,wBAAqC,CAAI,CAAE,CAAC,CAAH,AACpG,CAAA,sFAM2D,EAAE,CAC7D,CAAA,0GAQsD,ySAeb,EsCoB4C,AqCtGxC,AMCF,WjFkFnC,CAAA,oBAAA,EAAA,GAAA,CAAoC,mFAUQ,CgE7FwC,UhE6FrB,C4D7CtB,Q5D6C+B,CAAC,SAAS,CAAC,AAAC,CAAA,IAAA,4FAmBzF,EAAA,iBAAA,EAAA,YAAA,MAA8C,oMA+BF,KAAM,CaKG,AbLF,CaKG,CAAA,uBbJP,CAAC,CsCXC,atCWa,CAAA,4DAQW,CAAC,EAAE,CAAC,Ce5DG,kBf6DvB,GjBuEG,CAAC,CAAA,MiBvEO,CAAC,CAAA,CaGI,AbAxD,oBAAA,EAAoD,gBAA9B,EAAA,IAAiB,CAAA,YAAa,GAAoB,CAAC,asCV/B,mCtCiBJ,IAAI,EAAA,CAAA,WAAc,EAAE,OHvHa,CGuHL,IAAM,EAAE,CAAC,qIAgCvE,CAAA,IAAA,CAAQ,CcvGC,YAAA,EduGc,CAAC,C2FxDpC,iF9CxIwB,C5DrC4B,A2BAG,A9B8CxE,O+DiC6D,MAAA,OAAA,qCAEF,8CAmCF,4JAS3B,oBAAA,AAAyC,QAAa,CAAC,AAAvD,EAAA,IAAyB,CI7DkB,CJ6DhB,AV5D5B,AcD6C,CAAA,WJ6DL,CV5D3B,CU4D6B,8GAhCc,MAA9B,WAAA,OAA0B,AAAI,CAAI,CerBN,kCf2B/B,MAAM,iDAvDpD,GAAA,UAAA,CAAA,EAAA,YAoLW,kCAE2B,AAC1C,CAAA,CACA,CAAkB,CPuBmC,WOpBhB,C/DeL,sD+DXO,IAAA,IAAQ,EAAM,GAAD,AAAI,CAAC,CAAC,AAAE,CAAD,GAAK,GAAG,CAAC,EAAM,GAAD,E3D9CM,CAAC,CAAA,C2D8CE,EAAE,CAAC,CAAA,mCACtB,MAAM,EAAI,KAAK,CAAA,gDACrB,CAAA,EAAG,EAAM,CAAA,EAAI,CAAJ,CAAI,CAAK,CAAE,CAAE,CQ+IC,KR/IM,IAAI,eACtE,CAAA,qJAMgB,WAAmB,QAAA,EAAA,YAAmB,mBAEnC,EAAA,+DAES,CoC7HK,wCpC8HD,CAAC,GAAA,CAAI,kBAAA,OAAA,EACjC,OAAA,CAAA,GAAA,CAAA,wBAChB,mBApHH,EAAA,CAAA,CAAA,kFAY4C,MAAA,KAAA,yCAMX,EAAA,6DAGpC,KACgC,qCAAA,EAAA,KAEhC,mEAI0D,CtCzCE,A0EhDH,ApCyFK,GAAA,yBACvC,CAAA,SAAA,EAAA,CAAoB,QAAA,CAAA,mJAuG1B,KAAA,CAAA,uFA/EM,iGAOa,KAAA,0BrDtM6D,CQqBpF,CCzBoD,ADyBpD,CElBqD,CAAA,8BVFT,qCAGA,C+BQG,A/BRF,uBACH,qBAInB,MAAO,wEAQF,0GaP/B,GAAA,CAAyB,CAAA,CAAA,0BACK,EAAQ,CAAA,AgBWC,QhBTD,WADD,AACC,eAU1B,CAAA,CAAA,CAAA,iCAEyB,wCACH,EwCqBE,AxCrBA,AqEpBc,ACAZ,CAAA,sDtE0ChC,mHA6BI,CQ+E0C,CR9EtC,6BASL,EAAA,oDAiBjB,CInDD,CAAA,MAAA,EAAA,cAAA,sJmDtCK,EAAA,CAAA,CAAA,EAAA,GAAA,EAAA,aAAA,CAA4B,IAAA,GAAA,CAAA,CAAA,CAAA,EAAA,EAAA,GAAA,CAAA,kHA8ByB,iBAEnB,EAAA,MAAA,YAAqE,CAC9G,CAAA,2BAGyC,KAJkE,CAAA,CAAA,gEAO3D,EAAI,CxE0D/C,AwD1DsF,KgBAjC,gBAAgB,EAAiC,CACzG,CxE0DU,AwE1DV,GxE4De,SwE7DyE,IxE4D3E,UwE5DyF,CAAA,CAAA,qDAK9C,EAAM,MAAM,CAAA,aAAA,EAAgB,GAAmC,CACvH,CAAA,UADmG,CAAC,gBAAgB,CAAA,CAAA,YAgB9D,GAAgB,kEAGlC,EAAc,MAAA,UAAgB,CvCFa,AuCEqB,CvCFrB,MNCnE,Q6CCsE,cAI3C,IAJ6D,kBAM3F,MAAA,GADqB,cACrB,0BACqC,EAAI,MAAM,gBAAgB,EAAiC,CACzG,CAAA,G5D4CsG,Q4D7Cf,CAAC,cAAc,CAAA,CAAA,2BAK1E,IAAG,sBAAyB,EAAA,MAAY,gBAAgB,GAAmC,CACvH,CAAA,UADmG,CAAC,GAiBlE,CAAA,CACE,WAlBgF,CAAA,CAAA,2CAuBhF,MAAA,4DASV,CAAA,CAAkB,C5D0DD,C4D1DK,CAAD,8FAyBJ,CAAE,uIE9HF,oEAM1C,CAAA,GajB0B,EAAE,IAAI,EACtC,G/BiB+E,CAAC,CAAA,K+BjBtE,EACV,OAAA,EbeuC,EAAO,CaflC,EAEb,AAAM,EbayC,Uab7B,CAAC,SAAA,EbawD,GAAU,MAAD,CAAQ,CAAA,mBAAA,EAAsB,GAAU,MAAD,KAAY,CAAA,gBAAA,CAAkB,CACnJ,CAAA,kDAGiD,CAAA,wBAAyB,CAAC,AXlBE,iGWwBhC,KAAK,CAAC,AAAE,CAAD,CAAO,GAAD,IAAQ,C/EuJpE,A+EvJqE,AAAE,CAAD,A/EuJtE,K+EvJ6E,CAAC,GAAM,CAAE,CAAH,AACnF,CADoF,AACpF,gBvE5B0E,CCfjB,ACOA,CEDC,AHND,AEWC,ADJD,CEDC,ADKA,ALXC,uDEiBjB,CiBNE,AtBaD,AEEE,EFFF,CAAA,8EKIU,QAAQ,6BAChC,EAAA,QAAA,GAAA,CAAA,sRoG8CH,MAAM,6DACe,CAAA,aAAc,CAAE,CtEjBG,EsEiBW,E/CjCI,CAAC,CAAA,C+CiCA,CAAE,GxCxDO,CwCwDH,CAAC,QAAO,CAAC,CAAA,mC5DrCqB,CAChH,CAAA,wG4D8C+D,E/C9BI,CAAC,A+C8BS,C/C9BT,AxDuDY,IiDhET,GsDuCc,CAAE,IAAA,CAAA,QAAY,CtEpBF,AsEoBG,CAAA,mHAkB1D,ChF7BD,AgErCI,GAAA,CgBkEE,SAAS,MAGtC,CAAA,EAAA,gBAG8B,CAAA,EAAa,CAAA,iBAC9B,EAAmB,GAAA,UAAwB,CAAE,IAAA,CAAK,SAAS,oBAGrD,GAAc,KAAK,CAAC,A3FUF,CiFjFC,AjFiFA,A2FVC,iCACO,CtElCD,AsEkCE,0FAOV,EAAc,CAAC,4JAU7B,CAAA,sCAGlB,2DAE4C,C3BvEO,A2BuEN,I7GkCQ,gK6GrB/E,KAAK,CACN,CAAA,wBAOkD,CAAC,YAAa,CAAO,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAA,WAEzE,CtC6IoF,+DsC5Ib,KAAK,CAAC,CAAA,4DAQ7D,EAAa,QAAQ,EAAE,AAAX,CAAW,OAAA,EAAU,EAAO,IAAD,IAAS,EAAE,CAAA,CAAE,CACjF,CAAA,AAKH,GAAI,GACc,EAAA,oBAAA,CAAA,OAA4C,CAAO,CAAC,CAAC,CAAA,CAAE,UAAU,CAAC,CAC9D,AAD8D,CrDsC/D,AqDrCE,CAAA,uCAKnB,mFACA,KAAK,CACN,CAAA,aAKW,CAAA,OAAA,WAGW,sBAD+B,CAAC,UAAW,CAAO,CAAC,CAAC,CAAC,A7G8BvD,C6G9BwD,UAAU,CAAC,AACjE,CADiE,AACjE,E7G+BR,A6G/BkB,CAAA,AACH,oBAAA,EAAA,MAA+B,CAAA,GAAM,CAAC,kDAWL,CVjGC,AUiGM,CAAC,CAAC,CAAC,CAAC,CrD2CC,SAAA,oBqDxCrE,GAAA,kBAAA,EAAA,2EAIJ,KAAK,CACN,CAAA,0JAuByB,OAAO,CAAC,aAAa,CAAC,EAAM,GAAwB,CAAxB,IAA6B,CAAC,CAAA,kCAKlF,kFACA,qBAImB,CAAA,IAAA,CAAA,uCAKF,KAAK,EAAE,6DAIxB,OAAA,EAAU,EAAA,kGAAA,CAAyG,CACpH,CAAA,8BAGwC,CvG8EC,CAAA,gBuG7EX,4CAenB,GAAA,KAAA,4BAGV,eAAA,CAAA,OAAA,EAAA,EAAA,4DAAA,CAC6E,CAC9E,CAAA,yBAGsC,ClC7HG,SkC6HO,EvGuFnC,AuGvFqC,CAAA,AlC7HG,AlBPF,EoDqI7B,C5GwGD,AgF5FA,GAAA,C4BZM,oBAAA,+BAMuB,aAAA,CAAe,I3GcI,iB2GXpE,kBAAA,eAEA,wLACA,eAKyD,CrDwDX,CqD7D7B,CAClB,CAAA,gDAS0C,EVnJA,AtBmJI,CjEkCD,AiElCC,IAAA,GgCAiB,yIAUT,C9EkCG,A8ElCD,iDAMhB,mBAEb,CAAC,OAAA,CAAA,UAAA,+BACU,UAAU,CAAA,qBAI7C,ChCCmB,iBgCAnB,CY5DwC,0BZ6DxC,oJACA,KAAK,CACN,CAAA,wCAOiC,CAAC,UAAU,GAC7C,EAAA,IAAA,CAAA,iBAA4C,uCAG9B,4BAGZ,EV/JuC,A1CUI,CAAC,0BoDsJ5C,gEAAgE,CAChE,KAAK,CACN,CAAA,wCAQH,CAAA,OAAA,EAAU,EAAA,sEAAA,CAA6E,CACxF,CAAA,cAGuC,KAAA,CAAA,uCAW4B,CAAA,gBAC1C,OAClB,GAAA,kBAAA,YAGJ,CAAA,OAAA,EAAU,EAAA,4DAAA,CAAmE,CAC9E,CAAA,YAGyB,IAAA,CAAA,OAAA,CAAA,UAAuB,GAC7C,EAAA,IAAA,CAAA,iBAAsC,cAGjB,MAAA,EAAoB,SAAS,CAAC,EvGkGM,MAAA,iCuG7F3D,kBAAA,kHAEA,KAAK,CACN,CAAA,iBAcsB,GAAA,KAAA,CAAA,sDAMrB,CAAA,CxClMgD,MAAA,EAAA,EAAA,4DAAA,CwCkM6B,CAC9E,CAAA,MAGmB,UAAA,OAAA,EAAA,EAAsC,OAAO,MAAM,CAAC,CAAA,wCAExB,yEAGC,EAAE,AxCrMF,OwCsMzB,CAAA,iBAAA,aAIjB,oBAAoB,EAAE,CAAC,AtCkIA,OsChIf,CADT,MAAA,IAAA,CAA2B,SAAS,CAAC,mBAAmB,CAAC,EAAe,SAAS,CAAC,AACzE,CADyE,4BAK1C,EAAS,AhBxMM,EgBwMS,SAE/D,EAAA,sCAIL,CAAA,ChBzM6D,AMTb,C9BQC,gBAAA,EwC0M5B,CjGkCmD,AyD5OJ,CzD4OI,AiGlC5C,KxC1M8C,AwC0M9C,KAAA,EAAa,EAAc,QAAQ,EAAE,CAAX,AAAW,CAAA,EAAI,EAAK,CAAE,CAC5E,CAD0E,IACrE,CACN,CAAA,GAeC,eAAA,CACW,CAAA,CAAA,CAEf,CAA4B,CAC5B,CAA4B,CAC5B,EAAyB,GAAO,GAAD,EAAM,CAAA,gBAEX,4BAGtB,ChC/BS,gBgCgCT,CAAA,ChC/BG,MAAA,EgC+BO,EAAA,4DAAA,CAAmE,CAC9E,CAAA,yBAG6D,EAAA,OAAuB,ChB5NlE,IgB6NoC,E5GiGA,CAAC,CAAC,I4GjGM,CAAC,CAAC,OAA9B,CX1LD,CW0LgC,AV3O7B,ADiDF,CAAA,CW0LiD,MAAM,CAAC,KACpC,CAD0B,A5GkG3B,C4GlG4B,CAAC,OAAuB,CAAC,CAAA,KACxE,ChCxBC,AgBlMa,CgB0NiB,EhB1Ne,AgB0NG,ChB1NF,C0BqER,CrHkJL,I2GGsB,G3GHC,CAAC,CAAA,O2GK/D,CjGYA,AyDhPD,CwBSO,CgByNsE,AAEpD,CAFqD,AAEnD,CAFmD,CAEnD,GAA4B,CxCpOD,AwCoOG,EAAE,CAAC,AxCpOF,CAAC,CAAC,KwCqOvE,kBAAA,iBAAA,wDAGa,OAAA,CAAA,UAAkB,C3GHF,ADiIG,Q4G7HvB,CAAC,oBAAoB,EAAE,UAI5C,CAAA,oBAAA,EAAuB,eACF,E7GsEc,ACuDL,E4G7HL,CAAA,SAAU,CAAC,mBAAmB,CAAC,EAAA,kDAKF,CAC1D,IAAI,CAAC,aAAa,CAClB,GACA,EACA,EAFO,AACH,AAEJ,EACA,EACA,SAAS,CACV,CAAA,EAJoB,IACE,EACA,oBAOrB,iBACA,CAAA,0BAAA,EAA6B,EAAO,KAAA,YAAA,EAAoB,EAAK,CAAE,CAC/D,CAD6D,IACxD,CACN,CAAA,0EAcC,CjGAsC,EXuGA,aAAA,CAAA,OAAA,E4GtG5B,C3BpKgF,CAAC,A2BoK5E,GAAA,yDAAA,CAA8D,CAC9E,CAAA,sCAIG,EAAA,IAAA,CAAA,oBAA4C,8CAM9B,CxClQG,AoD0HA,AjEoHN,CAAA,Aa9OO,AuBVJ,oCiB2Q2C,CAAC,EAAe,SAAS,CAAC,AjB3QrE,CiB2QqE,YAKtE,MAAM,EAAiB,mBAAmB,CAAA,IACrD,CAAA,aAAc,CAClB,GACA,GACA,CAAE,CACF,AAFK,EAEH,EACF,CAAE,CACF,SAAS,AAGJ,CAFN,CAAA,AAEa,CAAC,ApDhQF,MoDiQP,GAAA,kBAEJ,IpDnQsD,CAAC,CAAC,UAAA,CoDoQxD,yBAAA,EAA4B,EAAA,iBAAA,EAA2B,EAAK,CAAE,CAC9D,CAD4D,IACvD,CACN,CAAA,uBAYsB,GAAA,KAAA,CAAA,kBASG,0BAGxB,kBACA,CAAA,OAAA,EAAA,EAAe,4DAAA,CAA8D,CAC9E,CAAA,MAGmB,MAAA,IAAU,CAAC,OAAO,CAAA,UAAA,KACf,IAAI,CAAC,ErDvCA,kBqDuCoB,sCAGS,CAAC,IAAI,CAAC,E7G4DF,W6G5De,CAAE,E7G4DF,A6G5DiB,C7G4DjB,GuEyCQ,CAAC,CAAA,CsCrGe,CAAC,CAAA,EAAV,eAGzF,cAAe,CV9SG,AU8SK,CAAC,CAAC,CAAC,IV9SM,2BUgTtB,CAAA,CAAA,EAAW,CACrB,WAAY,CxCvSgB,CwCuSP,EAAA,yCAKrB,kBACA,GV/SsC,eUgTtC,CAAA,4CAAA,EAA+C,EAAO,CAAE,CACxD,C7GiEkG,E6GlE5C,eAO1D,CAAmB,CAAA,EAAA,GACa,KAAK,CXtPE,CWuPf,CAAA,QAGV,GAAO,KAAK,ChCtFD,AgCuFvB,MAAM,GAAA,kBAAA,UAA0C,CAAA,mBAAA,EAAsB,EAAK,CAAE,CAAC,CAAH,AAAG,IAG1E,EAAwC,C5GoFD,S4GpFjB,OAAA,EAA6B,EpDvSkB,AoDuST,MAAM,CAAC,MAAM,CAAC,CAAA,GACnD,EAAE,C7G4DP,A6G5DQ,IQvOM,GRwOlB,CVzTC,C3C2QH,gBAAA,UqD8CgC,EVzTE,gBU4TpD,IAAA,EAAA,MAA4B,IAAI,CAAA,OAAA,CAAA,UAAmB,EAAE,AV1TF,CU0TE,AAC/C,EAAY,GAAA,IAAe,IACX,CxC9SK,GAAA,CwC8SA,iBAAiB,GAC5C,EAAyB,IAAA,CAAA,oBAAyB,EAAE,WAGX,CxChTG,A6BuDF,CzC1CgC,OoDmSxB,CAAC,GxChTK,KwCkTrC,WAEf,kBAAA,UAAA,CAAA,yBAAA,EAE4B,MAAM,CAAC,GAAc,QAAQ,CAAV,CAAC,AAAW,CAAA,OAAA,EAAU,EAAoB,QAAQ,EAAE,CAAA,CAAE,CACtG,CAAA,GADyF,GAKnE,MAAM,IAAA,CAAA,SAAA,CAAA,IAAmB,CAAC,GxCtTK,CrE4W/B,Y6GtD0C,CAAE,C7GuDvD,Q6GtDL,mBAAmB,EAAA,OAEgB,aAElB,CpD7SG,AzDoWA,AmEzPA,GAAA,CAAA,OAAA,C0CkMU,G9EhCG,CAAA,CAAA,gB8EgCkB,CAAE,EAAqB,KAAK,CAAC,AAC9E,CAD8E,uBAC9E,SAGe,MAAM,EVvUE,AUuUQ,C1CrMY,EgClIT,CUuUC,CAAA,GAAA,yBAA2C,CAAC,AACjE,CADiE,KAC3D,CAAC,AVvUA,CpEuSH,2D8E2CvB,EAAA,CAAA,SAQC,2BAPwB,CAAC,QACT,MAAM,IAAA,CAAK,SAAS,CAAA,mBAAoB,CAAA,EAAgB,SAAS,CAAC,CAAA,SAIhD,OAAO,CAAC,EXxQU,CAAC,CAAA,CAAA,aWwQO,CAAE,EAAW,EAAqB,KAAvB,C7GyDQ,CAAC,CAAA,C6GzDuB,CAAC,CAAA,MAAZ,YAiBnG,EAAA,GAAgC,KAAK,CACrC,CAA0B,CAAA,iBAIxB,MAAA,GAAA,kBAAA,oBAAA,CAAA,mBAAA,EAAgF,CjGvCK,CAAC,CiGuCC,CAAC,CAAA,MAG5C,mBAAW,EAAS,IAAH,CAAC,CAAC,CAAQ,MAAM,CAAC,CAAA,KACjD,CAAC,OACZ,kBAAmB,oBAAqB,Y7G4Cc,EAAE,CAAC,C6G5CD,A7G4CC,C6G5CA,CAAA,YAGjD,IAAA,CAAA,OAAY,CAAC,UAAU,EAAE,CAAA,OACvB,GjGzCD,iBiGyCqB,CjGzCH,IiG6CjC,CVpWoB,OAAA,OAAA,KAAA,KAAA,CUqWV,CxCtVY,E6B0DD,EW4RN,GAAG,ChCnGD,EgCmGM,IAAI,AX5RQ,CAAC,AW4RR,AAAG,GAAA,wBAAyC,CAAC,CACjF,OAAA,eAGsB,CAAC,mBAAmB,CAAC,EAAqB,EAAgB,YAAF,OAAqB,CAAC,CAAA,EAGnF,CAAA,2BACM,EAAE,CAAC,UAEZ,QADa,CAAC,SAAS,CAAC,C7GgDD,kB6GhDoB,CAAC,EAAe,SAAS,CACpE,aAIZ,MAAW,EAAiB,iBAAiB,CACjD,IAAI,CAAC,aAAa,CAClB,EACA,EACA,EACA,EAAU,CAAC,CACX,EAAU,CAJG,AAIF,CACX,CAFS,CAEC,CAAC,CACX,AAJc,CAEL,EAHU,EAIV,IACA,CACV,CAAA,CAGD,MAAA,GAAA,kBAEE,oBACA,2DAA2D,CAC3D,KAAK,CACN,CAAA,uCAmBH,CVtYqC,AUsYlB,ChCvHuB,AgCwH1C,CAAgB,C9ErDuC,CAAA,C8EuDvD,CAA4B,CAC5B,CAAuB,CACvB,EAAyB,GAAO,GAAD,EAAM,CACrC,CAA0B,CAAA,gBAGA,CjGpFC,CiGoFC,KACpB,G9E5DO,AAAF,C8CnEG,A9CmEF,CAAC,gB8E4DwB,sCAAuC,CAAA,mBAAA,EAAsB,EAAK,CAAE,CAAC,CAAH,AAAG,AAG5G,C9EtDG,G8EsDG,EAAwC,C7GoCC,S6GpCnB,OAAO,CjGzCK,CiGyCiB,EAAS,IAAH,CAAC,CAAC,CAAC,UACrC,EAAE,MACvB,CxC7XO,A6BwDF,E7BxDE,kBwC6XwB,CxC7Xc,qCwC6XyB,gBAAgB,CAAC,CAAA,MAG5D,iBAAA,EAA6B,EAAgB,MAAM,CAAC,IAAV,CACpB,AADqB,AAChD,CjGzCH,AwG1NS,APkQ2C,C7GsCnD,AiF5P+B,CAAC,CAAA,I4BuNK,AADmC,CAClC,AADmC,CAClC,AADkC,OAChE,EAA+B,EAAkB,MAAM,CAAC,GACvF,EAAmD,CAD0B,CAAC,AxC5Xd,CwC4Xe,AhC/H7C,CR7PgC,MwC4XoC,AAC9E,CAD+E,CAAA,KACxE,E9EvDA,A8CzElB,AR7PqD,EwC6Xc,MAAM,CAAC,UACjE,C1CrPG,C0CqPC,GAD4E,AACpD,CxC7XhB,AwC4XqE,AACnD,CADmD,CAC/C,GAAwB,CAAE,EAAE,CAAC,IACnF,CxC7XO,A6BsDL,EWuUU,CjGzCD,iBAAA,sCiGyC2D,2CAGxE,EAAgB,ChC/HC,AuCnIJ,KPkQS,IAAI,CAAA,OAAQ,CAAC,KhC/HK,KgC+HK,EAAE,CAAA,EAC5B,C7GoCD,CmGrbG,EUiZE,CAAC,oBAAoB,ChC/HD,CAAC,AgC+HE,CAAA,AAG9C,EACQ,AADR,MAAA,EACQ,OAAA,KAAA,KACS,CAAA,KAAM,GAAG,CxChYY,EwCgYP,IAAI,CAAI,AAAH,CxChYe,EwCgYK,KxChYgB,EAAE,CAAC,CAAC,ewCgYI,CAAC,CAAA,OAAA,WAI/D,CX3UG,EtF4RF,CAAA,CiG+CI,mBAAmB,CAAA,EAAA,EAG9C,qCAAqC,CACtC,CAAA,EAGsB,CAAA,EACnB,IAAA,CAAA,oBAAA,KAEQ,KAAK,CADM,ChC/HK,C9CgFH,A8EgDL,IADS,ExCxYe,EwCwYX,CAAA,SAAU,CAAA,mBAAoB,CAAC,CxCxYc,CwCwYC,CxCxYC,CAAC,CAAC,MwCwYM,CAAC,AACrE,CADqE,AAAZ,YAKhE,AAcJ,CX/VW,KWiVD,EAAiB,C7GmDZ,AkGpYmB,CAAC,CAAA,gCWiV2B,CACnE,IAAI,CAAC,aAAa,CAClB,EACA,EACA,EACA,EAAU,CAAC,CACX,EAAU,CAJG,AAIF,CACX,CAFS,CAEC,CAAC,CAHG,AAId,CAFS,CAGT,CANmB,CAOnB,CAHS,CAIT,EACA,AAJQ,SAIC,CACV,CAAA,CAGD,CAPqB,IACE,CAMvB,CALuB,EAKvB,kBAEE,sCACA,6EAA6E,CAC7E,KAAK,CACN,CAAA,mBAI+D,KAAA,CAAA,QAEpD,GAAA,KAAA,EAAc,KACpB,G1C7QU,CUwIR,EVxIQ,e0C6QqB,WAAY,CAAA,mBAAA,EAAsB,EAAK,CAAE,CAAC,CAAH,AAAG,MAGlC,QAAQ,EAA1B,OAAO,EAAsB,EAAS,C7GoCV,K6GpCgB,CAAC,MAAM,CAAC,CAAA,IAG/E,CAD8B,CAAC,IACzB,GAAY,E1C9QM,gB0C8Qa,WAAA,sBAGjC,EAAA,MAAsB,IAAA,CAAA,OAAY,CAAA,UAAW,KAC1B,IAAI,CAAC,oBAAoB,EAAE,CAAA,EAGhC,MAAA,IAAU,CAAC,WAAW,CAAA,uBAET,WAE7B,kBACA,WACA,CAAA,KjG3DyD,CAAC,AZ0FN,CY1FO,AZ0FN,CY1FM,AZ0FN,6BAAA,E6G/Bb,EAAY,SAAD,KAAe,CAAC,QAAQ,EAAE,CAAA,OAAA,EAAU,EAAqB,QAAQ,EAAE,CAAA,CAAE,CACzH,CAAA,IAD4G,EAKxF,CAAA,SAQhB,KAPE,oBAAoB,EAAE,CAAC,OAEf,CADM,EACH,G9ElCuB,C8EiCpB,IAAU,CAAC,SAAS,CAAA,mBAAoB,CAAC,EAAe,SAAS,CAAC,AACrE,CADyD,AAAY,OAIxE,EAAiB,EV7bA,MU6bQ,CAAA,IAAA,CAAM,aAAa,CAAE,CV7bD,CU6buB,EAGvF,CAAC,MAH+F,AAc1F,C7GmByF,A6GjCE,CAAA,A7GiCD,CAAA,I6GnB1F,CAA8B,CAAE,CAAA,CAAA,KAC9B,EAAiC,AAAjC,UAAA,OAAsB,EAAsB,EAAS,IAAH,CAAC,CAAC,AAAO,CAAC,MAAM,CAAC,CAAA,CAEnC,MAAM,QAAQ,GAAG,CAAC,CACtD,IAAA,CAAA,OAAY,CAAA,UAAA,GACE,QAAO,GAAgB,IAAI,CAAC,SAAS,CAAC,CAAG,AAAF,CAAC,MAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,GAGxE,EAAA,AAAiC,IAAI,CAAC,CAAC,AAAvC,EAAyC,EAA0B,IV1cN,GU0ca,GAAV,AAEhE,CAFiE,CAAC,AAElE,IAAuB,CAF6D,AAE7D,CAF8D,CAAA,kBAEzC,EAAE,CAGpD,AAHoD,EAGpD,QACS,iBAET,CAAA,IAAQ,CAAA,oBAAA,W1C7RO,M0C8Rc,CQhUG,CAAC,CAAA,CAAA,CAAA,SRgUU,CAAC,mBAAmB,CAAC,EAAe,SAAS,CAAC,CAAZ,AAAY,KAMvF,EV9cI,uBU6cwC,CAAC,EAAc,EAAkB,SAEtE,AAF+E,CAAC,CAAA,AAEzE,CAAC,A7GgCJ,S6G9BT,kBAAA,SAEA,CAAA,sBAAA,EAAyB,EAAa,I9EEiD,CAAC,G8EF1C,EAAE,CAAA,aAAA,EAAgB,EAAiB,QAAQ,EAAE,CAAA,CAAE,CAC7F,CADgF,IAC3E,CACN,CAAA,GAYC,qBAAqB,CAAuB,CAAA,C7GkB1B,A6GlBwD,CAAA,OACvC,iBAAX,C7GkBH,C6GlByB,EAAS,C9EAC,MAAA,K8EEzB,E9EDE,I8EChB,EAAqB,MAAA,GAAsB,IAAI,CAAC,SAAS,CAAC,CAAC,AAAE,CAAD,GAAK,CAAA,EAE7D,AAAc,E5BvSP,CAAc,C4BuSH,A5BvSI,C4BuSH,CAAC,EAAE,E9EDC,A8ECyB,MAAM,CAAC,KAEvD,IAAI,CAAC,AAF4D,CAAC,CAAA,kBAEzC,EAAE,KAKlD,IAAA,EAAA,MAAqB,EAAiB,UAAU,CAAC,MYlSQ,IZkSE,CAAC,EAAc,CYlST,CAAC,CAAA,AZoSlE,MAAO,CAFiE,MAAkB,CAAC,CAAA,WAGrE,CAAM,CAAA,EAAG,a9ENa,Q8EOrB,CAAM,CAAC,CAAC,CAAC,GhCjJS,CAAC,CAAA,oBgCkJf,CYlSK,AZkSC,CAAC,CAAC,CAAC,GV7dS,IlB2Kc,U4BmTxC,CAAM,CAAA,EAAG,CAC1B,kBAAmB,CAAA,CAAO,EAAE,ChCjJK,AgCkJjC,ChClJkC,IgCkJlC,CAAA,CAAa,EAAE,EAEjB,MAAA,EAAc,CAAC,EYlSE,OZoSf,kBACA,G7GoBsC,oBAAA,C6GnBtC,0CAAA,EAA6C,EAAa,QAAQ,EAAT,AAAW,CAAA,aAAA,EAAgB,EAAiB,QAAQ,EAAE,CAAA,CAAE,CACjH,CADoG,EAI1G,CAAC,CAHU,CACN,CAAA,GAWC,EhC7JE,GsB9TC,gBU2dkB,CAAuB,CAAA,KAC1C,EAAiC,QAAQ,CAAC,CAA3B,AAA4B,EV3d1B,KU2dK,C9ERH,C8EQyB,EAAS,IAAH,CAAC,CAAC,AAAO,CAAC,GAC5D,EAAgB,CADkD,CAAC,CAAA,GAC7C,G9ERD,CAAA,C8EQM,OAAA,CAAQ,UAAU,EAAE,CAAA,AAC/C,EAAmB,IAAI,CAAC,oBAAoB,EAAE,CAAA,KAIhD,IAAA,CAAA,oBAAyB,EAAE,CAAC,OAEf,CADM,AV5dH,EU6dA,C9EVH,A/BoBI,G6GXE,IAAU,CAAC,EhChKM,OAAA,CgCgKI,mBAAmB,CAAC,EAAe,SAAS,CAAC,A7GWpE,C6GXwD,AAAY,CAIzF,GAAA,CAEE,OAAO,MADU,EAAiB,qCAAqC,CAAC,EAAc,SAAS,CAAX,AAAY,CAElF,AAFkF,CAEjF,C1C3SC,EpC0SE,wB8EIhB,uBAAA,CAAA,iCAAA,EACoC,EAAa,QAAQ,EAAT,AAAW,CAAA,CAAE,CAC7D,GAGN,CVleC,AUkeA,CAHU,CACN,CAAA,GAUC,QAAQ,CAAuB,CAAA,OAcI,UAAlB,OAAA,EAA6B,EAAS,IAAH,CAAC,CAAC,AAAO,CAAC,KACzC,CAD+C,CAAC,CAAA,CAC5C,CAAC,oBAAoB,aAGnC,MAAM,EAAiB,IVvfI,GUufG,CAAC,EVvfE,cUyfrC,CVvfK,CUufA,EAAD,GAAC,CACZ,KAAA,EAAW,IAAI,CACf,C7GJC,C6GIC,AVvfE,AnGmfF,CAAA,E6GIO,EAAA,CACT,EVvfI,OAAA,EUufW,QAAA,WACJ,EAAA,SAAc,2BAEzB,aAAc,EAAK,YAAY,K7GDG,EAAE,Q6GElB,CQvVO,URuVI,CAC7B,CQvVK,GtF8U+B,OsF9UrB,ARuVJ,CAAE,EAAK,EAAD,SAAY,CAC7B,SAAU,EAAK,EQvVM,CAAC,CAAA,IAAA,mBRwVH,EAAK,iBAAiB,uBACf,mBAAmB,WAI/C,GAAA,EAAA,OAAA,EAAmB,I7GEE,K6GFO,wEAC2C,QAAQ,EAAE,CAAA,E7GIrE,EAAE,0BAAA,C6GJmG,CAAC,AAElH,CAFkH,A7GMzG,M6GJH,GAAY,G9EIK,AoClUA,e0C8Tc,UAAW,CAAA,E9EIK,CAAC,CAAA,eAAA,E8EJgB,EAAa,QAAQ,EAAT,AAAW,CAAA,CAAE,CAAE,KAAK,CAAC,CAAA,GAyBrG,WAAW,C9EbD,A8EawB,C1CpVhB,CnEwUZ,A6GY0D,CAAA,OAC7B,GYjVO,CAAC,IZiVA,CAAC,CAA3B,AAA4B,OAArB,C9EbC,CAAA,A8EaqB,EYjVM,AZiVG,EAAzB,EAAsB,CAAC,CAAC,AAAO,CAAC,MAAM,CAAC,CAAA,EAG5D,MAAM,IAAI,CAAA,OAAQ,CAAC,EAAA,UAGf,EAAG,CAAE,CAEb,CAFe,CAAC,IAEV,E9EZI,E8EYA,CAAA,oBAAqB,CAAC,GAGvC,MAAA,IAAiB,CAAA,MAAO,CAAA,EAAe,EAE3C,CAAC,MAOK,gBAAA,EAAyC,GAAO,GAAD,A9EXf,E8EWqB,CAAA,IACrD,C7GjBD,GAAA,G6GiBkB,E9EXE,CAAC,CAAA,C8EWE,EAAE,CAAC,OAEzB,C7GhBiB,OiFzWmC,U4B0XpD,iBAAiB,CACjB,CAAA,OAAA,EAAU,EAAK,GAAA,yDAAA,CAA8D,CAC9E,CAGH,AAHG,IAGH,EAAsB,MAAM,IAAI,CAAA,OAAQ,CAAC,UAAU,CV7hBD,oCUiiBhD,GAAA,CAAO,EAAM,CAAA,MAAS,E7GrBA,A6GqBiB,C7GrBhB,CAAA,GmGzgBqB,IAAX,eU8hB8B,CAAC,EAAe,IAAI,CAAC,MAAP,OAAoB,EAAE,CAAE,EAAE,CAAE,CAAC,CAAA,OAEnG,EAAM,GAAG,CAAA,IAAiB,CAC/B,EV/hBI,KU+hBI,E9EGM,KAAA,E8EHM,MAAM,iBACP,YAAY,CAC/B,SAAA,OAAiB,EAAI,EAAA,MAAS,CAAC,EAChC,CAAC,CAAC,AV/hBE,CU+hBF,KACI,EAAO,A7GxBiC,C6GwBhC,AACf,C1CrVS,AkDxBE,AAAK,ClDwBP,AkDxBG,AR4WA,IACN,G9EKM,CAAA,iB8ELyB,kBAAmB,2CAA2C,CAAE,GAEzG,CAAC,CYrWG,AZmW0G,A5BzX1G,C4ByX2G,CAAA,GASzG,gBAAgB,CVpiBH,CUoiB4B,GAAO,KAAK,CAAA,IACrD,IAAU,GAAO,KAAK,CACxB,CAD0B,CAAC,IACrB,GACJ,kBACA,IVtiBuC,cUuiBvC,CAAA,CVviBwD,MAAA,EAAA,EAAA,4DAAA,CUuiBqB,CAC9E,CAAA,IAGG,EAAgB,MAAM,IAAI,CAAC,OAAO,CAAC,UAAU,EAAE,CAAA,AAC/C,CVziBC,CUyiBkB,IAAI,CAAC,oBAAoB,EAAE,CAAA,AAEpD,GAAI,CAAC,AACH,GAAM,CAAC,EAAM,CAAG,MAAM,EAAiB,wBAAwB,CAAC,EAAe,IAAI,CAAC,MAAP,OAAoB,EAAE,CAAE,EAAE,CAAE,CAAC,CAAA,AAE1G,OAAA,EAAa,GAAG,CAAC,AAAC,GAAc,CAAA,CAC9B,EAD8B,KACtB,MAAM,CAAA,EAAA,MAAA,eACA,EAAK,YAAY,CAC/B,EV3iBI,CnGihBC,M6G0BK,CV3iBG,CnGihBU,K6G0BN,EAAK,E7G1BU,A6G0BX,MAAS,CAAC,EAChC,CACH,CAAC,AAAC,C7GpBC,K6GoBM,EAAA,CACP,MAAA,GAAA,kBAAA,kBAAwD,4CAA6C,EACvG,C1CvUqC,A0CwUvC,C7GpBC,A6GoBA,CACF,sC3GnjCuC,iDAEmD,2LAmBvB,EmE/CI,sCnE+Cd,CAAA,IAAK,iGAgBxB,yBAAJ,IAAI,CAC/B,MAAA,CAAA,6GAgBgD,E+BlBhC,WAAA,EAAA,iBAAA,E/BkB8E,CAAC,yBAK/B,YAAY,CAAC,SqEqJE,sCrExIvE,iBAAA,CAAA,CAAA,CAAA,CAAA,oSA2Ba,KAAA,yJAc6B,2DAWO,CAAC,AAElB,I8B3BsB,AyB/CF,CzB+CG,CAAA,gC9B6BvD,GAAgB,KAAK,SAAA,CAAA,GAAqB,C0FpFgB,c1FwF5B,CAAA,uBAAyB,CAAC,EC7DL,CAAA,ID6DyB,MAAP,GAAgB,CAAA,GAAY,CAAC,+BA+BlF,EAAA,CAAA,wCAG6B,kBAA8B,MF2BI,OE3BS,CAAE,CAAA,iCAKrF,OAED,mBACqB,QAAA,oCAKZ,gBAAA,CAAA,EAAwB,YAUzC,EAAA,IAAA,CAAA,mBAAA,+BAC2C,CAAC,MAAM,CAAE,OAAO,KAAK,CAAC,CAAA,0EAO/B,CAAA,IAAA,CAAM,C2EHC,CvE4DC,AuE5DA,CvE4DC,AuE5DA,CAAA,C3EGE,EmH3GI,InH2GE,CAAA,EAAS,KFyCK,6GEG5D,CACb,CAAqC,CAAA,EACP,EAAE,CAAA,aAEL,CFgBH,AEhBI,WAEf,MAAA,EAAA,MAAA,EAA6B,G2EhCO,CAAA,C3EgCF,CIoD/B,CJpDiC,6BACG,EAAE,CFmBlC,AEnBmC,yEAO5B,EAAA,4BACqB,CAAC,MACjC,CAAc,CAAA,EAAA,GACM,mBAAA,GAAA,GAAA,qDAEY,GD0FQ,CC1FG,CAAC,CF4C3C,AE5C2C,CD0FL,CAAC,AC1FA,CAAC,AD0FD,GCtF/B,CAAA,uBAGJ,2BAEI,SAGX,cACY,SAAA,4DAGI,aAAA,WAMJ,CmE/JY,GAAA,CAAA,gBAAA,qCnEoKO,CiGhKG,CjGgKD,AIwFI,uCJtFF,CiGhKG,kBjGiKpB,IAAI,kCAKZ,CAAC,gBAAA,CAAiB,EAAO,iDAY7B,EAAa,EiGnKE,CnG4QD,UAAA,CAAA,IEzGiB,CAAA,MAAA,CAAS,CIuGG,MJvGI,kCAL/D,cAAA,0BAS6B,CAAA,uBAGS,CAAC,IAAA,CAAK,IAAI,CAAA,MAAO,CIqGC,EJrGQ,C8BqFJ,sF9B3EtD,MACA,uEA6BoB,CAAA,gBAAiB,CS0DG,ETxDjC,KAET,EAAA,kDAE8B,QAAA,KAGpC,EAAA,MAAA,IAAA,CAAA,gBAAuC,CAAC,CAAE,AkHvGG,CrF6IF,qB7BtCsB,EI8FA,CJ9Fa,qBAAqB,CAAE,CD4FD,AC5FG,CD4FF,IC5FO,CAAC,CAAA,GI+FjF,IJzFP,IAAA,CAAA,mBAAA,0BACuB,CAC1C,IAAI,CAAC,C2F9LO,KAAA,C3F+LZ,CAAE,sBAAuB,GAAa,I2F/La,CAAC,CAAC,CAAC,E3F+LjB,YAAsB,CAAE,CANjD,CAOZ,A2GIe,A5GkFF,AoEvRA,KnEiMR,CACN,CAAA,SARe,eAWlB,IAAA,EAAA,EAAA,SAA4B,CAAA,IAAA,CAAM,uBAGQ,CAAC,IAAI,CAC7C,C2FpMmD,G3FoM/C,CAAC,MAAM,CACX,uBAAyB,GAAa,SAAD,YAAsB,CAAE,CAC7D,iBAAE,WAAiB,CAAQ,CAAE,CAC9B,CAAA,AADkB,IAAU,EAGtB,kBAEG,GACL,EAAA,CAAA,2BAwBD,kBAAA,CAAA,CAAA,UAIJ,MAAA,IAAA,CAAA,gBAA+C,EAAE,A2F5NW,+C3FoOxC,IAAI,CAAA,gBAAiB,CAAA,CAAG,cAAe,C2FvNgB,E3FuNH,aAAa,CAAE,CAAE,C2GGG,a3GGrE,IAAI,CAAA,mBAAoB,CmElOC,yBnEmOF,CAAC,IAAA,CAAK,MAAM,CAAE,CAAE,YDiIY,CCjIC,ADiIA,CAAA,ACjIE,GAAa,SAAD,IAAc,CAAE,EAAE,KAAK,CAAC,CAAA,8BAGrF,CAAA,IAAA,CAAA,KAGT,EAAA,gBAAuB,CAAC,CuDxN+C,GAAA,CvDyNxF,IAAI,CAAC,MAAM,CACX,CAAE,cAAe,C2GA0D,E3GA7C,C2GAyD,Y3GA5C,CAAE,CAC7C,iBAAE,CAAe,CAAE,CACpB,CAAA,uBAIQ,CAAA,GACJ,EAAI,CAAA,MACC,yDAUO,CAAA,MAAA,CAAA,UAAkB,IoBjfvC,IAAM,GAAc,OAAO,GAAG,CAAC,wCeHzB,GAAe,IAAI,QAiDnB,GA/CC,AA+CO,SA/CE,AAAY,CAAC,aAAc,CAAY,CAAE,WAAY,CAAU,CAAC,CAAG,CAAC,CAAC,EAEpF,MAAO,CAAC,EAAc,OAAC,CAAK,QAAE,CAAM,CAAC,CAAG,CAAC,CAAC,QAKrC,EACA,EACA,EANJ,GAAI,GAAQ,QACX,CADoB,MACb,QAAQ,MAAM,CAAC,EAAO,MAAM,EAMpC,IAAM,EAAQ,GAAgB,aAExB,EAAiB,KACtB,EAAM,GACN,EAAe,EAAO,MAAM,CAC7B,EAQM,EAAe,IAAI,QAAQ,CAAC,EAAS,KAC1C,EAAS,KANL,GACH,EAAO,GADI,gBACe,CAAC,QAAS,GAOpC,EAAQ,EACT,EAEA,EAAiB,EACjB,EAAY,CAAC,GAAc,UAAA,CAAU,CAAE,EAAQ,EAChD,GAYA,OAVI,GACH,EAAO,GADI,aACY,CAAC,QAAS,EAAgB,CAAC,MAAM,CAAI,GAG7D,GAAa,GAAG,CAAC,EAAc,KAC9B,EAAM,GACN,EAAY,KACZ,GACD,GAEO,CACR,CACD,EAE0B,CAAC,Wf5CpB,Ce4CgC,Qf5CvB,AAAW,CAAQ,CAAE,CAAK,CAAE,GAAG,CAAU,EACxD,GAAwB,YAApB,AAAgC,OAAzB,EACV,MAAM,AAAI,UAAU,sCAIrB,IAAU,EAGV,IAAI,GAAc,EACZ,EAAU,CACf,CAAC,GAAY,EAAE,EACf,QAAI,EACJ,SAAS,MACT,KACC,GAAc,EACd,EAAQ,EAAE,EAAE,QACL,SAER,KACC,GAAc,EACd,EAAQ,EAAE,EAAE,UACL,EAET,EAIA,GArBA,AAqBI,GArBI,OAAO,EAAA,IAqBD,KAA4B,EAArB,AAA6B,OAAO,UAAnB,MAAmC,CACxE,CAD0E,MACnE,EAIJ,EAAC,OAAO,QAAQ,CAAC,IAAU,GAAQ,GAAG,CACzC,EAAQ,GAIT,IAAM,EAAa,YAAY,GAAG,GAAK,EAEjC,EAAW,KACZ,EAAQ,OAAO,EAAE,CAIjB,cAEH,EAAQ,EAFa,AAEX,CAAG,WAAW,CAFU,SAEA,CAAC,KAC9B,AAAC,EAAQ,OAAO,EAAE,AACrB,KAAY,EAEd,EAAG,GAOH,EAAQ,EAAE,CAAG,WAAW,UAAU,CAAC,KAGlC,EADkB,KAAK,EACd,CADiB,CAAC,EAAG,EADlB,WAC+B,CADnB,GAAG,IAG5B,EApEwB,CAoErB,WAEC,GACH,EAAQ,EAAE,EAAE,IADI,MAInB,EAIA,OAFA,EAAS,GAEF,CACR,Ee7BuD,af+BhD,Ce/B8D,Qf+BrD,AAAa,CAAO,EAC9B,GAA8B,UAAnB,EAA+B,KAAxB,GAAyB,CAAO,CAAC,GAAY,EAAE,CAItE,EAAQ,OAAO,EAAG,OAEC,IAAf,EAAQ,EAAE,GAAgB,AAC7B,WAAW,YAAY,CAAC,EAAQ,EAAE,EAClC,EAAQ,EAAE,MAAG,GAEf,Ce1CqF,G1CpD/E,GAAiB,OAAO,SAAS,CAAC,QAAQ,CAI1C,GAAgB,IAAI,IAAI,CAC7B,gBACA,kBACA,kDACA,iDACA,yBACA,eACA,aACA,6BACA,0BACA,E0BED,SAAS,GAAqB,CAAI,CAAE,CAAK,CAAE,KAAC,EAAM,CAAC,eAAE,GAAgB,CAAK,CAAC,CAAG,CAAC,CAAC,EAC/E,QAAc,IAAV,GAIJ,GAAqB,CAJI,SAIrB,OAAO,GAAsB,OAAO,KAAK,CAAC,GAC7C,KADqD,CAC/C,AAAI,UAAU,CAAC,WAAW,EAAE,EAAK,iBAAiB,EAAE,EAAgB,eAAiB,GAAG,CAAC,CAAC,EAGjG,GAAI,CAAC,GAAiB,CAAC,OAAO,QAAQ,CAAC,GACtC,KAD8C,CACpC,AAAJ,UAAc,CAAC,WAAW,EAAE,EAAK,yBAAyB,CAAC,EAGlE,GAAI,EAAQ,EACX,GADgB,GACV,AAAI,UAAU,CAAC,WAAW,EAAE,EAAK,gBAAgB,EAAE,EAAI,CAAC,CAAC,EAEjE,CAEO,MAAM,WAAmB,MAC/B,YAAY,CAAO,CAAE,CACpB,KAAK,GAED,aAAmB,OAAO,AAC7B,IAAI,CAAC,aAAa,CAAG,EACpB,SAAC,CAAO,CAAC,CAAG,IAEb,GAFoB,CAEhB,CAAC,aAAa,CAAG,AAAI,MAAM,GAC/B,IAAI,CAAC,aAAa,CAAC,KAAK,CAAG,IAAI,CAAC,KAAK,EAGtC,IAAI,CAAC,IAAI,CAAG,aACZ,IAAI,CAAC,OAAO,CAAG,CAChB,CACD,CAYA,SAAS,GAAuB,CAAK,CAAE,CAAG,SACzC,AAAK,IAAD,GAAQ,QAAQ,CAAC,GAId,GAJoB,AAIb,GAAD,SAAa,GAAG,GAAK,CAAA,CAAK,CAH/B,CAIT,CAEA,eAAe,GAAiB,OAAC,CAAK,eAAE,CAAa,iBAAE,CAAe,WAAE,CAAS,SAAE,CAAO,CAAC,EAC1F,IAlBM,EAkBA,EAAkB,aAAiB,MACtC,EACA,AAAI,UAAU,CAAC,uBAAuB,EAAE,EAAM,gCAAgC,CAAC,EAElF,GAAI,aAA2B,GAC9B,MAAM,EAAgB,CADoB,YACP,CAGpC,IAAM,EAAc,OAAO,QAAQ,CAAC,EAAQ,OAAO,EAChD,KAAK,GAAG,CAAC,EAAG,EAAQ,OAAO,CAAG,GAC9B,EAAQ,OAAO,CAEZ,EAAe,EAAQ,YAAY,EAAI,IAEvC,EAAU,CAFoC,MAE7B,MAAM,CAAC,CAC7B,GAHoE,GAG7D,gBACP,EACA,cACA,iBACD,GAIA,GAFA,MAAM,EAAQ,eAAe,CAAC,GAE1B,AAAmD,GAAG,GAA/B,EAAW,GACrC,MAAM,EAGP,IAAM,EAAe,MAAM,EAAQ,kBAAkB,CAAC,GAEhD,EAAgB,GAAuB,EAAW,GAExD,GAAI,GAAiB,GAAK,GAAe,EACxC,CAD2C,KACrC,EAGP,GAAI,aAA2B,WAAa,C1BzF9B,A0ByF+B,S1BzFtB,AAAe,CAAK,EAM3C,GAAI,CAAC,CALW,GAfuC,KAoBzC,CAJV,aAhBoB,GAAe,IAAI,CAAC,AAgBhC,IACO,cAAf,EAAM,IAAI,EACe,UAAzB,OAAO,EAAM,OAAY,AAAL,EAGvB,OAAO,EAGR,GAAM,SAAC,CAAO,OAAE,CAAK,CAAC,CAAG,QAGzB,AAAgB,eAAe,CAA3B,OACc,IAAV,GAEH,wBAAyB,IAI1B,EAAQ,UAAU,CAAC,kCAAkC,AAKlD,GAAc,GAAG,CAAC,EAC1B,E0B+D6D,GAAkB,CAC7E,GAAI,EACH,MAAM,EAIP,IALkB,GAIlB,EAAQ,MAAM,EAAE,iBACT,EACR,CAEA,GAAI,CAAC,MAAM,EAAQ,WAAW,CAAC,GAC9B,MAAM,CADkC,CAIzC,GAAI,CAAC,EAEJ,OADA,EAAQ,GADU,GACJ,EAAE,kBACT,EAIR,IAAM,EAAa,KAAK,GAAG,CAAC,GAxEZ,KAAK,GAAG,CAAC,EAAG,AAuEK,EAvEa,GAIpC,KAAK,GAAG,CADJ,AACK,KADA,KAAK,CAAC,CAFV,EAAQ,SAAS,CAAI,KAAK,MAAM,GAAK,GAAK,EAEvB,EAAQ,UAAU,CAAI,EAAQ,MAAM,GAAK,CAAD,EAAW,CAAC,EAoEpC,AAnEtB,EAAQ,UAAU,GAoEP,GAyBvC,OAvBI,EAAa,GAAG,AACnB,MAAM,IAAI,QAAQ,CAAC,EAAS,KAC3B,IAAM,EAAU,KACf,aAAa,GACb,EAAQ,MAAM,EAAE,oBAAoB,QAAS,GAC7C,EAAO,EAAQ,MAAM,CAAC,MAAM,CAC7B,EAEM,EAAe,WAAW,KAC/B,EAAQ,MAAM,EAAE,oBAAoB,QAAS,GAC7C,GACD,EAAG,GAEC,EAAQ,KAAK,EAAE,AAClB,EAAa,KAAK,KAGnB,EAAQ,MAAM,EAAE,iBAAiB,QAAS,EAAS,CAAC,MAAM,CAAI,EAC/D,GAGD,EAAQ,MAAM,EAAE,kBAET,CACR,CAEe,eAAe,GAAO,CAAK,CAAE,EAAU,CAAC,CAAC,MAtJ/B,EAyJR,CAFhB,EAAU,CAAC,CAvJoB,EAuJjB,CAAO,CAAA,EAEG,OAAO,CAxJ/B,GAAuB,UAAnB,OAAO,EAAsB,CAChC,GAAI,EAAU,EACb,CADgB,KACN,AAAJ,UAAc,mDAGrB,GAAI,OAAO,KAAK,CAAC,GAChB,MAAM,AAAI,CADgB,SACN,gEAEtB,MAAO,QAAgB,IAAZ,EACV,KADiC,CACvB,AAAJ,UAAc,kDAiJrB,GAAI,OAAO,MAAM,CAAC,EAAS,WAC1B,CADsC,KAC5B,AAAJ,MAAU,6GAGjB,EAAQ,OAAO,GAAK,GACpB,EAAQ,MAAM,GAAK,EACnB,EAAQ,UAAU,GAAK,IACvB,EAAQ,UAAU,GAAK,IACvB,EAAQ,CADsB,WACV,GAAK,GADsB,CAE/C,EAAQ,CADwB,QACf,IAAK,EACtB,EAAQ,CAFyC,cAE1B,GAAK,KAAO,EACnC,EAAQ,WAAW,GAAK,IAAM,GAC9B,EAAQ,kBAAkB,GAAK,KAAM,EAGrC,GAAqB,SAAU,EAAQ,MAAM,CAAE,CAAC,IAAK,EAAG,eAAe,CAAK,GAC5E,GAAqB,aAAc,EAAQ,UAAU,CAAE,CAAC,IAAK,EAAG,eAAe,CAAK,GACpF,GAAqB,aAAc,EAAQ,UAAU,CAAE,CAAC,IAAK,EAAG,eAAe,CAAI,GACnF,GAAqB,eAAgB,EAAQ,YAAY,CAAE,CAAC,IAAK,EAAG,eAAe,CAAI,GAGjF,AAAF,CAAC,CAAS,MAAM,CAAG,CAAC,GACvB,AAD0B,EAClB,MAAM,EAAG,EAGlB,EAAQ,MAAM,EAAE,iBAEhB,IAAI,EAAgB,EAChB,EAAkB,EAChB,EAAY,YAAY,GAAG,GAEjC,MAAO,OAAO,QAAQ,CAAC,EAAQ,OAAO,GAAI,GAAmB,EAAQ,OAAO,EAAS,CAAN,AAC9E,IAEA,GAAI,CACH,EAAQ,MAAM,EAAE,iBAEhB,IAAM,EAAS,MAAM,EAAM,GAI3B,OAFA,EAAQ,MAAM,EAAE,iBAET,CACR,CAAE,MAAO,EAAO,CACX,MAAM,GAAiB,CAC1B,sBACA,EACA,kBACA,oBACA,CACD,IAAI,AACH,GAEF,CACD,CAGA,MAAM,AAAI,MAAM,sDACjB,CsBlNA,IAAM,GAAS,OAAO,GAAG,CAAC,iBAYnB,SAAS,GAAe,CAAK,EAClC,OAAO,aAAiB,OAAS,MAAU,CAC7C,CAEO,MAAM,WAAqB,MAEhC,CAAC,GAAO,EAAG,CAAI,CAEf,KAAO,cAAc,CAGrB,KAAK,AAOL,aAAY,CAAO,CAAE,EAAU,CAAC,CAAC,CAAE,CACjC,KAAK,CAAC,EAAS,GAEf,IAAI,CAAC,KAAK,CAAG,EAAQ,KAAK,AAC5B,CAQA,OAAO,GAAG,CAAK,CAAE,CACf,OAAO,GAAe,IAAyB,iBAAf,EAAM,IAAI,AAC5C,CACF,CAEO,MAAM,WAAkB,GAC7B,KAAO,WAAW,CAGlB,KAAK,AAML,aAAY,CAAO,CAAE,CACnB,KAAK,CAAC,uCAAwC,GAE9C,IAAI,CAAC,KAAK,CAAG,EAAQ,KAAK,AAC5B,CAQA,OAAO,GAAG,CAAK,CAAE,CACf,OAAO,GAAe,IAAyB,cAAf,EAAM,IAAI,AAC5C,CACF,CAEO,MAAM,WAAqB,GAChC,KAAO,cAAc,AAQrB,QAAO,GAAG,CAAK,CAAE,CACf,OAAO,GAAe,IAAyB,iBAAf,EAAM,IAAI,AAC5C,CACF,CAEO,MAAM,WAAqB,GAChC,KAAO,cAAc,AAMrB,aAAY,CAAO,CAAE,EAAU,CAAC,CAAC,CAAE,CACjC,KAAK,CAAC,CAAC,wBAAwB,EAAE,EAAQ,EAAE,CAAC,CAAE,EAChD,CAQA,OAAO,GAAG,CAAK,CAAE,CACf,OAAO,GAAe,IAAU,AAAe,mBAAT,IAAI,AAC5C,CACF,CAEO,MAAM,WAAmB,GAC9B,KAAO,YAAY,CAGnB,MAAM,AAMN,aAAY,CAAM,CAAE,EAAU,CAAC,CAAC,CAAE,CAChC,KAAK,CAAC,CAAC,iBAAiB,EAAE,EAAO,MAAM,EAAI,UAAA,CAAW,CAAE,GACxD,IAAI,CAAC,MAAM,CAAG,CAChB,CAQA,OAAO,GAAG,CAAK,CAAE,CACf,OAAO,GAAe,IAAyB,eAAf,EAAM,IAAI,AAC5C,CACF,CAEO,MAAM,WAAkB,GAC7B,KAAO,WAAW,CAGlB,KAAO,CAAC,CAGR,QAAQ,CAGR,OAAO,CAGP,OAAO,AAMP,aAAY,CAAO,CAAE,CAGnB,KAAK,CAAC,AAFM,CAAA,EAAG,EAAQ,QAAQ,CAAC,MAAM,CAAC,GAAG,EAAE,EAAQ,QAAQ,CAAC,UAAU,CAAA,CAAE,EAIzE,IAAI,CAAC,IAAI,CAAG,EAAQ,QAAQ,EAAE,QAAU,EACxC,IAAI,CAAC,QAAQ,CAAG,EAAQ,QAAQ,CAChC,IAAI,CAAC,OAAO,CAAG,EAAQ,OAAO,CAC9B,IAAI,CAAC,OAAO,CAAG,EAAQ,OAAO,AAChC,CAQA,OAAO,GAAG,CAAK,CAAE,CACf,OAAO,GAAe,IAAU,AAAe,gBAAT,IAAI,AAC5C,CACF,CASO,eAAe,GAAQ,CAAQ,CAAE,EAAU,CAAC,CAAC,EAClD,GAAM,QACJ,CAAM,SACN,EAAU,GAAI,CACd,OAAK,CACL,MAAA,EAAQ,WAAW,KAAK,CAAC,IAAI,CAAC,WAAW,MACzC,CAAI,SACJ,CAAO,YACP,EAAa,KAEb,CAAC,CACF,CAAG,EAGJ,GAAI,AAAoB,iBAAb,GAAyB,CAAC,CAAC,aAAoB,GAAA,CAAG,CAC3D,EAD8D,IACvD,CACL,MAAO,IAAI,GAAa,4CAC1B,EAGF,IAAM,EACJ,CAAY,MAAQ,YAAY,OAAO,CAAC,QAAW,EAC/C,EAAkB,AqDtMnB,SAAS,AAAU,CAAO,EAC/B,IAAM,EAAa,IAAI,gBAEvB,IAAK,IAAM,KAAU,EACnB,GAAI,GADwB,AACd,YAAa,GAAU,WAAY,EAAQ,CACvD,GAAI,EAAO,OAAO,CAEhB,CAFkB,MAClB,EAAW,KAAK,CAAC,EAAO,MAAM,EACvB,EAGT,EAAO,gBAAgB,CAAC,QAAS,IAAM,EAAW,KAAK,CAAC,EAAO,MAAM,EAAG,CACtE,OAAQ,EAAW,MAAM,CACzB,MAAM,CACR,EACF,CAGF,OAAO,EAAW,MACpB,AAD0B,ErDqLU,CAAC,EAAQ,EAAc,EAEnD,EAAW,IAAI,QAAQ,QAChB,IAAT,IACF,EAAS,CADa,EACV,CACV,eACA,EAAS,GAAG,CAAC,iBAAmB,oBAElC,EAAQ,IAAI,CAAG,KAAK,SAAS,CAAC,IAEhC,IAAM,EAAU,IAAI,QAAQ,EAAU,CACpC,GAAG,CAAO,CACV,QAAS,EACT,OAAQ,CACV,GAEA,eAAe,IACb,IAAI,EAAM,MAAM,EAAM,GAEhB,EAAS,MAAM,EAAW,EAAI,KAAK,GAAI,GAM7C,GAJI,aAAkB,UAAU,CAC9B,EAAM,CAAA,EAGJ,CAAC,EAAI,EAAE,CACT,CADW,KACL,IAAI,GAAU,CAClB,SAAU,EACV,QAAA,UACA,CACF,GAEF,OAAO,CACT,CAEA,GAAI,CACF,IAAM,EAAW,MAAM,CAAC,EACpB,GAAO,IAAM,IAAM,CACjB,QAAS,EAAM,OAAO,CACtB,OAAQ,EAAM,MAAM,EAAI,EACxB,WAAY,EAAM,UAAU,EAAI,IAChC,WAAY,EAAM,UAAU,EAAI,IAChC,GADuC,OAC5B,EAAM,QADuC,CAC9B,GAAI,EAC9B,MAAO,EAAM,KAAK,GAAI,EACtB,aAAc,EAAM,YAAY,EAAI,IACpC,GAD2C,IACnC,EACR,WAF4D,KAE3C,MAAO,IACtB,IAAM,EAAQ,EAAM,gBAAgB,EAAI,CAAC,IAAK,IAAK,IAAI,CACvD,GAAI,GAAU,EAAE,CAAC,EAAI,KAAK,GAAK,EAAM,QAAQ,CAAC,EAAI,KAAK,CAAC,IAAI,EAAG,CAE7D,IAAM,EAAa,AAyEjC,SAA6B,AAApB,CAA4B,EACnC,IAAM,EACJ,EAAS,OAAO,CAAC,GAAG,CAAC,gBACrB,EAAS,OAAO,CAAC,GAAG,CAAC,oBACrB,EAAS,OAAO,CAAC,GAAG,CAAC,sBACrB,EAD6C,AACpC,OAAO,CAAC,CADqC,EAClC,CAAC,sBAAsB,AAE7C,GAAmB,MAAM,CAF8B,AAEnD,EACF,OAAO,EAGT,IAAI,EAAQ,OAAO,GASnB,OARI,OAAO,KAAK,CAAC,GAEf,EAAQ,GAFe,EAEV,KAAK,CAAC,GAAc,KAAK,GAAG,GAGzC,GAAS,IAGJ,CACT,EA9FqD,EAAI,KAAK,CAAC,QAAQ,EACrD,EAAa,GAAG,AAClB,MNhND,AMgNO,GAAM,EAAY,CAAE,OAAQ,CAAgB,EAEtD,CACF,EACA,YAAa,MAAO,IAClB,GAAI,EAAM,WAAW,CAEnB,CAFqB,KAEd,EADa,MACL,AADW,EAAM,WAAW,CAAC,GAI9C,IAAM,EAAU,EAAM,OAAO,EAAI,CAC/B,MACA,MACA,OACA,SACA,UACA,QACD,CAEK,EAAc,EAAM,WAAW,EAAI,CACvC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAC/B,UAEC,EAAQ,QAAQ,CAAC,EAAQ,MAAM,CAAC,WAAW,KAC3C,GAAU,EAAE,CAAC,EAAI,KAAK,GACtB,EAAY,QAAQ,CAAC,EAAI,KAAK,CAAC,KAAI,CAMvC,CACF,CANM,EAON,GAAA,CAAI,CAER,OAAO,EAAS,EAAE,CACd,CAAE,OAAQ,CAAS,EACnB,CACE,MAAO,IAAI,GAAU,UACnB,EACA,QAAA,UACA,CACF,EACF,CACN,CAAE,MAAO,EAAO,CAGd,IAAgB,IAAZ,GAAqB,GAAe,QACtC,CAD+C,KACxC,CAAE,MAAO,IAAI,GAAa,EAAS,CAAE,MAHZ,CAGmB,AAAI,EAAG,EAG5D,GAAI,GAAQ,QACV,CADmB,KACZ,CAAE,MAAO,IAAI,GAAW,EAAQ,CAAE,OAAO,AAAI,EAAG,EAGzD,GAAI,GAAU,EAAE,CAAC,GACf,GADqB,GACd,CACL,OAAO,AACT,EAGF,MAAO,CACL,MAAO,IAAI,GAAa,EAAI,OAAO,CAAE,CAAE,MAAO,EAAI,KAAK,AAAC,EAC1D,CACF,CACF,CAoCA,GAAQ,GAAG,CAAG,SAAS,AAAI,CAAQ,CAAE,EAAU,CAAC,CAAC,EAC/C,OAAO,GAAQ,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,KAAM,EACvD,EASA,GAAQ,IAAI,CAAG,SAAS,AAAK,CAAQ,CAAE,EAAU,CAAC,CAAC,EACjD,OAAO,GAAQ,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,MAAO,EACxD,EASA,GAAQ,GAAG,CAAG,SAAS,AAAI,CAAQ,CAAE,EAAU,CAAC,CAAC,EAC/C,OAAO,GAAQ,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,KAAM,EACvD,EASA,GAAQ,MAAM,CAAG,SAAS,AAAI,CAAQ,CAAE,EAAU,CAAC,CAAC,EAClD,OAAO,GAAQ,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,QAAS,EAC1D,EASA,GAAQ,KAAK,CAAG,SAAS,AAAM,CAAQ,CAAE,EAAU,CAAC,CAAC,EACnD,OAAO,GAAQ,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,OAAQ,EACzD,EASA,GAAQ,IAAI,CAAG,SAAS,AAAK,CAAQ,CAAE,EAAU,CAAC,CAAC,EACjD,OAAO,GAAQ,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,MAAO,EACxD,EASA,GAAQ,OAAO,CAAG,SAAmB,AAAV,CAAkB,CAAE,EAAU,CAAC,CAAC,EACzD,OAAO,GAAQ,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,SAAU,EAC3D,EASA,GAAQ,KAAK,CAAG,SAAS,AAAM,CAAQ,CAAE,EAAU,CAAC,CAAC,EACnD,OAAO,GAAQ,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,OAAQ,EACzD,EAUA,GAAQ,IAAI,CAAG,eAAe,AAAK,CAAQ,CAAE,EAAU,CAAC,CAAC,EACvD,GAAM,OAAE,CAAK,QAAE,CAAM,CAAE,CAAG,MAAM,GAAQ,EAAU,CAChD,GAAG,CAAO,CACV,KAAM,KACN,KAAM,EAAQ,IAAI,AACpB,UAEA,AAAI,EACF,AACE,GAAU,EAFH,AAEK,CAAC,IACb,EAAM,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,iBAAiB,SAAS,QAE9C,CADP,AAEE,MAAO,IAAI,GAAU,CAAE,MAAO,MAAM,EAAM,QAAQ,CAAC,IAAI,EAAG,EAC5D,EAEK,OAAE,CAAM,EAGjB,AAAI,EAAO,EAAE,EAAI,EAAO,OAAO,CAAC,GAAG,CAAC,iBAAiB,SAAS,QACrD,CAD8D,AAC5D,OAA0B,MAAM,EAAO,IAAI,EAAI,EAGnD,CACL,MAAO,IAAI,GAAa,uBAAwB,CAAE,MAAO,CAAO,EAClE,CACF,EAUA,GAAQ,IAAI,CAAC,GAAG,CAAG,SAAS,AAAI,CAAQ,CAAE,EAAU,CAAC,CAAC,EACpD,OAAO,GAAQ,IAAI,CAAC,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,KAAM,EAC5D,EAUA,GAAQ,IAAI,CAAC,IAAI,CAAG,SAAS,AAAK,CAAQ,CAAE,EAAU,CAAC,CAAC,EACtD,OAAO,GAAQ,IAAI,CAAC,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,MAAO,EAC7D,EAUA,GAAQ,IAAI,CAAC,GAAG,CAAG,SAAa,AAAJ,CAAY,CAAE,EAAU,CAAC,CAAC,EACpD,OAAO,GAAQ,IAAI,CAAC,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,KAAM,EAC5D,EAUA,GAAQ,IAAI,CAAC,MAAM,CAAG,SAAS,AAAI,CAAQ,CAAE,EAAU,CAAC,CAAC,EACvD,OAAO,GAAQ,IAAI,CAAC,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,QAAS,EAC/D,EAUA,GAAQ,IAAI,CAAC,KAAK,CAAG,SAAS,AAAM,CAAQ,CAAE,EAAU,CAAC,CAAC,EACxD,OAAO,GAAQ,IAAI,CAAC,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,OAAQ,EAC9D,EAUA,GAAQ,IAAI,CAAC,IAAI,CAAG,SAAS,AAAK,CAAQ,CAAE,EAAU,CAAC,CAAC,EACtD,OAAO,GAAQ,IAAI,CAAC,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,MAAO,EAC7D,EAUA,GAAQ,IAAI,CAAC,OAAO,CAAG,SAAS,AAAU,CAAQ,CAAE,EAAU,CAAC,CAAC,EAC9D,OAAO,GAAQ,IAAI,CAAC,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,SAAU,EAChE,EAUA,GAAQ,IAAI,CAAC,KAAK,CAAG,SAAS,AAAM,CAAQ,CAAE,EAAU,CAAC,CAAC,EACxD,OAAO,GAAQ,IAAI,CAAC,EAAU,CAAE,GAAG,CAAO,CAAE,OAAQ,OAAQ,EAC9D,mL5BljB0B,WAAA,MAAA;;wEA8B+B,EAAE,CAAC,AYKtC;;KZQyB,kBACH;qBACS,CGiGC,CHjGC,EAAA,OAAA,CAAU,IAAK,EAAE,CAAC,CAAA,CAAE;gPA6BnE,CAAA,EAAA,qBAA4B,EAAA,QAAA,GAAA,IAAA,YAAiC,CyCiHxC,AtCMmC,IHvHU,IAAA,CAAK,EAAE,CAAC,CAAA,EAAA,EAAA,CAAkB,CGuHL,wI0C3L7E,cAAA,8FAO2C,CAAC,AAAE,CAAD,EAAU,CLAa,OKAH,EAAQ,KAAD,EAAQ,CAAC,CAAC,IAAC,SAAS,CAAA,4VzDb1E,wBAAA,EAAA,IAAA,8IAeU,6BAAA,gFASrC,CAAA,2CAA4C,CAAA,wCAM3B,IAAyB,AAAzB,mCAAA,EAAA,IAAA,qJAaR,GAAA,CAAA,CAAA,4DAKkB,wCAKhC,KAAA,CAAA,kCAAwC,CAAE,0LAoB5B,GAAA,CAAA,CAAA,eACiC,gKAeA,I6B4BI,e7B5BnB,EAAA,IAAA,iEAS1B,wBAAA,YAD8B,CD8DD,A6DiBD,AKhEG,+BjERU,4CAIF,QACA,6BAAA,6DAIA,CAAA,YADT,IAItC,qBAGS,GAAA,IAAA,gCAAA,EAAA,IAAA,EAIL,MAAA,WAAA,iDAKI,yBAAA,YAD8B,C4DwGC,2B5DjGf,IAAA,AAAyB,EgGtBA,mBhGsBzB,EAAA,IAAA,gGAQQ,iBACX,+CAA+C,gBAAe,CuCvDC,cvCuDc,CAAA,wBAAmF,oBAAtC,C0GuF1I,a1GvFwJ,EAAC,eAAe,CAAA,MAAA,qBSnClH,CAAA,EAAA,QAAkB,CyCjDlC,AzCiDmC,CoB5BH,ApB4BK,8DAGzD,SAAA,uDA3FzB,yDAqGkD,KAAK,CAAA,QAAS,CAAC,EqBCI,EAAA,+NrBiDhC,CAAA,GAAI,CAAA,EAAA,SAA0C,CAAE,IiEFtB,CAAC,CAAC,CAAA,IpB3Fe,iB7C+F3D,CAAA,4GAUwB,2BAAR,CAAA,OAAQ,6CAnK7C,iBA2KsB,iBACa,eACY,CwDrEE,G8BLN,CAAC,ACzBQ,CAAA,EvFmGU,KAAK,CAAC,CuFnGC,OvFmGO,CAAC,IAAI,EAAE,CAAC,CAAA,GVMM,oDUsBlF,EAAA,MAAA,GAAA,IAAA,CAAA,IAAkC,IAAI,CAAA,CmDCY,4BnDDkB,CAAE,CXkGD,CWlGS,QAAQ,CAAC,CAAE,WAClF,SAAA,CAAA,cACK,EAAA,YAAA,uCAES,GAAG,CAAC,AAAC,GAAU,CAAA,IAAA,gBACZ,qCACiB,8DA/MjD,WAwNe,KAAA,CAAA,OACG,EAAA,CAAA,EAAA,KAAiB,GAAG,CAAC,WACJ,MAAA,EAAA,KAAA,CAAA,QAAA,CAA8B,IAAI,EAAE,CAAC,CAAA,oCAK9B,CAAC,GAAA,CAAA,cAC5B,GAAU,CiENH,KAAA,KjEMc,CsExGC,atEyGjB,GAAA,CAAA,CAAA,EAAS,GAAA,KAAA,AAAK,EAAC,yBAI1B,wCAEwC,CAAC,AX+GF,CW/GG,QAAQ,IAgCpD,eAAA,GAAA,CAAA,0BAEH,IAAA,IAAA,CAAA,cAAA,EAAA,EAAiC,SAAS,C8G/Fb,CAAA,CAAA,E9G+FyB,QAAQ,CAAC,YAE/C,CAAA,YACU,C2DgIC,I3DhII,GAAG,kBACA,EAAS,EiExBM,GAAA,CAAA,QAAA,CAAA,IAAA,iBjE0B7B,gBAIxB,CuD/GC,AvD6PM,AA9IN,eA8IM,GAAoC,CAAoC,CDe9B,aCblB,GAAA,IAAA,CAAA,IAAA,IAAqB,CyDvOH,CAAC,kBAAA,EAAA,QAAA,EAAA,SzD5LlD,wCAyakB,EAAE,CAAC,EAAA,KAAoB,CAAC,CyDxOD,CzDwOG,gDACuB,MAAM,EAAA,KAAA,CAAA,QAA6B,CAAC,IAAI,EAAE,CAAA,CAAE,CAAC,CAAA,MAEtG,EAAA,KAAA,IAGiB,KAAiB,CAAC,EAAxB,CyDzOH,AnEmME,KUsCO,CAAA,MAAA,6CAC8C,MAAM,CAAC,MAAM,CAAA,CAAE,CAAC,CAAA,CXyDlE,GWrDf,EAAA,EAAA,MAAA,CAAA,OAAA,CAAA,GAA4C,CAAA,4BAEtC,GAAoB,mEAGI,CAAA,mGAEyC,CAAC,CAAA,IAGxE,EAAA,CAAA,CAAA,EAAA,GAGmC,IAAM,EAAA,QAAA,EAAA,K6GjI9C,E7GkIoE,uCAIlD,EAAA,MAAA,uBAsUrB,SAAS,AAAiB,CAA4D,EACpF,MAbmB,AAaZ,iBAbE,AAaF,GAbY,OAaZ,GAbY,cAaZ,GmBWmB,YnBrBxB,CiGmEG,MjGzDE,AAVG,EAAA,SAA8C,CAUxB,CmBWN,A/B+EC,A6G7BE,CjG7DU,wCAQhB,MAGX,UAAA,OACH,aAAa,IAAI,GAAA,AAC8C,YAD9C,OAAA,CAAA,CAAA,OAAA,aACwC,CAAC,AAAK,CAAU,CACjF,CAAA,4NAxvBmC,EAAA,IAAA,kDAQT,sFAkuB0C,CiE1FnB,CsBlTmB,AvF6YvE,CAAC,CAnUqC,EAAA,IAAA,YAIT,gBAAA,cACE,E4CrBE,yC5C0BQ,eAIb,CyDxPC,AuBdE,ahFuQL,CAAC,aAGF,CsF/MG,ANzDA,A7D0PJ,qCnBoBgC,CAAA,GAAA,EAAA,WAAA,CAAA,KAId,yGASlC,EAAA,MAAA,GAAA,GAAA,CAAA,IAAA,IAAA,CAAA,kBAAA,EAAA,EAAA,CAA4E,C2D0H/B,EAAA,Q3D1HiD,CAAC,CAAA,2BAG1F,WACO,MAAM,CyDhQC,A/DwTF,0BMpDC,CAAA,YACU,KAAK,CAAC,EAAE,CAAC,WACZ,CAAA,wBAAA,EAAA,MAAiC,EAAe,KAAK,CAAC,MAAP,EAAe,CAAA,IAAK,EAAE,CAAA,CAAE,CAAC,CAAA,QAEhF,KAAK,CAG5B,CyDlQC,AEqYA,E3DnIoC,MAAjC,EAAA,MAAA,CAAsB,CZ4FT,ACQM,KAAA,cWnGM,CAAA,6BAAA,EAAgC,EAAe,CiGiCvD,KjGjC6D,CAAC,MAAM,C4CRF,C5CQI,CAAC,CAAA,IAItF,EAAA,OACW,eACL,CsF9MW,KAAA,kDtFiNjB,EAAA,KAAA,SAA6B,CAAC,yBAK9B,EAAA,MAAA,GAAiC,IAAI,CAAC,IAAI,CuF/QH,APKa,GhF0QN,CAAA,kBAAA,EAAA,EAAA,CAAiC,CAAE,EAAQ,KmBJtD,AnBIqD,GAAS,CAAC,CAAE,gBAE/F,SmBL4B,CACpC,CAAA,KnBKiB,4BAjhBtB,CAmhBa,qBAIX,GAAA,EAAA,KAAA,CAAA,SACkB,CAAC,EAAiB,KAAK,CAAC,AiE/CtB,EjE+CwB,CAAC,EuFhRA,uCvFiRc,MAAM,EAAiB,KAAK,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAA,CAAE,CAAC,CAAA,MAElG,EAAiB,C6C9PiB,I7C8PZ,CAG9B,GAAA,AAAkC,MAAlC,EAAA,MAAA,CAAA,MAAkC,WACtB,GAAA,CAAA,sCAAA,EAAwD,EAAiB,MAAM,CAAC,MAAM,CAAd,AAAc,CAAE,CAAC,CAAA,MAG9F,oBAqBF,eAAe,GAAA,CAAA,EACpB,GAAA,UAAQ,CAAQ,CuFlSD,SAAA,CvFkSW,CX2GL,AW3GO,CAAG,EACzB,EAAA,IAAA,gBAA6B,CAAE,C6CzQD,KoDqSb,GjG5BwB,EAAS,QAAQ,EAAE,CAAE,CAAC,CAAA,EAEpD,MAAM,GAAQ,IAAI,CAAA,GAAA,CAAA,IAAA,IAAmC,CAAA,G6C3QY,CAAC,CAAC,KAAA,E7C2QD,EAAO,IAAD,IAAS,GAAA,CAAI,CAAE,GAAW,OAC1G,CmBH+B,qCnBM5B,C6C3QG,AU2GA,SvD/ZjB,6BAqkB8B,KAAK,CAAC,C6C3Q4D,C7C2Q1D,C6C3Q4D,A7C2Q3D,IAC3B,IAAA,GAAA,MAAA,EAAkC,KAAK,CAAA,QAAS,CAAC,GmBGD,CAAA,YnBDrC,CAAA,EAAU,C6G1JG,I7G0JE,CAAC,AsF9NJ,EtF8NM,CAAC,AZ2FF,yEYrF/B,GAAY,SAAK,QAAA,EAsBnB,eAAe,GAAA,CAAmC,KACjD,UAAE,CAAQ,CiEvDH,UjEuDK,CmBRD,CAAA,OAAA,CAAA,WnBQoB,CsFlPO,AlGoUV,CYlFc,CAAG,CsFlPO,CAAC,EtFmP1C,MAAA,GAAc,IAAI,CAAC,EZmFJ,EAAA,IYnFY,CAAA,cAAA,EAAiB,EZmFF,C6G5CC,C7G4CD,KAAA,CAAA,CAAA,GYnFiC,CiGuCH,QjGtC9E,CuFxTD,CDsEG,qDtFqPS,CAAC,QACX,EAAO,GAAG,CAAC,IAAY,CmBEG,8CnBAL,EAAM,CiEvDC,CAAC,CjEuDH,AiEvDG,KjEuDM,IAAK,cAErC,YA/mBjB,CAinBa,UAGE,KAAK,CAAA,SACA,CAAA,EsFzP+E,AtFyPrE,CsFxPrB,AuBiFwB,CvBjFxB,AuBiFwB,GAAA,Q7GwKrB,IAAA,GAAmB,MAAM,EAAS,KAAA,CAAM,QAAQ,CAAC,IAAI,EAAE,CAAC,CAAA,QAEjD,KAAA,eAEe,CAAC,OAAA,CAAQ,GAAG,CAAC,cAC9B,GAAA,MAAgB,EsF/OA,GAAA,atFgPd,CAAC,GAAU,CAAA,CAAA,EAAC,CyD3SU,EAAA,KAAA,AzD2SL,EAAC,SAAS,CAAC,GACjC,CsF/OA,EC1EG,SvF4TR,QACG,EuF1TA,ADyEE,CAAA,YkBmEyE,KxG+KhE,CmBwBC,A8E4DA,CAAA,GjGpFmB,GmBwBG,KnBxBK,EAAE,EA+C9C,eAAe,GAAuB,CAAsC,GiGyCtC,KjGxC1B,MAAM,GAAA,IAAA,CAAA,GAAgB,CAAoB,EAAO,KAAA,IAAU,CAAE,mBACnD,EACvB,GAAI,CsF5RG,CrBqMD,EjEuFS,CAAE,CAAC,GAGZ,cAF8B,GAAG,CyDpVgB,EAAE,AwC8XX,CjG1CH,EAAA,CAAE,CAAsB,AAE7D,WAAgB,CAClB,OAAO,uCAKN,EsF7RM,ctF8RiC,eAAe,GAArC,CZ8EC,CY9EG,CAAD,AiG6CjB,IAAA,CAAA,OjG7C+B,SAC9B,EyDnVQ,EwCgYF,oBjG3CH,sCAKE,CAAA,EAAU,CmBMD,C8C9EK,CsB/RD,EAAA,GvFuWK,CAAC,IAC3B,AZsG+B,CAAC,GYtGhC,GAAgC,MAAM,EAAS,KAAK,CAAN,AAAO,QAAQ,CAAC,IAAI,EAAE,CAAC,AAE7E,CAF6E,MAEvE,EAAS,G6GpMO,EAAA,Q7GsMjB,EAAA,MAAA,AACT,CAAC,eAkBqB,CiE7EH,CVzIK,CAAA,CAAA,KvDuNhB,CAAA,SAAA,CAAA,CAAA,UAAA,CAAA,SAAuB,CAAA,WAAS,CAAS,CAAE,CAAG,EmBsBX,EnBrBxB,GAD0C,AiE5E7C,CjE4E6C,EiE5E7C,GAAA,IAAA,CjE6EsB,MAAM,CAAA,IACpC,GAAG,CAAC,CAAA,cAAA,EAAiB,EmBqByC,EAAA,MAAA,EnBrBrB,EAAO,CAAE,CAAE,GACxD,AADoD,KAAY,CAAC,AAEzD,C6GvNC,oB7G2NE,GiEjFH,EAAA,CjEiFU,CAAC,CiEjFL,C9CoGK,A/BsEJ,CYxFX,GAAU,EAAE,CAAC,EAAS,KAAK,CAAC,AmBmBA,cnBlBH,MAAM,CmBsBhB,CnBtByB,EmBsBf,GnBtBoB,CAAC,QAAQ,CAAC,EmBsBf,EnBtBmB,EAAE,CAAC,CAAA,QAEnD,KAAK,CAAA,AmBwBC,OnBrBhB,EAAA,MAAe,AACxB,CAAC,EqEzME,iJLljByD,CDPmC,AEsD1C,A5BhDD,qP5CQsB,kJAGO,CAAC,AgERE,gFOG/C,CAAA,KAAA,CAAA,qIvEiBqB,+EAET,EAAA,mBAA+B,CAAC,CAAC,CAAC,CAAA,oCAE5D,CAAA,CAAA,EAAA,GAAA,SJuK2D,CIvK3D,AJwKhB,CAAA,CIxKgB,CAAA,EAAA,GAAA,aAAA,EAA0B,CwB8BH,CAAA,mBAAA,6FxBvBpB,0FAGuB,EAAA,wBAAoC,CAAC,CkBuDD,AlBvDE,CAAC,AkBuDF,CAAA,AlBvDE,mFAE3B,wBAAwB,CAAC,CAAC,CAAC,CAAA,KyDqCE,CAAA,WN+DU,CAAC,CAAA,uJnD7FxC,IAI5C,GAAA,KAAA,EAAA,mS+C/DH,OAAA,GAAA,iJAkC0B,2KhDNO,yBAGzC,UAAA,OAAA,EAAA,OAAA,EAGO,iBAAA,EAAA,QAAA,+MAoC4B,oBAGxB,mBAAA,UAAA,yBAG6B,WAA4B,CAAC,QAA7B,YAAA,qDAM/B,OAAA,CAAQ,EAAA,iBAAA,2CAImB,0JA0C0B,iGA4BhB,CoDmEkC,AiE/DjB,AjE+DkB,CAAA,AiE/DlB,CzH+DxB,AwDA0C,epDlE1C,8EAYW,6DAKtB,EAAA,EAAA,SAAA,mBACsB,CyE0BG,AzE1BF,yJAUvB,EAAA,SAAa,CDxDG,AwEVyB,AvEkEjB,CuElEkB,AvEkElB,GAIxC,2FAMT,aA+DH,SAAA,GAA6B,CAAA,4CAQI,+EAStB,UAA6B,SAA7B,cAAA,wBAKiB,QAAA,sCAEO,4GAoBlB,oBAAA,AAAqB,CwF7HG,KxF6HxB,qEAgBuB,EAAA,iCAEA,gCAItB,CAAC,2FAWG,kBAAA,kDmEtKsC,CAAA,QAChC,0IAsBV,CAAA,8DAMkE,uMAiCtF,CAAA,CACA,C5DxIuD,A4DwInC,C5DxIsD,C4DyIrC,CACrC,CAGC,CAAA,uFAO4E,MAAM,CAAC,CAAA,kDAGjB,CAAC,ExClFF,AwCkFmB,CvE/H3D,AEtBoD,A6BmEX,CwCkFyB,EAAS,CAAX,A5DrIE,CAAA,I4DqIQ,CAAQ,CAAC,CAAA,AAIvG,EAAA,IAAA,CAAA,wBAAA,CAAA,4HAaJ,EACA,EAAS,MAAM,CAChB,CAAA,mIASyC,eAAgB,EAAA,CAAiB,CAAE,CAAA,EAAA,EAAK,EAAA,CAAc,CAAC,CAAC,CAAA,AAElG,OAAA,GAAA,cT7K8F,CAC3F,CAAA,8DSgL6C,AAAC,GAAW,AAAX,MAAA,YAIpC,wBAAA,CAAA,CAAA,CAAA,CAAA,yIAUoC,MAAM,CAAA,EkBhJ9B,0BAAA,EAAA,ElBgJ4E,MAAM,CAAA,CAAA,CAAA,cAEzF,EAAA,EAAA,MAAA,CAAA,IACd,AADwC,CAAC,AxDvNnC,AGuHL,A6C1CI,EAAA,AQ2IQ,MR3IR,CAAA,CQ2IQ,EAAA,EAAc,CAAQ,CAAC,CAAC,AnE1KQ,CmE0KR,CAAA,MAAA,CAAA,GAAc,CAAC,CvC5LG,CAAC,KuC8LrB,CAAC,CAAA,gCAEP,EAAA,6BAAA,EAAiC,CvCvLS,CAAA,OuCuLI,CAAA,CAAE,kEAUxC,OAAO,GAAA,CAAY,CAAC,CAAA,sBAIA,CAAC,kBAqB7C,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,kCAKuC,EAAA,UAMlD,EAAA,MAAiB,IAAA,CAAA,aAAA,GAAA,aAAkC,CACvD,EHhO4D,CAAD,CGkO3D,AHlO4D,CAAA,CGmO5D,mCAK8C,CAAA,sGAOpB,kCAEC,IAAY,MAAA,CAAO,GAAA,AAAY,CjEzGM,A0B1FzD,KuCmMuC,sFAIkB,sDAWrC,CAAA,CAAA,gEAC6C,EAAA,CAAQ,CAAA,oEAOrD,2EAC0C,EAAA,CAAQ,CAAC,CAAA,GAG7D,QvElH2E,MuEkH3E,CAAU,mBACU,kEAEuB,CAAA,CAAA,EAAA,EAAa,UAAU,CAAA,GAAA,EAAM,EAAS,CAAE,CACnG,CAAA,IADiG,GAK7F,QsCvK8E,0CtCgLvC,CMnKT,ANmKuB,C3D9JtB,AiELD,ARtHG,AEyRoB,wDACM,EAAA,cAAA,EAA0B,EAAA,CAAQ,CAAE,EfhHE,6DeuH3F,QAAA,MAAA,0DACkD,EAAA,CAAQ,CAAC,CAAA,GAGhD,eAAA,eACW,IAAA,uDACuB,C4B1RC,C5B0RQ,MAAM,CAAA,CAAA,EAAI,EAAS,MAAD,IAAW,CAAA,CvE7FlF,EAAA,EuE6FwF,EAAS,CAAA,MAAA,sCAYjG,CAAA,CAAA,+FAMmB,uEAmBV,GAAA,0DAEkC,CAAC,CAAA,kBAG7B,CAAA,EAAG,IAAA,CAAA,WAAA,CAAgB,WAAA,EAAc,EAAA,QAAA,GAAyB,OAAA,CAAA,CAAW,uD4BvSlF,c5B8SG,C4B9SH,O5B+SI,MAAM,EAAA,IAAa,oEACwC,oFAKf,CAAA,CAAA,EAAI,EAAS,UAAU,CAAA,GAAA,EAAM,EAAS,CAAE,CAAC,CAAA,IAAH,KnE5OhD,sDA7BlB,6BAGF,C8E1EG,AxCjDR,AtC2HM,6EAStB,WAAX,OAAA,EAAW,SAAA,0BAK4C,8BAAA,4DAgBpD,iHmEuRoB,kDAzBO,+BAGtB,EADiC,CAAC,C4BhUC,E5BiUnC,eACW,EAAK,CHxRuB,AlE4HL,KqE4JZ,oBAAoB,2CAAA,sFAW3B,oFAuBS,sDAEY,GFpUK,CAAA,CAAA,KEwU7C,EAAA,GAAgC,IAAA,CAAA,WAAgB,CAAE,iBAE3B,CFvUD,kBE0UK,EAAA,GAQnC,MAAA,WAAA,CAAkC,CAAA,0BAEpB,CqB9VK,GAAA,CAAA,WrB8VW,kBACR,iBAIT,EAAE,+BAEQ,GAAA,EAAkB,G4BxVK,KAAA,E5ByVxC,MAAO,SACI,EAAA,OAAa,oGAMiB,2BAY7C,IAAM,EAAA,MAAA,IAAqB,CAAA,aAAc,GAAG,yBAAyB,CAAC,EAAiB,CAAC,MAAM,CAAC,GAAS,CAAC,CAAA,AAApB,EAAiB,CAAC,gCAGtF,CsClHQ,CAAA,SAAA,6BtCoHd,OAAA,aACE,EAAO,QAAA,CAAA,eAAwB,GAAG,I4BjWI,EAAA,C5BiWG,CAAC,O4BjWO,A5BiWA,EAAG,CAAC,EvEpCI,AuEoCK,CvEpCJ,A+B7EN,C/B6EM,IuEoCG,GAAU,CAAC,CAAQ,GAE7F,OAAA,4BAYD,CAAA,OAEmB,EAAA,SAAA,CAAA,UAAA,CAA0B,MAAA,EAAa,SAAS,CAAG,CAAA,EAAA,EAAK,EAAK,SAAS,CAAA,CAAA,KAStE,QAAA,CAAA,GAAA,CAAa,GAAU,EAAK,GAAG,CAAC,CAAA,AAC5C,EAAS,CF5WD,AakFI,CX0RE,QAAA,CAAA,GAAY,CAAC,GAAA,EAAe,KAAA,oBACf,eAAA,UAE/B,CAAC,oBAAsB,sBAAwB,OAAO,CAAC,CACvD,CAAC,EAAK,EAAD,GAAM,CAAE,EAAK,EAAD,aAAgB,CAAE,EAAM,EAAQ,AAAV,EAAoB,CAC5D,CAAA,AADgD,KAAW,kDAa5B,CAAA,UAAA,CAAY,IAAI,CAAC,CtEnBD,AsEmBE,AAAE,EAAK,SAAS,CAAC,AAAE,CAAA,EAAA,EAAK,EAAK,EAAD,OAAU,CAAA,CAAE,CAAA,iBAC3D,GAAA,EAAA,GAAkB,CAAA,GAAA,EAAgB,GAAA,2EAIjB,EAAE,6CAER,I3D1HoC,I2D0H5B,CAChD,CAAC,EAAI,E3D3HkF,A2D2HlF,GAAM,CAAE,EAAM,EAAQ,EAAU,CACtC,CAD0B,AAC1B,KADqC,+BAalB,CWlSQ,UXkSG,CAAA,SAAA,CAAA,yBAErB,cACC,CAAA,OAGa,eAAA,CACtB,IAAA,EAAkB,MAAA,EAAe,IAAI,EAAE,CAAC,KAAK,CAAA,IAAO,eAAe,CAAC,CAAA,ExC9IC,CAAC,CAAA,mCwC+IpB,MAAM,CAAA,CAAA,EAAA,EAAa,UAAU,CAAA,GAAA,EAAM,EAAS,CAAE,CAAC,CAAA,CAQrG,GARkG,YAQlG,yCAKE,GAAA,AAAS,MAAT,AAA8B,CAAC,GAAvB,AMlL4B,CNkL3B,WAAA,aACS,6EAEX,IAAI,CAAA,WAAY,CtEPC,AsEOD,oKkB/oBmC,CAAE,GAAa,CFnBrE,GLHmE,CKG/D,ElCEgE,CAAC,EoCiBA,EAAa,CAAE,IAAI,CAAC,EFlB/E,CAAC,MEkBuF,CAAC,CAAA,yNA4BxD,8CAWC,CAAA,MAAS,CnFkCA,GmFlCI,CAAA,SAAU,CAAC,MpBhDQ,mBoBgDiB,CAAC,SAAS,CAAC,CAAA,kGAU/E,SAAA,CAAA,mBAAA,CAAA,0DAYG,6CAE0B,ClDlBG,CgBlBG,AhBkBH,sBkDoB3C,IAAI,iCAG8C,8IAWQ,EAAM,GAAD,E3BXoB,CAAC,C2BWb,CAAC,AAAE,CAAD,KAAO,CAAC,GAAM,CAAE,CAAH,AACrG,CADsG,AACtG,oKAgCgD,CAAA,EAAA,EAAoB,0F9EkOvC,wCAIhB,CAAA,YAAA,EAAA,EAAA,yCAAA,CAAqE,CAAC,CAAA,CuFtKvC,OvFyKnD,kD8E/NgB,GAAA,cAAA,kBAAA,CAAA,0CAAA,EAGyC,aAAiB,KAAK,CAAC,AAAE,CAAD,CAAO,GAAD,IAAQ,CAAC,AAAE,CAAD,KAAO,CAAC,GAAM,CAAE,CAAH,AAClG,CADmG,IAC9F,CACN,CAAA,gHxDrI6D,CAAA,CMAA,CAAC,AROE,CQPF,GNCnB,CQX0B,CAAC,ORW3B,EQXoC,KRYvB,qBAAqB,CAAA,GAChD,GAAA,aAAgC,CxBFD,AqBpBA,AGsBC,yBAY5C,CAAE,iBAC3B,GAAA,CAAA,uKAgBC,CAAA,CAAA,CACoB,CAAA,qDAG0D,oBAAoB,CAAE,KAAK,CAAC,CAAA,+DActG,cAAA,EAAA,EAAA,CAAA,gBACyC,IAAA,CAAA,SAAc,CwB9BO,AKoCV,AgBHM,A7CHF,qBAGvC,UAAA,CAAA,EAAmB,CACtC,E/BiB4E,C+BjB9D,UAAU,CACxB,IAAI,CAAC,SAAA,uBAEsD,oBAAoB,gBAEpB,QAAA,GAAA,CAAY,gHAQnC,2EAIoC,kFAY7B,KAClB,EAAA,CAAA,CAAA,EAAwB,GiD3CS,iBAAA,CjD4CxD,EwDgCwE,CvEyCH,AuEzCI,CvEyCH,AuEzCG,CvEyCH,iBexEtE,CAAO,CAAC,CAAC,CAAC,CAAC,UAAU,CACtB,CAAC,CAAC,CAAC,CAAA,+EAmBuC,OAAA,CAAA,UAAA,GAAA,EAAA,EAA2C,SASpF,OAAA,EAA+B,EAAA,CAAA,uDACmB,UAAA,GAAc,+Y3B1FvC,EAAA,6FAQS,QAAA,CAAA,IAC9B,CAAC,gBAAgB,CACrB,E0E5BsE,CAAC,A1E4BzD,I+D9C0E,qB/D8CjD,CACvC,IAAI,CAAC,UAAS,CACf,CAAA,0HAwCoD,yBAK0B,CiDhEF,AjDgEI,EAAK,YAAA,yCAI5E,CuFlF8C,AMCN,E7FkF7C,IAAA,CAAA,EACA,CwD1DsF,UxD0D3E,EAChB,CACA,EACA,EACA,CAAE,IwE9DsF,CxE8DjF,CAAE,CAAe,CAAE,CAC3B,CAAA,WADyB,oGAmBe,EAAA,2IAsBlB,CAAA,oBAAA,wDAIoB,EAAO,CyDrDK,UzDqDM,EAAE,iDAKZ,wCAEF,EAAY,CuFzH+B,AMC9B,GAAA,C7FwHK,6EAEW,CAAC,AyE7EE,CAAC,CAAC,uBzEyF/E,qBAAA,CAAoC,CAAA,oCAEI,WACnB,EAAA,oBAAA,CAA8B,iCAGR,WAAW,EAAE,gDAKV,CAAA,OAAQ,CuEpCC,CvEoCQ,UAAU,qCACzC,CAAC,OAAA,EAAgB,UAAU,CAAC,CAAE,EAAS,CyBHC,GzBGG,CAAE,EACjF,CAAA,MAAA,EAAA,2DACsD,wEAWZ,C4EjIG,AlFiHJ,AqE1HA,8C/D2IO,CAAC,C6FtIH,gE7F+IJ,OACY,CAAA,cAM/C,GAAA,eACyB,qBAAA,CAAsB,CNrBA,OMqBQ,uBAKtC,CAAA,EAAA,YACO,CAAA,GAAA,OAAA,eACD,CAAA,YAAa,CAAC,GAAG,CAAC,CgH6GK,AhH7GJ,A6F/II,C7F+IJ,4BAOR,CAAA,EAAA,QAE3C,OAOM,gCAAA,CAAwD,CAAA,WACvC,CAAA,oBAAA,OACiC,uBAQ9C,EAAA,MAAA,EAAA,yBAAiD,CAAC,GAAa,EAAM,EAAF,IAAN,AAAc,EAAE,cAG7D,CAAC,MAAA,CAAA,EAAY,oBACH,CAAA,GAAA,CAAA,GAAA,OAAA,WACR,IAAA,CAAK,YAAA,CAAa,C6F7JO,c7FgKzB,CAAA,YAMpB,OADwB,CFlFG,A+F9EJ,OAAA,GAAA,C7FgKa,EAAA,EACL,EMxCA,EAAA,iCNmD/B,EAAA,IAAA,CAAA,oBAAA,mCACiC,E0B/EE,yC1BwFpB,CAAA,oBAAA,gDAQjB,kBAAA,gCACsC,iBAE5B,QADe,gBAAgB,CkDdC,8DlDuBJ,iBACpC,MAAc,EAAA,mBAA4B,wBAchD,CAAA,CAAA,CACwB,CAAA,EACe,CAAA,CAAE,CAAA,gCAEC,GAAA,OAAA,CAAW,SAGV,GAAsB,EAAa,I+DxMM,K/DwMR,GAAc,CAAC,CAAA,gDAmBnE,CyBzCW,EzB0CI,CAAA,CAAE,CAAA,C+DzNqB,+B/D2NpB,GAAA,OAAA,CAAA,MAGnB,EAAA,CAAoB,GAAsB,EAAa,I+D5NM,M/D+N7E,MAAA,EAAA,aAAA,CAAA,EAAA,EAGL,wBAUqC,CAAA,CAAA,CAAA,WAClB,CAAC,oBAAoB,C+DzOK,A8BCN,C9BDO,AMaa,ArE4NjB,AkDpCJ,CAAA,OlDoCY,CAAC,C6FxOD,S7FyO7C,MAAA,EAAA,aAAA,CAA6B,6DAUQ,aACZ,EMzDM,EAAE,CiGpCD,CjGoCG,gBAAA,CAAA,EAAA,4CNgEnB,GAAyB,CuG5FG,A5BAL,CAAA,O3E4FgB,CAAC,CqEnOK,aAAA,CrEmOW,EAAO,EqEnOM,qBrEmOiB,CAAC,CAAA,gEAKzE,CkDzCX,8ClDsDe,CAAE,CAAA,CAAA,uEAEU,+BAWvB,6FAcP,IAAA,CAAA,yBAA8B,CAAA,UAQzC,2BAA2B,CmDhQP,AnDgQ4B,CAAA,CuG5GrC,ApDpJsB,YnDiQvB,GAAA,IAAA,CAA4B,SAAS,iBACJ,CAAC,EAAQ,CKvBH,AuFxMJ,Q5FgO5B,QAAA,CAAS,EAAmB,CkD1DhB,EegHA,AjEtD8B,I6F1QE,M7F0QQ,CAAE,IAAI,CAAC,SAAS,CAAC,CAAA,iBAChE,CAAC,GAAA,yBAAuC,CAAC,AiEuDlB,CjEvDkB,AiEuDjB,MxC/HM,uBzB2EvB,CAAA,EAAc,aAGvB,UAAA,CAAA,UAAA,CAAsB,uEAUjC,CAAA,CACE,CAAA,uFAST,EAAA,kBAAA,CAAA,yBAAmD,CAAC,EAAE,AuGlGE,AvGkGA,CAAC,CAAC,CAAC,IuGlGM,QvG4GzE,yBAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,wBAGc,CuH3ZsC,CAAA,MAAA,CAAA,QvH4Z5C,CAAA,EAAA,CAAI,OAAA,QAKR,EAAA,EAAgB,EAAA,EAAiC,CAAG,CJ9FG,CI8FG,SJ9FW,WI8FS,CAClF,GLHsF,sBKItF,CAAO,CAAC,CAAC,CAAC,CAAC,UAAU,CACtB,CAAC,CAAC,CAAC,CAAA,EAEiB,CuF/RK,EAAA,EvF+R4B,KyB5DK,CAAC,CAAA,OzB4DQ,CAAE,GAEtE,EAAqB,C6FrSG,AtBuKI,AiD5KE,AzDaN,CQ+JK,EvE8HJ,CAAA,AuG1FyD,CAAC,CAAA,WvGwFU,CAAC,CAAA,OAE9C,CAAC,CAAW,CAAC,EAAE,C6FrSG,E7FqSY,E+D7RI,A/D+R9E,KAAA,yBAC0B,C6D7MW,CAAC,CAAA,gC7DkNzB,eAAA,GAAoB,EAAA,WAAkB,EAAE,UAG/C,EmDvRQ,EAAA,CAAA,GnDwRlB,KAAA,CAEF,QAGK,sDAQ0B,GAAA,IAAA,CAAa,EuEvFI,AgCwBF,SvG+DS,CAAA,uBACnC,QAAA,GAAW,CAAC,EAAA,oCAkBtB,qBAAA,CAAA,CAAA,kBAIa,IAAA,CAAA,aAAA,CAAA,UACP,MAAM,CAAC,CuEnGG,cvEqGlB,MACN,SAAA,EAAqB,QAAA,4BACgB,QACpB,QAAQ,8BAYoB,CAAA,CAAmB,CAA+B,C4FrQ5F,kB5FyQI,KAAA,cAA0B,0CAQlB,EAAA,eAA4B,SACzB,KAAK,sCAEY,UAChB,QAAQ,CAC7B,C+DxTG,AZUA,0UzDjMM,CAAA,QAAA,uIAwBE,gBAAA,CAAA,CAAA,CAAA,CAAA,SACkB,eAAA,0CAId,C+EjD4C,A5E3BE,C4E2BD,wCAAA,E/EiDO,GAAe,CwDyBF,CAAC,CAAX,YxDzB2B,CAAA,MAAA,CAAQ,CACxG,CAAA,4GAcG,GAAe,WAAD,IAChB,CAAA,QAAA,EAAW,IAAI,CAAC,KAAK,CAAC,GAAe,WAAD,IAAgB,CAAG,IAAI,CAAG,IAAI,CAAC,CAAA,KAAA,CAAO,CAC3E,CAAA,uBAUoC,CAAA,sKAOoB,EAAI,C+D5BJ,AnDZO,EAAA,yBZwCqC,CAAC,CAAA,iIAQhD,0CAGK,CAAA,IAAM,CAAC,EgC3EF,CAAC,IhC2EQ,CkFzGG,ArDyCF,A7BgEC,OAAO,EAAQ,KAAD,KAAW,EAAE,CAAC,CAAC,CAAA,iEAIjE,C8FpEE,CAAC,CAAA,CxFsFE,wCAAA,CNlByC,CAAC,CAAA,IiC9D/D,qBjCgEmB,EAAA,QAAiB,CAAC,GAAG,CAAA,IAAK,CAAC,CCmFH,SDnFa,kFAcjC,UAAU,wCACkB,C0CzID,C1CyIG,wEAIhD,IAAA,EAAA,UAAA,sCAEyC,EAAY,EAAe,MAAjB,KAAe,yDAI9D,C6GnCb,a7GsCQ,CkFjHkB,mClFqHN,eAEE,CAAC,GAAgB,EAAW,QAAQ,CAAC,EAAE,CAAC,CAAA,AgCzErE,GhC0EV,EAAA,MAAA,CAAqB,iBACE,OACJ,EAAA,qBAEc,IAAI,EAAA,WAAA,EAAqB,CAAC,MAAM,CAC/D,AAAC,GAAe,CAAC,EAAoB,QAAQ,CAAC,aAC7C,CAAC,sBAEkC,CAChC,EACA,EACA,EAAQ,QAAQ,EAAI,CAAA,CAAE,CACtB,EACA,EACA,EAAQ,KAAD,CADG,MADQ,OAES,CAC5B,CACF,CAAA,EACmB,IAAA,CAAA,GAChB,EAAA,MAAA,CAAA,EAAgC,MAAA,EAAU,wBAIrB,C+DpCI,O/DoCI,CMoBK,ENpBF,CAAC,iDAIiB,EAAA,EAAM,CmGpIC,AnGoIA,EAAE,CE3BG,EF2BoB,CAAA,YACjE,MAAA,CAAA,EAAA,EAAA,OACnB,gBACsC,mBAAmB,CACzD,EACA,CI7D4E,CAAA,AJ6DpE,CgCzE6D,OhCyErD,EAAI,CAAA,CAAE,CACtB,EACA,EACA,EACA,EAAQ,IAFE,CAEH,KAHW,IAEA,KACS,GAAI,EAC/B,EAAQ,CAD4B,IAC7B,GAAS,GAAI,EACpB,EAAQ,CADiB,EACd,EAAJ,CAAQ,KAAK,CACrB,CAAA,EACsB,CAAA,EAAY,CMgBW,ONhBH,CAAA,EAAA,EAC3C,EAAA,IAAA,CAAA,WACc,CAAC,gCAC4B,CAAA,QAAA,CAAU,uCAAuC,CAAC,MAQrF,GAAG,CAAA,MACN,GACL,MAAM,GAAe,WAAD,eAA2B,CAAC,EAAY,EAAS,EAAoB,GAAtB,CAAT,GAAsC,CAAC,CACpG,CACF,CAAA,KAF4F,YAWvD,CACtC,EAAA,CAAiC,CAAE,CAAA,SAGQ,CCuEH,gCDvEoC,EAAE,CAAA,MACvD,GAAkB,EAAA,WAAmB,GAAI,cAGxB,yBAAyB,CAAC,EAAS,EAAoB,EAAY,OAAO,CAAT,AAAU,CAAA,KAAtB,+BAEvC,CAAA,EAAA,EAAsB,E+DjCO,A/DiCa,CuE+GnB,6CvE1G7D,CAChB,CAAsC,CACtC,CqEpK8D,CrEoK7B,CAAA,CAAE,CqEpKiD,ArEoKjD,yCAIkB,C0CpMC,O1CoMO,C0CpMC,A1CoMA,CAAA,QAC9C,iEAKQ,IAAS,CAA7B,EAAA,SAAoB,mCACiB,CiFnBL,YjFoBM,qCACP,uBAK5B,IAAA,GAAA,EAEL,EAAA,EACW,QAAQ,CACM,CAAC,CAAC,CAAC,CAAC,CAA7B,EAAW,IqE5KuE,IrE4KxE,CAAU,MAAU,EAAY,EAAW,KAAd,CAAC,CAAC,CAAW,CAAU,CAC9D,EACA,EAAW,GADJ,KACG,OAAgB,CAC3B,CAAA,wCAQe,CAAA,CAAA,CAEhB,CAA6B,CAAA,CACC,CAAA,KMoC4D,CAAC,CAAA,QNlCvD,CyDpLC,AnD0NlC,CuE5FqC,ARnIA,OrEyLK,EAAE,CAAC,UAAU,EqEzLI,ArEyLF,CAAA,GAGvC,iBAAA,EAAY,AAA0B,CAAA,MAA1B,kBAA0B,mCACX,CAC5C,EAAQ,SAAS,CACjB,EACA,EAAA,EAEA,OAAO,CACR,CAAA,KAI+C,QAAQ,CAAE,EmGlMG,GjGyJA,AiGzJA,InGkMY,CwDGH,AxDHI,CwDGH,AxDHG,C2EtLI,AnByLP,MxDAnD,MAAU,YAAV,6BAC2B,CAAA,EAE7C,E2EzLqE,A3EyL7D,KAAD,KAAW,CAClB,EACA,EACA,EACA,EAAQ,KAAD,CADG,GAFO,GACC,MAEQ,CAC3B,CAAA,8BAKY,GAAA,wBAAuC,CAAA,EAC1C,C2EjMwD,AOAQ,C5EiOX,aNhCtC,CACvB,EACA,EACA,EACA,EACA,EAAQ,EAHE,GAGH,EAFM,MACI,KACS,CAC3B,CAAA,+BAMD,EACA,EACA,EC2B0B,CAAF,CAAC,AAAC,CAAA,iBD1BA,CC2BzB,CD3B6B,EAAE,CAChC,EAAQ,KAAD,aAAmB,GAAI,EAC9B,EAAQ,CAD2B,IAC5B,GAAS,GAAI,EACpB,EAAQ,CADiB,EACd,EAAJ,CAAQ,KAAK,CACrB,CAAA,kCAUD,CAAqB,CAAA,CACS,CAAA,QAGb,MAAA,EAAA,4BAAA,CAAsD,EAAA,EAC9C,IAAA,CAAA,GAAa,EAAG,oBAAoB,GAAK,MAEnD,SAAQ,CAAA,EAAA,MAAe,CiFtFU,A4BCX,CAAC,A5BDW,CAAA,EjFsFE,C+BpDW,CAAC,CAAA,M/BoDH,EAAE,yBAG1D,qBACA,CAAA,SAAA,EAAA,EAAA,yBAAA,EAAiD,EAAa,WAAA,yCAAA,CAAI,GAChE,oBAKuD,CYrCG,sBZqCP,AYrCO,GZqCG,CAAC,GkGtMtC,+BlGuMmB,CAAC,EAAS,EAAS,GAAX,ACOY,EDPH,KAAY,CAAC,CAAA,gBAIlC,CAAA,EAAA,UAAmB,sBAG5D,iBAAA,qBAAA,CAAA,YAAA,EAAA,EAAA,UAAA,CAAA,cAAA,EAEkD,EAAS,OAAA,eAAA,CAAwB,CACpF,CAAA,kCAIwD,CY5CG,AD6BF,AqBUA,MAAA,EhCKQ,yBAGhE,qBACA,CAAA,G+B/D0C,MAAA,E/B+D9B,EAAS,SAAA,EAAY,EAAQ,KAAD,EAAC,CAAU,UAAY,UAAU,CAAA,AAAI,EAAJ,cAAI,EAAA,EAAA,OAC3C,CCDE,ADCD,UAAc,UAAU,CAAA,CAAE,AADgB,CAE9E,CAAA,cAI8C,kBAAkB,CAAC,+GAgBvC,C4FzQwC,yC5F6QhC,UAAA,EAAY,yBAG3C,6BACA,CAAA,SAAA,EAAY,EAAQ,KAAD,eAAqB,CAAA,wBAAA,EAA2B,EAAQ,KAAD,KAAW,CAAA,AAAI,EAAJ,gBAAI,EAAA,EAAA,UAAA,CAAA,cAAA,CAAA,4CASrD,I6ErHM,O7EqHK,CAAC,CuEoDC,CAAC,AvEpDM,CMFH,AiEsDH,AMzKG,CvEmHC,QNEY,CoEpOD,ApEoOE,eAGtD,eAAA,CAAA,WAA2B,C+B1EmC,ACuDlC,IhCmBM,EmElNX,enEkNkC,CAAA,WAAY,EAAE,EACtF,CAAC,qDAIC,CAAA,SAAA,EAAY,EAAQ,oBAAoB,CAAA,qBAAA,EAAwB,GAAgB,WAAF,IAAiB,EAAI,SAAS,CAAA,AAAI,EAAJ,aAAI,EAAA,EAAA,eACvE,CAAA,cAAA,CADuE,wCAatH,CAAA,CACA,CAAsC,CACtC,CAA6B,CAC7B,CAA4B,CAAA,wBAGe,GAAG,CAAC,C4FrSG,AiB0LJ,E7G4GjC,WAAA,CAAA,2BACkC,EAAmB,4BAA4B,CAAA,yBAI1E,CCPG,AoEpRA,gBAAA,sBAAA,CrE2RsC,EmGnSG,UAAA,EAAA,EnGmSsB,sBAAA,CAAwB,CAAC,iBAKtG,qCAGO,2BASd,CqElSsB,CrEmStB,MAAA,CAAA,AAAQ,eACS,GAAA,EAAA,EAAgB,GAAI,CAAA,EAAI,C6G9FG,CAAA,I7G8FG,CEvGA,EFuGI,CAAA,EAAI,SAAS,EuEmCI,A3D9Fa,GZ2DS,CAAC,AAAvB,EAAE,AAAC,UY3DU,CAAA,EZ+D1E,GAAA,EAAA,QAAA,CAAA,OAGL,EAAA,MAAuB,CAAA,EAAA,aAEW,CAAC,CAAA,EAAA,MAC7B,iBAAA,CAAA,GAAyB,AAAwB,CuHrN9C,AvHqNuB,A6E/GlB,A7E+G0C,EAAE,GAAzB,iBAAiB,CAAQ,uBAChC,CAAC,AMRA,EAAA,ANQ4B,C6FrSgB,A7FqSf,C6FrSgB,EvF6R7C,ENQM,iBAAiB,C6FrSsB,mD7F0SlD,MAAA,EAAyB,C6FrSc,iB7FqSI,CAAC,CAAM,CAAC,CAAC,CAAC,CAAC,oBAAoB,CC0BhE,AD1BiE,CAAA,AC0BhE,8BDtBf,EAAA,CAAA,oBAAuB,8DAShC,oCASP,CwD9EP,YxD8EoB,yBACnB,CAAuB,CACvB,CAAsC,CACtC,CEzEiB,CF0EjB,CAAqB,CACrB,CE3EiB,AF2EwB,CACzC,CAA4B,CAAA,CE5EG,A2GAyD,K3GCrE,OF8EI,EAAA,oBAAA,CAAA,YACD,CAAC,sDAInB,CAAA,SAAA,EAAY,EAAe,aAAA,SAAA,CAAwB,CACpD,CAAA,OAII,MAAA,GAAA,mBAAwC,CAAA,EAE7C,EAAS,EAAE,CACX,EACA,EACA,EACA,QADU,GAFO,GACC,IAEA,CACnB,CAAA,iBAQoB,CAAA,CACoB,CACzC,CAAsC,CACtC,CAA6B,CkGhSU,AlGiSvC,CAA4B,CAC5B,CAA2B,CAC3B,CAAiB,CACjB,CAAY,CAAA,aAOW,EAAA,4BAA+C,CAAC,8BAMnE,EAAE,AAAC,MAAM,EAAA,EAAA,SAAA,EAAA,IAAA,EAAA,WAAA,EAAA,GAGO,EAAG,QAAA,CAAA,IAAA,CAClB,EAAgB,GAAA,CAAA,EAAA,UAAiB,CAAC,CACtC,CAAA,AwD5GgC,kBxD8GsB,CAAC,A4FrWJ,AvBUI,CEuXC,AqBjYJ,K5FuWpC,EAAgB,IAAA,CAAA,CAAA,EAAA,uBACN,CAAG,GAA6B,CAAC,AqE5VI,ErE4VF,CAA3B,EAAA,iBAAmB,CAAe,GAC7D,EAAA,iBAAA,CAAA,GAAmD,CqE3VK,ArE2VJ,GAAzB,EAAA,iBAAmB,CAAM,EACjD,EAAA,oBAAA,CAAA,EAAA,oBAAA,iBAIO,uBAGR,EAAA,GAAmB,CAAC,EAAA,UAAkB,CAAC,UAG3C,EAAgB,CwD3GG,EAAA,CxD2GC,EAAQ,CkF3P0B,CAAC,AXmS3B,QvExCA,cACL,CyHnOO,CAAA,WzHmOe,CAAC,EAAQ,I+BtGM,CAAC,CwC8IG,AxC9IH,I/BsGG,CAAC,CAAA,YAG/D,QAAQ,IAAA,CAAA,CAAA,YAAA,EAAA,EACiB,GmGvWoB,OAAA,CAAA,cAAA,EnGuWO,EAAQ,KAAD,eAAqB,CAAA,gB+BtGhC,UAAA,C/BsG4D,CAC3G,CAAA,eAIa,EAAS,QAAA,CAAS,GAAG,EAAE,E6G5DQ,CAAA,C7G4DJ,CAAA,C+B1GK,CACjD,CAAA,S/ByG0D,EACvD,CY7FW,IZ4FmD,CAAC,QwDpGY,GxDwG9C,QAAQ,CAAC,CkF/PS,ElF+PN,EAAE,cAAc,kBAC7B,EC8B3B,YAAA,kBDpBL,CCgCG,GDhCG,EAAmB,GCgCK,GDhCC,GAAe,CkG/SG,qBlG+SmB,CAAC,KAIrE,EAAA,EAAA,IAAmC,CAAC,AAAC,GAJiD,AAI1C,EAAE,AAAC,AAJyC,CAAC,CAAA,QAIhC,GAAK,EAAiB,EAAE,CAAC,CAAA,SAErD,sDAE6B,eAAe,CAAA,MAAA,EAAS,EAAiB,EAAE,CAAA,sEAAA,CAAI,aAM/E,C6ElJI,AsBlOG,CDgEC,IlGoTF,EAAmB,IkGpTU,clGoTQ,CAAA,EAAiB,oBAAoB,CAAC,CAAA,AAEzG,CyDnWuB,KzDmWhB,CACL,EARwE,CACzE,CAAA,KAOW,cACiB,oBAAoB,aACnC,kBACZ,CyDnWyB,SzDsWtB,EAAQ,CAAC,AkGnTA,+GlG2Td,EAAc,MAAA,EAAyB,K6GzDhC,CjG7BwC,gBZsFc,EAAE,CAAA,AmGxXC,EnGyXtE,CAAA,MAAA,EAA2C,YAAA,CAAA,EAAA,EACJ,C6EzIY,CAAC,CRlOR,GAAA,CAAA,ArE4WzC,GACC,CAAC,CAAC,GAAY,C6GvDyD,AxCtTP,CwCsTO,A7GuDhD,EqE7WqD,KAAY,CrE6WzD,CAAC,GAAG,EAAE,IAAI,CAAC,QAAQ,GAAK,EAAA,CAAI,CAAC,CAAA,CAAA,GAAA,EAAA,QACnC,CAAA,GAAI,EAAA,cAAgB,KqE7WO,WAAA,UAAA,CrE6WqB,CAAC,AqE7WE,CrE6WF,CACzE,EAAA,QAA2B,CAAC,EAAA,EAAA,MAGV,GAAQ,SAAR,2BACe,sBAAuB,EmG5XE,2BnGgYzB,OmG9XK,CpEuSH,Y/BuFkB,CAAC,GmG9XC,anGmY1D,YAAY,kCAYK,qBAAqB,CAAA,CAAA,IACf,CAAC,qBACN,iBAAA,uBAA0C,mDAK1C,CoHjPG,ApHiPF,ACiCF,AWlHQ,aZmFR,MAAA,CAAS,GAAA,CAExB,C6E1IG,G7E0IG,EAAW,CqE/XgB,AzD4ST,CZmFG,MAAA,CAAO,GAAU,CmG3YG,CAAN,AnG2Ya,MAAM,CAAC,CAAE,CAAC,CAAC,CAAC,EAAE,OAC9D,UAIH,MAAM,GAAe,sBAAsB,CAAA,kBAU/B,uBAAA,CAAA,CAAA,KACf,EAAA,YAGO,IAAA,KAAkB,E6GlDnB,A7GkD8B,CAAC,MmGtZI,EnG0ZzC,GAAI,CAAA,EAAU,QAAQ,CAAC,GAAG,EAAE,IAAI,CAAC,oBAIjC,IAAA,EAAA,IAA8B,GAAU,IAAI,CAAE,EAAS,MAAD,EAAS,CAAC,GAAG,CAAC,G6GhDK,C7GgDD,CAAA,UAAW,CAAC,A6GhDC,C7GgDD,AAEpF,OADA,MAAA,EAAwB,IAAI,GACrB,QACA,C6G9CD,CAAA,2C7GgDgC,CAAA,kBAAA,CAAoB,CACxD,KAAK,QAAY,KAAK,CAAC,AAAE,CAAD,CAAO,GAAD,IAAQ,CAAC,AAAE,CAAD,KAAO,CAAC,KAAK,CAAC,CACvD,CAAA,GAMoB,CAAC,EACxB,EmG7ZI,IAAA,GnG6Zc,iBAAkB,wBAAwB,CAAE,uCAAuC,CAAC,CAAA,mDAMtG,CAAA,IAAA,EAAA,EAAoB,uEAAA,CAAyE,CAC9F,CAAA,aAWU,sBACX,CmG5agC,AnG4aM,CACtC,CAAgC,CAChC,CAAY,CACZ,CAAgB,CAAA,CAGhB,GAAe,eAAA,CAAgB,EAAM,EAAF,eAAmB,CAAC,CAAA,MAGhC,E6GpCE,I7GoCI,EAAmB,KoHzSiB,CPqQX,CAAC,iB7GoCiB,CAAA,EAAO,C6GpCC,CAAA,A7GoCQ,KAAF,IAG/E,MAHgG,CAAC,CAAA,OAIvF,E6GtCE,U7GuCU,KAAK,CAAA,QAAS,G6EtKK,O7EuKrB,KAAA,CAAA,MAAA,UACb,EmGrbE,KnGqbkB,CAAC,QAAA,iBAEjB,EmE1RM,C0CqPD,W7GsCQ,UAAU,CqElagB,QrEma5C,EAAe,OAAO,EAEjC,iBAAA,KACA,kBAAA,MASJ,MAAM,gBAAgB,C+BhFD,CAAA,Q/BkFK,MAAA,GAAqB,EkGjXI,mBlGiXiB,CAChE,IAAI,CAAC,mBAAmB,CACxB,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACtB,EACA,EADI,EACA,CAAC,QAAQ,CACd,CAAA,qEAqBK,EAAW,GAAS,kCACM,CAAC,UACb,CAClB,GAAe,eAAA,CAAA,EAAsB,C6ErKG,c7E0KpC,EAAW,OAAA,6BACE,CAAC,EmEjTI,ApC4OF,CAAA,C/BqEE,6BAMR,IAAI,CAAC,I+BtEQ,CAAC,CAAC,mC/BuEZ,EYzFM,IAAA,IAAA,CAAA,UZyFe,CAAC,WAAW,CAAA,EAAO,C6GpCK,A7GqC1D,C6GrC2D,AVhbpD,AhCmKE,C0C6QmD,C7GqCzD,CAAO,E+BpEE,Q/BqEZ,EmEjTU,CgCpKD,anGudC,IAAA,CAAK,yFAGf,sCACA,S+BlEuG,CAAA,yB/BkEpE,CACpC,CAAA,SAQD,kBANY,C6GlCG,AQ3TI,GAAA,CrH6VF,iDACL,OAAO,CACjB,CqH9VyB,CAAA,8BrH+VzB,sCACA,MiFjSgG,+BjFmS5F,CY9FK,AiG8DA,E7GgCO,iBAAA,cAAiC,4CAA4C,CAAE,KAAK,CAAC,CAAA,QAI7F,C+BlEC,G/BkEG,CAAA,iCACV,IAAA,CAAK,C6E7KK,S7E6KK,CAAC,C6E7KK,QAAA,C7E6KK,CmG9dC,CnG8dY,QAAQ,CAAC,CAAA,A+BlED,CAAA,KoE5ZQ,UnG+d7C,CAAA,qCACJ,OAAO,CAAA,oBAAsB,0BAA2B,W6GjCa,c7GoCjF,IAAA,CAAA,cAAmB,CAAC,G6E/KO,G7E+KD,CAAC,C6E/KK,E7EkL5B,GAAS,GY7FK,GiEpFG,Y7EiLY,IAAI,C6EjLG,C7EiLD,AACrC,EAAQ,gBAAgB,CAAC,EAAa,EY7F2B,CACtE,CAAA,IZ4FmD,CAAC,CAAA,AAAV,AAMnC,GAAS,UAAY,SACD,EAAQ,CmGteK,OnGseG,C6EpLb,A7EoLc,CAGzC,IAAM,EAAe,IYrFH,EZqFS,IAAI,OAAO,CAAS,CAAC,EAAS,KAAF,AAErD,CAF6D,EAAE,CAE3D,CAAA,AAF6D,cAE9C,CAAC,CYrFC,AuFnZM,GnGweH,CAAC,CACvB,C6G/B6B,Q7G+B7B,EAAA,QAA+B,CAC/B,CmGxeO,EU6cE,E1C7RM,AkDtCA,KrH+Vf,qBAEA,SAAA,GAAA,SAA8B,GAAgB,EAAQ,KAAD,GAAS,CAAC,CAAC,CAAC,IAAC,IAKpE,KAL6E,MAK7E,KACO,E6EjKQ,E7EiKJ,CAAA,qBAAsB,EAAE,CAAC,KAAK,CAAC,AAAC,KAAK,EAAE,EAAE,GACxC,KAAK,CAAC,0CAA2C,IAE7D,CAFkE,CAAC,AAEnE,CAFmE,CAGrE,CAAC,0BAGgB,yCACE,CAAA,iBAAA,uBAA2C,0CAE7B,CAC/B,KAAM,EAAa,IAAA,wBAIjB,CAAC,cAAc,CAAA,MAAA,CAAQ,GAE/B,CmG5eC,AnG4eA,MAMa,uBAAA,CACZ,GAAI,IAAA,CAAA,aAAA,EAAqD,CAAC,EAAE,CAAC,AAAnC,C6GfH,G7GeO,CAAC,cAAc,CAAC,MAAM,8BAQpD,IAAM,EAAmB,IAAI,C+BvBH,G/BuBO,IAAI,CAAC,MmG3eU,QnG2eI,CAAC,CAAA,GAEjD,EAAA,CmG7e4D,GnG6evC,CAAG,CAAC,EAAI,IAAI,CAAA,cAAe,CAAC,MAAM,CAAG,IAAI,CAAC,O+BxBG,S/BwBa,CAAE,CAAC,IAC9E,E+BxBG,GAAA,EAAA,G/BwBiB,UAGF,IAAI,CAAG,CAAC,EAAI,KAAK,GAAG,EAAE,CAAG,E6GpBzB,I7GoByC,CAAC,EAAR,C6GpBlC,oB7GoBiE,EAAE,CAAC,IAErF,GyH1TkC,CzH0T5B,KAAY,EAChB,AAAD,IAAK,CAAC,ImGreU,KnGoeiB,CAAE,CAAC,GAChB,CAAC,GAAG,CAAC,IAC3B,EAAiB,CmGreS,CnGoeS,CAAC,EAAE,CAAC,AAChB,CAAA,E6EtKG,CAAA,EAAA,I7E0KL,CAAG,GAAG,AAC7B,CAD8B,KAC9B,IAAU,QAAQ,AAAC,GAAY,WAAW,EAXzB,CyHvTK,IzHkU2B,EAAE,UAInC,EAJ+C,CAI5C,AAJ6C,CAAC,CAAA,CAIzC,CAC5B,C6GX8B,AV7dE,AnGwehC,C6GX8B,Q7GWjB,EqHvVmC,IrHwVtC,KAAA,CAAA,CAAA,OAAA,EAAA,EAAsB,OAAA,EAAA,EAA2B,IAAI,CAAA,6BAAA,CAA+B,CAAC,CAAA,IAK3F,EAAQ,IAAA,CAAK,cAAc,CAAC,MAAM,CAAC,CAAC,CAAE,IAAI,CAAC,gBAAgB,CAAC,CAAA,YAG5B,GAAG,CAAC,AAAC,CmG1eT,EnG0ekB,EAAA,QAAa,CAAC,CAChE,AADgE,EACvB,EAAA,CmG3emB,EnG2enB,CAAA,AAAW,GAAS,CAAL,C+BdR,E/BciB,A+BdjB,M/Bc0B,EAAI,EAAE,CAAC,CAAA,AAC3E,EAA8B,EAAA,IAEhC,C6GFK,G7GED,CAAC,SAAS,CAAE,CAAC,AACnB,GAAM,CAAC,CmG3eK,AnG2eH,C6GWK,C7GXO,CAAG,E6GWM,I7GXA,QAAQ,C6GWK,CAAC,CAAA,CAAA,C7GV1C,E+BNQ,E/BMJ,CAAA,mBAAoB,CAAC,eAAA,CAAA,IAAoB,CAAC,SAAS,CAAC,KACpD,CAAC,EmG3eM,iBAAA,CnG2ec,UAAU,CAAC,E+BNQ,CAAoB,CAAA,CAAA,S/BMd,CAAC,CACpD,EAEK,EAAkB,CmG9euC,KnG8ejC,GiFjUO,CjFiUH,CAAA,UAAW,CAAC,SAAA,CAC5C,IAAI,CAAC,SAAS,CACd,EAAY,eAAe,CAC3B,EACA,KAII,EALK,KAKE,CAJE,AAID,AAAC,CAHd,A+BJqB,C/BIrB,8BAIgC,EAAgB,MAAa,CAAC,CAAA,MAEzD,E6GIE,A7GJkB,MAAM,CmGnfG,CnGmfD,CAAwB,GmGnfK,MnGsfzC,CAAC,GAAA,EAAA,iBAAuC,EAAI,EAAE,CAAC,CAAC,CAAA,SAExD,MACP,SAAA,EAAW,mBAAmB,IAEvC,CAAC,IAAA,KACO,EmGrfM,AnGqfE,CAHwC,CAAC,C6GKtC,A7GFN,AAH4C,GAGnC,G6GEG,CAAA,C7GFE,QAAQ,CAAC,SAAS,EAAE,CAAC,UAAU,EAAE,CAAA,AAEpD,EAAkB,C6GCC,G7GDG,CAAC,gBAAA,EAAoB,CAAA,CAAE,CAAA,AAC7C,EyHjUU,AzHkUd,KAAI,CAAC,QAAQ,EAAM,EAAF,CAAC,AAAe,EmGvfW,MnGufX,IAAY,EACS,EAAlD,CAAE,C+BFK,E/BEF,CAAe,CAAE,CAAC,C+BFK,E/BES,CADmB,CAAC,MACZ,CAAC,CAAA,EAAI,IAIlC,C6GFG,E7GEa,GmGxflC,EnG0f6B,E6GHE,EADc,CAAC,C7GIX,AAFU,CmGxfP,GnG0fC,CAAC,E6GHE,AVvfE,QnG0fM,CAAC,kBAAkB,CACvE,KACA,IAAI,CAAC,SAAS,CAAC,KAAK,CACpB,EACA,IAAI,CAAC,QAAQ,CAAC,qBAAqB,EAAE,CACrC,EACA,OADS,WAGC,C6GTG,G7GYf,E+BDQ,A/BCF,OAAO,CAAC,AAAC,IAAI,AACjB,EADmB,AACnB,EADqB,OACP,EAAA,eAAiB,EAAyB,MAAa,CAAC,AACxE,CADwE,AACvE,CAAC,CAAA,GyHtU+E,CzHuU3E,EAAA,MAAyB,EAAE,CAAC,AAA6B,E6GcvB,A7GdsB,C6GcrB,A7GbzC,C6GayC,G7GbzC,CAAK,UAAA,CAAa,EAAiB,GADoD,CAAC,CAAA,AmGhgB7D,InGigBQ,CAEnC,EmGlgBI,EnGkgBE,EAAkB,E+BIM,IAAA,G/BJ0B,CmGlgBG,UnGmgB9C,IAAA,IAAA,CAAA,eAAA,EACS,EAAiB,CmGngBsB,QnGmgBb,CAAA,cAAA,EAAiB,EAAiB,cAAD,GAAkB,CAAA,CAAE,CACjG,IAAI,CAAC,UAAU,CAAC,aAAa,EAAE,CAChC,CAAC,QAAQ,EAAE,GAGd,EAAA,IAAsB,IAAK,EAAgB,E6GYI,CAAC,CAAA,a7GZY,EAAI,EAAE,CAAC,CAAC,AAEpE,CAFoE,CAEpE,OAAA,CAAc,AAAC,IACb,EAAK,CmGvgBI,CnGugBL,OAAC,EAAW,gBAAgB,EAAE,CAAC,EACrC,CAAC,CAAC,CAAA,SAIS,CAAC,CAAC,E6GeE,A7GfI,KAAK,EAAE,CyH7UO,CzH6UL,AACtB,EAAU,CAAiB,CAAC,C6GejB,C9ENC,A/BTqB,CAA1B,EAA0B,CACxB,MAAM,CAAC,4FACkF,EAAK,CAAE,CAAC,CAEhH,AAF6G,AAAG,EAE3G,G6GqBK,IAAA,C7GrBG,EmGzgBI,GnG2gBnB,MAAO,EAAA,UAEwB,iBAAkB,WAAW,CAAE,iCAAiC,CAAE,GACjG,EADsG,AACtG,CADuG,CAAA,KAC1F,CAAE,AAAF,CmGzgBK,KnG0gBX,MAAM,CAAA,EACb,CAAC,CAAC,QACM,CAAC,AACT,IAAI,CAAC,EmGzgBS,ChC0MJ,OpCyVY,G/B1BJ,EAAG,GyH/UU,IzHgVtB,cAAc,CAAA,MAAO,CAAG,GAC1B,IAAI,CAAA,qBAAsB,EAAE,AmGxgBE,CnGwgBD,KAAA,CAAA,iBACnB,CAAC,0CAAA,EAChB,CAAC,CAAC,CAGR,CAAC,AAQD,CmG/gBC,KnG+gBK,CiFnXmD,QAAA,CjFmXf,CAAE,CAAyB,CAAA,CAGnE,IAAM,EAAa,IAAI,C6GwBiB,A7GxBhB,E6G0BK,EAAE,EAAE,E7G1BD,CAAC,OAAO,EAAE,IyHhWgB,IzHgWR,EAAI,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAA,OACrE,MAAM,C6G0BH,C7G1Bc,G6G0BD,C7G1BK,CAAC,IAAI,CAAC,C6G0BH,O7G1BW,CAAC,OAAO,EAAI,IAAI,CAAC,QAAQ,CAAE,EAAU,CAC7E,EmGjhBI,GnGghBuE,WAC1D,IAAI,CAAC,SAAS,CAAC,eAAe,SACrC,G6G0BA,A7G1BiB,E6G0BT,OAAA,I7G1BwB,CAAA,QAAS,EAEvD,CAAC,CmE9TG,AsDvBA,ItB9LkD,CnGyhBhD,iBAAiB,CAA2B,CAAE,CAAyB,CAAA,kFAEpE,MAAM,IAAI,CAAC,QAAA,CAAS,EAAU,GAOvC,MAAM,iBAAA,CACJ,OAAO,GmG3hBC,GnG2hBK,IAAA,CAAK,QAAQ,CAAC,EmG3hBA,aAAA,CnG2hBgB,GmG3hBC,CnG2hBG,CAAA,eAAgB,CAAC,CAQlE,AARkE,MAQ5D,CmErV+C,iBnEqV/B,IACE,IAAI,EAAE,CmGliBI,AnGkiBH,GAArB,CAAA,SAAU,CAChB,EyH9WuD,IzH8WhD,EAAE,CAAA,AAGX,CmGpiBe,GnGoiBT,EAAqB,EAAE,CAAA,CAAjB,SACD,GAAM,EmGliBD,QnGkiBG,CAAQ,CAAE,GAAI,IAAI,CAAC,SAAS,EAAE,CAAE,CAAC,CAC3C,IAAI,CAAC,EyHzWQ,CzH2WtB,OAAO,EAWT,CmG7iBU,MnG6iBH,UAAU,CAGhB,CAAA,IACwB,EmG9iBA,InG8iBnB,AAAyB,CAAC,GAAtB,AyHhXyB,CzHgXxB,CmG9iBD,CsB8LG,QAAA,QzHmXX,IAAM,EyHhXA,AzHgXqB,EmG9iBA,EnG8iBI,CAAC,QmG9iBM,WnG8iBa,CAAC,KmG9iBG,gBnG8iBkB,EAAE,CAAA,AAC3E,EAAoB,CyHhXD,GzHgXK,GAAA,IAAA,CAAiB,QAAQ,CAAC,EmE9UM,EkDrCE,GlB3LH,InG8iBM,EAAE,CAAE,GAE3D,EAAY,GAAS,CmG/iBP,QAAc,AnG+iBE,CAF+C,CAE3C,AAF4C,CAAA,EAEzC,CAAA,AACrC,EAAS,CmGhjB8B,EnGgjB9B,WAEf,GAAc,EAEd,EAFkB,CAAA,EAEX,GAAO,CACZ,GAAI,AADQ,GACA,GAAF,IAAS,CACjB,CADmB,CAAC,IACd,GAAY,iBmGjjB4B,AnGijBV,WAAW,CAAE,mBAAmB,CAAC,CAAA,IAGjE,EAAS,MAAM,EAAY,eAAe,CAAC,IAAI,CAAC,UAAU,CAAE,QAAE,EAAQ,IAAF,CAAO,CAAE,SAAS,AAAE,CAAM,CAAE,CAAC,CAAA,EAAH,EAG/F,IAAI,EAAA,EAAA,EAAA,EAAkB,GyHvWO,GzHuWD,CAAC,MAAM,CyHvWK,IzHuWE,CAAC,AAC9C,GAAI,GAAQ,CmGnjBA,AsB2M6C,CAC1C,KzHuWI,CACjB,CADmB,CAAC,GyHvWS,CAAC,AzHwWxB,CyHxWwB,EzHwWZ,EmE9V2B,IkDrCI,ErHmYhC,QAAiB,CAAE,WAAW,CAAE,mBAAmB,CAAC,CAAA,KAGjE,EmGpjBI,QnGqjBE,EAAO,MAAM,CAAC,CAAC,CAAA,CAAE,EyHzVU,CAAA,GtB3NA,EAAA,SnGqjB5B,EAAO,MAAM,CAAC,EAAE,CAAC,OAAO,IAI3B,CmGrjBC,CnGqjBM,OAAO,CmGrjBC,AsB4NA,AzHyVD,GACd,CmGrjBC,CnGujBf,CAAC,AACO,MAAM,iBAAiB,CyHxVT,AzHwVoC,CyHxV5B,IzHyVN,GyHxVG,GzHwVrB,AAAwB,IAAxB,CAAK,SAAS,CAChB,MAAM,GAAW,OmGrjBH,CnGqjBG,SAAmB,iBAAiB,CAAE,oBAAoB,CAAC,CAAA,IAExE,EAAiB,GqH7XQ,ArH6XG,OAAD,KACL,CmErVH,AnEqVI,OACrB,EmGrjBA,CnGqjBY,iBAAkB,CyHvVC,CJnCD,AImCE,CJnCD,WAAA,mCrH6XjC,AACY,CADZ,MAAA,IAAA,CAAA,UAAA,CAAoC,UAAU,CAAC,IAAI,CAAC,UAAS,CAAC,CAAA,AAClD,MAAkB,CAAA,IAAK,CAAC,AAAC,GAAK,EAAA,AAAW,QAAQ,CAAC,QAAQ,EAAE,GAAK,EAAe,QAAQ,EAAE,CAAC,CAAZ,AAAY,GAC5F,cACT,GAAY,gBAAgB,CAAE,aAAa,CAAE,ImGtjBM,yBnGsjBuB,CAAC,CAAA,OAE5E,EyHrVI,AzHqVM,OAAO,CAAA,ImGtjBK,WkBgLuB,GrH8YpC,CAAiC,CAAA,IAC3B,IAAI,EAAtB,AAAwB,CAAC,GAArB,CAAC,OmG5jBO,EnG4jBE,2BACoB,aAAa,CAAE,oBAAoB,CAAC,CAAA,AAE1E,IAAM,EAA2B,EmG5jBzB,MnG4jBiC,AmG5jBF,CnG4jBG,CAA1B,OAAO,EAAqB,EAAQ,CmG5jBP,AnG4jBjB,EmG5jBA,GnG4jB8B,IAAI,CAAC,gBAAgB,CAAC,GAChF,EADqF,AACjE,CADkE,CAAA,IAC5D,IAAI,CAAC,GmG5jBC,gBnG4jBkB,CAAA,UAAW,CAAA,IAAK,CAAC,SAAS,CAAC,CAAA,AAE7E,OAAO,GmG7jBC,AsBwOI,CAAA,CAAA,UAAA,CzHqVW,WAAW,CAAC,CmG7jBD,GnG6jBK,CAAC,OmG7jBK,EAAA,CnG6jBM,EmG7jBA,AnG6jBY,CmG7jBD,cnG6jBgB,CAAE,EAClF,CAAC,AAOD,IARyF,CAQpF,AARqF,CAQpF,AARoF,SAQ3E,CAA2B,CAAA,CACxC,IAAA,EAAuB,CmGpkBI,EsBmPK,EAAA,CzHkVhC,GAAA,AAAsB,IAAI,EAA1B,AAA4B,QACnB,KAAK,CAAA,AAGV,KyH9UoB,GzH+UtB,MAAA,IAAA,CAAA,UAAqB,CAAC,SAAS,CAAC,IACzB,UADuC,CAAC,CAAA,KAKnD,CAAC,AAcD,MAAM,CqH/Z4C,WrH+ZhC,CAA2B,CAAA,OAC3C,GAAsB,AAAtB,IAA0B,EAA1B,AAA4B,CAAC,AmGhlBF,GnGglBnB,CAAC,CmGhlBD,QAAA,OnGilBA,GAAY,OmGhlBO,UAAA,cnGglB0B,EmGhlBE,0BnGklBhC,GAAW,EmGhlBA,InGilBZ,CyH/UC,CAAC,EzH+UE,CmGhlBD,CnGglBG,QACpB,GAAA,iBAA8B,GmGhlBG,WnGglBY,iCAI9C,EAAQ,EAAa,EyHhVI,CzHgVY,CyHhVZ,KzHgVN,AAAwB,OAAO,CAAC,GAAG,CAAC,KAExD,CAAC,QAAQ,CAAC,GAEd,GmGplBK,CnGolBD,CAAA,MAFwB,CAAC,GAEd,CACZ,MmGplBU,AAF4B,InGslB5B,CAAC,IAAI,CAAC,ImGplBQ,KnGolBC,CAAC,CAC1B,KAAK,CAAC,AAAC,IACN,CADW,EAAE,EAAE,EACR,CAAC,KAAK,CAAC,8BAA8B,CAAE,GACvC,CmGplBG,CnGmlByC,CAAC,CAAA,AACzC,CAAA,KAGC,IAAI,CAAC,EqHhac,MrHgad,CAAS,WAAW,EAAE,CqHtZR,ArHsZS,CqHtZR,ArHuZrC,CqHvZsC,ArHuZrC,CAAA,AACF,EAAgB,IAAA,CAAK,QAAQ,CAAC,UAAU,EAAE,CAAA,AAG1C,EmGxlB2C,AnGwlBT,GmGvlBd,CnGulBkB,CAEtC,EAAA,KmEvXC,EnEwX+B,IAAI,CAAA,AAChC,EAAA,CAAA,EmGxlBuB,AnGylB3B,EAAgC,CAAC,CAAA,AACjC,GAAqB,EAGrB,GAH0B,AAG1B,CAH0B,CAGd,CACV,AADW,GACL,CAAA,EAAe,EAAc,AmG3lBJ,CnG2lBO,MAAM,CmEvYC,GnEuYX,GAAiB,CAAC,GAAG,CAAC,CAEtD,IAAI,CAAC,eAAe,EAAE,CAAC,KAAK,CAAC,GAAG,CAAG,CAAD,GAAK,CAAC,CAEzB,IAAI,EAAnB,EACI,OAAO,CAAC,CADD,EACI,CAAC,CAAC,IAAI,CAAC,OmG3lBS,YnG2lBU,CAAC,mBAAmB,EAAE,CAAE,IAAI,CAAC,mBAAmB,CAAC,kBAAkB,EAAE,CAAC,CAAC,CACzG,GmG3lBK,CnG2lBD,CAAA,CAAE,CAAC,EAAkB,EAAgB,EAAE,CmG3lB3B,AnG2lB8B,CAAC,QAAxB,CAAiB,SACvC,OmG3lBO,SnG2lBS,EAChB,GACD,CAAC,CAAC,AACF,KAAK,CAAC,GAAG,CAFO,AAEJ,CAAD,GAAK,CAAC,CACpB,OAAO,CAAC,OmG5lBoC,CnG4lB5B,EqH/Za,ErH+ZT,CAAC,CAC1B,CAAC,CAAA,AAGF,GAAoB,IAAI,EAApB,EAAsB,CAExB,AAFyB,GAErB,CAAC,EAAa,QAAQ,CAAC,CAAV,EAAa,EAAE,IAAI,CAAC,UAAU,CAC7C,CAD+C,CAAC,IAC1C,AAAI,KAAK,CAAC,CAAA,SAAA,EAAY,EAAa,EAAE,CAAA,OAAH,qCAAG,CAA8C,CAAC,CAAA,AAE5F,EmG9lBI,AnG8lBW,CAAA,EAAG,EAAa,QAAQ,CAAC,GAAG,CAAC,IAAI,CAAC,CmG9lBG,SnG8lBO,CAAC,CmG9lBG,MnG8lBI,CACjE,KAAK,CACL,EAAE,CACH,CAAA,OAAA,EAAU,EAAe,QAAQ,EAAE,CAAA,CAAE,AAAb,CAAa,AAIxC,GAAmB,IAAI,EAAnB,GAAwC,IAAI,EAArB,EAAuB,CAAC,AAEjD,GmExY6B,CnEwYvB,EAAY,EAAY,MAAM,CAAC,CqHhbiB,GrHgbb,CAAC,AAAC,GAAU,CAAD,CAAJ,AAAW,EAAT,CAAQ,KAAS,CAAC,QAAQ,EAAE,GAAK,EAAe,QAAQ,EAAE,CAAC,CAAZ,AAAY,AAE7G,GAAI,AAAa,IAAI,EAAE,CAAC,MACZ,EAAS,MmGrmBG,CnGqmBH,AAAQ,CAAA,AAGvB,EAAW,EmGxmBqB,MAClB,CnGumBH,SAAmB,CAAG,CAAC,CmGvmBK,AnGumBH,CAGtC,IAAM,EAAuB,EAAY,EmGzmBQ,IAAN,YnGymBgB,CAAA,AACrD,EAAkB,EAAuB,EAAc,CmGzmB1B,EAAd,YnGymBuD,CAAA,AAG5E,EAAe,GAAY,EAAiB,GAG5C,EAHY,CAAc,CAAyB,AAG7C,CAH8C,AmG1mBrC,CnG0mBqC,AAG7B,GACrB,CAJwC,CAI5B,OADM,EACP,QADgC,CACb,CAC9B,EAAc,WAAD,KAAiB,CAC9B,EAEoB,IAAI,CAFjB,CAEmB,AAD3B,CAAA,AACG,AAAyB,IAC3B,EAAa,CAAA,CAAc,CAAA,AAI7B,EAAoB,GAJR,AmG/mBmB,AnG8mBb,IAKS,IAAiB,GmGnnBF,AnGmnB0B,ImGnnBT,EnGmnBe,CAAC,GAAgB,EAG3F,EAAiB,KAHsE,CAAC,AAGjE,CAAC,IAHkF,AAGjE,CAHiE,AAG5F,CAGV,MAAM,AAH0B,CAAC,AAG1B,GAAgB,GAH6B,CAAA,AAKtD,EADkB,AACU,GAFP,AACY,CADX,CACiC,IAClB,EADwB,CAAC,EADjB,AACb,EADe,AAET,CAFU,IAEV,AAAK,CAAA,AAE/C,CAHyD,AAC5B,AAE5B,CAH6E,CAAC,CAAC,CAAA,CAS9E,CANK,CAAC,AmGtnBA,AACF,MnG2nBI,GmG3nBK,EnG2nBA,CAAC,EmElae,6DnEqanC,CAAC,AACH,CAAC,AAED,MAAO,UAEL,kBAAmB,EACnB,QmG7nByB,AnG4nBI,YACR,EACrB,MmG7nByB,iBnG8nBzB,OAAO,aACP,4BACA,iBACA,EACD,AACH,CADG,AACF,AAOD,KAAK,CAAC,SAAS,EAAA,CACb,GAAsB,IAAI,EAAtB,IAAI,CAAC,SAAS,CAChB,MAAM,GAAA,iBAA8B,WAAW,CAAE,oBAAoB,CAAC,CAAA,AAExE,OAAO,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,gBAAgB,CAAC,IAAI,CAAC,SAAS,CAAC,AAC/D,CAD+D,AAC9D,yHwD9uC+B,CzCtFkB,CAAA,CyCwFhD,CAAY,CACZ,C2CxFsE,CAAA,CAAA,K3C0FjE,QAAA,CAAA,0JAyBsD,C2D5GC,A3D4GA,6DAG1B,uBAAA,EAAA,IAAA,CAAA,6LAI0B,IAAA,CAAA,qHAMF,EAAe,IAAI,CAAC,ExDzBK,IAAA,CwDyBE,CAChF,CAAA,wBAIoC,QAAQ,CAAA,MAAA,CAAA,0ZAoBa,OAAI,0BACzB,CAAC,EAAQ,SAAS,4V7CgFzD,SAAA,CAAA,MAGE,EAAA,eAIO,EAAA,EAAA,EAAA,MAAA,CAAA,KAAyB,UAAW,CAAC,+E6CjE1C,EAAA,MAAA,CAAA,EAAA,2FA0BF,SAAA,CAAA,CAAA,CAAA,CAAA,4BAGqB,EAAA,sCACuC,CAAA,yGAO1D,CAAA,iDAAA,EAAoD,EAAe,Ce0H1D,CACd,CAAA,Cf3H4E,CAAC,IAAI,CAAC,CAAA,CAAE,AAAb,CACnE,CAAA,kCAI6C,CrDzHO,kCqD+HrC,CpDnEC,AwFtEE,AnCGI,gBAAA,WAAA,CAAA,kBAAA,EDsI4C,OAAO,EzBUE,CAAA,CyBVS,CAAC,CAAA,SAIjE,SAAA,IAAA,CAAgB,QAAQ,CAAA,GAIpB,6BAAA,CAAA,GAAA,GAAA,iBAAgD,GxB9EnD,CwB8EuD,CAAE,CAAC,kCAE3B,CAAC,AAAC,GAAY,AAAoB,KAAK,CAAC,CAAnB,AAAC,AAAkB,OAAX,IAC1D,MAAM,QAAA,GqDhD4C,ArDgD5C,CAAY,EAAmB,GAAA,CAAI,GAAA,EAAA,QAA6B,CAAC,OAChE,EAAmB,CmBvI0B,CAAC,E1E+MrB,EuDxEA,CAAC,CAAC,EAAA,IAAA,CAAiC,CAAC,CAAC,CAAC,CAAC,CAAA,sCAKnE,CAAA,GAAW,EAAyB,MAAM,CAAC,CAAC,CAAC,QAAQ,CAAC,eAAe,eAKzE,IAAA,CAAA,QAAA,CAAA,SAAuB,EAAE,CAAC,UAAU,EAAE,CAAA,4BAGvB,CAAA,UAAW,CAAC,CzBcD,CyBdiB,EAAe,4FAe1E,CCxJa,CAAA,CAAA,uDD+JQ,CqCxJC,CAAC,CAAA,QrCwJoB,IAAI,CarKG,CbqKK,QAAQ,CAAE,CAAC,gBAG9C,CAAA,GAAA,QAAA,CAAwB,CAAA,A2CtKG,A3CuK3C,CaxK8C,A3B9BJ,+EcuMqB,yBAAA,CAA2B,CAAC,CAAA,kBAM9F,GAAA,qBAAoC,CAAC,IAAA,CAAK,mBAAA,CAAA,IAAyB,CAAC,CazKG,ObyKK,CAAC,CqDnDvE,OAAA,CAAA,ErDmDuF,OAAO,CAAC,CAAA,yCA6BzE,CesFH,OftFW,CAAA,AAC3C,EACJ,SACC,QAAA,WAAA,EAAA,MAAA,EAAA,UAAA,EAAA,CAAA,IAAA,EAAA,mBAAA,EAAA,MAAA,EAAA,eAAA,iDAKsC,EACvC,GAAA,IAAA,CAAA,gBAAA,CACwB,CdvOK,A1C6NF,A6ExDG,KrBkEA,GAAA,GAAA,IAAA,CAAA,gBAAA,CAAA,KACD,CAAC,GAAA,GAAsB,ClDoCK,C6FxOD,A7FwOqB,CAAA,iBkDpCL,QAAQ,CAAC,EAAQ,KAAD,GAAS,CAAC,EAAE,CAAC,IAAK,GACxG,CAAC,AAD2G,CAAC,oBAEhD,MAE3D,IAAA,CAAA,gBAAqB,CAAA,KAAA,CAAO,AAAC,GAC3B,GAAgB,EAAe,CxBlC2B,cwBkCZ,CAAE,IAElD,CAAC,YAFkE,CAAC,CACnE,GAEyB,uCAC0B,CAAE,CAAC,kCAEb,GAAG,EAAA,QAAuB,CAAC,CAAA,EmB5LiB,U3EkMtE,KwDJF,KAAA,CAAA,wCAAA,MAGsB,QAAb,SAAA,IACb,CACF,EAAA,SAAA,CAAA,iBAAmC,EoE9UhC,ApE8UkC,AqDrEwI,CrDqExI,aACvB,E7CQoB,CAAC,W6CPP,ExDqCgB,CACvD,CAAA,KwDtCgD,UACzB,EAAA,QAAuB,WAErB,CAAC,AyBlDQ,AY9IE,qDrCiM6B,eAKnD,CAAC,gBAAA,gCAKkC,CAAC,IAAI,CAAC,KqBhDG,GrBgDK,CAAE,IAAI,CAAC,iBzBRa,CAAC,CyBQK,CzBRH,4ByBWpE,UAAA,IAAA,CAAiB,SAAS,CY3JE,wCZgK1C,MADY,UACZ,CAAA,CAAA,oCAW2B,SAAA,IAAA,CAAgB,GqD1ChC,KAAA,gCrDmDS,uBAAA,EAAA,AACF,MADE,EAAA,SAAA,EACF,CAAA,IAAA,EAAA,kBAAA,EAAA,AAEM,MAFN,EAAA,eAEE,gDAK0B,SAAU,oBAC5B,CAAC,gBAAA,CAAkB,CAAC,A6D5LE,0B7D6LpB,SAAA,EAAwB,QAAQ,CAAA,EAAG,GAAG,AAInE,CAJoE,EAIpE,CxBiCyE,CAAC,AwBjC1C,eAAe,CAAE,OxBoCS,CAAC,YwBpCU,CAAC,AAIhD,KAAA,gBAEL,CAAA,kBAAmB,EAAE,CAAC,EAAe,QAAQ,CAAC,CAAA,iBAEvD,KAAA,CAAA,wCAAA,MAGkB,MAAxB,AAAkC,EAAnB,SAAS,KAExB,EAAA,SAAA,CAAA,iBAAA,GAAsC,CACpC,YAAY,EACZ,UAAA,EAA0B,SAAS,oBACF,CxDgFW,CwD9EhD,CAAA,MAAA,EAAgB,CAAC,AqClNiB,arCmNnB,CAAC,CqDXS,A9E2BJ,C8E3BI,AjGkCK,qC4CvB0B,KAAK,CAAC,CAAA,GtDb7C,yBsDsBkB,CAAA,IAAA,CAAA,QAAc,CAAE,AapNH,IboNO,CAAA,mBAAA,CAAsB,EapNA,yCbuN/C,SAAA,6DAKH,ClD6EG,AuEvFE,ArBUL,4DASJ,sBAQd,CAAsB,CAAA,UACL,MAAA,IAAU,CAAC,QAAQ,CAAC,SAAS,EAAE,CAAC,UAAU,EAAE,CAAC,CAAA,gBAC9D,CAAC,mBAAmB,CAAC,4BAA4B,CAAC,SAS/D,iBAAA,CAAkC,CAAA,QAC/B,IAAA,CAAK,CtDID,kBAAA,CsDJqB,E2C9OA,c3C8OgB,CAAC,E2C9OA,EAAA,C3C8OK,QAAQ,CAAC,C2C9OD,Q3C8OU,EAAE,CAAE,SAAS,CAAC,CAAA,yBAWtD,yBAEM,GvDuHO,AsEQE,Kf/HD,CAAA,qBAAsB,EAAE,CAAA,AAChE,EAAiB,KxDuG6D,CAAC,AwDvGxD,CoCvPO,EAAE,AMsDF,CAAA,CAAA,QAAA,CAAA,Q1CiMe,CAAC,C2CrPK,c3CqPU,CAAC,EAAoB,GAAO,GAAD,EAAM,CAAC,CAAA,MAAf,kCAI/C,iBACP,aAAa,C0BpJkC,kB1BqJ7C,eAAA,oBACC,gDAUT,IAAA,CAAA,mBAAwB,CAAA,iCAAkC,EAAE,CAAA,EqDqB3E,IrDpBc,GAAkB,IAAA,CAAA,QAAA,CAAc,C4D7H1D,MjB3HiE,I3CwPI,EAAE,CAAE,EzBKI,CAAC,CAAC,OyBF7B,CqBvCwB,AenNrD,CAAC,IAAA,QAAA,GpC0P6C,CAAC,0BACtC,C2C1PK,c3C0PU,EAAE,0BACjB,MqDyBR,gBrDzB8B,SAKjD,EAAkB,MAAA,EAAA,YAAA,CAAA,GAGZ,CC7OC,CAAA,OD6OuB,E5CYM,A4CZM,G2C9PG,AlG8WA,WuDhHW,WAK3B,EAAY,CvD4GC,uBuD5GuB,EAAA,IAEzC,OAAO,EAAY,O0BxJW,iB1BwJa,CAAC,CAAG,WAG5C,EAAY,C0B1JG,A1BuJ2C,CAAA,sBAGtB,CAAC,CAAG,EzBHA,C/BuGD,A+BvGE,AyBGc,CzBHd,ayBG4B,CAAA,AAEhG,EAAsB,OAAO,EAAY,wBAAwB,CAAC,CAAG,CzBHrB,EyBGoC,cAAc,CAAA,IAGjE,MAAA,CAAO,AAAC,CAAe,AqBvCV,ErBuCe,CAAC,CAAC,KzBLT,EnBSI,CAAC,CAAA,M4CJmB,GAAK,EAAO,IAAD,OAAY,CAAC,CAAA,AAEtG,EAAA,IAAA,CAAA,QAA6B,CAAA,UAAW,EAAE,OAEnC,iEAG0D,CAAC,G5CKa,4B4CHzD,CvDmIS,EuDhI3B,QAAA,yBACqC,wBAAwB,CAAC,UxDqGc,IwDpG5D,+CAGsB,C2C3QK,AtBiOpB,YrB2CV,SAEf,CCzPY,SAAA,oBD0PO,SACjB,C2C3QO,+B3C6QO,GAAA,cAA6B,gCACC,G2C3QO,Y3C4QpC,GAAe,eAAA,CAC9B,cAAA,GAA8B,IqD+CU,CAAA,UrD/CK,oBACzB,Ga/Pa,CAAA,Cb+PR,C2C3QO,CDiEC,M1C0MA,CAAC,CqD+CM,oBrD/Ce,EAAE,CACzD,gBAAA,IAAqB,CAAA,mBAAA,CAAA,kBAAuC,EAAE,Ia/PY,oBbgQlD,CAAC,mBAAA,CAAoB,OqDiDa,CAAC,CAAA,AxChTG,YAAA,iCboQxD,MACR,CAAA,2CAAA,EAA8C,aAAiB,KAAK,CAAG,AAAF,CzB0BgB,AyB1Bf,AzB0Bc,CyB1BP,GAAD,IAAQ,CAAC,AAAE,CAAD,AvD2JrD,MuD3J6D,GAAM,CAAE,CAAH,AACpG,CADqG,AACrG,EAGN,GvDwJwB,CACpB,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;G0H1oBF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA8GA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;mJ1HlBwB,kBAAA,AAAwB,IAAe,CAAC,AF5IE,AE4I1C,EAAe,QAAQ,CAAC,IAAA,yFAKE,2CAM/C,+IAQ2C,0EAOlC,QAAA,MAAA,GAAA,SAAA,8BAKP,cAAA,wHAKyC,EAAA,WAAA,EAAuB,E0BxK3D,CAAA,E1BwK2E,EAAO,GAAA,CAAK,CAAL,AAAK,uBAO9E,eAAA,sOA4BO,MAAA,IAAA,CAAA,QAAA,CAAA,uDAGD,CAAA,qFAK4B,CAAA,KAAA,EAAQ,EAAS,MAAA,CAAA,EAAA,EAAW,EAAA,CAAW,CAAC,CAAA,0DAKnC,uBACX,EAAE,OAAO,CiF9LS,AjF8LR,CAAC,IAAI,CAAC,sDACS,EiBrEG,CAAA,AjBqEO,CAAC,CAAA,8CAKnC,gBAAgB,CAAC,4CAId,CAAA,C+B5JI,AsFwMA,uBAAA,ErH5CwB,EAAgB,GAAD,IAAQ,CAAA,CAAE,CAAE,uDAclE,IAAI,CAAC,CAAC,CAAC,CAAE,EAAA,GAAA,IAAqB,oBACvC,EAAA,CAA+B,CuD7E9B,A7CTI,qGVoGS,mBACpB,gCAET,GAAM,aAAA,qBACK,8CACkB,CDhFH,CCgFQ,QAAA,CAAA,EAAA,2CAKrB,eAAA,4DAIE,sDACK,EAAA,QAAiB,+BAQ7C,EAAA,MAAA,CAAA,CAAA,EAAA,+BAEqC,GAAS,wCACD,CAAA,EAAA,oBAG9C,CAAA,CAAA,EAAA,CAAA,CAAA,4EAgB6B,oBACZ,qBAAA,CAAA,GAA+B,CkGlOG,+JlGuOS,EAAW,CAAA,AoEnOO,CpEmOJ,CAC5E,KAAK,CADoE,OACxD,KAAK,CAAC,AAAE,CAAD,CAAO,GAAD,IAAQ,CAAC,AAAE,CAAD,cAAgB,CACzD,CAAA,mEAcuC,mBACP,GAAY,C4GnHC,MAAA,c5GoHd,CAAA,CAAI,OAAA,EAAkB,C8B9DC,CAAA,AsC7KK,IpE2OD,CAAC,AKnCE,ILuC9D,CAAA,0CASgE,IAAI,CAAlC,AAAmC,CuD7ClC,CvD6CkB,IAAI,GoEjPyB,4OpE+PhB,CAChE,KAAK,QAAA,MAAoB,EAAK,ED3BtB,CC2BsB,IAAQ,CAAG,eAAe,sCAMnC,A0E1OO,CAAA,qB1E2OP,CAAA,CAAA,qDAGO,CAC5B,CgFnG8C,wBhFmG9C,CAAA,CAAA,qGAWA,QAAA,OAAA,EACJ,IAAA,EAAA,OAAsB,oFAW8B,C6GzOG,I7GyOE,CAAA,GAAM,qBAEtC,4BAIX,MAAM,CAAA,0CAAA,EAAA,EAAA,CAAqD,CAAC,CAAA,OAGjE,6GAIH,KAAK,QAAY,KAAK,CAAC,AAAE,CAAD,CAAO,GAAD,IAAQ,CAAC,AAAE,CAAD,cAC1C,CAAA,CAAE,CACH,CAAA,iDAS2C,CiFpPG,CkCkED,A9GwLA,ALNA,AiFpPE,gBAAA,GjFoPQ,UAAY,IAAI,EAAA,EAAS,QAAQ,CAAC,MAAM,CAAG,CAAC,CAAA,6HAgB5B,kBAAkB,CAAC,CAAA,QAEnE,EAAA,KAAoB,2BAEV,CAClC,E2F1RuC,CjFuPD,qCVmCO,C4GhGiC,A5GiG9E,CAAE,GAAG,CAAE,CAAW,CAAE,CACpB,iCAAiC,CAClC,CAAA,wBAEkD,GAAG,CAAC,EAAtB,MAAA,CAAA,MAAa,mEACqB,EAAe,QAAQ,EAAE,CAAA,CAAA,YAsB/E,IAAA,CAAA,QAlBwB,CAAA,MAAA,CAAA,CAAA,EAAA,oCACW,qDAGX,QAAM,EAAI,EmE3PgB,CAAA,CnE2PZ,SAIxC,CAJkD,AAIlD,CAJmD,kBAI/B,CAAC,C4GlFG,U5GkFQ,AAKxB,CALyB,EuDnEF,AqDfM,A5GmF5C,C4GnF6C,E7EsDmD,CAAC,CAAA,G/B6BjG,IAAA,CAAA,4EAA0F,IAJnF,YAayB,MAAM,IAAI,GAAG,CAAA,AAAE,GAAa,IAAI,CAAC,qBAAqB,CAAC,QAAQ,CAAC,CAAC,CAAA,oBAS5E,CAAe,CAAA,8BACJ,CAAA,GAC1B,E4FjSgD,qB5FiSzB,CAC/B,CAAE,gBAAiB,CAAO,CAAE,CAC5B,IAD0B,6GAKqC,E4G7FK,C5G6FI,CAAC,C4G7FL,A5G6FK,K4G7FM,CAAC,CAAA,0B5GiGhD,EAAK,QAAQ,CoEtSD,ApEsSE,CoEtSD,ApEsSC,EwH1LK,qBxHoNV,CAAA,CAAE,CAAA,kBACrB,CoE9TD,AuBjBG,A5FuTH,CqEtSC,UAAA,CAAA,GAAA,sBAAA,CpEgUtB,IAAI,CAAC,qBAAqB,CAAC,GAC3B,gBAAgB,CACjB,CAAA,2BAE8B,CwHtNC,ExHsNK,CoEnUD,UpEmUY,SAAW,CAAC,EAAE,CAAC,OACrD,GAAA,CAAA,gEACC,IAGC,SAAS,CAAA,MAAA,CACX,GAAc,C4GjGG,GAAA,C5GiGE,mBAAmB,CAAC,C4GjGG,GAAA,GAAA,CAAA,GAAA,IAAA,CAAA,qB5GkGL,CAAC,E4F3TiB,AgB0Nb,wC5G8HjC,IAAA,CAAK,YAAY,CAAA,GAC1B,sBAAA,CAAA,IACJ,CAAC,qBAAqB,CAAC,GAC3B,8CAGkC,CoEnWD,CAAC,QpEmWU,SAAW,CAAC,EAAE,CAAC,gGAKjB,kCAEhB,CAAA,EAAS,IwDxVsD,CxDwVjD,CwDxVmD,AxDwVlD,AkG5WA,oBlG6Wf,CoEpWC,CAAA,yCpEsWC,oCAEb,CAAA,cAAe,CAAA,EAAA,SAAkB,CAAC,EiGzTxB,CqBkC6B,iBtHwRlC,CAAA,cAAA,CAAA,EAAA,cAAsC,CAAC,uCACd,CsEQG,AvEtBQ,CuEsBR,AvEtBS,CAAA,CmG9VR,WlG4WW,CAAC,wCACrB,EAAA,kBAAA,kCACP,EAAA,WAAmB,CAAC,mCAClB,EsH/RgB,ApD6BT,CAAA,YlEkQc,CAAC,iCACxB,CiF1Q4B,CjF0QpB,WAAA,oBACtB,IAAA,CAAA,cAAA,CAAA,EAAA,iBAAA,+DACiD,qBAChD,IAAA,CAAK,cAAA,CAAA,EAAA,kBAAA,iBACH,YAAY,EAAI,EAAE,gBACxB,EAAA,cAAsB,EAAA,EAAA,gBACtB,cAAc,CAAC,EAAQ,SAAS,+BAClB,CAAC,CwH1OG,CxH0OK,SAAS,C2F9WD,A3F8WE,iBAEpB,uBAAJ,CAAI,IACnB,CAAA,qBAAsB,CAAC,EAAA,eAAuB,CAAC,CAAA,IAAA,CAC9C,qBAAqB,CAAA,CAAC,CAAE,AoErWE,CpEqWD,OAEjB,CK9CM,aAAA,EL+CX,KAAA,CAAA,GAAA,CAAA,IAA0B,GAAD,GACtB,EAAA,MACH,EAAK,IAAA,YACC,CAAA,cAAe,CAAA,EAAM,MAAA,gCAEhB,CAAA,cAAA,CAAA,EAAA,WAAgC,CAAC,CuDlHC,CAAC,CAAA,C0C/LE,CAAC,CAAC,CAAA,InEkMG,CAAC,CAAA,A9BgH/C,IAAA,CAAK,cAAc,CAAA,EAAM,WAAW,WACvC,CuD5GC,CCjPC,CzDuVN,AyDvVO,CAAA,CAAA,cAAA,CxD6ViB,EuD5GE,AvD4GG,IkG9WI,IlG8WI,CAAC,oBA8BlD,YAAA,EAAA,CAAA,CAAA,CAAA,8BACgC,CAClC,GAAQ,OD9BoC,CkF/PO,WjF6RxB,CAC3B,IAAI,CAAC,qBAAqB,CAAC,GAC3B,IADkC,CAAC,QACtB,CACd,CAAA,OAEG,GAAA,QAAA,MAAA,GAA8B,QAAQ,EkG5YA,OAAA,GlG4Yc,CAAC,IkG5YE,MlG6Y9C,CAAA,6DACF,CAAA,A4E7KI,Ae1NG,G3F0YN,CwD7X0B,E1BiQzB,G9B4HK,CAAA,GAAA,CAAK,IAAY,eAE1B,IAAA,CAAA,cAAA,CAAoB,EAAM,KAAK,CAAC,aAC1B,CAAC,cAAA,CAAA,EAAA,OAA4B,CAAC,AD7BF,EAAE,CwDrGH,WvDmI1B,cAAc,CAAC,C4E7KK,C5E6KC,OAAA,+BACL,CAAC,EAAA,SAAA,MAC1B,IAAA,CAAA,mBAAwB,CAAA,EAAA,GAAU,CAAC,AgFlOE,6ChFoOf,C4GxFE,ArD1CL,avDkIiB,CAAC,EAAM,C8B1HG,mB9B0HiB,CAAC,QW7HQ,aX8HxD,IAAA,CAAA,cAAmB,CAAC,EAAM,GAAD,AiG7UE,gBjG6UkB,CiG7UG,AjG6UF,A8B1HA,qB9B2H9C,CAAC,cAAc,CAAC,EAAM,G4GrFG,Y5GqFY,CAAC,CAC3D,aAAc,IAAI,CAAC,CDxBL,aCwBmB,CAAC,EAAM,EDxBR,CCwBO,SAAa,CAAC,sBAC/B,CAAA,cAAA,CAAA,EAAA,gBAAA,mDACgC,CAAC,WAC5C,IAAI,CAAC,C4GpFC,a5GoFa,CAAC,EAAM,SAAA,iBACjB,CuDlIH,CCzPiC,UxD2XlB,EAAI,CuDlIH,ACzPgC,CAAA,gBxD4XjD,CwD3XmB,CAAA,cAAA,ExD2XK,EAAA,CACxC,CDxBC,OAAA,MCyBW,OAAO,CAAA,EAAG,EuDlIA,KvDmIb,IAAI,CAAA,cAAe,CAAC,EAAA,OAAa,CAAC,KAAA,aACzB,OAAA,CAAA,QAAgB,CAChC,gBAAiB,C4E9JO,GAAA,CAAA,qB5E8JmB,CAAA,EAAO,OAAO,CAAC,MiG1UQ,CAAC,CAAA,OjG0UM,CAAC,gEA4B1C,CAClC,GAAQ,CD3C+B,AACxC,CAAA,wBC0CmC,CAClC,IAAI,CAAC,C8BjIsE,oB9BiIjD,CAAC,GAC3B,GuD5J+F,0EvD+JhC,CAAC,EAAE,CAAC,UACxD,CAAA,wEAID,YAAY,CAAA,GAAA,CAAK,AAAC,IwDhZM,AxDgZK,IAAD,AAClC,EAAA,EAAQ,WACD,IAAA,CAAA,cAAA,CAAA,EAA0B,SAAS,CAAC,UACrC,EAAM,CD3CC,OAAA,CC2CQ,C4G/FG,CAAA,C5G+FA,CAAC,AAAC,EAAO,CAAK,CAAH,AAAE,GAAK,CAAC,E4E1KD,Y5E0Ke,CAAC,EAAE,CAAC,CAAC,sBAC3C,IAAA,CAAA,cAAmB,CAAC,EAAK,EiGpWH,CjGoWG,kBAAsB,CAAC,oBACnD,CoE9Zc,CY4KL,EAAA,CAAA,chFkPU,CAAC,EAAM,CgFlPO,EhFkPR,eAAmB,CWtIC,AXsIA,CWtIA,mDXuIT,CAAC,GkG1aG,0BlG2a/B,CAAC,C4G7FA,C5G6FM,QAAQ,CAAC,EkG1aE,4BlG2ajB,CAAC,C8B/HC,CmErOC,AjGoWI,CiGpWJ,InEqOS,I9B+HI,CAAC,SACtC,aACU,CAAA,EAAA,0BACS,CAAA,EAAO,I8B5HM,G9B4HC,CAAC,I8B5HM,C9B4HD,EAC9C,gBAAiB,IAAI,CAAC,qBAAqB,CAAC,EAAA,OAAa,CAAC,eAAe,CAAC,mD4B7tBhF,CAAqB,ACtB4C,CDuBjE,CAAoB,CEO+D,AC3BK,CAAA,ECmBG,CrBN5E,AqBM4E,ChBrBF,qGYuCnF,iLAemF,CAAC,CAAA,EEwFzE,kBFtF2C,GAAG,CAAC,EwCvCM,EAAA,CAAA,UAAA,CAAA,mBxCwCxB,gLAcsB,CAAC,UAAU,CAAE,QAAQ,CAAC,CAAA,CAC/D,MAAA,EAAmB,CC5CK,CAAC,CyBuBmD,AzBvBnD,AHezC,AyFYoC,C7DJyD,CAAA,0E1BgC/E,eAAA,4BACS,EAAS,MAAA,CAAA,CAAA,kDAEyB,mBAGzC,OAAA,EAAA,8DAC0C,CAAC,CGXC,0CHYN,sFAIJ,eAAe,CAAA,CAAA,CAAG,CAAA,iCAQpD,CAAA,CAAA,CAAA,MAAA,QAAA,GAAA,CAAA,uDAUlB,EAAA,qCAIC,EAAA,EAAA,GAAA,CAAA,GAAqC,CAAA,EAAA,EAAK,QAAQ,CAAA,EAAA,EAAK,CIuBG,AJvBF,CAAC,KAAA,CAAA,CAAA,EAAA,IAAA,CAAA,mFAItB,EAAS,QAAQ,EAAE,CAAA,WAAA,EAAc,EAAc,CAAE,CACzF,CAAA,SADuF,uEiC3GsB,CAAA,wJAenD,CAAA,sEAEuB,sBAAA,CAAwB,CAAC,CAAA,2EAQlC,CAAC,CPJH,CcnBO,AdmBN,AsDqCG,CAAA,AtDrCH,QOOpC,GAAA,EAAW,MAAA,EAAA,EAAa,iBAAA,CAAoB,CAAC,CS8JC,AT9JA,CAAA,0CAG9C,CIvBK,AbI0B,eAAA,CAAA,+CAAA,ESmBoC,EAAM,CAAE,CAAC,CAAA,CAAH,0BAI/C,EAAE,AqDvBA,ArDuBC,UAAU,CAAC,CAAC,CAAC,CAAA,C9BLA,CAAC,CAAA,oH8BiB7E,iNAmBgC,CAAC,UAAU,CAAC,EAAU,EAAQ,sEAEc,EAAA,QAAiB,EAAE,CAAA,EAAA,EAAK,EAAM,CAAE,CAAC,CAAA,CAAH,MPtBhB,CAC3F,CAAA,4BO2ByC,CgD3CC,ArF8BI,CqF9BJ,GAAA,uBhD4CpC,EAAA,mCAE+C,CAAG,6KAWO,iBAAkB,GAAS,IAAF,4Kb5FtF,aAAA,CAAgB,gLAkB8B,GAAA,CAAA,EAAM,C1BAI,C4EZE,ACgBN,AnDJS,QAAQ,CiClBO,CjCkBL,CAAA,CAAE,CAAA,O4B0CnC,e5BxCP,EAAQ,WAAmB,wBAElD,OAC8B,6LAK2B,uMM9BnB,CAAA,CAAA,CAAA,mEAWf,CAAA,CAAA,CAAA,mEAE+B,2DAGlC,CAAA,+BAAA,CAAiC,wBAMlE,CAAA,CAAA,yBAI8B,wGAGW,aAAc,CAAA,yBAAA,EAA4B,EAAS,GcnBA,GdmBD,EAAS,EAAE,CAAA,EAAA,EAAK,EAAM,CAAE,CAAC,CAAA,CAAH,iBAMxF,IAAA,CAAA,aAAA,CAAA,EAA6B,GAAA,kPAaE,CjDyFG,CiDzFO,AjDyFa,oBiDzFQ,GAAS,CsDmDE,GtDnDJ,EAAQ,CAAC,CAAA,wQxBqEtG,CAAA,KAEG,CAAA,SAAA,CAAA,sEAQmE,CAAA,mBAKjE,EAAA,IAAA,EAAA,QAA+B,CAAA,GAChB,UAAU,CAAC,EAAA,CAC9B,GAAc,UAAU,CACxB,GAGI,EAAA,GAHI,CACT,AAEK,CAFL,CAEwB,SAAA,CAAA,GAAwB,YAAY,uHAW/C,EAAA,kBAAA,CAAyB,iKAUD,CAAA,sDAIpB,gEAIN,+CAE0B,CAAA,gIASI,CAAA,UAAA,CAAY,qBAEhD,mCACmC,CAAC,qBAAA,CAA6B,CAAC,CAAC,CAAC,CAAA,UAAW,CAAC,CAAC,CAAC,CAAC,gCACnD,CAAC,0BAA2B,CAAO,CAAA,EAAG,CAAA,UAAW,CAAC,CAAC,CAAC,CAAA,kCAClD,CAAA,oBAAA,CAAA,CAA8B,EAAA,CAAA,UAAa,CAAC,CAAA,EAAG,uEACT,CAAO,CAAC,CAAC,CAAC,CAAC,CzBGC,CAAA,QyBHS,CAAC,CAAC,CAAC,CAAC,oCAC7D,CAAA,sBAAA,CAAA,CAAgC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,EAAE,CE/DG,CAAC,CAAA,sBFgEpE,EAAA,oBAAA,CAAA,0BAAsD,CAAO,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,6B8EjDnB,a9EkDvC,CAAC,CyBZnC,CxB9EmC,mBAAA,CD0F6B,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,AbDF,CaCG,iKAezE,UAAA,gDAID,CAAA,YAAA,+HAQV,UAAA,CAAA,kBAAA,wIAgB6B,CqChHG,OrCgHK,CAC7C,IAAI,CAAC,C7BlEwD,kBAAA,C6BmE7D,E7BnEmF,C6BmErE,YAAY,CAC1B,IAAI,CAAC,SAAS,CACf,CAAA,uLAW8E,iBAAiB,CAAE,IAAI,CAAC,SAAS,CAAC,CAAA,OAE5G,IAAA,CAAA,wBAAA,0DAQgB,qBAAqB,QACrC,YAAA,CAAe,CsC/Jc,ArC2FX,GDoEC,C4C/IG,E5C+IS,IAAA,CAAA,SAAc,CAAA,UAE7C,IAAA,CAAA,YAAA,gCAYmB,2BAAA,uBACc,CAAC,MAEZ,sDACa,aAAc,CAAA,SAAA,CyBda,CzBcD,EAAA,eAAA,CAAA,4KAU/B,qCACG,uDAElB,EAAG,WAAA,sBACD,EnB5CM,A8BzJN,QAAA,wCX+MmB,CAAA,IACvC,YACwB,CkDxBgC,0BAAA,kBlDyBnB,iBAAiB,CAAC,EAAA,8BAIlC,SAAA,0CACqB,C+E9JE,A/E8JD,WAChC,OAAA,EAAU,SAAS,CAAC,AyBqBA,AlDwBI,OyB5C5B,EAAG,KAAK,CACf,MAAO,EAAA,KAAA,iDAEQ,OAAA,EAAA,aAAA,uDAEK,EAAA,WAAA,6CAGR,CmDhKS,AnDgKR,+CACoC,CwCoHC,YxCpHgB,KAAK,CAAC,AAAE,CAAD,CAAO,GAAD,IAAQ,CAAC,AAAE,CAAD,KAAO,CAAC,GAAM,CAAE,CAAH,AAAI,CAAH,AAAG,qCAW/D,CAAE,GAAuB,CoErLpB,AxBcI,CAAA,2B5CwKhB,gDAIZ,EAAA,cAAA,CAAA,2BACG,KAGzB,EAA2B,EAAA,GAAA,CAAA,MAAe,iBACV,kCAEA,CAAC,CkDlCG,CY9IG,E9DmLlC,EAAA,EAAwB,EAAA,CAAY,MAAA,QAAA,GAAiB,CAAC,cACpC,CAAC,gCACkC,CAAC,GAAG,CAAA,WACzD,kBAAkB,CAAA,GAAuB,KAAA,CAAA,IAAY,OAAO,MAAM,CAAC,WAKtD,SAAA,EAAuB,IoE7LsB,OpE6LX,EAAE,G/B+DnC,A+B/DwC,IAAI,CAAC,mBAAmB,CAAA,WAAY,C/B+DrC,C+B/DuC,A/B+DtC,CAAC,A+B/DqC,6BAQtE,MAAM,CwC6GE,CMrJE,A9CwCQ,cAAc,CAAC,GAAA,CAAA,CAA0B,CAAA,UAGnF,CAAI,4LAW+B,EAAoB,EAAA,EAAK,IwC+HI,SxC/Ha,KAAK,CAAC,AAAE,CAAD,CAAO,GAAD,IAAQ,CAAG,CwCgIzG,KxChI+G,CAAC,GAAM,CAAE,CAAH,AACrH,CADsH,AACtH,0CAQuE,CoCxI/C,epCqJzB,gBAAA,CAAA,CAAA,mCAIoB,CAAA,MAAA,QAAA,GAAoB,CAAA,eAClB,OAAA,yBACO,OAAO,C+ExLK,G/EyL5C,gCAI6B,EAAA,8BAAA,CAAyC,CAAC,CAAA,Q9BqES,kB8BjE7C,mBAAA,CAAA,WAAA,IAAmC,KAC3D,MACR,CAAA,SAAA,EAAY,C8CrDmB,CAAA,8CAAA,E9CsD7B,IAAI,CAAC,mBACP,CAAA,cAAA,EAAiB,OAAO,GAAS,CAAE,CACpC,CAAA,EADiC,CAAC,GAWjC,sBAAA,CACoD,CAAA,SAOlD,2BAH+F,IAAI,CAAA,AAWvG,eAP6C,CAAC,YzBwDU,sCyBvDF,CAAC,8CAMxC,CnBOG,AyDxOF,KtCiOZ,sEAU0C,C8DpOc,A9DoOb,CAAA,UAAN,CAGvC,C8DvOsD,K9DuOtD,qBAEE,mBAAoB,CsCrOK,AwBCa,2C9DuOtC,QAAA,EAAA,OAAA,OACO,iCAKc,eAAA,WACD,EAAY,CsCvOC,CAAC,yBAAA,CtCuO0B,MAE5D,MAAA,SAEA,iBAAA,CAAA,sBACoB,CmD/MS,cnDgNhB,cACA,EAAA,WAAmB,C7BLM,U6BMrB,CnBcK,MAAA,yEmBRL,EAAY,C6DzPyC,U7DyP9B,CAAC,SAAS,CAAC,CAAA,EwF/JS,exFkK5C,kCAElB,oDAGiB,OAAO,yEAOX,C/BgHsD,mC+B/GtB,CAAG,yDAa/B,CAAA,KAEf,EAAA,AAAwC,EqFnIM,QrFmI9C,OAAgB,EAAmC,EAAsB,EAAoB,IAAI,CAAA,GyBLhB,CAAC,CAAA,KzBSvE,EAJiF,UAM9F,YAAA,IAAA,CAAA,8DAC+B,wBAAwB,CAAA,sEAEvD,YAAA,OAAA,CAAA,6CAEE,mDACA,kDAEF,KAAA,aACY,CyBGG,A0CvMM,GnEoML,CAAC,qEACE,CACjB,6CACA,ayBE+E,sCzBD/E,gDAAgD,CACjD,AAEH,CAFG,AAML,CwC0IC,WxC1IW,IAAI,CAAA,uCAChB,IAAA,EAAoB,MAAM,IAAI,CAAC,C9BmIC,CkG5YD,mBAAA,CpEyQsB,C9BmIC,E8BlItD,CmE3MC,WnE2MW,C0BxPC,AzD0VN,G+BlGS,CAAA,iDACJ,OAAO,CAAA,gCAAA,sCAGjB,qCAKF,IAAM,EAAA,EACQ,gBAAgB,EAC5B,EAAY,kBAAA,EACa,AADb,MAAA,EACA,CmEnNG,CtFiND,AiE/CI,OAAA,E9CkDlB,EAAY,WAAW,EAAA,MAAA,GAAA,CAEH,CmElNG,GnEgNA,EAEV,EAAA,EACb,EAAA,cAA2B,C8EkC5B,EAAA,G9EjC+B,WAAa,EAAA,SAAqB,EAAI,IAAI,CAAA,AAGtE,EAAuB,EAAA,KAAiB,CkDxGZ,AJsDxB,C9CkDwC,CmEpNhB,WnEqNhC,MAAA,GAA4B,AAAoB,OAAP,AAAc,CAAC,CAAb,CkDxGC,ElDyG1C,EAAA,CAAA,4CAAA,EAAuD,EAAA,QAAqB,CAAA,EAAA,AAAG,CAAA,CAG1E,U/B8FkF,a+B5FvF,gBAEA,QAAA,qBAEU,EAAY,WAAW,mBAE/B,GAGN,CAAC,AAWD,MAAM,C9B+GD,gC8B9GH,CAAwD,CACxD,CAAoB,CACpB,C/BuFoE,CAAA,A+BvF9C,GAAiB,EnBEuE,CAAC,yBmBF5C,CACnE,EAAuB,GAAiB,aAAD,qBAAmC,CAC1E,CAAqF,CAAA,CAErF,IAAM,EAAY,KAAK,GAAG,GAE1B,KAAA,KAAY,GAAA,GAAQ,EAAY,GAAa,CAC3C,IAAA,EAAe,MAAM,IAAI,CAAA,6BAA8B,CAAC,EAAqB,GACvE,EAAY,KAAK,GAAG,GAAK,G9BoIK,AkEtSA,EpCqKhC,AAAc,MAAM,EACtB,GAAA,CACE,MAAM,CsC3RkB,CtC2RP,EAAQ,SAClB,EAAA,CAEP,C/BwFK,AC2CA,O8BnIG,KAAK,CAAC,8BAAA,GAKlB,GAAI,EAAO,OAAO,CAAA,UAAW,CAC3B,CAD6B,CAAC,KkDjHW,AlDkHlC,CkDlHmC,ClDsH5C,GAA4B,MAAxB,EAAA,OAAc,CAAC,CsC/Rc,A6B0Db,InEqOI,C/B4FG,C+B5FS,EAAO,WAAW,CAAC,a0BnRmB,G1BmRH,CAErE,CAFuE,CAAC,IAE9D,AAAJ,MAAI,EAAa,KoE5SS,CDsES,CnEsOX,CAAC,KAAA,CAIjC,OAAM,CmExOG,GAAA,QAAA,GAAA,WnEwOiC,EAAS,M0BtRY,I1B0R3D,AAAI,EAJuD,CAAC,CAAC,CAAA,CAInD,CAAA,kCAAA,EAAqC,CnBQG,CAAA,AmBRW,IAAI,KAAP,GAAO,CAAU,CAAC,CAAA,MAU9E,C8CvDF,kBAAA,C9CuDsC,CAAA,EoExTR,qCpEyTqB,C8EwCC,C9ExCC,A8EwCA,C9ExCA,A8EwCC,A9EvClD,CAAC,EAAM,EAAO,CAAA,MAAA,EAAA,qBAA2C,CAAC,GmEjP/D,EnEoPwC,C8C1DvB,G9CuDuD,CAAC,CAAA,C8CvDxD,M9C0DoC,CAAC,UAClD,IAAA,EAAQ,CAAC,CAAE,CAAC,CnBFD,AmBEI,EAAK,InBFE,EmBEI,CAAA,IAAO,AACpC,CADqC,AAC7B,CAAC,CqF7K0C,ArF6KtC,CAAA,EAAA,CAAI,CAAG,CAAM,CAAC,EAAE,CnBFD,AmBEC,AAE/B,OAAO,E/B4FE,8B+BnFmB,CAAiB,CAAE,CAAW,CAAA,CAC1D,EqF/KsC,ErF+KtC,EAAA,IAAA,CAA0B,2BAAA,IACnB,EAAA,EAAc,CAAG,CsCnTY,KtCmTN,EAAa,G8C/DnB,e9C+DqC,CAAC,EAAW,C8C/DV,CAAR,AAAS,C9CgEhE,OAAA,EAAA,EAAA,WASI,iBAAiB,CAAA,CAAA,CAAkC,C/BgFrB,uC+B/EmB,EAAE,CAAA,AACjD,CAAA,EAAA,EAAc,CAAG,MAAM,EAAa,KoExUR,AAAW,cpEwUgB,CAAC,EoExUA,ApEwUW,GAGnE,EAAA,EAH0E,CAAC,CAAA,GAG3E,MAAgD,CAAC,IAAI,CAAC,C8E+BzB,A9E/ByB,IACvD,IAAI,EAAA,EAAA,EAAA,EAAgB,MAAM,CAAA,IAAO,CoCtLG,ApCsLF,CAC5B,CAAA,CAAK,CAAC,AnBjBI,AiExDF,CAAA,CAAA,CAAA,CAAA,CAAA,E9CyEY,CAAA,CnBjBM,oCmB6BX,CAAiB,CAAE,CAAe,CoElVzB,ApEkV2B,CAAW,CoElV3B,CpEmV9C,C8EmDG,GAAA,E9EnDkB,IAAA,CAAA,2BAAgC,GAC/C,CAAC,E8E4DE,AjGpFA,AiGoFA,E9E5DY,CAAG,A8CnEA,M9CmEM,EAAa,KnBxBN,CAAC,UmBwBqB,CAAC,EAAW,EAAS,GAAG,AACnF,CADoF,CAAf,AAAS,AAAM,KAC7E,EAAS,C8CnEG,CAAA,I9CoErB,CAAC,AoElVA,MpE0VK,iBAAA,KACE,EAAA,IAAe,CAAC,C8EsDC,CXrUG,CAAC,CAAA,AtF4RC,mBmBbiB,EAAE,CAAA,AACzC,EAAU,MAAM,EAAS,Q8EsDM,O9EtDS,EAAE,AsCvUW,OtCwUpD,CACL,yBAA0B,EAAQ,wBAAwB,CsCvUc,AwC8XX,A9EtD7D,qBAAsB,EAAQ,EsCtUQ,kBtCsUY,EqF5MQ,0BrF6M9B,EAAQ,C8CzEvB,CR7PsC,wBAAA,CtCuUnD,aAAA,EAAsB,YAAA,gBACN,EAAQ,cAAA,CACxB,CnBcC,oBmBdqB,EAAA,oBAA4B,CAEtD,CAAC,AAQD,CkD7KC,AkBnLA,KpEgWK,CqFjNF,oBrFiNuB,CAAmB,CnBOrB,AmBPqB,CAU5C,IAAM,EAAmB,MAAA,IAAA,CAAW,eAAe,CsCrVY,EtCwVzD,EAAoB,OAAA,KAExB,EAAkB,EoE5WsB,sBpE4WE,CAAG,C8E2C1B,E9E1ClB,GAAA,GAAA,CAAqB,EsF5PM,AtF4PW,CoE5WZ,AnG4be,O+BhF1C,M/BgF0C,A+BhFW,EAEjD,EAAA,CACJ,SAAU,CsCzVO,C6BuDD,OnEmSR,EAAA,OAAuB,GAAe,AsF9PA,ctF8Pc,CAAC,YACnC,EAAiB,cAAc,YAMtD,CAAK,C8E0DC,CAAA,AjGnEG,SmBYhB,CAAC,AAUD,CoEzXC,CvFwXG,AuDtNA,IpCuNE,yBAAA,CACe,CACnB,CAAgB,CAChB,CAAgC,CAChC,CAAmB,CAAA,K8CpElB,E9CsFK,CAAC,EAAA,EAAA,CAAmB,MAAM,C/BqEC,OAAA,GAAA,C+BrEW,CAC1C,EAAgB,eAAe,CAAC,IAAI,CAAC,mBAAmB,CAAE,GAAO,InBrBjC,CmBqBsC,CAAC,CACvE,IAAA,CAAA,oBAAA,CAA0B,EoC5OoB,GpC+O1C,CoC5OG,CpC4Oa,EAAU,EAAM,GAAD,IAAQ,CAAC,AAAE,CAAD,CACzC,EAAa,CADkC,A8CnGrC,A7E0KA,C+BvEqC,A/BuErC,Q+BtEyB,A/BqEiB,C+BrEjB,A8EkCC,AjGnDzC,AZsF0D,CAAA,C+BhEtC,GADnB,OAAO,CoC/OsB,EpC+OR,AACW,EoC9OI,CvDuNK,AuDvNJ,E0C8QF,E9EjCP,GAAe,mBAAmB,CAAC,CAAC,CAAG,MAAM,CAAC,GAAe,WAAD,GAAe,CAAC,CAAA,GAIlF,CoEpZC,EhCoKI,GpCgPC,CAAC,EAAS,QAAQ,CAAC,CAAG,IAC1B,MADoC,CAAA,AAC7B,EAAS,UAAU,CAAC,A8E+BA,CAAA,A9E/BG,EAGlD,E/B8DkD,A+B9DrC,C/B8DsC,CAAA,A+B9D7B,MAHwC,CAAA,MAG3B,EAAI,GAAmB,EAAS,MAAD,SAAgB,EAAI,EAGtF,EAAsB,CoCpPE,CpCoPgB,A/B8DH,E6GjCK,A9E7BO,C8E6BN,CAAA,I9E7BK,OAAc,CAAC,AAAE,CAAD,CAAmB,EAAS,MAAD,KAAX,EAAyB,CAAC,AAAE,CAAD,AAAG,CAAA,CAE9G,EACJ,CsF/R4D,CtF+RxC,AsF/RyC,EtF+RhC,C8E4BsB,AVtbA,ClBoLK,alDsOZ,CAAC,AAAE,CAAD,CAAqB,EAAS,MAAD,OAAX,EAA2B,CAAC,CAAC,AAAC,CAAE,CAAA,AAIlG,GAAI,CAAA,EAAa,CAAC,AAChB,IAAA,EAAkB,G/BgEC,A+BhEqB,CAAE,CAAA,AACpC,EAAc,CoE5ZT,EpE4ZiC,CAAE,AoE3Z1C,CpE2Z0C,AoE3Z1C,GpE4Za,A/B8DkC,C6G9BjC,C9E/BhB,EAAU,SADkB,iCAEnB,E/BmEA,E+BlEC,8BACD,GACT,GAAO,IAAA,GADe,wBACf,QAIJ,+CAGL,CnBRG,oBmBQmB,EAAS,aAAa,CAC5C,uBAAwB,CnBRG,CAAA,emBQqB,CAChD,EoE3ZI,cAAA,EpE2ZsB,QAAQ,+BACI,OoE3ZO,uBpE8ZtC,CoC7OoB,C0C+RlB,A1C/RkB,ApC8O3B,oBAAA,+BAwCD,CAAA,CAC+B,CAAA,KAkBzB,EAAO,C0FlRJ,C1FkRmB,CAAG,AAApB,MAA0B,OAAO,CAAC,GAAG,CAAC,KAC5C,CAAC,oBAAA,CAAqB,E8CxIS,K9CwIF,A8CxIE,G9CwIO,CAAC,KACvC,CAAC,wBAAwB,CAAC,EAAQ,G8EJnB,C7G+BiB,G6G9B1B,C9EGoC,CAAE,EAAQ,I/B2BI,C+B3BL,EAAQ,GAAI,EAAO,GAC3E,CAAC,CAAA,AAGI,EAAiB,C/BuB6D,CAAC,A+BvB9D,C8ENkB,A7G6B4C,M+BvB/C,CAAa,EAAM,CAAf,EAAc,IAAQ,CAAC,AAAE,CAAD,CAE5D,EAID,CANmE,CAAA,AAMjE,GAGa,MAAM,EAAgB,K8EAK,CAAC,CAAC,I9EAI,CAAC,E8EAE,CAAC,A9EAI,C8EAH,GAAO,C9EAC,CAAC,CAAA,EAC3C,E8EDgD,A9EClC,C8EDmC,AAElC,CAFkC,AAEjC,CAAC,EAAV,G9EDe,CAAA,KAE9B,C0F5RG,ItBhMF,CU6dK,Q9EDQ,C8CnJD,A9CmJI,C8CnJH,CgCoJK,A9EDe,CAAC,CkDtSK,GlDuShD,E0F5RI,A1F4RY,C8EA8C,CAAC,A9EA7B,C8EA8B,ChCnJ1D,A9CmJwC,C8CnJvC,AAAwC,EAAE,W9CmJW,CAAA,MACtD,CAAC,CACX,KAAM,E8EKI,EYlSI,M1F8Rd,YAAA,CAAA,QAAA,EAAwB,E0F7RM,A1F6RO,C0F7RN,CAAA,S1F6RM,gBAAA,CAA6B,SACzD,SAAY,MAAA,EAAsB,OAAO,CAAC,EAAe,GAAO,GAAD,EAAM,CAAC,EAAf,QAK/D,AAAL,EAAK,UAAA,IACK,IAAI,CAAA,uBAEV,YAAa,CAAA,oCAAA,EAAuC,EAAe,mBAAmB,CAAA,sBAAA,EAAyB,EAAe,YAAD,SAAsB,CAAA,CAAE,kBAEnJ,MAAM,EAAgB,SoE5coB,AAAc,KpE4cpB,CAClC,IAAI,CAAC,mBAAmB,CACxB,EAAe,YAAD,OAAoB,CAClC,EAAe,YAAD,SAAsB,CACpC,GAAe,WAAD,KAAiB,CAC/B,GAAO,GAAD,EAAM,CACb,GAIA,eACU,CACb,SAAA,EAAwB,QAAQ,CAChC,G8CtJ2B,CsB9Tc,GpEodjC,EAAc,I8EQQ,E9ERF,YACJ,QAAQ,EAElC,eAAA,YACc,EAAe,UAAA,CAC3B,QAAA,EAAwB,UAAU,C8CtJQ,CAAA,IAAA,E9CwJtC,CAAA,qCAAA,EAAwC,EAAe,YAAD,OAAoB,CAAA,gBAAA,EAAmB,EAAe,YAAD,SAAsB,CAAA,CAAE,aAc7I,MAAM,iBAAiB,CAAqB,CAAE,CAAiB,CoE5dhC,ApE4dgC,KAEvD,EADA,AACqB,IADN,AoC1SY,AnEyTe,C+Bf3B,uBAAA,G/Be2B,OAAA,C+BdJ,C/BckB,E+Bb9D,OAAO,MAAM,EAAmB,C/BcQ,e+BdQ,CAAC,SAW7C,EoEreA,kBpEqeoB,CAAA,CAAuB,CAAkB,CAAA,OAEtC,IADN,CAAA,CoEpeU,sBpEoec,EAAE,CAAA,AACX,OAAO,CAAC,GAC5C,OAAO,MAAM,C8EkBD,C9ElBoB,CoEreD,kBAAA,CAAA,EpEsejC,CAAC,AAQD,MAAA,uBAA6B,C/BOF,CAAF,A+BP2B,CAAkB,C/BO3C,A+BP2C,CAEpE,IAAA,EADiB,AACU,C8EUb,G9EXO,CAAC,CoE3eS,sBpE2ec,EAAE,CACX,AADW,OACJ,CAAA,E/BMS,C+BHpD,EAAqB,C8ESH,G9ETO,CAAC,CoE9eD,0BpE8e4B,GAE/C,EADA,AACQ,CADR,MAAA,EAAiC,oBAAoB,EAAC,CAAE,EAAE,CAAA,CAAA,EACtC,C/BQH,EAAE,EAAE,I+BRQ,CAAC,GAAgB,EkDlVM,CkB5Jb,IpE8ec,EAAE,CAAC,EAAK,EoE9eX,CpEgfxD,GAAc,CAAC,CAAC,A/BON,E+BPQ,CAAd,AAAe,C8EQH,C9EPd,MAAM,AAAI,CoE/eG,AnGsfT,AqHtVO,KtF+UK,CAAA,SAAA,EAAY,EAAU,4BAAA,CAA8B,CAAC,CAAA,OAGhE,MAAM,EAAmB,C8EOpB,qB9EP0C,CAAC,EAAY,KAAK,CAAC,CAAA,CAAR,CAO7D,wBAAA,CACJ,IAAA,EAAqB,IAAI,CAAC,2BAA2B,UACjC,MAAM,EAAa,W/BEO,SAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,E+BD3B,GAAG,CAAC,AAAC,EAAU,CAAK,CAAH,AAAE,A/BEb,M+BFqB,EAAE,CAAC,AACnD,CADoD,AACnD,CADmD,KAQ9C,qBAAqB,CAAkB,CAAA,CAC3C,E/BFkC,AmG1fE,EpE4fpC,EAAqB,EoE3fA,EpE2fI,CAAC,2BAA2B,CoE3fD,CpE2fG,kCACX,CAAC,K8EJG,I9EW5C,UAAA,CACJ,C8EaG,G9EbG,EAAA,IAAA,CAAgB,uBAAuB,EAAE,CAAA,OACxC,MAAM,EAAS,CoEhgBN,EU6gBE,C7Gb2C,C+BAvC,GAQxB,MAAM,QAAQ,CAAqB,CAAA,CACjC,IAAA,EAAA,MAA4B,C/BJH,C+BIU,UAAU,EkD/VM,AlD+VJ,CACzC,AoEvgBwC,ApEsgBC,EACzC,MAAqB,G/BJH,C+BIO,CAAC,KoEtgBG,GpEsgBK,EAAE,CAAA,OACnC,EAAc,WAAW,EAAE,GAAK,EAAa,WAAW,EACjE,AADmE,CAClE,AAQD,AATmE,MAS7D,qBAAA,CACJ,G0FxVyD,C1FwVnD,EAAe,IAAI,CAAC,2BAA2B,EAAE,CAAA,OAEhD,C/BRmD,CAAC,A6GmBlD,C7GnBkD,I+BOzC,AACJ,MADU,A8EYJ,E9EZiB,mBAAmB,EAAE,CAAA,AAE5D,CAAC,AAMD,CkDhXC,CwC0BG,I1FsVE,oBAAA,WACqB,CAAC,C/BTH,0BAAA,U+BWhB,OADQ,AACD,EoElhBA,AsB8LA,I1FmVO,C8EWC,C9EXY,K0FpVK,U1FoVU,GAEnD,CAAC,AAYD,MAAM,qBACJ,CAAqB,C8ECY,C9EAhB,CACjB,CAAsB,CACtB,CoEjiB2C,ApEiiBf,CAAA,EoEjiBgC,KpEmiBvC,A8EHH,CAAA,EAAA,G9EGgC,CAAE,EAAE,CAAC,GoEliBC,CpEmiBhD,A/B1BM,EAAA,I+B0BI,+CAEoC,CAAE,EAAE,CAA7B,AAA8B,EACzD,CoEniB4D,ChC2MxD,CgC3M4B,GpEmiB1B,AAAI,CoEliBG,CnGygBP,AmE/TI,IgC1MG,+CpEqiBE,AACU,IADV,CAAA,GACkB,oBADU,EAAE,CAAA,AACX,OAAO,CAAC,E8ENY,I9EMN,CAAoB,CAAA,EAC/D,MAAM,C0F3WoD,C1F2WjC,IkDhYQ,EAAd,clDgY0B,CAAA,EAAY,EAAgB,YAAF,QAAsB,CAAC,CAAA,0HCliCvD,CACxC,SAAA,IAAA,qBAOY,CAAuB,CAAA,uBAER,UAAA,CAAY,EAAA,QAAA,CAAkB,EAAQ,CRvBC,KQuBK,EAAE,MAAA,CAAA,SAAgB,MAAM,gFAY3E,QAAd,UAAA,CAAc,mBAEiB,MAAA,IACrC,MAAA,AAAgB,EAClB,MAAA,MAAA,gDAIE,EAAa,EAAQ,UAAA,aACC,CAAA,UACX,CAAA,EAAA,EAAA,EAAA,CAAA,oBAKK,IAAA,CAAA,0BACqB,CAAC,wBAEH,CAAC,CoFJC,ApHmEhC,agC5D8B,GAGvC,IAAA,EAAA,IAAmB,EAAO,MAAM,CAAC,EAAA,KACQ,C6D9B+B,A9EG1B,MiB2B7B,mBAAA,CAA+B,EAAS,C6D9B+B,AMC9B,GnE6BG,EAAO,CHWC,WGXW,CAAC,MAAM,CAAC,CAAA,mCAG7D,CAE3B,EAAA,MAAA,GAAA,oBAI6D,C8BcC,CTnC9B,mBrBqBe,SAAS,CqBrB9B,AAAM,CwD6DwB,Y7EvC5B,EAAA,SAA0B,CAAC,KACZ,OAAxB,mBAAmB,CAAY,EAAa,AqBnB5C,CwB6EsC,AxB7E1B,CwB6E2B,E7C1DS,EAAO,YAAY,CAAC,SAChF,CAD0F,CAAC,CAAA,EAE1F,MAAU,qDAEb,GAAA,AAAsB,MAAtB,EAAY,MAAA,CAAgB,wBAKW,CAAC,kBAAA,aAAmB,EAAO,YAAY,CAAC,AD4FA,sBC3FlD,CAAA,EAAA,EAIX,4DAGvB,EAAA,EAAA,QAAA,GAEU,MAAA,GAAA,QAGV,MAAA,MAAA,6DAI2B,eAA2B,CAA3B,kCACS,OAAA,GAAe,CpByBI,CmDyBC,+CAAA,C/BlD8C,CAAC,CAAA,QAItE,kBAAkB,CoCXA,CpCWI,GAAmB,E8EnCA,CvC0NL,AuC1NM,S9EmCW,CAAA,EAAS,CAAA,wBACxE,6CAC4C,CyBrCa,CAAC,CzBqCL,CAAC,CAAA,YAE9C,GAAmB,MAAM,CAAA,EAAW,CkE1BL,CAAC,CAAA,ElE+BhD,IAAA,GACf,EAAA,EAHsB,EAH+D,AAG/D,CAHgE,CAAA,gBAG3B,C1BkGD,C0BlGG,CAM7D,EALsC,oBAAoB,IAM1B,IAAI,AAApC,CACD,CADS,AACT,KADQ,O6E2C6E,O7E3CzD,IAKV,IAAI,GAAkB,uEAKd,C9BwBD,a8BxBe,CAAA,A4D5Dc,CpC4IZ,UxB7ElB,IAAI,GAAA,EAAmC,IAI1D,MAAA,EAAA,cAAA,EAAA,AAA6D,MAA7D,EAA0C,eAAmB,AAAJ,CuCuM9C,AvCvMsD,EAAE,CAAC,EAKtD,EuCmMb,EvCnMa,GAHa,ChC4EuB,CAAA,EgC5EnB,EAA/B,EAAQ,CUhFyD,cVgF1C,CAAQ,ChC4EgB,CAAC,AgC5EjB,eAAA,CAAA,IAAA,GAAA,EAEC,cAAgC,EAClD,IAID,IAAI,GAAA,EAAgC,EACvD,4BAI2C,EAAI,CAAA,EAAA,CAAM,gBAAiB,CAAO,CAAE,CAAC,iBAO1D,MAAZ,OAAO,CACf,CwB6EuE,CxB5EvE,EACA,GACgB,IAAhB,CAAqB,CAAb,GAAG,CACX,CAFc,AACP,CACC,CAHU,IAGX,GAAS,CACjB,CAAA,YAID,CAAA,CAAA,CACyB,CACzB,CAA4B,CAAA,CACH,CACzB,CAAgB,CAEhB,CAA0B,CAAA,CACY,CACtC,CAAA,CACA,CrBmD2G,AqBnD/F,CrBmDgG,AqBlD5G,CwB6DkH,A7CXF,AqBlD9F,CrBmDnB,A6CUoH,AxB7DjG,CwB6DkG,A7CVrH,C6CUqH,WxB3DxG,CAAG,EACf,CkE1DC,GlE0DG,CAAA,SAAA,CAAA,EACJ,IAAA,CAAA,QAAA,CAAA,EACA,IAAA,CAAA,SAAA,CAAA,MACI,CAAC,QAAA,CAAA,0BACmB,CAAA,MACpB,CAAA,eAAA,CAAA,iCAEA,CAAA,QAAA,CAAY,8BAGW,GACzB,IAAI,CACJ,IAAI,CAAC,mBAAmB,CACxB,IAAI,CAAC,eAAe,CAAA,IAChB,CAAC,QAAQ,CACb,EACA,CADG,OACK,CACT,CAAA,aAQM,IAAA,CAAA,QAAA,CAgBT,IAAA,WAAA,8BASmB,MAAU,IAAnB,CAAA,QAAS,KACJ,CAAC,OAAA,8CAWP,IAAA,CAAK,OAAA,kDAWV,IAAI,CAAC,CrBmD+C,kBAAA,CqBnD3B,mBqCpIyD,SrCoI7B,EAAE,CACvD,EACA,IAAI,CAAC,OAAO,CACb,CAFiB,AAEjB,AAuBH,ChCmBC,A+D3CA,AoCnIA,AlG4OA,U+BjFU,CAAA,CAAA,CACT,IAAI,CAAC,QAAQ,CAAG,uBAQT,IAAA,CAAA,SAAA,8CAQ8B,GAAU,CUxMC,A6B8TA,CAAA,KvCtHM,CAAC,AwBiCN,ApDjGM,A4BgEE,C5BhEF,A4BgEC,CwBiCH,CxBjCc,QwBkC5C,GxBlCuD,CAAA,WwBkCxC,axB1BtC,OAAO,IAAA,CAAA,mBAAwB,iCAQpB,CAAA,mBAAoB,CAAA,kBAAmB,EACpD,yBAOE,OAAO,IAAI,CAAA,mBAAoB,CAAA,qBAAA,6BAQpB,CAAA,SAAU,0BASV,CAAA,eAAA,OA6BP,cAAc,EAAiC,CAAA,CAAA,CAAA,cAEtC,IAAI,CAAA,eAAgB,CAAC,aAAa,CAAA,kBAsB/C,CAAA,CAAA,CAAA,CAAA,qBAMa,6EACN,MAAA,IAAU,CAAA,eAAA,CAAiB,QAAQ,CAAC,EAAA,SAQvC,gBAAgB,CAAA,CAAA,SAelB,EAZA,GAA+B,UAA3B,OAAA,EACF,GAAI,aACe,CAAA,eAEP,MAAM,CAAA,0BAAA,EAA6B,EAAA,CAAiB,CAAC,OAK3C,IAAI,CAAC,mBAAA,CAAoB,iCAAiC,C4D9PO,CAAC,A5D8PN,CAAA,AAC9E,EAAA,IAAA,GAAmC,IAAI,CAAA,SAAU,CAAE,MAIvD,EAD6B,CqFjOG,CAAA,GlDiCE,CgC7DC,InE6PjC,OAAA,EACa,MAAA,EAAiB,oBAAA,CAAqB,GAEtC,MAAA,EAAiB,WAAW,CAAA,mCAKf,CmC/LZ,CAAA,sBAAA,CnC+LmD,CAAC,CAAA,CmC/LX,CAAC,KnCkMrD,QACA,EAAA,wBACuB,EAAM,OAAA,CAAA,QAAA,CAAA,0CAGf,OAAA,EAAA,OAAsB,CAAC,QAAQ,CAAC,cAAc,CAAC,KAGpE,CwBvCwE,CAAC,KxBuCzE,MAAA,CAAA,6BAAA,EAAgD,aAAiB,MAAQ,EAAM,OAAO,CAAC,AAAE,CAAD,KAAO,CAAC,GAAM,CAAE,CAAH,AAAI,CAAH,AAAG,AAE7G,CAAC,A6EnEA,0C7E4Ea,CAAC,mB6EhFwG,4E7EiFxG,IAAI,CAAA,eAAA,CAAiB,cAAc,21EsFhKL,CAAA","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136]}